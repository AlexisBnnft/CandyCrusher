
--- Simulation 1 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 9
Depth 3: State = 0x87ca, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x6504, Score: 12
Depth 4: State = 0x6504, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6504: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x87ca, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 15.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((0, 0), (1, 0))] = 15.0, N[0x87ca, ((0, 0), (1, 0))] = 1
Updated Q[0x6504, ((0, 1), (1, 1))] = 15.0, N[0x6504, ((0, 1), (1, 1))] = 1

--- Simulation 2 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [15.0, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 3
Depth 1: State = 0x87ca, Legal Moves = [((0, 5), (1, 5)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87ca, Score: 6
Depth 2: State = 0x87ca, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x6603, Score: 9
Depth 3: State = 0x6603, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6603: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x6603, Score: 12
Depth 4: State = 0x6603, Legal Moves = [((2, 1), (3, 1)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6603: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x6658, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((0, 5), (1, 5))] = 15.0, N[0x87ca, ((0, 5), (1, 5))] = 1
Updated Q[0x87ca, ((1, 2), (2, 2))] = 15.0, N[0x87ca, ((1, 2), (2, 2))] = 1
Updated Q[0x6603, ((1, 0), (1, 1))] = 15.0, N[0x6603, ((1, 0), (1, 1))] = 1
Updated Q[0x6603, ((2, 1), (3, 1))] = 15.0, N[0x6603, ((2, 1), (3, 1))] = 1

--- Simulation 3 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [15.832554611157697, 15.832554611157697, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (1, 6))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 12
Depth 3: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 3), (4, 3)), ((3, 5), (4, 5)), ((4, 2), (4, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x22ca, Score: 15
Depth 4: State = 0x22ca, Legal Moves = [((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 3), (4, 3)), ((3, 5), (4, 5)), ((4, 2), (4, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x22ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0x22ca, Score: 18
End of simulation with depth 5. Reward (Score): 18
Updated Q[0x87cd, ((1, 5), (1, 6))] = 18.0, N[0x87cd, ((1, 5), (1, 6))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 18.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 18.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 18.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0x22ca, ((1, 4), (1, 5))] = 18.0, N[0x22ca, ((1, 4), (1, 5))] = 1

--- Simulation 4 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.048147073968206, 16.048147073968206, 19.048147073968206, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0xc9b0, Score: 9
Depth 1: State = 0xc9b0, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (0, 5)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xc9b0: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x6557, Score: 12
Depth 2: State = 0x6557, Legal Moves = [((0, 4), (0, 5)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6557: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x6557, Score: 15
Depth 3: State = 0x6557, Legal Moves = [((1, 4), (2, 4)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6557: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x6557, Score: 18
Depth 4: State = 0x6557, Legal Moves = [((0, 3), (1, 3)), ((1, 4), (1, 5)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((3, 2), (3, 3)), ((3, 5), (4, 5)), ((3, 6), (3, 7)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6557: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x6556, Score: 24
End of simulation with depth 5. Reward (Score): 24
Updated Q[0x87cd, ((2, 2), (2, 3))] = 24.0, N[0x87cd, ((2, 2), (2, 3))] = 1
Updated Q[0xc9b0, ((0, 1), (1, 1))] = 24.0, N[0xc9b0, ((0, 1), (1, 1))] = 1
Updated Q[0x6557, ((0, 4), (0, 5))] = 24.0, N[0x6557, ((0, 4), (0, 5))] = 1
Updated Q[0x6557, ((1, 4), (2, 4))] = 24.0, N[0x6557, ((1, 4), (2, 4))] = 1
Updated Q[0x6557, ((0, 3), (1, 3))] = 24.0, N[0x6557, ((0, 3), (1, 3))] = 1

--- Simulation 5 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.177410022515474, 16.177410022515474, 19.177410022515474, 25.177410022515474, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((3, 5), (4, 5))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x2323, Score: 9
Depth 3: State = 0x2323, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 0), (2, 1)), ((2, 5), (2, 6)), ((3, 6), (3, 7)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2323: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x221e, Score: 12
Depth 4: State = 0x221e, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 0), (2, 1)), ((2, 5), (2, 6)), ((3, 6), (3, 7)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x221e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x22c9, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((3, 5), (4, 5))] = 15.0, N[0x87cd, ((3, 5), (4, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 15.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x2323, ((0, 1), (1, 1))] = 15.0, N[0x2323, ((0, 1), (1, 1))] = 1
Updated Q[0x221e, ((1, 0), (1, 1))] = 15.0, N[0x221e, ((1, 0), (1, 1))] = 1

--- Simulation 6 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.268636241179518, 16.268636241179518, 19.268636241179518, 25.268636241179518, 16.268636241179518, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 3), (4, 4))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x87cb, Score: 6
Depth 2: State = 0x87cb, Legal Moves = [((0, 5), (1, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cb, Score: 9
Depth 3: State = 0x87cb, Legal Moves = [((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((3, 5), (4, 5)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (1, 6))
New board state after move: 0x87cb, Score: 12
Depth 4: State = 0x87cb, Legal Moves = [((2, 2), (2, 3)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x6501, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((4, 3), (4, 4))] = 19.0, N[0x87cd, ((4, 3), (4, 4))] = 1
Updated Q[0x87cd, ((0, 2), (1, 2))] = 19.0, N[0x87cd, ((0, 2), (1, 2))] = 1
Updated Q[0x87cb, ((0, 5), (1, 5))] = 19.0, N[0x87cb, ((0, 5), (1, 5))] = 1
Updated Q[0x87cb, ((1, 5), (1, 6))] = 19.0, N[0x87cb, ((1, 5), (1, 6))] = 1
Updated Q[0x87cb, ((2, 2), (2, 3))] = 19.0, N[0x87cb, ((2, 2), (2, 3))] = 1

--- Simulation 7 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.33856619904585, 16.33856619904585, 19.33856619904585, 25.33856619904585, 16.33856619904585, 20.33856619904585, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 4), (4, 5))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((3, 7), (4, 7)), ((4, 2), (5, 2)), ((4, 4), (5, 4)), ((4, 5), (5, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (6, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((3, 7), (4, 7)), ((4, 2), (5, 2)), ((4, 4), (5, 4)), ((4, 5), (5, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (6, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 12
Depth 3: State = 0x87c9, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((3, 7), (4, 7)), ((4, 2), (5, 2)), ((4, 4), (5, 4)), ((4, 5), (5, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (6, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xa7e4, Score: 16
Depth 4: State = 0xa7e4, Legal Moves = [((1, 0), (1, 1)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((3, 7), (4, 7)), ((4, 2), (5, 2)), ((4, 4), (5, 4)), ((4, 5), (5, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (6, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa7e4: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0xa78f, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((4, 4), (4, 5))] = 19.0, N[0x87cd, ((4, 4), (4, 5))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 19.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 2), (2, 2))] = 19.0, N[0x87c9, ((1, 2), (2, 2))] = 1
Updated Q[0xa7e4, ((1, 0), (1, 1))] = 19.0, N[0xa7e4, ((1, 0), (1, 1))] = 1

--- Simulation 8 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.39495883417946, 16.39495883417946, 19.39495883417946, 25.39495883417946, 16.39495883417946, 20.39495883417946, 20.39495883417946, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 6), (5, 6))
New board state after move: 0x87cd, Score: 4
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 7
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 4), (3, 5)), ((3, 5), (3, 6)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 10
Depth 3: State = 0x87cd, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 4), (3, 5)), ((3, 5), (3, 6)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x2374, Score: 13
Depth 4: State = 0x2374, Legal Moves = [((0, 0), (0, 1)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 4), (3, 5)), ((3, 5), (3, 6)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2374: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0xca06, Score: 16
End of simulation with depth 5. Reward (Score): 16
Updated Q[0x87cd, ((4, 6), (5, 6))] = 16.0, N[0x87cd, ((4, 6), (5, 6))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 16.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 16.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 0), (1, 0))] = 16.0, N[0x87cd, ((0, 0), (1, 0))] = 1
Updated Q[0x2374, ((0, 0), (0, 1))] = 16.0, N[0x2374, ((0, 0), (0, 1))] = 1

--- Simulation 9 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.442026886600882, 16.442026886600882, 19.442026886600882, 25.442026886600882, 16.442026886600882, 20.442026886600882, 20.442026886600882, 17.442026886600882, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 6), (4, 7))
New board state after move: 0x87cd, Score: 6
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 9
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 4), (3, 5)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 12
Depth 3: State = 0x87cd, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 4), (3, 5)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0xc9af, Score: 15
Depth 4: State = 0xc9af, Legal Moves = [((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 4), (3, 5)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xc9af: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 6), (2, 6))
New board state after move: 0xc9af, Score: 18
End of simulation with depth 5. Reward (Score): 18
Updated Q[0x87cd, ((4, 6), (4, 7))] = 18.0, N[0x87cd, ((4, 6), (4, 7))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 18.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 18.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 0), (1, 0))] = 18.0, N[0x87cd, ((0, 0), (1, 0))] = 1
Updated Q[0xc9af, ((1, 6), (2, 6))] = 18.0, N[0xc9af, ((1, 6), (2, 6))] = 1

--- Simulation 10 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.48230380736751, 16.48230380736751, 19.48230380736751, 25.48230380736751, 16.48230380736751, 20.48230380736751, 20.48230380736751, 17.48230380736751, 19.48230380736751, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 7), (5, 7))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 3), (4, 4)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 10
Depth 2: State = 0x87c9, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 3), (4, 4)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87c9, Score: 13
Depth 3: State = 0x87c9, Legal Moves = [((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 7), (3, 8)), ((4, 3), (4, 4)), ((4, 5), (4, 6)), ((5, 1), (5, 2)), ((5, 5), (5, 6)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x4393, Score: 22
Depth 4: State = 0x4393, Legal Moves = [((0, 3), (1, 3)), ((0, 3), (0, 4)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((3, 3), (4, 3)), ((3, 7), (3, 8)), ((4, 5), (4, 6)), ((5, 5), (5, 6)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x4393: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4393, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((4, 7), (5, 7))] = 25.0, N[0x87cd, ((4, 7), (5, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 5), (2, 5))] = 25.0, N[0x87c9, ((1, 5), (2, 5))] = 1
Updated Q[0x87c9, ((2, 2), (2, 3))] = 25.0, N[0x87c9, ((2, 2), (2, 3))] = 1
Updated Q[0x4393, ((0, 3), (1, 3))] = 25.0, N[0x4393, ((0, 3), (1, 3))] = 1

--- Simulation 11 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.517427129385148, 16.517427129385148, 19.517427129385148, 25.517427129385148, 16.517427129385148, 20.517427129385148, 20.517427129385148, 17.517427129385148, 19.517427129385148, 26.517427129385148, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((5, 1), (5, 2))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 1), (4, 1)), ((3, 2), (4, 2)), ((3, 5), (4, 5)), ((4, 1), (5, 1)), ((4, 1), (4, 2)), ((4, 2), (5, 2)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((2, 2), (2, 3)), ((2, 7), (2, 8)), ((3, 1), (4, 1)), ((3, 2), (4, 2)), ((3, 5), (4, 5)), ((4, 1), (5, 1)), ((4, 1), (4, 2)), ((4, 2), (5, 2)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x6602, Score: 9
Depth 3: State = 0x6602, Legal Moves = [((1, 3), (2, 3)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 1), (4, 1)), ((3, 2), (4, 2)), ((3, 5), (4, 5)), ((4, 1), (5, 1)), ((4, 1), (4, 2)), ((4, 2), (5, 2)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6602: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x64ad, Score: 12
Depth 4: State = 0x64ad, Legal Moves = [((0, 1), (1, 1)), ((1, 1), (1, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 1), (4, 1)), ((3, 1), (3, 2)), ((3, 2), (4, 2)), ((3, 5), (4, 5)), ((4, 1), (5, 1)), ((4, 1), (4, 2)), ((4, 2), (5, 2)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x64ad: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x655b, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((5, 1), (5, 2))] = 15.0, N[0x87cd, ((5, 1), (5, 2))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((2, 2), (2, 3))] = 15.0, N[0x87cd, ((2, 2), (2, 3))] = 1
Updated Q[0x6602, ((1, 3), (2, 3))] = 15.0, N[0x6602, ((1, 3), (2, 3))] = 1
Updated Q[0x64ad, ((0, 1), (1, 1))] = 15.0, N[0x64ad, ((0, 1), (1, 1))] = 1

--- Simulation 12 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.548513891703386, 16.548513891703386, 19.548513891703386, 25.548513891703386, 16.548513891703386, 20.548513891703386, 20.548513891703386, 17.548513891703386, 19.548513891703386, 26.548513891703386, 16.548513891703386, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 5), (0, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xca06, Score: 22
Depth 4: State = 0xca06, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xca06: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x86c9, Score: 31
End of simulation with depth 5. Reward (Score): 31
Updated Q[0x87cd, ((5, 3), (5, 4))] = 31.0, N[0x87cd, ((5, 3), (5, 4))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 31.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 31.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 31.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xca06, ((0, 1), (1, 1))] = 31.0, N[0xca06, ((0, 1), (1, 1))] = 1

--- Simulation 13 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.576358667876065, 16.576358667876065, 19.576358667876065, 25.576358667876065, 16.576358667876065, 20.576358667876065, 20.576358667876065, 17.576358667876065, 19.576358667876065, 26.576358667876065, 16.576358667876065, 32.576358667876065, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((5, 4), (5, 5))
New board state after move: 0x87c9, Score: 6
Depth 1: State = 0x87c9, Legal Moves = [((0, 2), (1, 2)), ((0, 4), (1, 4)), ((0, 5), (1, 5)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (3, 2)), ((2, 5), (2, 6)), ((3, 2), (3, 3)), ((3, 5), (3, 6)), ((3, 6), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (7, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x87cb, Score: 9
Depth 2: State = 0x87cb, Legal Moves = [((0, 3), (1, 3)), ((0, 5), (1, 5)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (3, 2)), ((2, 5), (2, 6)), ((3, 2), (3, 3)), ((3, 5), (3, 6)), ((3, 6), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (7, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x86ca, Score: 12
Depth 3: State = 0x86ca, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 5), (2, 6)), ((3, 2), (3, 3)), ((3, 5), (3, 6)), ((3, 6), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (7, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x86ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x86ca, Score: 15
Depth 4: State = 0x86ca, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (2, 2)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((3, 5), (3, 6)), ((3, 6), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (7, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x86ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x8720, Score: 21
End of simulation with depth 5. Reward (Score): 21
Updated Q[0x87cd, ((5, 4), (5, 5))] = 21.0, N[0x87cd, ((5, 4), (5, 5))] = 1
Updated Q[0x87c9, ((0, 2), (1, 2))] = 21.0, N[0x87c9, ((0, 2), (1, 2))] = 1
Updated Q[0x87cb, ((0, 3), (1, 3))] = 21.0, N[0x87cb, ((0, 3), (1, 3))] = 1
Updated Q[0x86ca, ((0, 5), (1, 5))] = 21.0, N[0x86ca, ((0, 5), (1, 5))] = 1
Updated Q[0x86ca, ((1, 1), (1, 2))] = 21.0, N[0x86ca, ((1, 1), (1, 2))] = 1

--- Simulation 14 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.601545927365663, 16.601545927365663, 19.601545927365663, 25.601545927365663, 16.601545927365663, 20.601545927365663, 20.601545927365663, 17.601545927365663, 19.601545927365663, 26.601545927365663, 16.601545927365663, 32.60154592736566, 22.601545927365663, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((5, 6), (6, 6))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 4), (4, 4)), ((3, 7), (4, 7)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 4), (4, 4)), ((3, 7), (4, 7)), ((3, 7), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 9
Depth 3: State = 0x87cd, Legal Moves = [((1, 0), (1, 1)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 4), (4, 4)), ((3, 7), (4, 7)), ((3, 7), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x871e, Score: 12
Depth 4: State = 0x871e, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (1, 3)), ((1, 6), (1, 7)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 4), (4, 4)), ((3, 7), (4, 7)), ((3, 7), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x871e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x871f, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((5, 6), (6, 6))] = 15.0, N[0x87cd, ((5, 6), (6, 6))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 0), (1, 1))] = 15.0, N[0x87cd, ((1, 0), (1, 1))] = 1
Updated Q[0x871e, ((0, 2), (0, 3))] = 15.0, N[0x871e, ((0, 2), (0, 3))] = 1

--- Simulation 15 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.624517568269194, 16.624517568269194, 19.624517568269194, 25.624517568269194, 16.624517568269194, 20.624517568269194, 20.624517568269194, 17.624517568269194, 19.624517568269194, 26.624517568269194, 16.624517568269194, 32.6245175682692, 22.624517568269194, 16.624517568269194, inf, inf, inf, inf, inf, inf]
Selected move: ((5, 6), (5, 7))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 7), (6, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (7, 6)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 7), (6, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (7, 6)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 9
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 7), (6, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (7, 6)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 12
Depth 4: State = 0x87c9, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 7), (6, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (7, 6)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0xca03, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((5, 6), (5, 7))] = 15.0, N[0x87cd, ((5, 6), (5, 7))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 15.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((0, 0), (1, 0))] = 15.0, N[0x87c9, ((0, 0), (1, 0))] = 1

--- Simulation 16 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.645615447515674, 16.645615447515674, 19.645615447515674, 25.645615447515674, 16.645615447515674, 20.645615447515674, 20.645615447515674, 17.645615447515674, 19.645615447515674, 26.645615447515674, 16.645615447515674, 32.645615447515674, 22.645615447515674, 16.645615447515674, 16.645615447515674, inf, inf, inf, inf, inf]
Selected move: ((5, 8), (5, 9))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 9
Depth 3: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0xc9b0, Score: 12
Depth 4: State = 0xc9b0, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xc9b0: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x87cb, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((5, 8), (5, 9))] = 15.0, N[0x87cd, ((5, 8), (5, 9))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 15.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0xc9b0, ((0, 1), (1, 1))] = 15.0, N[0xc9b0, ((0, 1), (1, 1))] = 1

--- Simulation 17 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.665109222315394, 16.665109222315394, 19.665109222315394, 25.665109222315394, 16.665109222315394, 20.665109222315394, 20.665109222315394, 17.665109222315394, 19.665109222315394, 26.665109222315394, 16.665109222315394, 32.665109222315394, 22.665109222315394, 16.665109222315394, 16.665109222315394, 16.665109222315394, inf, inf, inf, inf]
Selected move: ((6, 1), (7, 1))
New board state after move: 0x8676, Score: 3
Depth 1: State = 0x8676, Legal Moves = [((0, 5), (1, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (6, 1)), ((5, 2), (6, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 2), (8, 2)), ((8, 2), (9, 2)), ((8, 3), (9, 3))]
UCB1 values for moves at state 0x8676: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x8676, Score: 6
Depth 2: State = 0x8676, Legal Moves = [((1, 2), (1, 3)), ((1, 6), (1, 7)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (6, 1)), ((5, 2), (6, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 2), (8, 2)), ((8, 2), (9, 2)), ((8, 3), (9, 3))]
UCB1 values for moves at state 0x8676: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x8676, Score: 9
Depth 3: State = 0x8676, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((0, 2), (0, 3)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (6, 1)), ((5, 2), (6, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 2), (8, 2)), ((8, 2), (9, 2)), ((8, 3), (9, 3))]
UCB1 values for moves at state 0x8676: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x65ae, Score: 12
Depth 4: State = 0x65ae, Legal Moves = [((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (6, 1)), ((5, 2), (6, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 2), (8, 2)), ((8, 2), (9, 2)), ((8, 3), (9, 3))]
UCB1 values for moves at state 0x65ae: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x22cd, Score: 18
End of simulation with depth 5. Reward (Score): 18
Updated Q[0x87cd, ((6, 1), (7, 1))] = 18.0, N[0x87cd, ((6, 1), (7, 1))] = 1
Updated Q[0x8676, ((0, 5), (1, 5))] = 18.0, N[0x8676, ((0, 5), (1, 5))] = 1
Updated Q[0x8676, ((1, 2), (1, 3))] = 18.0, N[0x8676, ((1, 2), (1, 3))] = 1
Updated Q[0x8676, ((0, 1), (1, 1))] = 18.0, N[0x8676, ((0, 1), (1, 1))] = 1
Updated Q[0x65ae, ((2, 1), (2, 2))] = 18.0, N[0x65ae, ((2, 1), (2, 2))] = 1

--- Simulation 18 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.68321518055661, 16.68321518055661, 19.68321518055661, 25.68321518055661, 16.68321518055661, 20.68321518055661, 20.68321518055661, 17.68321518055661, 19.68321518055661, 26.68321518055661, 16.68321518055661, 32.68321518055661, 22.68321518055661, 16.68321518055661, 16.68321518055661, 16.68321518055661, 19.68321518055661, inf, inf, inf]
Selected move: ((6, 4), (6, 5))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 5), (1, 6)), ((2, 2), (3, 2)), ((3, 2), (3, 3)), ((3, 6), (4, 6)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (7, 1)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 6), (1, 7)), ((2, 2), (3, 2)), ((2, 4), (2, 5)), ((3, 6), (4, 6)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (7, 1)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 9
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((2, 2), (3, 2)), ((3, 6), (4, 6)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (7, 1)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 12
Depth 4: State = 0x87cd, Legal Moves = [((2, 2), (3, 2)), ((3, 6), (4, 6)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (7, 1)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x665a, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((6, 4), (6, 5))] = 15.0, N[0x87cd, ((6, 4), (6, 5))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 15.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 4), (1, 4))] = 15.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((2, 2), (3, 2))] = 15.0, N[0x87cd, ((2, 2), (3, 2))] = 1

--- Simulation 19 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.70010933704164, 16.70010933704164, 19.70010933704164, 25.70010933704164, 16.70010933704164, 20.70010933704164, 20.70010933704164, 17.70010933704164, 19.70010933704164, 26.70010933704164, 16.70010933704164, 32.70010933704164, 22.70010933704164, 16.70010933704164, 16.70010933704164, 16.70010933704164, 19.70010933704164, 16.70010933704164, inf, inf]
Selected move: ((6, 7), (6, 8))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 9
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xcaae, Score: 21
Depth 3: State = 0xcaae, Legal Moves = [((1, 4), (1, 5)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 4), (2, 5)), ((2, 7), (2, 8)), ((3, 4), (4, 4)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0xcaae: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0xcaae, Score: 24
Depth 4: State = 0xcaae, Legal Moves = [((1, 6), (1, 7)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 7), (2, 8)), ((3, 4), (4, 4)), ((3, 4), (3, 5)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0xcaae: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 6), (1, 7))
New board state after move: 0xcaae, Score: 27
End of simulation with depth 5. Reward (Score): 27
Updated Q[0x87cd, ((6, 7), (6, 8))] = 27.0, N[0x87cd, ((6, 7), (6, 8))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 27.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 27.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xcaae, ((1, 4), (1, 5))] = 27.0, N[0xcaae, ((1, 4), (1, 5))] = 1
Updated Q[0xcaae, ((1, 6), (1, 7))] = 27.0, N[0xcaae, ((1, 6), (1, 7))] = 1

--- Simulation 20 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.71593676432625, 16.71593676432625, 19.71593676432625, 25.71593676432625, 16.71593676432625, 20.71593676432625, 20.71593676432625, 17.71593676432625, 19.71593676432625, 26.71593676432625, 16.71593676432625, 32.71593676432625, 22.71593676432625, 16.71593676432625, 16.71593676432625, 16.71593676432625, 19.71593676432625, 16.71593676432625, 28.71593676432625, inf]
Selected move: ((7, 3), (8, 3))
New board state after move: 0x861e, Score: 3
Depth 1: State = 0x861e, Legal Moves = [((0, 5), (1, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (6, 2)), ((6, 7), (6, 8)), ((8, 2), (9, 2))]
UCB1 values for moves at state 0x861e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x861e, Score: 6
Depth 2: State = 0x861e, Legal Moves = [((1, 6), (1, 7)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (6, 2)), ((6, 7), (6, 8)), ((8, 2), (9, 2))]
UCB1 values for moves at state 0x861e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 6), (1, 7))
New board state after move: 0x861e, Score: 9
Depth 3: State = 0x861e, Legal Moves = [((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((4, 4), (4, 5)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (6, 2)), ((6, 7), (6, 8)), ((8, 2), (9, 2))]
UCB1 values for moves at state 0x861e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (1, 6))
New board state after move: 0x861e, Score: 12
Depth 4: State = 0x861e, Legal Moves = [((0, 3), (1, 3)), ((1, 8), (1, 9)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 4), (4, 4)), ((3, 5), (4, 5)), ((3, 6), (4, 6)), ((4, 4), (4, 5)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (6, 2)), ((6, 7), (6, 8)), ((8, 2), (9, 2))]
UCB1 values for moves at state 0x861e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x861e, Score: 18
End of simulation with depth 5. Reward (Score): 18
Updated Q[0x87cd, ((7, 3), (8, 3))] = 18.0, N[0x87cd, ((7, 3), (8, 3))] = 1
Updated Q[0x861e, ((0, 5), (1, 5))] = 18.0, N[0x861e, ((0, 5), (1, 5))] = 1
Updated Q[0x861e, ((1, 6), (1, 7))] = 18.0, N[0x861e, ((1, 6), (1, 7))] = 1
Updated Q[0x861e, ((1, 5), (1, 6))] = 18.0, N[0x861e, ((1, 5), (1, 6))] = 1
Updated Q[0x861e, ((0, 3), (1, 3))] = 18.0, N[0x861e, ((0, 3), (1, 3))] = 1

--- Simulation 21 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.730818382602287, 16.730818382602287, 19.730818382602287, 25.730818382602287, 16.730818382602287, 20.730818382602287, 20.730818382602287, 17.730818382602287, 19.730818382602287, 26.730818382602287, 16.730818382602287, 32.73081838260229, 22.730818382602287, 16.730818382602287, 16.730818382602287, 16.730818382602287, 19.730818382602287, 16.730818382602287, 28.730818382602287, 19.730818382602287]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 22
Depth 4: State = 0x87c9, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xc9ac, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.0, N[0x87cd, ((5, 3), (5, 4))] = 2
Updated Q[0x87cd, ((0, 7), (1, 7))] = 25.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((0, 7), (0, 8))] = 25.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 2), (2, 2))] = 25.0, N[0x87c9, ((1, 2), (2, 2))] = 1

--- Simulation 22 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.744855993405594, 16.744855993405594, 19.744855993405594, 25.744855993405594, 16.744855993405594, 20.744855993405594, 20.744855993405594, 17.744855993405594, 19.744855993405594, 26.744855993405594, 16.744855993405594, 29.233799505131085, 22.744855993405594, 16.744855993405594, 16.744855993405594, 16.744855993405594, 19.744855993405594, 16.744855993405594, 28.744855993405594, 19.744855993405594]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((3, 6), (4, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xa891, Score: 16
Depth 3: State = 0xa891, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa891: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0xa891, Score: 19
Depth 4: State = 0xa891, Legal Moves = [((1, 5), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa891: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0xa891, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.0, N[0x87cd, ((5, 3), (5, 4))] = 3
Updated Q[0x87cd, ((0, 5), (0, 6))] = 22.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xa891, ((0, 1), (1, 1))] = 22.0, N[0xa891, ((0, 1), (1, 1))] = 1
Updated Q[0xa891, ((1, 5), (2, 5))] = 22.0, N[0xa891, ((1, 5), (2, 5))] = 1

--- Simulation 23 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.7581360736184, 16.7581360736184, 19.7581360736184, 25.7581360736184, 16.7581360736184, 20.7581360736184, 20.7581360736184, 17.7581360736184, 19.7581360736184, 26.7581360736184, 16.7581360736184, 27.015060335375573, 22.7581360736184, 16.7581360736184, 16.7581360736184, 16.7581360736184, 19.7581360736184, 16.7581360736184, 28.7581360736184, 19.7581360736184]
Selected move: ((6, 7), (6, 8))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 12
Depth 3: State = 0x87cb, Legal Moves = [((2, 2), (2, 3)), ((3, 2), (4, 2)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x8673, Score: 18
Depth 4: State = 0x8673, Legal Moves = [((0, 2), (1, 2)), ((1, 0), (1, 1)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x8673: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x8674, Score: 21
End of simulation with depth 5. Reward (Score): 21
Updated Q[0x87cd, ((6, 7), (6, 8))] = 24.0, N[0x87cd, ((6, 7), (6, 8))] = 2
Updated Q[0x87cd, ((0, 5), (1, 5))] = 21.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 21.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((2, 2), (2, 3))] = 21.0, N[0x87cb, ((2, 2), (2, 3))] = 1
Updated Q[0x8673, ((0, 2), (1, 2))] = 21.0, N[0x8673, ((0, 2), (1, 2))] = 1

--- Simulation 24 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.7707326777154, 16.7707326777154, 19.7707326777154, 25.7707326777154, 16.7707326777154, 20.7707326777154, 20.7707326777154, 17.7707326777154, 19.7707326777154, 26.7707326777154, 16.7707326777154, 27.02233298814185, 22.7707326777154, 16.7707326777154, 16.7707326777154, 16.7707326777154, 19.7707326777154, 16.7707326777154, 25.25209708408117, 19.7707326777154]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 25
Depth 3: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 31
Depth 4: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 34
End of simulation with depth 5. Reward (Score): 34
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.0, N[0x87cd, ((5, 3), (5, 4))] = 4
Updated Q[0x87cd, ((0, 4), (1, 4))] = 34.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 34.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 34.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 34.0, N[0x87cd, ((0, 6), (1, 6))] = 1

--- Simulation 25 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.782709687623857, 16.782709687623857, 19.782709687623857, 25.782709687623857, 16.782709687623857, 20.782709687623857, 20.782709687623857, 17.782709687623857, 19.782709687623857, 26.782709687623857, 16.782709687623857, 28.89135484381193, 22.782709687623857, 16.782709687623857, 16.782709687623857, 16.782709687623857, 19.782709687623857, 16.782709687623857, 25.26056610900578, 19.782709687623857]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xa83d, Score: 19
Depth 3: State = 0xa83d, Legal Moves = [((1, 0), (1, 1)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa83d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0xa93e, Score: 22
Depth 4: State = 0xa93e, Legal Moves = [((0, 1), (1, 1)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa93e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x86c8, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.4, N[0x87cd, ((5, 3), (5, 4))] = 5
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 25.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0xa83d, ((1, 0), (1, 1))] = 25.0, N[0xa83d, ((1, 0), (1, 1))] = 1
Updated Q[0xa93e, ((0, 1), (1, 1))] = 25.0, N[0xa93e, ((0, 1), (1, 1))] = 1

--- Simulation 26 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.794122577994102, 16.794122577994102, 19.794122577994102, 25.794122577994102, 16.794122577994102, 20.794122577994102, 20.794122577994102, 17.794122577994102, 19.794122577994102, 26.794122577994102, 16.794122577994102, 28.202356008872393, 22.794122577994102, 16.794122577994102, 16.794122577994102, 16.794122577994102, 19.794122577994102, 16.794122577994102, 25.268636241179518, 19.794122577994102]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 10
Depth 2: State = 0x87c9, Legal Moves = [((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 16
Depth 4: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 6), (1, 7)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x871e, Score: 42
End of simulation with depth 5. Reward (Score): 42
Updated Q[0x87cd, ((5, 3), (5, 4))] = 29.833333333333332, N[0x87cd, ((5, 3), (5, 4))] = 6
Updated Q[0x87cd, ((1, 1), (1, 2))] = 42.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 2), (2, 2))] = 42.0, N[0x87c9, ((1, 2), (2, 2))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 42.0, N[0x87cd, ((1, 5), (2, 5))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 42.0, N[0x87cd, ((0, 3), (1, 3))] = 1

--- Simulation 27 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.80501981651767, 16.80501981651767, 19.80501981651767, 25.80501981651767, 16.80501981651767, 20.80501981651767, 20.80501981651767, 17.80501981651767, 19.80501981651767, 26.80501981651767, 16.80501981651767, 30.570229587680068, 22.80501981651767, 16.80501981651767, 16.80501981651767, 16.80501981651767, 19.80501981651767, 16.80501981651767, 25.27634175243574, 19.80501981651767]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x8673, Score: 13
Depth 3: State = 0x8673, Legal Moves = [((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8673: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x8674, Score: 16
Depth 4: State = 0x8674, Legal Moves = [((0, 3), (0, 4)), ((0, 4), (1, 4)), ((0, 5), (1, 5)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8674: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x8673, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 29.571428571428573, N[0x87cd, ((5, 3), (5, 4))] = 7
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 0), (1, 1))] = 28.0, N[0x87cd, ((1, 0), (1, 1))] = 1
Updated Q[0x8673, ((0, 3), (1, 3))] = 28.0, N[0x8673, ((0, 3), (1, 3))] = 1
Updated Q[0x8674, ((0, 3), (0, 4))] = 28.0, N[0x8674, ((0, 3), (0, 4))] = 1

--- Simulation 28 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.815443985917586, 16.815443985917586, 19.815443985917586, 25.815443985917586, 16.815443985917586, 20.815443985917586, 20.815443985917586, 17.815443985917586, 19.815443985917586, 26.815443985917586, 16.815443985917586, 30.257601900843685, 22.815443985917586, 16.815443985917586, 16.815443985917586, 16.815443985917586, 19.815443985917586, 16.815443985917586, 25.28371275330666, 19.815443985917586]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 16
Depth 3: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x6659, Score: 19
Depth 4: State = 0x6659, Legal Moves = [((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6659: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 6), (2, 6))
New board state after move: 0x6659, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 29.375, N[0x87cd, ((5, 3), (5, 4))] = 8
Updated Q[0x87cd, ((0, 5), (1, 5))] = 28.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 28.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0x6659, ((1, 6), (2, 6))] = 28.0, N[0x6659, ((1, 6), (2, 6))] = 1

--- Simulation 29 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.82543269122014, 16.82543269122014, 19.82543269122014, 25.82543269122014, 16.82543269122014, 20.82543269122014, 20.82543269122014, 17.82543269122014, 19.82543269122014, 26.82543269122014, 16.82543269122014, 30.020387917280686, 22.82543269122014, 16.82543269122014, 16.82543269122014, 16.82543269122014, 19.82543269122014, 16.82543269122014, 25.29077583456137, 19.82543269122014]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x8778, Score: 16
Depth 2: State = 0x8778, Legal Moves = [((1, 0), (1, 1)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8778: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x8677, Score: 19
Depth 3: State = 0x8677, Legal Moves = [((1, 4), (1, 5)), ((1, 5), (2, 5)), ((4, 0), (4, 1)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8677: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0x8677, Score: 22
Depth 4: State = 0x8677, Legal Moves = [((4, 0), (4, 1)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8677: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 0), (4, 1))
New board state after move: 0x231f, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 29.22222222222222, N[0x87cd, ((5, 3), (5, 4))] = 9
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x8778, ((1, 0), (1, 1))] = 28.0, N[0x8778, ((1, 0), (1, 1))] = 1
Updated Q[0x8677, ((1, 4), (1, 5))] = 28.0, N[0x8677, ((1, 4), (1, 5))] = 1
Updated Q[0x8677, ((4, 0), (4, 1))] = 28.0, N[0x8677, ((4, 0), (4, 1))] = 1

--- Simulation 30 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.835019299622342, 16.835019299622342, 19.835019299622342, 25.835019299622342, 16.835019299622342, 20.835019299622342, 20.835019299622342, 17.835019299622342, 19.835019299622342, 26.835019299622342, 16.835019299622342, 29.833895322096335, 22.835019299622342, 16.835019299622342, 16.835019299622342, 16.835019299622342, 19.835019299622342, 16.835019299622342, 25.29755459037115, 19.835019299622342]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x21ca, Score: 22
Depth 2: State = 0x21ca, Legal Moves = [((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x21ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x21ca, Score: 25
Depth 3: State = 0x21ca, Legal Moves = [((0, 4), (0, 5)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x21ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x21ca, Score: 28
Depth 4: State = 0x21ca, Legal Moves = [((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x21ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x2276, Score: 31
End of simulation with depth 5. Reward (Score): 31
Updated Q[0x87cd, ((5, 3), (5, 4))] = 29.4, N[0x87cd, ((5, 3), (5, 4))] = 10
Updated Q[0x87cd, ((1, 1), (1, 2))] = 31.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x21ca, ((0, 3), (0, 4))] = 31.0, N[0x21ca, ((0, 3), (0, 4))] = 1
Updated Q[0x21ca, ((0, 4), (0, 5))] = 31.0, N[0x21ca, ((0, 4), (0, 5))] = 1
Updated Q[0x21ca, ((1, 0), (1, 1))] = 31.0, N[0x21ca, ((1, 0), (1, 1))] = 1

--- Simulation 31 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.844233548567576, 16.844233548567576, 19.844233548567576, 25.844233548567576, 16.844233548567576, 20.844233548567576, 20.844233548567576, 17.844233548567576, 19.844233548567576, 26.844233548567576, 16.844233548567576, 29.983197855076828, 22.844233548567576, 16.844233548567576, 16.844233548567576, 16.844233548567576, 19.844233548567576, 16.844233548567576, 25.30407004828386, 19.844233548567576]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 10
Depth 2: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x44e6, Score: 13
Depth 3: State = 0x44e6, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x44e6: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x44e6, Score: 16
Depth 4: State = 0x44e6, Legal Moves = [((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x44e6: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0xca02, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.454545454545453, N[0x87cd, ((5, 3), (5, 4))] = 11
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 19.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0x44e6, ((1, 5), (2, 5))] = 19.0, N[0x44e6, ((1, 5), (2, 5))] = 1
Updated Q[0x44e6, ((2, 2), (3, 2))] = 19.0, N[0x44e6, ((2, 2), (3, 2))] = 1

--- Simulation 32 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.853102049128744, 16.853102049128744, 19.853102049128744, 25.853102049128744, 16.853102049128744, 20.853102049128744, 20.853102049128744, 17.853102049128744, 19.853102049128744, 26.853102049128744, 16.853102049128744, 29.013276745018068, 22.853102049128744, 16.853102049128744, 16.853102049128744, 16.853102049128744, 19.853102049128744, 16.853102049128744, 25.31034102516962, 19.853102049128744]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 13
Depth 2: State = 0x87c9, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x64af, Score: 16
Depth 3: State = 0x64af, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x64af: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x665b, Score: 19
Depth 4: State = 0x665b, Legal Moves = [((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x665b: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x665b, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.916666666666668, N[0x87cd, ((5, 3), (5, 4))] = 12
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((0, 0), (1, 0))] = 22.0, N[0x87c9, ((0, 0), (1, 0))] = 1
Updated Q[0x64af, ((0, 2), (1, 2))] = 22.0, N[0x64af, ((0, 2), (1, 2))] = 1
Updated Q[0x665b, ((1, 5), (2, 5))] = 22.0, N[0x665b, ((1, 5), (2, 5))] = 1

--- Simulation 33 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.861648705529518, 16.861648705529518, 19.861648705529518, 25.861648705529518, 16.861648705529518, 20.861648705529518, 20.861648705529518, 17.861648705529518, 19.861648705529518, 26.861648705529518, 16.861648705529518, 28.45407835730366, 22.861648705529518, 16.861648705529518, 16.861648705529518, 16.861648705529518, 19.861648705529518, 16.861648705529518, 25.31638442386708, 19.861648705529518]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xa8e5, Score: 31
Depth 4: State = 0xa8e5, Legal Moves = [((0, 5), (1, 5)), ((0, 5), (0, 6)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((1, 5), (1, 6)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 6), (6, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa8e5: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0xa8e5, Score: 34
End of simulation with depth 5. Reward (Score): 34
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.384615384615383, N[0x87cd, ((5, 3), (5, 4))] = 13
Updated Q[0x87cd, ((0, 5), (0, 6))] = 34.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 34.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 34.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xa8e5, ((0, 5), (1, 5))] = 34.0, N[0xa8e5, ((0, 5), (1, 5))] = 1

--- Simulation 34 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.86989506696672, 16.86989506696672, 19.86989506696672, 25.86989506696672, 16.86989506696672, 20.86989506696672, 20.86989506696672, 17.86989506696672, 19.86989506696672, 26.86989506696672, 16.86989506696672, 28.903230964898896, 22.86989506696672, 16.86989506696672, 16.86989506696672, 16.86989506696672, 19.86989506696672, 16.86989506696672, 25.322215481959443, 19.86989506696672]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 6), (2, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 19
Depth 4: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x6557, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.928571428571427, N[0x87cd, ((5, 3), (5, 4))] = 14
Updated Q[0x87cd, ((0, 6), (0, 7))] = 22.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 22.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 22.0, N[0x87cc, ((0, 1), (1, 1))] = 1

--- Simulation 35 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.877860624385143, 16.877860624385143, 19.877860624385143, 25.877860624385143, 16.877860624385143, 20.877860624385143, 20.877860624385143, 17.877860624385143, 19.877860624385143, 26.877860624385143, 16.877860624385143, 28.43045079118304, 22.877860624385143, 16.877860624385143, 16.877860624385143, 16.877860624385143, 19.877860624385143, 16.877860624385143, 25.32784798162594, 19.877860624385143]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (0, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((0, 3), (0, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x87cc, Score: 20
Depth 4: State = 0x87cc, Legal Moves = [((0, 0), (0, 1)), ((0, 3), (1, 3)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0xc904, Score: 23
End of simulation with depth 5. Reward (Score): 23
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.6, N[0x87cd, ((5, 3), (5, 4))] = 15
Updated Q[0x87cd, ((0, 3), (0, 4))] = 23.0, N[0x87cd, ((0, 3), (0, 4))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 23.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 23.0, N[0x87cd, ((0, 1), (1, 1))] = 1
Updated Q[0x87cc, ((0, 0), (0, 1))] = 23.0, N[0x87cc, ((0, 0), (0, 1))] = 1

--- Simulation 36 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.88556306218843, 16.88556306218843, 19.88556306218843, 25.88556306218843, 16.88556306218843, 20.88556306218843, 20.88556306218843, 17.88556306218843, 19.88556306218843, 26.88556306218843, 16.88556306218843, 28.086850289205312, 22.88556306218843, 16.88556306218843, 16.88556306218843, 16.88556306218843, 19.88556306218843, 16.88556306218843, 25.33329442762831, 19.88556306218843]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 16
Depth 3: State = 0x87ca, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (2, 2)), ((1, 6), (2, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((1, 0), (1, 1)), ((1, 6), (2, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x8775, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.25, N[0x87cd, ((5, 3), (5, 4))] = 16
Updated Q[0x87cd, ((0, 5), (1, 5))] = 22.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((0, 2), (1, 2))] = 22.0, N[0x87ca, ((0, 2), (1, 2))] = 1
Updated Q[0x87cd, ((1, 0), (1, 1))] = 22.0, N[0x87cd, ((1, 0), (1, 1))] = 1

--- Simulation 37 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.893018472824846, 16.893018472824846, 19.893018472824846, 25.893018472824846, 16.893018472824846, 20.893018472824846, 20.893018472824846, 17.893018472824846, 19.893018472824846, 26.893018472824846, 16.893018472824846, 27.723254618206212, 22.893018472824846, 16.893018472824846, 16.893018472824846, 16.893018472824846, 19.893018472824846, 16.893018472824846, 25.33856619904585, 19.893018472824846]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (0, 5)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x8777, Score: 13
Depth 3: State = 0x8777, Legal Moves = [((0, 3), (1, 3)), ((0, 3), (0, 4)), ((0, 6), (0, 7)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8777: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x8774, Score: 16
Depth 4: State = 0x8774, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((0, 6), (0, 7)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8774: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x8675, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.941176470588236, N[0x87cd, ((5, 3), (5, 4))] = 17
Updated Q[0x87cd, ((0, 3), (0, 4))] = 22.0, N[0x87cd, ((0, 3), (0, 4))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 22.0, N[0x87cd, ((0, 1), (1, 1))] = 1
Updated Q[0x8777, ((0, 3), (1, 3))] = 22.0, N[0x8777, ((0, 3), (1, 3))] = 1
Updated Q[0x8774, ((0, 1), (0, 2))] = 22.0, N[0x8774, ((0, 1), (0, 2))] = 1

--- Simulation 38 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.900241540605883, 16.900241540605883, 19.900241540605883, 25.900241540605883, 16.900241540605883, 20.900241540605883, 20.900241540605883, 17.900241540605883, 19.900241540605883, 26.900241540605883, 16.900241540605883, 27.40205274035909, 22.900241540605883, 16.900241540605883, 16.900241540605883, 16.900241540605883, 19.900241540605883, 16.900241540605883, 25.343673679254792, 19.900241540605883]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 16
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 8), (3, 8)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 22
Depth 2: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 8), (3, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x8720, Score: 25
Depth 3: State = 0x8720, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (0, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 5), (3, 5)), ((2, 8), (3, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8720: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0xc9ad, Score: 28
Depth 4: State = 0xc9ad, Legal Moves = [((0, 3), (0, 4)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 5), (3, 5)), ((2, 8), (3, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xc9ad: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0xc9af, Score: 37
End of simulation with depth 5. Reward (Score): 37
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.5, N[0x87cd, ((5, 3), (5, 4))] = 18
Updated Q[0x87cd, ((0, 4), (1, 4))] = 37.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 37.0, N[0x87cd, ((0, 1), (1, 1))] = 1
Updated Q[0x8720, ((0, 2), (1, 2))] = 37.0, N[0x8720, ((0, 2), (1, 2))] = 1
Updated Q[0xc9ad, ((0, 3), (0, 4))] = 37.0, N[0xc9ad, ((0, 3), (0, 4))] = 1

--- Simulation 39 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.9072456998841, 16.9072456998841, 19.9072456998841, 25.9072456998841, 16.9072456998841, 20.9072456998841, 20.9072456998841, 17.9072456998841, 19.9072456998841, 26.9072456998841, 16.9072456998841, 27.94954212259231, 22.9072456998841, 16.9072456998841, 16.9072456998841, 16.9072456998841, 19.9072456998841, 16.9072456998841, 25.34862636777693, 19.9072456998841]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 13
Depth 2: State = 0x87c9, Legal Moves = [((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 1), (3, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 2), (4, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 1), (3, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 2), (4, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 32
End of simulation with depth 5. Reward (Score): 32
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.736842105263158, N[0x87cd, ((5, 3), (5, 4))] = 19
Updated Q[0x87cd, ((1, 1), (1, 2))] = 32.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((0, 4), (1, 4))] = 32.0, N[0x87c9, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 32.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 32.0, N[0x87cd, ((1, 5), (2, 5))] = 1

--- Simulation 40 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.91404327174953, 16.91404327174953, 19.91404327174953, 25.91404327174953, 16.91404327174953, 20.91404327174953, 20.91404327174953, 17.91404327174953, 19.91404327174953, 26.91404327174953, 16.91404327174953, 28.17595374711159, 22.91404327174953, 16.91404327174953, 16.91404327174953, 16.91404327174953, 19.91404327174953, 16.91404327174953, 25.353432976938578, 19.91404327174953]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 13
Depth 2: State = 0x87ca, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x21c9, Score: 16
Depth 3: State = 0x21c9, Legal Moves = [((0, 2), (0, 3)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x21c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0xa791, Score: 22
Depth 4: State = 0xa791, Legal Moves = [((1, 0), (1, 1)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa791: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0xa791, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.6, N[0x87cd, ((5, 3), (5, 4))] = 20
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((1, 2), (2, 2))] = 25.0, N[0x87ca, ((1, 2), (2, 2))] = 1
Updated Q[0x21c9, ((0, 2), (0, 3))] = 25.0, N[0x21c9, ((0, 2), (0, 3))] = 1
Updated Q[0xa791, ((1, 0), (1, 1))] = 25.0, N[0xa791, ((1, 0), (1, 1))] = 1

--- Simulation 41 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.920645582639843, 16.920645582639843, 19.920645582639843, 25.920645582639843, 16.920645582639843, 20.920645582639843, 20.920645582639843, 17.920645582639843, 19.920645582639843, 26.920645582639843, 16.920645582639843, 28.02946940834674, 22.920645582639843, 16.920645582639843, 16.920645582639843, 16.920645582639843, 19.920645582639843, 16.920645582639843, 25.35810151574062, 19.920645582639843]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 22
Depth 3: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((0, 4), (0, 5)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x87cd, Score: 25
Depth 4: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.61904761904762, N[0x87cd, ((5, 3), (5, 4))] = 21
Updated Q[0x87cd, ((0, 3), (1, 3))] = 28.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 28.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 28.0, N[0x87cd, ((0, 1), (1, 1))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 28.0, N[0x87cd, ((0, 6), (0, 7))] = 1

--- Simulation 42 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.927063067650955, 16.927063067650955, 19.927063067650955, 25.927063067650955, 16.927063067650955, 20.927063067650955, 20.927063067650955, 17.927063067650955, 19.927063067650955, 26.927063067650955, 16.927063067650955, 28.03956725602211, 22.927063067650955, 16.927063067650955, 16.927063067650955, 16.927063067650955, 19.927063067650955, 16.927063067650955, 25.36263936291014, 19.927063067650955]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 11
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 6), (1, 6)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x443c, Score: 51
Depth 2: State = 0x443c, Legal Moves = [((0, 2), (1, 2)), ((0, 6), (0, 7)), ((0, 7), (1, 7)), ((1, 6), (1, 7)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((2, 3), (2, 4)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((3, 7), (4, 7)), ((3, 8), (4, 8)), ((4, 7), (4, 8)), ((4, 8), (5, 8)), ((5, 4), (5, 5)), ((7, 4), (8, 4)), ((7, 5), (7, 6)), ((8, 1), (9, 1))]
UCB1 values for moves at state 0x443c: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x433d, Score: 54
Depth 3: State = 0x433d, Legal Moves = [((0, 6), (0, 7)), ((0, 7), (1, 7)), ((1, 6), (1, 7)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((2, 3), (2, 4)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((3, 7), (4, 7)), ((3, 8), (4, 8)), ((4, 7), (4, 8)), ((4, 8), (5, 8)), ((5, 4), (5, 5)), ((7, 4), (8, 4)), ((7, 5), (7, 6)), ((8, 1), (9, 1))]
UCB1 values for moves at state 0x433d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x433d, Score: 57
Depth 4: State = 0x433d, Legal Moves = [((0, 8), (0, 9)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((2, 3), (2, 4)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((3, 7), (4, 7)), ((3, 8), (4, 8)), ((4, 7), (4, 8)), ((4, 8), (5, 8)), ((5, 4), (5, 5)), ((7, 4), (8, 4)), ((7, 5), (7, 6)), ((8, 1), (9, 1))]
UCB1 values for moves at state 0x433d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 8), (0, 9))
New board state after move: 0x433d, Score: 60
End of simulation with depth 5. Reward (Score): 60
Updated Q[0x87cd, ((5, 3), (5, 4))] = 29.09090909090909, N[0x87cd, ((5, 3), (5, 4))] = 22
Updated Q[0x87cd, ((0, 5), (0, 6))] = 60.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x443c, ((0, 2), (1, 2))] = 60.0, N[0x443c, ((0, 2), (1, 2))] = 1
Updated Q[0x433d, ((0, 6), (0, 7))] = 60.0, N[0x433d, ((0, 6), (0, 7))] = 1
Updated Q[0x433d, ((0, 8), (0, 9))] = 60.0, N[0x433d, ((0, 8), (0, 9))] = 1

--- Simulation 43 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.933305360847935, 16.933305360847935, 19.933305360847935, 25.933305360847935, 16.933305360847935, 20.933305360847935, 20.933305360847935, 17.933305360847935, 19.933305360847935, 26.933305360847935, 16.933305360847935, 29.50309117877601, 22.933305360847935, 16.933305360847935, 16.933305360847935, 16.933305360847935, 19.933305360847935, 16.933305360847935, 25.36705333075988, 19.933305360847935]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 8), (1, 9)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (0, 5)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 8), (1, 9)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x861d, Score: 22
Depth 4: State = 0x861d, Legal Moves = [((0, 3), (1, 3)), ((0, 3), (0, 4)), ((1, 5), (2, 5)), ((1, 8), (1, 9)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x861d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x8722, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 29.043478260869566, N[0x87cd, ((5, 3), (5, 4))] = 23
Updated Q[0x87cd, ((0, 7), (0, 8))] = 28.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 28.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 28.0, N[0x87cd, ((0, 1), (1, 1))] = 1
Updated Q[0x861d, ((0, 3), (1, 3))] = 28.0, N[0x861d, ((0, 3), (1, 3))] = 1

--- Simulation 44 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.939381374483514, 16.939381374483514, 19.939381374483514, 25.939381374483514, 16.939381374483514, 20.939381374483514, 20.939381374483514, 17.939381374483514, 19.939381374483514, 26.939381374483514, 16.939381374483514, 29.4478672318032, 22.939381374483514, 16.939381374483514, 16.939381374483514, 16.939381374483514, 19.939381374483514, 16.939381374483514, 25.37134972120418, 19.939381374483514]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 13
Depth 2: State = 0x87cb, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xca03, Score: 16
Depth 3: State = 0xca03, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xca03: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x65ac, Score: 20
Depth 4: State = 0x65ac, Legal Moves = [((0, 0), (1, 0)), ((0, 2), (0, 3)), ((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 8), (2, 9)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x65ac: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x44e9, Score: 23
End of simulation with depth 5. Reward (Score): 23
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.791666666666668, N[0x87cd, ((5, 3), (5, 4))] = 24
Updated Q[0x87cd, ((1, 1), (1, 2))] = 23.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((1, 2), (2, 2))] = 23.0, N[0x87cb, ((1, 2), (2, 2))] = 1
Updated Q[0xca03, ((0, 1), (1, 1))] = 23.0, N[0xca03, ((0, 1), (1, 1))] = 1
Updated Q[0x65ac, ((0, 0), (1, 0))] = 23.0, N[0x65ac, ((0, 0), (1, 0))] = 1

--- Simulation 45 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.945299368713787, 16.945299368713787, 19.945299368713787, 25.945299368713787, 16.945299368713787, 20.945299368713787, 20.945299368713787, 17.945299368713787, 19.945299368713787, 26.945299368713787, 16.945299368713787, 29.188749237525585, 22.945299368713787, 16.945299368713787, 16.945299368713787, 16.945299368713787, 19.945299368713787, 16.945299368713787, 25.37553437505543, 19.945299368713787]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.52, N[0x87cd, ((5, 3), (5, 4))] = 25
Updated Q[0x87cd, ((0, 4), (0, 5))] = 22.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 22.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 7), (0, 8))] = 22.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 22.0, N[0x87cd, ((0, 6), (0, 7))] = 1

--- Simulation 46 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.951067013141866, 16.951067013141866, 19.951067013141866, 25.951067013141866, 16.951067013141866, 20.951067013141866, 20.951067013141866, 17.951067013141866, 19.951067013141866, 26.951067013141866, 16.951067013141866, 28.910213402628372, 22.951067013141866, 16.951067013141866, 16.951067013141866, 16.951067013141866, 19.951067013141866, 16.951067013141866, 25.379612715541995, 19.951067013141866]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 10
Depth 2: State = 0x87c9, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0xa7e4, Score: 13
Depth 3: State = 0xa7e4, Legal Moves = [((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa7e4: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xa7e5, Score: 16
Depth 4: State = 0xa7e5, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa7e5: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x2221, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.153846153846153, N[0x87cd, ((5, 3), (5, 4))] = 26
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((0, 0), (1, 0))] = 19.0, N[0x87c9, ((0, 0), (1, 0))] = 1
Updated Q[0xa7e4, ((1, 2), (2, 2))] = 19.0, N[0xa7e4, ((1, 2), (2, 2))] = 1
Updated Q[0xa7e5, ((0, 0), (1, 0))] = 19.0, N[0xa7e5, ((0, 0), (1, 0))] = 1

--- Simulation 47 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.956691441308287, 16.956691441308287, 19.956691441308287, 25.956691441308287, 16.956691441308287, 20.956691441308287, 20.956691441308287, 17.956691441308287, 19.956691441308287, 26.956691441308287, 16.956691441308287, 28.537584916973497, 22.956691441308287, 16.956691441308287, 16.956691441308287, 16.956691441308287, 19.956691441308287, 16.956691441308287, 25.38358978683877, 19.956691441308287]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x8621, Score: 20
Depth 2: State = 0x8621, Legal Moves = [((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8621: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x871f, Score: 23
Depth 3: State = 0x871f, Legal Moves = [((0, 4), (0, 5)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x871f: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x64ae, Score: 45
Depth 4: State = 0x64ae, Legal Moves = [((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 3), (3, 3)), ((3, 0), (4, 0)), ((3, 2), (3, 3)), ((3, 3), (3, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x64ae: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xc959, Score: 48
End of simulation with depth 5. Reward (Score): 48
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.88888888888889, N[0x87cd, ((5, 3), (5, 4))] = 27
Updated Q[0x87cd, ((1, 1), (1, 2))] = 48.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x8621, ((1, 0), (1, 1))] = 48.0, N[0x8621, ((1, 0), (1, 1))] = 1
Updated Q[0x871f, ((0, 4), (0, 5))] = 48.0, N[0x871f, ((0, 4), (0, 5))] = 1
Updated Q[0x64ae, ((1, 2), (2, 2))] = 48.0, N[0x64ae, ((1, 2), (2, 2))] = 1

--- Simulation 48 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.962179299072858, 16.962179299072858, 19.962179299072858, 25.962179299072858, 16.962179299072858, 20.962179299072858, 20.962179299072858, 17.962179299072858, 19.962179299072858, 26.962179299072858, 16.962179299072858, 29.266510471061565, 22.962179299072858, 16.962179299072858, 16.962179299072858, 16.962179299072858, 19.962179299072858, 16.962179299072858, 25.387470288278287, 19.962179299072858]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 8), (1, 8))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 16
Depth 4: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x43e9, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.535714285714285, N[0x87cd, ((5, 3), (5, 4))] = 28
Updated Q[0x87cd, ((0, 6), (0, 7))] = 19.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((0, 8), (1, 8))] = 19.0, N[0x87cd, ((0, 8), (1, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 19.0, N[0x87cc, ((0, 1), (1, 1))] = 1

--- Simulation 49 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.96753678768858, 16.96753678768858, 19.96753678768858, 25.96753678768858, 16.96753678768858, 20.96753678768858, 20.96753678768858, 17.96753678768858, 19.96753678768858, 26.96753678768858, 16.96753678768858, 28.907543788256774, 22.96753678768858, 16.96753678768858, 16.96753678768858, 16.96753678768858, 19.96753678768858, 16.96753678768858, 25.39125860480859, 19.96753678768858]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 16
Depth 3: State = 0x87c9, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87c9, Score: 19
Depth 4: State = 0x87c9, Legal Moves = [((2, 2), (2, 3)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0xa8e5, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.310344827586206, N[0x87cd, ((5, 3), (5, 4))] = 29
Updated Q[0x87cd, ((0, 7), (1, 7))] = 22.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 5), (2, 5))] = 22.0, N[0x87c9, ((1, 5), (2, 5))] = 1
Updated Q[0x87c9, ((2, 2), (2, 3))] = 22.0, N[0x87c9, ((2, 2), (2, 3))] = 1

--- Simulation 50 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.97276970224875, 16.97276970224875, 19.97276970224875, 25.97276970224875, 16.97276970224875, 20.97276970224875, 20.97276970224875, 17.97276970224875, 19.97276970224875, 26.97276970224875, 16.97276970224875, 28.67667896459073, 22.97276970224875, 16.97276970224875, 16.97276970224875, 16.97276970224875, 19.97276970224875, 16.97276970224875, 25.39495883417946, 19.97276970224875]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 2), (6, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 2), (6, 2)), ((5, 5), (5, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.2, N[0x87cd, ((5, 3), (5, 4))] = 30
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 25.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 25.0, N[0x87cd, ((1, 5), (2, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 25.0, N[0x87cd, ((0, 4), (0, 5))] = 1

--- Simulation 51 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.977883466088976, 16.977883466088976, 19.977883466088976, 25.977883466088976, 16.977883466088976, 20.977883466088976, 20.977883466088976, 17.977883466088976, 19.977883466088976, 26.977883466088976, 16.977883466088976, 28.561110463497812, 22.977883466088976, 16.977883466088976, 16.977883466088976, 16.977883466088976, 19.977883466088976, 16.977883466088976, 25.39857481126827, 19.977883466088976]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 5), (1, 5)), ((0, 7), (0, 8)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.096774193548388, N[0x87cd, ((5, 3), (5, 4))] = 31
Updated Q[0x87cd, ((0, 4), (0, 5))] = 25.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 7), (0, 8))] = 25.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 25.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1

--- Simulation 52 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.98288316164224, 16.98288316164224, 19.98288316164224, 25.98288316164224, 16.98288316164224, 20.98288316164224, 20.98288316164224, 17.98288316164224, 19.98288316164224, 26.98288316164224, 16.98288316164224, 28.45291052267895, 22.98288316164224, 16.98288316164224, 16.98288316164224, 16.98288316164224, 19.98288316164224, 16.98288316164224, 25.40211012989785, 19.98288316164224]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 6), (2, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x8620, Score: 16
Depth 4: State = 0x8620, Legal Moves = [((1, 0), (1, 1)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8620: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x87cd, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.8125, N[0x87cd, ((5, 3), (5, 4))] = 32
Updated Q[0x87cd, ((0, 6), (0, 7))] = 19.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 19.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x8620, ((1, 0), (1, 1))] = 19.0, N[0x8620, ((1, 0), (1, 1))] = 1

--- Simulation 53 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.987773558175434, 16.987773558175434, 19.987773558175434, 25.987773558175434, 16.987773558175434, 20.987773558175434, 20.987773558175434, 17.987773558175434, 19.987773558175434, 26.987773558175434, 16.987773558175434, 28.16389204061229, 22.987773558175434, 16.987773558175434, 16.987773558175434, 16.987773558175434, 19.987773558175434, 16.987773558175434, 25.40556816244916, 19.987773558175434]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x8776, Score: 16
Depth 3: State = 0x8776, Legal Moves = [((0, 0), (0, 1)), ((0, 3), (1, 3)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8776: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0xa93d, Score: 19
Depth 4: State = 0xa93d, Legal Moves = [((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa93d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0xa93d, Score: 44
End of simulation with depth 5. Reward (Score): 44
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.303030303030305, N[0x87cd, ((5, 3), (5, 4))] = 33
Updated Q[0x87cd, ((0, 3), (1, 3))] = 44.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 1), (0, 2))] = 44.0, N[0x87cd, ((0, 1), (0, 2))] = 1
Updated Q[0x8776, ((0, 0), (0, 1))] = 44.0, N[0x8776, ((0, 0), (0, 1))] = 1
Updated Q[0xa93d, ((1, 4), (1, 5))] = 44.0, N[0xa93d, ((1, 4), (1, 5))] = 1

--- Simulation 54 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.992559136776652, 16.992559136776652, 19.992559136776652, 25.992559136776652, 16.992559136776652, 20.992559136776652, 20.992559136776652, 17.992559136776652, 19.992559136776652, 26.992559136776652, 16.992559136776652, 28.649890326913493, 22.992559136776652, 16.992559136776652, 16.992559136776652, 16.992559136776652, 19.992559136776652, 16.992559136776652, 25.408952077529985, 19.992559136776652]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 22
Depth 3: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x64b0, Score: 25
Depth 4: State = 0x64b0, Legal Moves = [((0, 2), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x64b0: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x65af, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.294117647058822, N[0x87cd, ((5, 3), (5, 4))] = 34
Updated Q[0x87cd, ((0, 7), (0, 8))] = 28.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 28.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0x64b0, ((0, 2), (1, 2))] = 28.0, N[0x64b0, ((0, 2), (1, 2))] = 1

--- Simulation 55 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.99724411291266, 16.99724411291266, 19.99724411291266, 25.99724411291266, 16.99724411291266, 20.99724411291266, 20.99724411291266, 17.99724411291266, 19.99724411291266, 26.99724411291266, 16.99724411291266, 28.63664218660755, 22.99724411291266, 16.99724411291266, 16.99724411291266, 16.99724411291266, 19.99724411291266, 16.99724411291266, 25.41226485592545, 19.99724411291266]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x22cc, Score: 25
Depth 3: State = 0x22cc, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (0, 3)), ((1, 0), (1, 1)), ((1, 5), (1, 6)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x22cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x2276, Score: 28
Depth 4: State = 0x2276, Legal Moves = [((0, 1), (1, 1)), ((0, 1), (0, 2)), ((0, 2), (1, 2)), ((0, 2), (0, 3)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2276: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x2277, Score: 31
End of simulation with depth 5. Reward (Score): 31
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.37142857142857, N[0x87cd, ((5, 3), (5, 4))] = 35
Updated Q[0x87cd, ((0, 4), (0, 5))] = 31.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 31.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x22cc, ((0, 1), (1, 1))] = 31.0, N[0x22cc, ((0, 1), (1, 1))] = 1
Updated Q[0x2276, ((0, 1), (1, 1))] = 31.0, N[0x2276, ((0, 1), (1, 1))] = 1

--- Simulation 56 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.001832456833604, 17.001832456833604, 20.001832456833604, 26.001832456833604, 17.001832456833604, 21.001832456833604, 21.001832456833604, 18.001832456833604, 20.001832456833604, 27.001832456833604, 17.001832456833604, 28.709800015057883, 23.001832456833604, 17.001832456833604, 17.001832456833604, 17.001832456833604, 20.001832456833604, 17.001832456833604, 25.41550930502637, 20.001832456833604]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xca06, Score: 13
Depth 3: State = 0xca06, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xca06: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0xa93d, Score: 19
Depth 4: State = 0xa93d, Legal Moves = [((1, 5), (2, 5)), ((2, 3), (3, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa93d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0xa93d, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.194444444444443, N[0x87cd, ((5, 3), (5, 4))] = 36
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 22.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0xca06, ((0, 1), (1, 1))] = 22.0, N[0xca06, ((0, 1), (1, 1))] = 1
Updated Q[0xa93d, ((1, 5), (2, 5))] = 22.0, N[0xa93d, ((1, 5), (2, 5))] = 1

--- Simulation 57 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.00632791206601, 17.00632791206601, 20.00632791206601, 26.00632791206601, 17.00632791206601, 21.00632791206601, 21.00632791206601, 18.00632791206601, 20.00632791206601, 27.00632791206601, 17.00632791206601, 28.52883242978878, 23.00632791206601, 17.00632791206601, 17.00632791206601, 17.00632791206601, 20.00632791206601, 17.00632791206601, 25.418688071905724, 20.00632791206601]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 6), (0, 7)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 16
Depth 4: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.027027027027028, N[0x87cd, ((5, 3), (5, 4))] = 37
Updated Q[0x87cd, ((0, 6), (1, 6))] = 22.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 22.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 22.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1

--- Simulation 58 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.01073401220414, 17.01073401220414, 20.01073401220414, 26.01073401220414, 17.01073401220414, 21.01073401220414, 21.01073401220414, 18.01073401220414, 20.01073401220414, 27.01073401220414, 17.01073401220414, 28.357589662373826, 23.01073401220414, 17.01073401220414, 17.01073401220414, 17.01073401220414, 20.01073401220414, 17.01073401220414, 25.42180365519198, 20.01073401220414]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 10
Depth 2: State = 0x87ca, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (1, 3)), ((0, 3), (0, 4)), ((0, 6), (0, 7)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87ca, Score: 19
Depth 4: State = 0x87ca, Legal Moves = [((0, 4), (0, 5)), ((0, 5), (1, 5)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87ca, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.86842105263158, N[0x87cd, ((5, 3), (5, 4))] = 38
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((0, 3), (1, 3))] = 22.0, N[0x87ca, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 2), (0, 3))] = 22.0, N[0x87cd, ((0, 2), (0, 3))] = 1
Updated Q[0x87ca, ((0, 4), (0, 5))] = 22.0, N[0x87ca, ((0, 4), (0, 5))] = 1

--- Simulation 59 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.01505409618363, 17.01505409618363, 20.01505409618363, 26.01505409618363, 17.01505409618363, 21.01505409618363, 21.01505409618363, 18.01505409618363, 20.01505409618363, 27.01505409618363, 17.01505409618363, 28.19530599176985, 23.01505409618363, 17.01505409618363, 17.01505409618363, 17.01505409618363, 20.01505409618363, 17.01505409618363, 25.424858415869174, 20.01505409618363]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 13
Depth 3: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x8631, Score: 22
Depth 4: State = 0x8631, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8631: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0xcaad, Score: 37
End of simulation with depth 5. Reward (Score): 37
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.102564102564102, N[0x87cd, ((5, 3), (5, 4))] = 39
Updated Q[0x87cd, ((0, 6), (0, 7))] = 37.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 37.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 37.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0x8631, ((0, 1), (0, 2))] = 37.0, N[0x8631, ((0, 1), (0, 2))] = 1

--- Simulation 60 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.019291322198388, 17.019291322198388, 20.019291322198388, 26.019291322198388, 17.019291322198388, 21.019291322198388, 21.019291322198388, 18.019291322198388, 20.019291322198388, 27.019291322198388, 17.019291322198388, 28.425909493982363, 23.019291322198388, 17.019291322198388, 17.019291322198388, 17.019291322198388, 20.019291322198388, 17.019291322198388, 25.42785458711763, 20.019291322198388]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x64ad, Score: 19
Depth 3: State = 0x64ad, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x64ad: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2222, Score: 22
Depth 4: State = 0x2222, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2222: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x22cb, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.025, N[0x87cd, ((5, 3), (5, 4))] = 40
Updated Q[0x87cd, ((0, 7), (0, 8))] = 25.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x64ad, ((0, 0), (0, 1))] = 25.0, N[0x64ad, ((0, 0), (0, 1))] = 1
Updated Q[0x2222, ((0, 1), (1, 1))] = 25.0, N[0x2222, ((0, 1), (1, 1))] = 1

--- Simulation 61 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.02344868040237, 17.02344868040237, 20.02344868040237, 26.02344868040237, 17.02344868040237, 21.02344868040237, 21.02344868040237, 18.02344868040237, 20.02344868040237, 27.02344868040237, 17.02344868040237, 28.344935327926677, 23.02344868040237, 17.02344868040237, 17.02344868040237, 17.02344868040237, 20.02344868040237, 17.02344868040237, 25.430794283295487, 20.02344868040237]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 8), (0, 9)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 8), (0, 9))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 16
Depth 3: State = 0x87cb, Legal Moves = [((0, 1), (0, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x86cb, Score: 19
Depth 4: State = 0x86cb, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x86cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x6503, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.024390243902438, N[0x87cd, ((5, 3), (5, 4))] = 41
Updated Q[0x87cd, ((0, 8), (0, 9))] = 28.0, N[0x87cd, ((0, 8), (0, 9))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((0, 1), (0, 2))] = 28.0, N[0x87cb, ((0, 1), (0, 2))] = 1
Updated Q[0x86cb, ((0, 1), (1, 1))] = 28.0, N[0x86cb, ((0, 1), (1, 1))] = 1

--- Simulation 62 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.02752900452085, 17.02752900452085, 20.02752900452085, 26.02752900452085, 17.02752900452085, 21.02752900452085, 21.02752900452085, 18.02752900452085, 20.02752900452085, 27.02752900452085, 17.02752900452085, 28.34103707587672, 23.02752900452085, 17.02752900452085, 17.02752900452085, 17.02752900452085, 20.02752900452085, 17.02752900452085, 25.433679508149105, 20.02752900452085]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((1, 6), (2, 6)), ((1, 6), (1, 7)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 25
Depth 4: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 4), (3, 5)), ((3, 8), (3, 9)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 31
End of simulation with depth 5. Reward (Score): 31
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.095238095238095, N[0x87cd, ((5, 3), (5, 4))] = 42
Updated Q[0x87cd, ((0, 7), (0, 8))] = 31.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 31.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 7), (1, 7))] = 31.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 31.0, N[0x87cd, ((0, 6), (1, 6))] = 1

--- Simulation 63 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.03153498248125, 17.03153498248125, 20.03153498248125, 26.03153498248125, 17.03153498248125, 21.03153498248125, 21.03153498248125, 18.03153498248125, 20.03153498248125, 27.03153498248125, 17.03153498248125, 28.408710748600132, 23.03153498248125, 17.03153498248125, 17.03153498248125, 17.03153498248125, 20.03153498248125, 17.03153498248125, 25.436512162330185, 20.03153498248125]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((1, 1), (1, 2)), ((1, 7), (1, 8)), ((2, 2), (2, 3)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 7), (1, 8)), ((2, 2), (2, 3)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 7), (1, 8)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.093023255813954, N[0x87cd, ((5, 3), (5, 4))] = 43
Updated Q[0x87cd, ((0, 4), (1, 4))] = 28.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 28.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 28.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1

--- Simulation 64 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.035469166160848, 17.035469166160848, 20.035469166160848, 26.035469166160848, 17.035469166160848, 21.035469166160848, 21.035469166160848, 18.035469166160848, 20.035469166160848, 27.035469166160848, 17.035469166160848, 28.40342939360958, 23.035469166160848, 17.035469166160848, 17.035469166160848, 17.035469166160848, 20.035469166160848, 17.035469166160848, 25.439294050288463, 20.035469166160848]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x8676, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.954545454545453, N[0x87cd, ((5, 3), (5, 4))] = 44
Updated Q[0x87cd, ((0, 4), (0, 5))] = 22.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 22.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 22.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 22.0, N[0x87cd, ((0, 1), (1, 1))] = 1

--- Simulation 65 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.039333980337616, 17.039333980337616, 20.039333980337616, 26.039333980337616, 17.039333980337616, 21.039333980337616, 21.039333980337616, 18.039333980337616, 20.039333980337616, 27.039333980337616, 17.039333980337616, 28.261986619772813, 23.039333980337616, 17.039333980337616, 17.039333980337616, 17.039333980337616, 20.039333980337616, 17.039333980337616, 25.442026886600882, 20.039333980337616]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 19
Depth 4: State = 0x87c9, Legal Moves = [((1, 0), (1, 1)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x87cc, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.822222222222223, N[0x87cd, ((5, 3), (5, 4))] = 45
Updated Q[0x87cd, ((0, 6), (1, 6))] = 22.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 4), (1, 4))] = 22.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 0), (1, 1))] = 22.0, N[0x87c9, ((1, 0), (1, 1))] = 1

--- Simulation 66 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.04313173092085, 17.04313173092085, 20.04313173092085, 26.04313173092085, 17.04313173092085, 21.04313173092085, 21.04313173092085, 18.04313173092085, 20.04313173092085, 27.04313173092085, 17.04313173092085, 28.126794318043945, 23.04313173092085, 17.04313173092085, 17.04313173092085, 17.04313173092085, 20.04313173092085, 17.04313173092085, 25.444712301791544, 20.04313173092085]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 22
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 25
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 8), (4, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 28
Depth 3: State = 0x87cd, Legal Moves = [((0, 3), (0, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 8), (4, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x8676, Score: 31
Depth 4: State = 0x8676, Legal Moves = [((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 8), (4, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8676: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x8676, Score: 34
End of simulation with depth 5. Reward (Score): 34
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.956521739130434, N[0x87cd, ((5, 3), (5, 4))] = 46
Updated Q[0x87cd, ((0, 6), (1, 6))] = 34.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 34.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 3), (0, 4))] = 34.0, N[0x87cd, ((0, 3), (0, 4))] = 1
Updated Q[0x8676, ((0, 3), (1, 3))] = 34.0, N[0x8676, ((0, 3), (1, 3))] = 1

--- Simulation 67 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.046864612529717, 17.046864612529717, 20.046864612529717, 26.046864612529717, 17.046864612529717, 21.046864612529717, 21.046864612529717, 18.046864612529717, 20.046864612529717, 27.046864612529717, 17.046864612529717, 28.25831546158605, 23.046864612529717, 17.046864612529717, 17.046864612529717, 17.046864612529717, 20.046864612529717, 17.046864612529717, 25.447351847690538, 20.046864612529717]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 1), (0, 2)), ((0, 5), (0, 6)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x8777, Score: 19
Depth 3: State = 0x8777, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8777: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x8777, Score: 22
Depth 4: State = 0x8777, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8777: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x8777, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.95744680851064, N[0x87cd, ((5, 3), (5, 4))] = 47
Updated Q[0x87cd, ((0, 3), (1, 3))] = 28.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 1), (0, 2))] = 28.0, N[0x87cd, ((0, 1), (0, 2))] = 1
Updated Q[0x8777, ((0, 6), (1, 6))] = 28.0, N[0x8777, ((0, 6), (1, 6))] = 1
Updated Q[0x8777, ((0, 6), (1, 6))] = 28.0, N[0x8777, ((0, 6), (1, 6))] = 1

--- Simulation 68 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.050534715480566, 17.050534715480566, 20.050534715480566, 26.050534715480566, 17.050534715480566, 21.050534715480566, 21.050534715480566, 18.050534715480566, 20.050534715480566, 27.050534715480566, 17.050534715480566, 28.25654803735035, 23.050534715480566, 17.050534715480566, 17.050534715480566, 17.050534715480566, 20.050534715480566, 17.050534715480566, 25.449947002374735, 20.050534715480566]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 7), (2, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 16
Depth 4: State = 0x87cb, Legal Moves = [((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 7), (2, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cc, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.770833333333332, N[0x87cd, ((5, 3), (5, 4))] = 48
Updated Q[0x87cd, ((0, 7), (1, 7))] = 19.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 19.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((0, 4), (1, 4))] = 19.0, N[0x87cb, ((0, 4), (1, 4))] = 1

--- Simulation 69 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.054144032237296, 17.054144032237296, 20.054144032237296, 26.054144032237296, 17.054144032237296, 21.054144032237296, 21.054144032237296, 18.054144032237296, 20.054144032237296, 27.054144032237296, 17.054144032237296, 28.06732348582495, 23.054144032237296, 17.054144032237296, 17.054144032237296, 17.054144032237296, 20.054144032237296, 17.054144032237296, 25.45249917472887, 20.054144032237296]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 16
Depth 4: State = 0x87ca, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xa93c, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.591836734693878, N[0x87cd, ((5, 3), (5, 4))] = 49
Updated Q[0x87cd, ((0, 5), (1, 5))] = 19.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 19.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((1, 2), (2, 2))] = 19.0, N[0x87ca, ((1, 2), (2, 2))] = 1

--- Simulation 70 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.05769446337333, 17.05769446337333, 20.05769446337333, 26.05769446337333, 17.05769446337333, 21.05769446337333, 21.05769446337333, 18.05769446337333, 20.05769446337333, 27.05769446337333, 17.05769446337333, 27.885793086604355, 23.05769446337333, 17.05769446337333, 17.05769446337333, 17.05769446337333, 20.05769446337333, 17.05769446337333, 25.455009708661297, 20.05769446337333]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x2321, Score: 13
Depth 2: State = 0x2321, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2321: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x22cb, Score: 16
Depth 3: State = 0x22cb, Legal Moves = [((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x22cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x2277, Score: 19
Depth 4: State = 0x2277, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2277: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x2277, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.48, N[0x87cd, ((5, 3), (5, 4))] = 50
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x2321, ((1, 0), (1, 1))] = 22.0, N[0x2321, ((1, 0), (1, 1))] = 1
Updated Q[0x22cb, ((1, 3), (1, 4))] = 22.0, N[0x22cb, ((1, 3), (1, 4))] = 1
Updated Q[0x2277, ((1, 5), (2, 5))] = 22.0, N[0x2277, ((1, 5), (2, 5))] = 1

--- Simulation 71 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.061187823088755, 17.061187823088755, 20.061187823088755, 26.061187823088755, 17.061187823088755, 21.061187823088755, 21.061187823088755, 18.061187823088755, 20.061187823088755, 27.061187823088755, 17.061187823088755, 27.771495977401038, 23.061187823088755, 17.061187823088755, 17.061187823088755, 17.061187823088755, 20.061187823088755, 17.061187823088755, 25.457479887005196, 20.061187823088755]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((3, 2), (3, 3)), ((4, 2), (4, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((3, 7), (3, 8)), ((4, 2), (4, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 5), (5, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((0, 3), (0, 4)), ((0, 6), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((3, 7), (3, 8)), ((4, 2), (4, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 5), (5, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x871f, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.431372549019606, N[0x87cd, ((5, 3), (5, 4))] = 51
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 25.0, N[0x87cd, ((1, 5), (2, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 25.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 3), (0, 4))] = 25.0, N[0x87cd, ((0, 3), (0, 4))] = 1

--- Simulation 72 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.064625844321753, 17.064625844321753, 20.064625844321753, 26.064625844321753, 17.064625844321753, 21.064625844321753, 21.064625844321753, 18.064625844321753, 20.064625844321753, 27.064625844321753, 17.064625844321753, 27.72047799409693, 23.064625844321753, 17.064625844321753, 17.064625844321753, 17.064625844321753, 20.064625844321753, 17.064625844321753, 25.459910935132914, 20.064625844321753]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 13
Depth 3: State = 0x87cb, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x6603, Score: 16
Depth 4: State = 0x6603, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6603: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xc902, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.26923076923077, N[0x87cd, ((5, 3), (5, 4))] = 52
Updated Q[0x87cd, ((0, 6), (0, 7))] = 19.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((0, 0), (1, 0))] = 19.0, N[0x87cb, ((0, 0), (1, 0))] = 1
Updated Q[0x6603, ((1, 2), (2, 2))] = 19.0, N[0x6603, ((1, 2), (2, 2))] = 1

--- Simulation 73 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.06801018348945, 17.06801018348945, 20.06801018348945, 26.06801018348945, 17.06801018348945, 21.06801018348945, 21.06801018348945, 18.06801018348945, 20.06801018348945, 27.06801018348945, 17.06801018348945, 27.55601218287511, 23.06801018348945, 17.06801018348945, 17.06801018348945, 17.06801018348945, 20.06801018348945, 17.06801018348945, 25.462304024308224, 20.06801018348945]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 6), (1, 6)), ((0, 6), (0, 7)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 7), (1, 7)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((0, 7), (1, 7)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 7), (1, 8)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 37
End of simulation with depth 5. Reward (Score): 37
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.452830188679247, N[0x87cd, ((5, 3), (5, 4))] = 53
Updated Q[0x87cd, ((0, 7), (1, 7))] = 37.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 37.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 37.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 37.0, N[0x87cd, ((0, 5), (1, 5))] = 1

--- Simulation 74 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.071342424889806, 17.071342424889806, 20.071342424889806, 26.071342424889806, 17.071342424889806, 21.071342424889806, 21.071342424889806, 18.071342424889806, 20.071342424889806, 27.071342424889806, 17.071342424889806, 27.737350952292957, 23.071342424889806, 17.071342424889806, 17.071342424889806, 17.071342424889806, 20.071342424889806, 17.071342424889806, 25.46466027479897, 20.071342424889806]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x87cb, Score: 22
Depth 4: State = 0x87cb, Legal Moves = [((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cb, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.462962962962962, N[0x87cd, ((5, 3), (5, 4))] = 54
Updated Q[0x87cd, ((0, 6), (1, 6))] = 28.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 28.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x87cb, ((1, 5), (2, 5))] = 28.0, N[0x87cb, ((1, 5), (2, 5))] = 1

--- Simulation 75 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.074624084793236, 17.074624084793236, 20.074624084793236, 26.074624084793236, 17.074624084793236, 21.074624084793236, 21.074624084793236, 18.074624084793236, 20.074624084793236, 27.074624084793236, 17.074624084793236, 27.745283541620292, 23.074624084793236, 17.074624084793236, 17.074624084793236, 17.074624084793236, 20.074624084793236, 17.074624084793236, 25.466980758770234, 20.074624084793236]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x8775, Score: 22
Depth 4: State = 0x8775, Legal Moves = [((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8775: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x8775, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.418181818181818, N[0x87cd, ((5, 3), (5, 4))] = 55
Updated Q[0x87cd, ((0, 4), (0, 5))] = 25.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 4), (1, 4))] = 25.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 25.0, N[0x87cd, ((0, 1), (1, 1))] = 1
Updated Q[0x8775, ((0, 3), (1, 3))] = 25.0, N[0x8775, ((0, 3), (1, 3))] = 1

--- Simulation 76 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.077856615249548, 17.077856615249548, 20.077856615249548, 26.077856615249548, 17.077856615249548, 21.077856615249548, 21.077856615249548, 18.077856615249548, 20.077856615249548, 27.077856615249548, 17.077856615249548, 27.698359947025736, 23.077856615249548, 17.077856615249548, 17.077856615249548, 17.077856615249548, 20.077856615249548, 17.077856615249548, 25.469266502976282, 20.077856615249548]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 2), (0, 3)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87c9, Score: 19
Depth 2: State = 0x87c9, Legal Moves = [((0, 6), (1, 6)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87c9, Score: 22
Depth 3: State = 0x87c9, Legal Moves = [((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x87c9, Score: 25
Depth 4: State = 0x87c9, Legal Moves = [((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x87c9, Score: 31
End of simulation with depth 5. Reward (Score): 31
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.482142857142858, N[0x87cd, ((5, 3), (5, 4))] = 56
Updated Q[0x87cd, ((0, 2), (0, 3))] = 31.0, N[0x87cd, ((0, 2), (0, 3))] = 1
Updated Q[0x87c9, ((0, 6), (1, 6))] = 31.0, N[0x87c9, ((0, 6), (1, 6))] = 1
Updated Q[0x87c9, ((1, 3), (1, 4))] = 31.0, N[0x87c9, ((1, 3), (1, 4))] = 1
Updated Q[0x87c9, ((1, 4), (2, 4))] = 31.0, N[0x87c9, ((1, 4), (2, 4))] = 1

--- Simulation 77 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.081041407633766, 17.081041407633766, 20.081041407633766, 26.081041407633766, 17.081041407633766, 21.081041407633766, 21.081041407633766, 18.081041407633766, 20.081041407633766, 27.081041407633766, 17.081041407633766, 27.76023371268055, 23.081041407633766, 17.081041407633766, 17.081041407633766, 17.081041407633766, 20.081041407633766, 17.081041407633766, 25.471518491267837, 20.081041407633766]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 1), (3, 2)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x6504, Score: 19
Depth 4: State = 0x6504, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6504: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x6504, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.385964912280702, N[0x87cd, ((5, 3), (5, 4))] = 57
Updated Q[0x87cd, ((0, 3), (1, 3))] = 22.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 0), (1, 0))] = 22.0, N[0x87cd, ((0, 0), (1, 0))] = 1
Updated Q[0x6504, ((1, 5), (2, 5))] = 22.0, N[0x6504, ((1, 5), (2, 5))] = 1

--- Simulation 78 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.084179795951798, 17.084179795951798, 20.084179795951798, 26.084179795951798, 17.084179795951798, 21.084179795951798, 21.084179795951798, 18.084179795951798, 20.084179795951798, 27.084179795951798, 17.084179795951798, 27.66202127004864, 23.084179795951798, 17.084179795951798, 17.084179795951798, 17.084179795951798, 20.084179795951798, 17.084179795951798, 25.473737666929512, 20.084179795951798]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((0, 2), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x87cd, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.344827586206897, N[0x87cd, ((5, 3), (5, 4))] = 58
Updated Q[0x87cd, ((0, 7), (0, 8))] = 25.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((0, 7), (1, 7))] = 25.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 2), (1, 2))] = 25.0, N[0x87cd, ((0, 2), (1, 2))] = 1

--- Simulation 79 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.08727305992522, 17.08727305992522, 20.08727305992522, 26.08727305992522, 17.08727305992522, 21.08727305992522, 21.08727305992522, 18.08727305992522, 20.08727305992522, 27.08727305992522, 17.08727305992522, 27.618899966109876, 23.08727305992522, 17.08727305992522, 17.08727305992522, 17.08727305992522, 20.08727305992522, 17.08727305992522, 25.47592493486112, 20.08727305992522]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 16
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 31
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 7), (3, 7)), ((2, 8), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x8677, Score: 40
Depth 3: State = 0x8677, Legal Moves = [((0, 2), (1, 2)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((2, 7), (3, 7)), ((2, 8), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8677: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x861e, Score: 46
Depth 4: State = 0x861e, Legal Moves = [((0, 3), (0, 4)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 7), (3, 7)), ((2, 8), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x861e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x861e, Score: 49
End of simulation with depth 5. Reward (Score): 49
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.71186440677966, N[0x87cd, ((5, 3), (5, 4))] = 59
Updated Q[0x87cd, ((0, 6), (0, 7))] = 49.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 49.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x8677, ((0, 2), (1, 2))] = 49.0, N[0x8677, ((0, 2), (1, 2))] = 1
Updated Q[0x861e, ((0, 3), (0, 4))] = 49.0, N[0x861e, ((0, 3), (0, 4))] = 1

--- Simulation 80 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.090322427872557, 17.090322427872557, 20.090322427872557, 26.090322427872557, 17.090322427872557, 21.090322427872557, 21.090322427872557, 18.090322427872557, 20.090322427872557, 27.090322427872557, 17.090322427872557, 27.98400120726318, 23.090322427872557, 17.090322427872557, 17.090322427872557, 17.090322427872557, 20.090322427872557, 17.090322427872557, 25.478081163615013, 20.090322427872557]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 13
Depth 3: State = 0x87cb, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x86ca, Score: 16
Depth 4: State = 0x86ca, Legal Moves = [((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x86ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x8674, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.566666666666666, N[0x87cd, ((5, 3), (5, 4))] = 60
Updated Q[0x87cd, ((0, 6), (1, 6))] = 19.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((1, 2), (2, 2))] = 19.0, N[0x87cb, ((1, 2), (2, 2))] = 1
Updated Q[0x86ca, ((1, 0), (1, 1))] = 19.0, N[0x86ca, ((1, 0), (1, 1))] = 1

--- Simulation 81 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.09332907940292, 17.09332907940292, 20.09332907940292, 26.09332907940292, 17.09332907940292, 21.09332907940292, 21.09332907940292, 18.09332907940292, 20.09332907940292, 27.09332907940292, 17.09332907940292, 27.836914288755306, 23.09332907940292, 17.09332907940292, 17.09332907940292, 17.09332907940292, 20.09332907940292, 17.09332907940292, 25.4802071873008, 20.09332907940292]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 22
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 28
Depth 2: State = 0x87cc, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (1, 1)), ((1, 3), (1, 4)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((3, 5), (3, 6)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0xa93c, Score: 31
Depth 3: State = 0xa93c, Legal Moves = [((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((3, 5), (3, 6)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa93c: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0xa792, Score: 34
Depth 4: State = 0xa792, Legal Moves = [((0, 3), (0, 4)), ((2, 2), (3, 2)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((3, 5), (3, 6)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa792: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0xa792, Score: 37
End of simulation with depth 5. Reward (Score): 37
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.721311475409838, N[0x87cd, ((5, 3), (5, 4))] = 61
Updated Q[0x87cd, ((1, 1), (1, 2))] = 37.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 0), (1, 0))] = 37.0, N[0x87cc, ((0, 0), (1, 0))] = 1
Updated Q[0xa93c, ((2, 1), (3, 1))] = 37.0, N[0xa93c, ((2, 1), (3, 1))] = 1
Updated Q[0xa792, ((0, 3), (0, 4))] = 37.0, N[0xa792, ((0, 3), (0, 4))] = 1

--- Simulation 82 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.096294147936412, 17.096294147936412, 20.096294147936412, 26.096294147936412, 17.096294147936412, 21.096294147936412, 21.096294147936412, 18.096294147936412, 20.096294147936412, 27.096294147936412, 17.096294147936412, 27.989714437533205, 23.096294147936412, 17.096294147936412, 17.096294147936412, 17.096294147936412, 20.096294147936412, 17.096294147936412, 25.48230380736751, 20.096294147936412]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 35
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((3, 7), (4, 7)), ((4, 3), (4, 4)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (5, 7)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 3), (6, 4)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3)), ((8, 5), (9, 5))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 41
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((3, 7), (4, 7)), ((4, 3), (4, 4)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (5, 7)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 3), (6, 4)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3)), ((8, 5), (9, 5))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 44
Depth 3: State = 0x87cb, Legal Moves = [((1, 4), (1, 5)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((3, 7), (4, 7)), ((4, 3), (4, 4)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (5, 7)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 3), (6, 4)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3)), ((8, 5), (9, 5))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0x87cb, Score: 53
Depth 4: State = 0x87cb, Legal Moves = [((2, 6), (2, 7)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((3, 3), (3, 4)), ((3, 6), (3, 7)), ((3, 7), (4, 7)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (5, 7)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 3), (6, 4)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3)), ((8, 5), (9, 5))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 6), (2, 7))
New board state after move: 0x87cb, Score: 59
End of simulation with depth 5. Reward (Score): 59
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.225806451612904, N[0x87cd, ((5, 3), (5, 4))] = 62
Updated Q[0x87cd, ((0, 5), (1, 5))] = 59.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 59.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((1, 4), (1, 5))] = 59.0, N[0x87cb, ((1, 4), (1, 5))] = 1
Updated Q[0x87cb, ((2, 6), (2, 7))] = 59.0, N[0x87cb, ((2, 6), (2, 7))] = 1

--- Simulation 83 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.09921872306443, 17.09921872306443, 20.09921872306443, 26.09921872306443, 17.09921872306443, 21.09921872306443, 21.09921872306443, 18.09921872306443, 20.09921872306443, 27.09921872306443, 17.09921872306443, 28.492407496043263, 23.09921872306443, 17.09921872306443, 17.09921872306443, 17.09921872306443, 20.09921872306443, 17.09921872306443, 25.484371794272622, 20.09921872306443]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 16
Depth 2: State = 0x87c9, Legal Moves = [((0, 0), (1, 0)), ((0, 4), (0, 5)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0xa892, Score: 19
Depth 3: State = 0xa892, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa892: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x4492, Score: 25
Depth 4: State = 0x4492, Legal Moves = [((1, 5), (2, 5)), ((2, 8), (2, 9)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x4492: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x4492, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.22222222222222, N[0x87cd, ((5, 3), (5, 4))] = 63
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((0, 0), (1, 0))] = 28.0, N[0x87c9, ((0, 0), (1, 0))] = 1
Updated Q[0xa892, ((1, 1), (1, 2))] = 28.0, N[0xa892, ((1, 1), (1, 2))] = 1
Updated Q[0x4492, ((1, 5), (2, 5))] = 28.0, N[0x4492, ((1, 5), (2, 5))] = 1

--- Simulation 84 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.102103852761942, 17.102103852761942, 20.102103852761942, 26.102103852761942, 17.102103852761942, 21.102103852761942, 21.102103852761942, 18.102103852761942, 20.102103852761942, 27.102103852761942, 17.102103852761942, 28.487062413862166, 23.102103852761942, 17.102103852761942, 17.102103852761942, 17.102103852761942, 20.102103852761942, 17.102103852761942, 25.486411889046337, 20.102103852761942]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((0, 5), (0, 6)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 16
Depth 4: State = 0x87cd, Legal Moves = [((0, 2), (1, 2)), ((0, 2), (0, 3)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 3), (3, 4)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x861e, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.125, N[0x87cd, ((5, 3), (5, 4))] = 64
Updated Q[0x87cd, ((0, 4), (1, 4))] = 22.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 22.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 22.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 2), (1, 2))] = 22.0, N[0x87cd, ((0, 2), (1, 2))] = 1

--- Simulation 85 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.104950545462604, 17.104950545462604, 20.104950545462604, 26.104950545462604, 17.104950545462604, 21.104950545462604, 21.104950545462604, 18.104950545462604, 20.104950545462604, 27.104950545462604, 17.104950545462604, 28.388118818182825, 23.104950545462604, 17.104950545462604, 17.104950545462604, 17.104950545462604, 20.104950545462604, 17.104950545462604, 25.488424804758928, 20.104950545462604]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 13
Depth 2: State = 0x87ca, Legal Moves = [((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 3), (2, 3)), ((1, 3), (1, 4)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.123076923076923, N[0x87cd, ((5, 3), (5, 4))] = 65
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((0, 3), (1, 3))] = 28.0, N[0x87ca, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 28.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 28.0, N[0x87cd, ((1, 5), (2, 5))] = 1

--- Simulation 86 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.107759772006837, 17.107759772006837, 20.107759772006837, 26.107759772006837, 17.107759772006837, 21.107759772006837, 21.107759772006837, 18.107759772006837, 20.107759772006837, 27.107759772006837, 17.107759772006837, 28.3845123469756, 23.107759772006837, 17.107759772006837, 17.107759772006837, 17.107759772006837, 20.107759772006837, 17.107759772006837, 25.490411227898246, 20.107759772006837]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 16
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 7), (2, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 19
Depth 2: State = 0x87ca, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 7), (2, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x22c9, Score: 22
Depth 3: State = 0x22c9, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 7), (2, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x22c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x231f, Score: 25
Depth 4: State = 0x231f, Legal Moves = [((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 7), (2, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x231f: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x231f, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.12121212121212, N[0x87cd, ((5, 3), (5, 4))] = 66
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((1, 2), (2, 2))] = 28.0, N[0x87ca, ((1, 2), (2, 2))] = 1
Updated Q[0x22c9, ((0, 1), (1, 1))] = 28.0, N[0x22c9, ((0, 1), (1, 1))] = 1
Updated Q[0x231f, ((1, 5), (2, 5))] = 28.0, N[0x231f, ((1, 5), (2, 5))] = 1

--- Simulation 87 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.110532467472012, 17.110532467472012, 20.110532467472012, 26.110532467472012, 17.110532467472012, 21.110532467472012, 21.110532467472012, 18.110532467472012, 20.110532467472012, 27.110532467472012, 17.110532467472012, 28.38100070939354, 23.110532467472012, 17.110532467472012, 17.110532467472012, 17.110532467472012, 20.110532467472012, 17.110532467472012, 25.492371819663838, 20.110532467472012]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 22
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 8), (1, 9)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 25
Depth 4: State = 0x87cd, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (0, 4)), ((1, 2), (2, 2)), ((1, 8), (1, 9)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87c9, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.119402985074625, N[0x87cd, ((5, 3), (5, 4))] = 67
Updated Q[0x87cd, ((0, 5), (1, 5))] = 28.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 28.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 2), (0, 3))] = 28.0, N[0x87cd, ((0, 2), (0, 3))] = 1

--- Simulation 88 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.113269532893185, 17.113269532893185, 20.113269532893185, 26.113269532893185, 17.113269532893185, 21.113269532893185, 21.113269532893185, 18.113269532893185, 20.113269532893185, 27.113269532893185, 17.113269532893185, 28.377579949683295, 23.113269532893185, 17.113269532893185, 17.113269532893185, 17.113269532893185, 20.113269532893185, 17.113269532893185, 25.4943072171837, 20.113269532893185]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x86cb, Score: 16
Depth 4: State = 0x86cb, Legal Moves = [((1, 5), (2, 5)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x86cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x86cb, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.985294117647058, N[0x87cd, ((5, 3), (5, 4))] = 68
Updated Q[0x87cd, ((0, 7), (0, 8))] = 19.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 0), (1, 0))] = 19.0, N[0x87cd, ((0, 0), (1, 0))] = 1
Updated Q[0x86cb, ((1, 5), (2, 5))] = 19.0, N[0x86cb, ((1, 5), (2, 5))] = 1

--- Simulation 89 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.1159718368821, 17.1159718368821, 20.1159718368821, 26.1159718368821, 17.1159718368821, 21.1159718368821, 21.1159718368821, 18.1159718368821, 20.1159718368821, 27.1159718368821, 17.1159718368821, 28.241893393655797, 23.1159718368821, 17.1159718368821, 17.1159718368821, 17.1159718368821, 20.1159718368821, 17.1159718368821, 25.496218034659087, 20.1159718368821]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 10
Depth 2: State = 0x87c9, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87c9, Score: 13
Depth 3: State = 0x87c9, Legal Moves = [((0, 4), (0, 5)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((3, 7), (3, 8)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (5, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87c9, Score: 16
Depth 4: State = 0x87c9, Legal Moves = [((1, 3), (2, 3)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((2, 4), (2, 5)), ((3, 7), (3, 8)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (5, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x87cd, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.855072463768117, N[0x87cd, ((5, 3), (5, 4))] = 69
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 5), (2, 5))] = 19.0, N[0x87c9, ((1, 5), (2, 5))] = 1
Updated Q[0x87c9, ((0, 4), (0, 5))] = 19.0, N[0x87c9, ((0, 4), (0, 5))] = 1
Updated Q[0x87c9, ((1, 3), (2, 3))] = 19.0, N[0x87c9, ((1, 3), (2, 3))] = 1

--- Simulation 90 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.11864021715159, 17.11864021715159, 20.11864021715159, 26.11864021715159, 17.11864021715159, 21.11864021715159, 21.11864021715159, 18.11864021715159, 20.11864021715159, 27.11864021715159, 17.11864021715159, 28.110126773691732, 23.11864021715159, 17.11864021715159, 17.11864021715159, 17.11864021715159, 20.11864021715159, 17.11864021715159, 25.49810486444243, 20.11864021715159]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((0, 5), (0, 6)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 16
Depth 4: State = 0x87cd, Legal Moves = [((0, 2), (0, 3)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87c9, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.728571428571428, N[0x87cd, ((5, 3), (5, 4))] = 70
Updated Q[0x87cd, ((0, 4), (1, 4))] = 19.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 19.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 19.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 2), (0, 3))] = 19.0, N[0x87cd, ((0, 2), (0, 3))] = 1

--- Simulation 91 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.1212754819519, 17.1212754819519, 20.1212754819519, 26.1212754819519, 17.1212754819519, 21.1212754819519, 21.1212754819519, 18.1212754819519, 20.1212754819519, 27.1212754819519, 17.1212754819519, 27.982112343002278, 23.1212754819519, 17.1212754819519, 17.1212754819519, 17.1212754819519, 20.1212754819519, 17.1212754819519, 25.49996827805295, 20.1212754819519]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 8), (0, 9)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 25
Depth 4: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.732394366197184, N[0x87cd, ((5, 3), (5, 4))] = 71
Updated Q[0x87cd, ((0, 6), (1, 6))] = 28.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 28.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 28.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 28.0, N[0x87cd, ((0, 6), (1, 6))] = 1

--- Simulation 92 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.123878411424922, 17.123878411424922, 20.123878411424922, 26.123878411424922, 17.123878411424922, 21.123878411424922, 21.123878411424922, 18.123878411424922, 20.123878411424922, 27.123878411424922, 17.123878411424922, 27.984452360488483, 23.123878411424922, 17.123878411424922, 17.123878411424922, 17.123878411424922, 20.123878411424922, 17.123878411424922, 25.501808827134276, 20.123878411424922]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x433e, Score: 16
Depth 4: State = 0x433e, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((0, 4), (0, 5)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x433e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x43e7, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.61111111111111, N[0x87cd, ((5, 3), (5, 4))] = 72
Updated Q[0x87cd, ((0, 7), (0, 8))] = 19.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 19.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x433e, ((0, 1), (1, 1))] = 19.0, N[0x433e, ((0, 1), (1, 1))] = 1

--- Simulation 93 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.126449758881936, 17.126449758881936, 20.126449758881936, 26.126449758881936, 17.126449758881936, 21.126449758881936, 21.126449758881936, 18.126449758881936, 20.126449758881936, 27.126449758881936, 17.126449758881936, 27.861715618504096, 23.126449758881936, 17.126449758881936, 17.126449758881936, 17.126449758881936, 20.126449758881936, 17.126449758881936, 25.503627044357916, 20.126449758881936]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xae3f, Score: 20
Depth 3: State = 0xae3f, Legal Moves = [((0, 3), (1, 3)), ((0, 3), (0, 4)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xae3f: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0xae41, Score: 23
Depth 4: State = 0xae41, Legal Moves = [((1, 0), (1, 1)), ((1, 2), (2, 2)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xae41: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0xaeec, Score: 26
End of simulation with depth 5. Reward (Score): 26
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.589041095890412, N[0x87cd, ((5, 3), (5, 4))] = 73
Updated Q[0x87cd, ((0, 4), (0, 5))] = 26.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 26.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xae3f, ((0, 3), (1, 3))] = 26.0, N[0xae3f, ((0, 3), (1, 3))] = 1
Updated Q[0xae41, ((1, 0), (1, 1))] = 26.0, N[0xae41, ((1, 0), (1, 1))] = 1

--- Simulation 94 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.12899025200992, 17.12899025200992, 20.12899025200992, 26.12899025200992, 17.12899025200992, 21.12899025200992, 21.12899025200992, 18.12899025200992, 20.12899025200992, 27.12899025200992, 17.12899025200992, 27.838220557355033, 23.12899025200992, 17.12899025200992, 17.12899025200992, 17.12899025200992, 20.12899025200992, 17.12899025200992, 25.50542344427627, 20.12899025200992]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x86ca, Score: 46
Depth 4: State = 0x86ca, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((0, 5), (0, 6)), ((0, 6), (0, 7)), ((2, 6), (3, 6)), ((3, 2), (3, 3)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 2), (5, 3)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 7), (6, 8)), ((7, 2), (8, 2)), ((7, 3), (8, 3)), ((7, 5), (8, 5)), ((8, 2), (8, 3)), ((8, 3), (8, 4))]
UCB1 values for moves at state 0x86ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x86cb, Score: 49
End of simulation with depth 5. Reward (Score): 49
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.87837837837838, N[0x87cd, ((5, 3), (5, 4))] = 74
Updated Q[0x87cd, ((0, 6), (0, 7))] = 49.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 49.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 2), (1, 2))] = 49.0, N[0x87cd, ((0, 2), (1, 2))] = 1
Updated Q[0x86ca, ((0, 2), (1, 2))] = 49.0, N[0x86ca, ((0, 2), (1, 2))] = 1

--- Simulation 95 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.13150059401118, 17.13150059401118, 20.13150059401118, 26.13150059401118, 17.13150059401118, 21.13150059401118, 21.13150059401118, 18.13150059401118, 20.13150059401118, 27.13150059401118, 17.13150059401118, 28.126160289413228, 23.13150059401118, 17.13150059401118, 17.13150059401118, 17.13150059401118, 20.13150059401118, 17.13150059401118, 25.50719852412846, 20.13150059401118]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((2, 2), (2, 3)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x21c9, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.8, N[0x87cd, ((5, 3), (5, 4))] = 75
Updated Q[0x87cd, ((0, 6), (0, 7))] = 22.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 22.0, N[0x87cd, ((1, 5), (2, 5))] = 1
Updated Q[0x87cd, ((2, 2), (2, 3))] = 22.0, N[0x87cd, ((2, 2), (2, 3))] = 1

--- Simulation 96 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.133981464680645, 17.133981464680645, 20.133981464680645, 26.133981464680645, 17.133981464680645, 21.133981464680645, 21.133981464680645, 18.133981464680645, 20.133981464680645, 27.133981464680645, 17.133981464680645, 28.04641095461581, 23.133981464680645, 17.133981464680645, 17.133981464680645, 17.133981464680645, 20.133981464680645, 17.133981464680645, 25.508952764602082, 20.133981464680645]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((0, 0), (1, 0)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x86c9, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.763157894736842, N[0x87cd, ((5, 3), (5, 4))] = 76
Updated Q[0x87cd, ((0, 6), (1, 6))] = 25.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 7), (0, 8))] = 25.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 0), (1, 0))] = 25.0, N[0x87cd, ((0, 0), (1, 0))] = 1

--- Simulation 97 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.136433521424863, 17.136433521424863, 20.136433521424863, 26.136433521424863, 17.136433521424863, 21.136433521424863, 21.136433521424863, 18.136433521424863, 20.136433521424863, 27.136433521424863, 17.136433521424863, 28.00822362682852, 23.136433521424863, 17.136433521424863, 17.136433521424863, 17.136433521424863, 20.136433521424863, 17.136433521424863, 25.510686630553774, 20.136433521424863]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 13
Depth 2: State = 0x87c9, Legal Moves = [((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((3, 2), (3, 3)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0x87c9, Score: 16
Depth 3: State = 0x87c9, Legal Moves = [((2, 2), (2, 3)), ((3, 2), (3, 3)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0xa7e6, Score: 19
Depth 4: State = 0xa7e6, Legal Moves = [((1, 0), (1, 1)), ((2, 0), (2, 1)), ((3, 2), (3, 3)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa7e6: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0xa790, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.68831168831169, N[0x87cd, ((5, 3), (5, 4))] = 77
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 4), (1, 5))] = 22.0, N[0x87c9, ((1, 4), (1, 5))] = 1
Updated Q[0x87c9, ((2, 2), (2, 3))] = 22.0, N[0x87c9, ((2, 2), (2, 3))] = 1
Updated Q[0xa7e6, ((1, 0), (1, 1))] = 22.0, N[0xa7e6, ((1, 0), (1, 1))] = 1

--- Simulation 98 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.138857400226435, 17.138857400226435, 20.138857400226435, 26.138857400226435, 17.138857400226435, 21.138857400226435, 21.138857400226435, 18.138857400226435, 20.138857400226435, 27.138857400226435, 17.138857400226435, 27.932057110606458, 23.138857400226435, 17.138857400226435, 17.138857400226435, 17.138857400226435, 20.138857400226435, 17.138857400226435, 25.512400571691142, 20.138857400226435]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x87ca, Score: 13
Depth 3: State = 0x87ca, Legal Moves = [((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 2), (3, 3)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cb, Score: 16
Depth 4: State = 0x87cb, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 2), (3, 3)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cb, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.576923076923077, N[0x87cd, ((5, 3), (5, 4))] = 78
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 19.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x87ca, ((0, 3), (1, 3))] = 19.0, N[0x87ca, ((0, 3), (1, 3))] = 1
Updated Q[0x87cb, ((1, 5), (2, 5))] = 19.0, N[0x87cb, ((1, 5), (2, 5))] = 1

--- Simulation 99 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.14125371655733, 17.14125371655733, 20.14125371655733, 26.14125371655733, 17.14125371655733, 21.14125371655733, 21.14125371655733, 18.14125371655733, 20.14125371655733, 27.14125371655733, 17.14125371655733, 27.81937231767654, 23.14125371655733, 17.14125371655733, 17.14125371655733, 17.14125371655733, 20.14125371655733, 17.14125371655733, 25.514095023218584, 20.14125371655733]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 22
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 3), (1, 4)), ((1, 4), (2, 4)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xca02, Score: 28
Depth 4: State = 0xca02, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xca02: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x443d, Score: 32
End of simulation with depth 5. Reward (Score): 32
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.632911392405063, N[0x87cd, ((5, 3), (5, 4))] = 79
Updated Q[0x87cd, ((0, 5), (1, 5))] = 32.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 32.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 32.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xca02, ((0, 1), (1, 1))] = 32.0, N[0xca02, ((0, 1), (1, 1))] = 1

--- Simulation 100 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.143623066244295, 17.143623066244295, 20.143623066244295, 26.143623066244295, 17.143623066244295, 21.143623066244295, 21.143623066244295, 18.143623066244295, 20.143623066244295, 27.143623066244295, 17.143623066244295, 27.874087830002804, 23.143623066244295, 17.143623066244295, 17.143623066244295, 17.143623066244295, 20.143623066244295, 17.143623066244295, 25.515770406449242, 20.143623066244295]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 2), (0, 3)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87c9, Score: 13
Depth 2: State = 0x87c9, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87c9, Score: 16
Depth 3: State = 0x87c9, Legal Moves = [((1, 5), (1, 6)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (1, 6))
New board state after move: 0x87c9, Score: 22
Depth 4: State = 0x87c9, Legal Moves = [((2, 2), (2, 3)), ((2, 6), (2, 7)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x6502, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.6, N[0x87cd, ((5, 3), (5, 4))] = 80
Updated Q[0x87cd, ((0, 2), (0, 3))] = 25.0, N[0x87cd, ((0, 2), (0, 3))] = 1
Updated Q[0x87c9, ((1, 5), (2, 5))] = 25.0, N[0x87c9, ((1, 5), (2, 5))] = 1
Updated Q[0x87c9, ((1, 5), (1, 6))] = 25.0, N[0x87c9, ((1, 5), (1, 6))] = 1
Updated Q[0x87c9, ((2, 2), (2, 3))] = 25.0, N[0x87c9, ((2, 2), (2, 3))] = 1

Best move selected: ((5, 3), (5, 4))

--- Summary of States Visited ---
State 0x87cd visited 100 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x6504 visited 1 times
State 0x87ca visited 1 times
State 0x87ca visited 1 times
State 0x6603 visited 1 times
State 0x6603 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x22ca visited 1 times
State 0xc9b0 visited 1 times
State 0x6557 visited 1 times
State 0x6557 visited 1 times
State 0x6557 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x2323 visited 1 times
State 0x221e visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x87cb visited 1 times
State 0x87cb visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0xa7e4 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x2374 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xc9af visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x4393 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x6602 visited 1 times
State 0x64ad visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xca06 visited 1 times
State 0x87c9 visited 1 times
State 0x87cb visited 1 times
State 0x86ca visited 1 times
State 0x86ca visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x871e visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0xc9b0 visited 1 times
State 0x8676 visited 1 times
State 0x8676 visited 1 times
State 0x8676 visited 1 times
State 0x65ae visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xcaae visited 1 times
State 0xcaae visited 1 times
State 0x861e visited 1 times
State 0x861e visited 1 times
State 0x861e visited 1 times
State 0x861e visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xa891 visited 1 times
State 0xa891 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x8673 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xa83d visited 1 times
State 0xa93e visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8673 visited 1 times
State 0x8674 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x6659 visited 1 times
State 0x87cd visited 1 times
State 0x8778 visited 1 times
State 0x8677 visited 1 times
State 0x8677 visited 1 times
State 0x87cd visited 1 times
State 0x21ca visited 1 times
State 0x21ca visited 1 times
State 0x21ca visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x44e6 visited 1 times
State 0x44e6 visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x64af visited 1 times
State 0x665b visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xa8e5 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8777 visited 1 times
State 0x8774 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8720 visited 1 times
State 0xc9ad visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x21c9 visited 1 times
State 0xa791 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x443c visited 1 times
State 0x433d visited 1 times
State 0x433d visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x861d visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0xca03 visited 1 times
State 0x65ac visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0xa7e4 visited 1 times
State 0xa7e5 visited 1 times
State 0x87cd visited 1 times
State 0x8621 visited 1 times
State 0x871f visited 1 times
State 0x64ae visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8620 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8776 visited 1 times
State 0xa93d visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x64b0 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x22cc visited 1 times
State 0x2276 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xca06 visited 1 times
State 0xa93d visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x8631 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x64ad visited 1 times
State 0x2222 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x86cb visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8676 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8777 visited 1 times
State 0x8777 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x2321 visited 1 times
State 0x22cb visited 1 times
State 0x2277 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x6603 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8775 visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x6504 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8677 visited 1 times
State 0x861e visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x86ca visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0xa93c visited 1 times
State 0xa792 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x87cb visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0xa892 visited 1 times
State 0x4492 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x22c9 visited 1 times
State 0x231f visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x86cb visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x433e visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xae3f visited 1 times
State 0xae41 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x86ca visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0xa7e6 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87cb visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xca02 visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6504: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x87ca, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 15.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((0, 0), (1, 0))] = 15.0, N[0x87ca, ((0, 0), (1, 0))] = 1
Updated Q[0x6504, ((0, 1), (1, 1))] = 15.0, N[0x6504, ((0, 1), (1, 1))] = 1

--- Simulation 2 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [15.0, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 3
Depth 1: State = 0x87ca, Legal Moves = [((0, 5), (1, 5)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87ca, Score: 6
Depth 2: State = 0x87ca, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x6603, Score: 9
Depth 3: State = 0x6603, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6603: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x6603, Score: 12
Depth 4: State = 0x6603, Legal Moves = [((2, 1), (3, 1)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6603: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x6658, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((0, 5), (1, 5))] = 15.0, N[0x87ca, ((0, 5), (1, 5))] = 1
Updated Q[0x87ca, ((1, 2), (2, 2))] = 15.0, N[0x87ca, ((1, 2), (2, 2))] = 1
Updated Q[0x6603, ((1, 0), (1, 1))] = 15.0, N[0x6603, ((1, 0), (1, 1))] = 1
Updated Q[0x6603, ((2, 1), (3, 1))] = 15.0, N[0x6603, ((2, 1), (3, 1))] = 1

--- Simulation 3 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [15.832554611157697, 15.832554611157697, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (1, 6))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 12
Depth 3: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 3), (4, 3)), ((3, 5), (4, 5)), ((4, 2), (4, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x22ca, Score: 15
Depth 4: State = 0x22ca, Legal Moves = [((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 3), (4, 3)), ((3, 5), (4, 5)), ((4, 2), (4, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x22ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0x22ca, Score: 18
End of simulation with depth 5. Reward (Score): 18
Updated Q[0x87cd, ((1, 5), (1, 6))] = 18.0, N[0x87cd, ((1, 5), (1, 6))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 18.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 18.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 18.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0x22ca, ((1, 4), (1, 5))] = 18.0, N[0x22ca, ((1, 4), (1, 5))] = 1

--- Simulation 4 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.048147073968206, 16.048147073968206, 19.048147073968206, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0xc9b0, Score: 9
Depth 1: State = 0xc9b0, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (0, 5)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xc9b0: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x6557, Score: 12
Depth 2: State = 0x6557, Legal Moves = [((0, 4), (0, 5)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6557: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x6557, Score: 15
Depth 3: State = 0x6557, Legal Moves = [((1, 4), (2, 4)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6557: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x6557, Score: 18
Depth 4: State = 0x6557, Legal Moves = [((0, 3), (1, 3)), ((1, 4), (1, 5)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((3, 2), (3, 3)), ((3, 5), (4, 5)), ((3, 6), (3, 7)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6557: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x6556, Score: 24
End of simulation with depth 5. Reward (Score): 24
Updated Q[0x87cd, ((2, 2), (2, 3))] = 24.0, N[0x87cd, ((2, 2), (2, 3))] = 1
Updated Q[0xc9b0, ((0, 1), (1, 1))] = 24.0, N[0xc9b0, ((0, 1), (1, 1))] = 1
Updated Q[0x6557, ((0, 4), (0, 5))] = 24.0, N[0x6557, ((0, 4), (0, 5))] = 1
Updated Q[0x6557, ((1, 4), (2, 4))] = 24.0, N[0x6557, ((1, 4), (2, 4))] = 1
Updated Q[0x6557, ((0, 3), (1, 3))] = 24.0, N[0x6557, ((0, 3), (1, 3))] = 1

--- Simulation 5 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.177410022515474, 16.177410022515474, 19.177410022515474, 25.177410022515474, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((3, 5), (4, 5))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x2323, Score: 9
Depth 3: State = 0x2323, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 0), (2, 1)), ((2, 5), (2, 6)), ((3, 6), (3, 7)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2323: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x221e, Score: 12
Depth 4: State = 0x221e, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 0), (2, 1)), ((2, 5), (2, 6)), ((3, 6), (3, 7)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x221e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x22c9, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((3, 5), (4, 5))] = 15.0, N[0x87cd, ((3, 5), (4, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 15.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x2323, ((0, 1), (1, 1))] = 15.0, N[0x2323, ((0, 1), (1, 1))] = 1
Updated Q[0x221e, ((1, 0), (1, 1))] = 15.0, N[0x221e, ((1, 0), (1, 1))] = 1

--- Simulation 6 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.268636241179518, 16.268636241179518, 19.268636241179518, 25.268636241179518, 16.268636241179518, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 3), (4, 4))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x87cb, Score: 6
Depth 2: State = 0x87cb, Legal Moves = [((0, 5), (1, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cb, Score: 9
Depth 3: State = 0x87cb, Legal Moves = [((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((3, 5), (4, 5)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (1, 6))
New board state after move: 0x87cb, Score: 12
Depth 4: State = 0x87cb, Legal Moves = [((2, 2), (2, 3)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x6501, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((4, 3), (4, 4))] = 19.0, N[0x87cd, ((4, 3), (4, 4))] = 1
Updated Q[0x87cd, ((0, 2), (1, 2))] = 19.0, N[0x87cd, ((0, 2), (1, 2))] = 1
Updated Q[0x87cb, ((0, 5), (1, 5))] = 19.0, N[0x87cb, ((0, 5), (1, 5))] = 1
Updated Q[0x87cb, ((1, 5), (1, 6))] = 19.0, N[0x87cb, ((1, 5), (1, 6))] = 1
Updated Q[0x87cb, ((2, 2), (2, 3))] = 19.0, N[0x87cb, ((2, 2), (2, 3))] = 1

--- Simulation 7 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.33856619904585, 16.33856619904585, 19.33856619904585, 25.33856619904585, 16.33856619904585, 20.33856619904585, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 4), (4, 5))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((3, 7), (4, 7)), ((4, 2), (5, 2)), ((4, 4), (5, 4)), ((4, 5), (5, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (6, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((3, 7), (4, 7)), ((4, 2), (5, 2)), ((4, 4), (5, 4)), ((4, 5), (5, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (6, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 12
Depth 3: State = 0x87c9, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((3, 7), (4, 7)), ((4, 2), (5, 2)), ((4, 4), (5, 4)), ((4, 5), (5, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (6, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xa7e4, Score: 16
Depth 4: State = 0xa7e4, Legal Moves = [((1, 0), (1, 1)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((3, 7), (4, 7)), ((4, 2), (5, 2)), ((4, 4), (5, 4)), ((4, 5), (5, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (6, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa7e4: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0xa78f, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((4, 4), (4, 5))] = 19.0, N[0x87cd, ((4, 4), (4, 5))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 19.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 2), (2, 2))] = 19.0, N[0x87c9, ((1, 2), (2, 2))] = 1
Updated Q[0xa7e4, ((1, 0), (1, 1))] = 19.0, N[0xa7e4, ((1, 0), (1, 1))] = 1

--- Simulation 8 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.39495883417946, 16.39495883417946, 19.39495883417946, 25.39495883417946, 16.39495883417946, 20.39495883417946, 20.39495883417946, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 6), (5, 6))
New board state after move: 0x87cd, Score: 4
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 7
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 4), (3, 5)), ((3, 5), (3, 6)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 10
Depth 3: State = 0x87cd, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 4), (3, 5)), ((3, 5), (3, 6)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x2374, Score: 13
Depth 4: State = 0x2374, Legal Moves = [((0, 0), (0, 1)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 4), (3, 5)), ((3, 5), (3, 6)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2374: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0xca06, Score: 16
End of simulation with depth 5. Reward (Score): 16
Updated Q[0x87cd, ((4, 6), (5, 6))] = 16.0, N[0x87cd, ((4, 6), (5, 6))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 16.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 16.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 0), (1, 0))] = 16.0, N[0x87cd, ((0, 0), (1, 0))] = 1
Updated Q[0x2374, ((0, 0), (0, 1))] = 16.0, N[0x2374, ((0, 0), (0, 1))] = 1

--- Simulation 9 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.442026886600882, 16.442026886600882, 19.442026886600882, 25.442026886600882, 16.442026886600882, 20.442026886600882, 20.442026886600882, 17.442026886600882, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 6), (4, 7))
New board state after move: 0x87cd, Score: 6
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 9
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 4), (3, 5)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 12
Depth 3: State = 0x87cd, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 4), (3, 5)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0xc9af, Score: 15
Depth 4: State = 0xc9af, Legal Moves = [((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 4), (3, 5)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xc9af: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 6), (2, 6))
New board state after move: 0xc9af, Score: 18
End of simulation with depth 5. Reward (Score): 18
Updated Q[0x87cd, ((4, 6), (4, 7))] = 18.0, N[0x87cd, ((4, 6), (4, 7))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 18.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 18.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 0), (1, 0))] = 18.0, N[0x87cd, ((0, 0), (1, 0))] = 1
Updated Q[0xc9af, ((1, 6), (2, 6))] = 18.0, N[0xc9af, ((1, 6), (2, 6))] = 1

--- Simulation 10 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.48230380736751, 16.48230380736751, 19.48230380736751, 25.48230380736751, 16.48230380736751, 20.48230380736751, 20.48230380736751, 17.48230380736751, 19.48230380736751, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 7), (5, 7))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 3), (4, 4)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 10
Depth 2: State = 0x87c9, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 3), (4, 4)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87c9, Score: 13
Depth 3: State = 0x87c9, Legal Moves = [((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 7), (3, 8)), ((4, 3), (4, 4)), ((4, 5), (4, 6)), ((5, 1), (5, 2)), ((5, 5), (5, 6)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x4393, Score: 22
Depth 4: State = 0x4393, Legal Moves = [((0, 3), (1, 3)), ((0, 3), (0, 4)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((3, 3), (4, 3)), ((3, 7), (3, 8)), ((4, 5), (4, 6)), ((5, 5), (5, 6)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x4393: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4393, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((4, 7), (5, 7))] = 25.0, N[0x87cd, ((4, 7), (5, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 5), (2, 5))] = 25.0, N[0x87c9, ((1, 5), (2, 5))] = 1
Updated Q[0x87c9, ((2, 2), (2, 3))] = 25.0, N[0x87c9, ((2, 2), (2, 3))] = 1
Updated Q[0x4393, ((0, 3), (1, 3))] = 25.0, N[0x4393, ((0, 3), (1, 3))] = 1

--- Simulation 11 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.517427129385148, 16.517427129385148, 19.517427129385148, 25.517427129385148, 16.517427129385148, 20.517427129385148, 20.517427129385148, 17.517427129385148, 19.517427129385148, 26.517427129385148, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((5, 1), (5, 2))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 1), (4, 1)), ((3, 2), (4, 2)), ((3, 5), (4, 5)), ((4, 1), (5, 1)), ((4, 1), (4, 2)), ((4, 2), (5, 2)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((2, 2), (2, 3)), ((2, 7), (2, 8)), ((3, 1), (4, 1)), ((3, 2), (4, 2)), ((3, 5), (4, 5)), ((4, 1), (5, 1)), ((4, 1), (4, 2)), ((4, 2), (5, 2)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x6602, Score: 9
Depth 3: State = 0x6602, Legal Moves = [((1, 3), (2, 3)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 1), (4, 1)), ((3, 2), (4, 2)), ((3, 5), (4, 5)), ((4, 1), (5, 1)), ((4, 1), (4, 2)), ((4, 2), (5, 2)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6602: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x64ad, Score: 12
Depth 4: State = 0x64ad, Legal Moves = [((0, 1), (1, 1)), ((1, 1), (1, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 1), (4, 1)), ((3, 1), (3, 2)), ((3, 2), (4, 2)), ((3, 5), (4, 5)), ((4, 1), (5, 1)), ((4, 1), (4, 2)), ((4, 2), (5, 2)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x64ad: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x655b, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((5, 1), (5, 2))] = 15.0, N[0x87cd, ((5, 1), (5, 2))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((2, 2), (2, 3))] = 15.0, N[0x87cd, ((2, 2), (2, 3))] = 1
Updated Q[0x6602, ((1, 3), (2, 3))] = 15.0, N[0x6602, ((1, 3), (2, 3))] = 1
Updated Q[0x64ad, ((0, 1), (1, 1))] = 15.0, N[0x64ad, ((0, 1), (1, 1))] = 1

--- Simulation 12 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.548513891703386, 16.548513891703386, 19.548513891703386, 25.548513891703386, 16.548513891703386, 20.548513891703386, 20.548513891703386, 17.548513891703386, 19.548513891703386, 26.548513891703386, 16.548513891703386, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 5), (0, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xca06, Score: 22
Depth 4: State = 0xca06, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xca06: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x86c9, Score: 31
End of simulation with depth 5. Reward (Score): 31
Updated Q[0x87cd, ((5, 3), (5, 4))] = 31.0, N[0x87cd, ((5, 3), (5, 4))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 31.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 31.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 31.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xca06, ((0, 1), (1, 1))] = 31.0, N[0xca06, ((0, 1), (1, 1))] = 1

--- Simulation 13 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.576358667876065, 16.576358667876065, 19.576358667876065, 25.576358667876065, 16.576358667876065, 20.576358667876065, 20.576358667876065, 17.576358667876065, 19.576358667876065, 26.576358667876065, 16.576358667876065, 32.576358667876065, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((5, 4), (5, 5))
New board state after move: 0x87c9, Score: 6
Depth 1: State = 0x87c9, Legal Moves = [((0, 2), (1, 2)), ((0, 4), (1, 4)), ((0, 5), (1, 5)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (3, 2)), ((2, 5), (2, 6)), ((3, 2), (3, 3)), ((3, 5), (3, 6)), ((3, 6), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (7, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x87cb, Score: 9
Depth 2: State = 0x87cb, Legal Moves = [((0, 3), (1, 3)), ((0, 5), (1, 5)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (3, 2)), ((2, 5), (2, 6)), ((3, 2), (3, 3)), ((3, 5), (3, 6)), ((3, 6), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (7, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x86ca, Score: 12
Depth 3: State = 0x86ca, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 5), (2, 6)), ((3, 2), (3, 3)), ((3, 5), (3, 6)), ((3, 6), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (7, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x86ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x86ca, Score: 15
Depth 4: State = 0x86ca, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (2, 2)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((3, 5), (3, 6)), ((3, 6), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (7, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x86ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x8720, Score: 21
End of simulation with depth 5. Reward (Score): 21
Updated Q[0x87cd, ((5, 4), (5, 5))] = 21.0, N[0x87cd, ((5, 4), (5, 5))] = 1
Updated Q[0x87c9, ((0, 2), (1, 2))] = 21.0, N[0x87c9, ((0, 2), (1, 2))] = 1
Updated Q[0x87cb, ((0, 3), (1, 3))] = 21.0, N[0x87cb, ((0, 3), (1, 3))] = 1
Updated Q[0x86ca, ((0, 5), (1, 5))] = 21.0, N[0x86ca, ((0, 5), (1, 5))] = 1
Updated Q[0x86ca, ((1, 1), (1, 2))] = 21.0, N[0x86ca, ((1, 1), (1, 2))] = 1

--- Simulation 14 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.601545927365663, 16.601545927365663, 19.601545927365663, 25.601545927365663, 16.601545927365663, 20.601545927365663, 20.601545927365663, 17.601545927365663, 19.601545927365663, 26.601545927365663, 16.601545927365663, 32.60154592736566, 22.601545927365663, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((5, 6), (6, 6))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 4), (4, 4)), ((3, 7), (4, 7)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 4), (4, 4)), ((3, 7), (4, 7)), ((3, 7), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 9
Depth 3: State = 0x87cd, Legal Moves = [((1, 0), (1, 1)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 4), (4, 4)), ((3, 7), (4, 7)), ((3, 7), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x871e, Score: 12
Depth 4: State = 0x871e, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (1, 3)), ((1, 6), (1, 7)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 4), (4, 4)), ((3, 7), (4, 7)), ((3, 7), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x871e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x871f, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((5, 6), (6, 6))] = 15.0, N[0x87cd, ((5, 6), (6, 6))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 0), (1, 1))] = 15.0, N[0x87cd, ((1, 0), (1, 1))] = 1
Updated Q[0x871e, ((0, 2), (0, 3))] = 15.0, N[0x871e, ((0, 2), (0, 3))] = 1

--- Simulation 15 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.624517568269194, 16.624517568269194, 19.624517568269194, 25.624517568269194, 16.624517568269194, 20.624517568269194, 20.624517568269194, 17.624517568269194, 19.624517568269194, 26.624517568269194, 16.624517568269194, 32.6245175682692, 22.624517568269194, 16.624517568269194, inf, inf, inf, inf, inf, inf]
Selected move: ((5, 6), (5, 7))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 7), (6, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (7, 6)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 7), (6, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (7, 6)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 9
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 7), (6, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (7, 6)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 12
Depth 4: State = 0x87c9, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 7), (6, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (7, 6)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0xca03, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((5, 6), (5, 7))] = 15.0, N[0x87cd, ((5, 6), (5, 7))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 15.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((0, 0), (1, 0))] = 15.0, N[0x87c9, ((0, 0), (1, 0))] = 1

--- Simulation 16 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.645615447515674, 16.645615447515674, 19.645615447515674, 25.645615447515674, 16.645615447515674, 20.645615447515674, 20.645615447515674, 17.645615447515674, 19.645615447515674, 26.645615447515674, 16.645615447515674, 32.645615447515674, 22.645615447515674, 16.645615447515674, 16.645615447515674, inf, inf, inf, inf, inf]
Selected move: ((5, 8), (5, 9))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 9
Depth 3: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0xc9b0, Score: 12
Depth 4: State = 0xc9b0, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xc9b0: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x87cb, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((5, 8), (5, 9))] = 15.0, N[0x87cd, ((5, 8), (5, 9))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 15.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0xc9b0, ((0, 1), (1, 1))] = 15.0, N[0xc9b0, ((0, 1), (1, 1))] = 1

--- Simulation 17 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.665109222315394, 16.665109222315394, 19.665109222315394, 25.665109222315394, 16.665109222315394, 20.665109222315394, 20.665109222315394, 17.665109222315394, 19.665109222315394, 26.665109222315394, 16.665109222315394, 32.665109222315394, 22.665109222315394, 16.665109222315394, 16.665109222315394, 16.665109222315394, inf, inf, inf, inf]
Selected move: ((6, 1), (7, 1))
New board state after move: 0x8676, Score: 3
Depth 1: State = 0x8676, Legal Moves = [((0, 5), (1, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (6, 1)), ((5, 2), (6, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 2), (8, 2)), ((8, 2), (9, 2)), ((8, 3), (9, 3))]
UCB1 values for moves at state 0x8676: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x8676, Score: 6
Depth 2: State = 0x8676, Legal Moves = [((1, 2), (1, 3)), ((1, 6), (1, 7)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (6, 1)), ((5, 2), (6, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 2), (8, 2)), ((8, 2), (9, 2)), ((8, 3), (9, 3))]
UCB1 values for moves at state 0x8676: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x8676, Score: 9
Depth 3: State = 0x8676, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((0, 2), (0, 3)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (6, 1)), ((5, 2), (6, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 2), (8, 2)), ((8, 2), (9, 2)), ((8, 3), (9, 3))]
UCB1 values for moves at state 0x8676: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x65ae, Score: 12
Depth 4: State = 0x65ae, Legal Moves = [((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (6, 1)), ((5, 2), (6, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 2), (8, 2)), ((8, 2), (9, 2)), ((8, 3), (9, 3))]
UCB1 values for moves at state 0x65ae: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x22cd, Score: 18
End of simulation with depth 5. Reward (Score): 18
Updated Q[0x87cd, ((6, 1), (7, 1))] = 18.0, N[0x87cd, ((6, 1), (7, 1))] = 1
Updated Q[0x8676, ((0, 5), (1, 5))] = 18.0, N[0x8676, ((0, 5), (1, 5))] = 1
Updated Q[0x8676, ((1, 2), (1, 3))] = 18.0, N[0x8676, ((1, 2), (1, 3))] = 1
Updated Q[0x8676, ((0, 1), (1, 1))] = 18.0, N[0x8676, ((0, 1), (1, 1))] = 1
Updated Q[0x65ae, ((2, 1), (2, 2))] = 18.0, N[0x65ae, ((2, 1), (2, 2))] = 1

--- Simulation 18 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.68321518055661, 16.68321518055661, 19.68321518055661, 25.68321518055661, 16.68321518055661, 20.68321518055661, 20.68321518055661, 17.68321518055661, 19.68321518055661, 26.68321518055661, 16.68321518055661, 32.68321518055661, 22.68321518055661, 16.68321518055661, 16.68321518055661, 16.68321518055661, 19.68321518055661, inf, inf, inf]
Selected move: ((6, 4), (6, 5))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 5), (1, 6)), ((2, 2), (3, 2)), ((3, 2), (3, 3)), ((3, 6), (4, 6)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (7, 1)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 6), (1, 7)), ((2, 2), (3, 2)), ((2, 4), (2, 5)), ((3, 6), (4, 6)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (7, 1)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 9
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((2, 2), (3, 2)), ((3, 6), (4, 6)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (7, 1)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 12
Depth 4: State = 0x87cd, Legal Moves = [((2, 2), (3, 2)), ((3, 6), (4, 6)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (7, 1)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x665a, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((6, 4), (6, 5))] = 15.0, N[0x87cd, ((6, 4), (6, 5))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 15.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 4), (1, 4))] = 15.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((2, 2), (3, 2))] = 15.0, N[0x87cd, ((2, 2), (3, 2))] = 1

--- Simulation 19 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.70010933704164, 16.70010933704164, 19.70010933704164, 25.70010933704164, 16.70010933704164, 20.70010933704164, 20.70010933704164, 17.70010933704164, 19.70010933704164, 26.70010933704164, 16.70010933704164, 32.70010933704164, 22.70010933704164, 16.70010933704164, 16.70010933704164, 16.70010933704164, 19.70010933704164, 16.70010933704164, inf, inf]
Selected move: ((6, 7), (6, 8))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 9
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xcaae, Score: 21
Depth 3: State = 0xcaae, Legal Moves = [((1, 4), (1, 5)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 4), (2, 5)), ((2, 7), (2, 8)), ((3, 4), (4, 4)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0xcaae: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0xcaae, Score: 24
Depth 4: State = 0xcaae, Legal Moves = [((1, 6), (1, 7)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 7), (2, 8)), ((3, 4), (4, 4)), ((3, 4), (3, 5)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0xcaae: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 6), (1, 7))
New board state after move: 0xcaae, Score: 27
End of simulation with depth 5. Reward (Score): 27
Updated Q[0x87cd, ((6, 7), (6, 8))] = 27.0, N[0x87cd, ((6, 7), (6, 8))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 27.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 27.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xcaae, ((1, 4), (1, 5))] = 27.0, N[0xcaae, ((1, 4), (1, 5))] = 1
Updated Q[0xcaae, ((1, 6), (1, 7))] = 27.0, N[0xcaae, ((1, 6), (1, 7))] = 1

--- Simulation 20 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.71593676432625, 16.71593676432625, 19.71593676432625, 25.71593676432625, 16.71593676432625, 20.71593676432625, 20.71593676432625, 17.71593676432625, 19.71593676432625, 26.71593676432625, 16.71593676432625, 32.71593676432625, 22.71593676432625, 16.71593676432625, 16.71593676432625, 16.71593676432625, 19.71593676432625, 16.71593676432625, 28.71593676432625, inf]
Selected move: ((7, 3), (8, 3))
New board state after move: 0x861e, Score: 3
Depth 1: State = 0x861e, Legal Moves = [((0, 5), (1, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (6, 2)), ((6, 7), (6, 8)), ((8, 2), (9, 2))]
UCB1 values for moves at state 0x861e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x861e, Score: 6
Depth 2: State = 0x861e, Legal Moves = [((1, 6), (1, 7)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (6, 2)), ((6, 7), (6, 8)), ((8, 2), (9, 2))]
UCB1 values for moves at state 0x861e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 6), (1, 7))
New board state after move: 0x861e, Score: 9
Depth 3: State = 0x861e, Legal Moves = [((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((4, 4), (4, 5)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (6, 2)), ((6, 7), (6, 8)), ((8, 2), (9, 2))]
UCB1 values for moves at state 0x861e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (1, 6))
New board state after move: 0x861e, Score: 12
Depth 4: State = 0x861e, Legal Moves = [((0, 3), (1, 3)), ((1, 8), (1, 9)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 4), (4, 4)), ((3, 5), (4, 5)), ((3, 6), (4, 6)), ((4, 4), (4, 5)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (6, 2)), ((6, 7), (6, 8)), ((8, 2), (9, 2))]
UCB1 values for moves at state 0x861e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x861e, Score: 18
End of simulation with depth 5. Reward (Score): 18
Updated Q[0x87cd, ((7, 3), (8, 3))] = 18.0, N[0x87cd, ((7, 3), (8, 3))] = 1
Updated Q[0x861e, ((0, 5), (1, 5))] = 18.0, N[0x861e, ((0, 5), (1, 5))] = 1
Updated Q[0x861e, ((1, 6), (1, 7))] = 18.0, N[0x861e, ((1, 6), (1, 7))] = 1
Updated Q[0x861e, ((1, 5), (1, 6))] = 18.0, N[0x861e, ((1, 5), (1, 6))] = 1
Updated Q[0x861e, ((0, 3), (1, 3))] = 18.0, N[0x861e, ((0, 3), (1, 3))] = 1

--- Simulation 21 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.730818382602287, 16.730818382602287, 19.730818382602287, 25.730818382602287, 16.730818382602287, 20.730818382602287, 20.730818382602287, 17.730818382602287, 19.730818382602287, 26.730818382602287, 16.730818382602287, 32.73081838260229, 22.730818382602287, 16.730818382602287, 16.730818382602287, 16.730818382602287, 19.730818382602287, 16.730818382602287, 28.730818382602287, 19.730818382602287]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 22
Depth 4: State = 0x87c9, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xc9ac, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.0, N[0x87cd, ((5, 3), (5, 4))] = 2
Updated Q[0x87cd, ((0, 7), (1, 7))] = 25.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((0, 7), (0, 8))] = 25.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 2), (2, 2))] = 25.0, N[0x87c9, ((1, 2), (2, 2))] = 1

--- Simulation 22 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.744855993405594, 16.744855993405594, 19.744855993405594, 25.744855993405594, 16.744855993405594, 20.744855993405594, 20.744855993405594, 17.744855993405594, 19.744855993405594, 26.744855993405594, 16.744855993405594, 29.233799505131085, 22.744855993405594, 16.744855993405594, 16.744855993405594, 16.744855993405594, 19.744855993405594, 16.744855993405594, 28.744855993405594, 19.744855993405594]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((3, 6), (4, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xa891, Score: 16
Depth 3: State = 0xa891, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa891: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0xa891, Score: 19
Depth 4: State = 0xa891, Legal Moves = [((1, 5), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa891: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0xa891, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.0, N[0x87cd, ((5, 3), (5, 4))] = 3
Updated Q[0x87cd, ((0, 5), (0, 6))] = 22.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xa891, ((0, 1), (1, 1))] = 22.0, N[0xa891, ((0, 1), (1, 1))] = 1
Updated Q[0xa891, ((1, 5), (2, 5))] = 22.0, N[0xa891, ((1, 5), (2, 5))] = 1

--- Simulation 23 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.7581360736184, 16.7581360736184, 19.7581360736184, 25.7581360736184, 16.7581360736184, 20.7581360736184, 20.7581360736184, 17.7581360736184, 19.7581360736184, 26.7581360736184, 16.7581360736184, 27.015060335375573, 22.7581360736184, 16.7581360736184, 16.7581360736184, 16.7581360736184, 19.7581360736184, 16.7581360736184, 28.7581360736184, 19.7581360736184]
Selected move: ((6, 7), (6, 8))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 12
Depth 3: State = 0x87cb, Legal Moves = [((2, 2), (2, 3)), ((3, 2), (4, 2)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x8673, Score: 18
Depth 4: State = 0x8673, Legal Moves = [((0, 2), (1, 2)), ((1, 0), (1, 1)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x8673: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x8674, Score: 21
End of simulation with depth 5. Reward (Score): 21
Updated Q[0x87cd, ((6, 7), (6, 8))] = 24.0, N[0x87cd, ((6, 7), (6, 8))] = 2
Updated Q[0x87cd, ((0, 5), (1, 5))] = 21.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 21.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((2, 2), (2, 3))] = 21.0, N[0x87cb, ((2, 2), (2, 3))] = 1
Updated Q[0x8673, ((0, 2), (1, 2))] = 21.0, N[0x8673, ((0, 2), (1, 2))] = 1

--- Simulation 24 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.7707326777154, 16.7707326777154, 19.7707326777154, 25.7707326777154, 16.7707326777154, 20.7707326777154, 20.7707326777154, 17.7707326777154, 19.7707326777154, 26.7707326777154, 16.7707326777154, 27.02233298814185, 22.7707326777154, 16.7707326777154, 16.7707326777154, 16.7707326777154, 19.7707326777154, 16.7707326777154, 25.25209708408117, 19.7707326777154]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 25
Depth 3: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 31
Depth 4: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 34
End of simulation with depth 5. Reward (Score): 34
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.0, N[0x87cd, ((5, 3), (5, 4))] = 4
Updated Q[0x87cd, ((0, 4), (1, 4))] = 34.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 34.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 34.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 34.0, N[0x87cd, ((0, 6), (1, 6))] = 1

--- Simulation 25 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.782709687623857, 16.782709687623857, 19.782709687623857, 25.782709687623857, 16.782709687623857, 20.782709687623857, 20.782709687623857, 17.782709687623857, 19.782709687623857, 26.782709687623857, 16.782709687623857, 28.89135484381193, 22.782709687623857, 16.782709687623857, 16.782709687623857, 16.782709687623857, 19.782709687623857, 16.782709687623857, 25.26056610900578, 19.782709687623857]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xa83d, Score: 19
Depth 3: State = 0xa83d, Legal Moves = [((1, 0), (1, 1)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa83d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0xa93e, Score: 22
Depth 4: State = 0xa93e, Legal Moves = [((0, 1), (1, 1)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa93e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x86c8, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.4, N[0x87cd, ((5, 3), (5, 4))] = 5
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 25.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0xa83d, ((1, 0), (1, 1))] = 25.0, N[0xa83d, ((1, 0), (1, 1))] = 1
Updated Q[0xa93e, ((0, 1), (1, 1))] = 25.0, N[0xa93e, ((0, 1), (1, 1))] = 1

--- Simulation 26 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.794122577994102, 16.794122577994102, 19.794122577994102, 25.794122577994102, 16.794122577994102, 20.794122577994102, 20.794122577994102, 17.794122577994102, 19.794122577994102, 26.794122577994102, 16.794122577994102, 28.202356008872393, 22.794122577994102, 16.794122577994102, 16.794122577994102, 16.794122577994102, 19.794122577994102, 16.794122577994102, 25.268636241179518, 19.794122577994102]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 10
Depth 2: State = 0x87c9, Legal Moves = [((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 16
Depth 4: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 6), (1, 7)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x871e, Score: 42
End of simulation with depth 5. Reward (Score): 42
Updated Q[0x87cd, ((5, 3), (5, 4))] = 29.833333333333332, N[0x87cd, ((5, 3), (5, 4))] = 6
Updated Q[0x87cd, ((1, 1), (1, 2))] = 42.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 2), (2, 2))] = 42.0, N[0x87c9, ((1, 2), (2, 2))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 42.0, N[0x87cd, ((1, 5), (2, 5))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 42.0, N[0x87cd, ((0, 3), (1, 3))] = 1

--- Simulation 27 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.80501981651767, 16.80501981651767, 19.80501981651767, 25.80501981651767, 16.80501981651767, 20.80501981651767, 20.80501981651767, 17.80501981651767, 19.80501981651767, 26.80501981651767, 16.80501981651767, 30.570229587680068, 22.80501981651767, 16.80501981651767, 16.80501981651767, 16.80501981651767, 19.80501981651767, 16.80501981651767, 25.27634175243574, 19.80501981651767]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x8673, Score: 13
Depth 3: State = 0x8673, Legal Moves = [((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8673: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x8674, Score: 16
Depth 4: State = 0x8674, Legal Moves = [((0, 3), (0, 4)), ((0, 4), (1, 4)), ((0, 5), (1, 5)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8674: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x8673, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 29.571428571428573, N[0x87cd, ((5, 3), (5, 4))] = 7
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 0), (1, 1))] = 28.0, N[0x87cd, ((1, 0), (1, 1))] = 1
Updated Q[0x8673, ((0, 3), (1, 3))] = 28.0, N[0x8673, ((0, 3), (1, 3))] = 1
Updated Q[0x8674, ((0, 3), (0, 4))] = 28.0, N[0x8674, ((0, 3), (0, 4))] = 1

--- Simulation 28 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.815443985917586, 16.815443985917586, 19.815443985917586, 25.815443985917586, 16.815443985917586, 20.815443985917586, 20.815443985917586, 17.815443985917586, 19.815443985917586, 26.815443985917586, 16.815443985917586, 30.257601900843685, 22.815443985917586, 16.815443985917586, 16.815443985917586, 16.815443985917586, 19.815443985917586, 16.815443985917586, 25.28371275330666, 19.815443985917586]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 16
Depth 3: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x6659, Score: 19
Depth 4: State = 0x6659, Legal Moves = [((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6659: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 6), (2, 6))
New board state after move: 0x6659, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 29.375, N[0x87cd, ((5, 3), (5, 4))] = 8
Updated Q[0x87cd, ((0, 5), (1, 5))] = 28.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 28.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0x6659, ((1, 6), (2, 6))] = 28.0, N[0x6659, ((1, 6), (2, 6))] = 1

--- Simulation 29 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.82543269122014, 16.82543269122014, 19.82543269122014, 25.82543269122014, 16.82543269122014, 20.82543269122014, 20.82543269122014, 17.82543269122014, 19.82543269122014, 26.82543269122014, 16.82543269122014, 30.020387917280686, 22.82543269122014, 16.82543269122014, 16.82543269122014, 16.82543269122014, 19.82543269122014, 16.82543269122014, 25.29077583456137, 19.82543269122014]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x8778, Score: 16
Depth 2: State = 0x8778, Legal Moves = [((1, 0), (1, 1)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8778: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x8677, Score: 19
Depth 3: State = 0x8677, Legal Moves = [((1, 4), (1, 5)), ((1, 5), (2, 5)), ((4, 0), (4, 1)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8677: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0x8677, Score: 22
Depth 4: State = 0x8677, Legal Moves = [((4, 0), (4, 1)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8677: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 0), (4, 1))
New board state after move: 0x231f, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 29.22222222222222, N[0x87cd, ((5, 3), (5, 4))] = 9
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x8778, ((1, 0), (1, 1))] = 28.0, N[0x8778, ((1, 0), (1, 1))] = 1
Updated Q[0x8677, ((1, 4), (1, 5))] = 28.0, N[0x8677, ((1, 4), (1, 5))] = 1
Updated Q[0x8677, ((4, 0), (4, 1))] = 28.0, N[0x8677, ((4, 0), (4, 1))] = 1

--- Simulation 30 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.835019299622342, 16.835019299622342, 19.835019299622342, 25.835019299622342, 16.835019299622342, 20.835019299622342, 20.835019299622342, 17.835019299622342, 19.835019299622342, 26.835019299622342, 16.835019299622342, 29.833895322096335, 22.835019299622342, 16.835019299622342, 16.835019299622342, 16.835019299622342, 19.835019299622342, 16.835019299622342, 25.29755459037115, 19.835019299622342]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x21ca, Score: 22
Depth 2: State = 0x21ca, Legal Moves = [((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x21ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x21ca, Score: 25
Depth 3: State = 0x21ca, Legal Moves = [((0, 4), (0, 5)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x21ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x21ca, Score: 28
Depth 4: State = 0x21ca, Legal Moves = [((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x21ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x2276, Score: 31
End of simulation with depth 5. Reward (Score): 31
Updated Q[0x87cd, ((5, 3), (5, 4))] = 29.4, N[0x87cd, ((5, 3), (5, 4))] = 10
Updated Q[0x87cd, ((1, 1), (1, 2))] = 31.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x21ca, ((0, 3), (0, 4))] = 31.0, N[0x21ca, ((0, 3), (0, 4))] = 1
Updated Q[0x21ca, ((0, 4), (0, 5))] = 31.0, N[0x21ca, ((0, 4), (0, 5))] = 1
Updated Q[0x21ca, ((1, 0), (1, 1))] = 31.0, N[0x21ca, ((1, 0), (1, 1))] = 1

--- Simulation 31 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.844233548567576, 16.844233548567576, 19.844233548567576, 25.844233548567576, 16.844233548567576, 20.844233548567576, 20.844233548567576, 17.844233548567576, 19.844233548567576, 26.844233548567576, 16.844233548567576, 29.983197855076828, 22.844233548567576, 16.844233548567576, 16.844233548567576, 16.844233548567576, 19.844233548567576, 16.844233548567576, 25.30407004828386, 19.844233548567576]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 10
Depth 2: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x44e6, Score: 13
Depth 3: State = 0x44e6, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x44e6: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x44e6, Score: 16
Depth 4: State = 0x44e6, Legal Moves = [((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x44e6: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0xca02, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.454545454545453, N[0x87cd, ((5, 3), (5, 4))] = 11
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 19.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0x44e6, ((1, 5), (2, 5))] = 19.0, N[0x44e6, ((1, 5), (2, 5))] = 1
Updated Q[0x44e6, ((2, 2), (3, 2))] = 19.0, N[0x44e6, ((2, 2), (3, 2))] = 1

--- Simulation 32 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.853102049128744, 16.853102049128744, 19.853102049128744, 25.853102049128744, 16.853102049128744, 20.853102049128744, 20.853102049128744, 17.853102049128744, 19.853102049128744, 26.853102049128744, 16.853102049128744, 29.013276745018068, 22.853102049128744, 16.853102049128744, 16.853102049128744, 16.853102049128744, 19.853102049128744, 16.853102049128744, 25.31034102516962, 19.853102049128744]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 13
Depth 2: State = 0x87c9, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x64af, Score: 16
Depth 3: State = 0x64af, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x64af: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x665b, Score: 19
Depth 4: State = 0x665b, Legal Moves = [((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x665b: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x665b, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.916666666666668, N[0x87cd, ((5, 3), (5, 4))] = 12
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((0, 0), (1, 0))] = 22.0, N[0x87c9, ((0, 0), (1, 0))] = 1
Updated Q[0x64af, ((0, 2), (1, 2))] = 22.0, N[0x64af, ((0, 2), (1, 2))] = 1
Updated Q[0x665b, ((1, 5), (2, 5))] = 22.0, N[0x665b, ((1, 5), (2, 5))] = 1

--- Simulation 33 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.861648705529518, 16.861648705529518, 19.861648705529518, 25.861648705529518, 16.861648705529518, 20.861648705529518, 20.861648705529518, 17.861648705529518, 19.861648705529518, 26.861648705529518, 16.861648705529518, 28.45407835730366, 22.861648705529518, 16.861648705529518, 16.861648705529518, 16.861648705529518, 19.861648705529518, 16.861648705529518, 25.31638442386708, 19.861648705529518]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xa8e5, Score: 31
Depth 4: State = 0xa8e5, Legal Moves = [((0, 5), (1, 5)), ((0, 5), (0, 6)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((1, 5), (1, 6)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 6), (6, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa8e5: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0xa8e5, Score: 34
End of simulation with depth 5. Reward (Score): 34
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.384615384615383, N[0x87cd, ((5, 3), (5, 4))] = 13
Updated Q[0x87cd, ((0, 5), (0, 6))] = 34.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 34.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 34.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xa8e5, ((0, 5), (1, 5))] = 34.0, N[0xa8e5, ((0, 5), (1, 5))] = 1

--- Simulation 34 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.86989506696672, 16.86989506696672, 19.86989506696672, 25.86989506696672, 16.86989506696672, 20.86989506696672, 20.86989506696672, 17.86989506696672, 19.86989506696672, 26.86989506696672, 16.86989506696672, 28.903230964898896, 22.86989506696672, 16.86989506696672, 16.86989506696672, 16.86989506696672, 19.86989506696672, 16.86989506696672, 25.322215481959443, 19.86989506696672]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 6), (2, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 19
Depth 4: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x6557, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.928571428571427, N[0x87cd, ((5, 3), (5, 4))] = 14
Updated Q[0x87cd, ((0, 6), (0, 7))] = 22.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 22.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 22.0, N[0x87cc, ((0, 1), (1, 1))] = 1

--- Simulation 35 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.877860624385143, 16.877860624385143, 19.877860624385143, 25.877860624385143, 16.877860624385143, 20.877860624385143, 20.877860624385143, 17.877860624385143, 19.877860624385143, 26.877860624385143, 16.877860624385143, 28.43045079118304, 22.877860624385143, 16.877860624385143, 16.877860624385143, 16.877860624385143, 19.877860624385143, 16.877860624385143, 25.32784798162594, 19.877860624385143]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (0, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((0, 3), (0, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x87cc, Score: 20
Depth 4: State = 0x87cc, Legal Moves = [((0, 0), (0, 1)), ((0, 3), (1, 3)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0xc904, Score: 23
End of simulation with depth 5. Reward (Score): 23
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.6, N[0x87cd, ((5, 3), (5, 4))] = 15
Updated Q[0x87cd, ((0, 3), (0, 4))] = 23.0, N[0x87cd, ((0, 3), (0, 4))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 23.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 23.0, N[0x87cd, ((0, 1), (1, 1))] = 1
Updated Q[0x87cc, ((0, 0), (0, 1))] = 23.0, N[0x87cc, ((0, 0), (0, 1))] = 1

--- Simulation 36 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.88556306218843, 16.88556306218843, 19.88556306218843, 25.88556306218843, 16.88556306218843, 20.88556306218843, 20.88556306218843, 17.88556306218843, 19.88556306218843, 26.88556306218843, 16.88556306218843, 28.086850289205312, 22.88556306218843, 16.88556306218843, 16.88556306218843, 16.88556306218843, 19.88556306218843, 16.88556306218843, 25.33329442762831, 19.88556306218843]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 16
Depth 3: State = 0x87ca, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (2, 2)), ((1, 6), (2, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((1, 0), (1, 1)), ((1, 6), (2, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x8775, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.25, N[0x87cd, ((5, 3), (5, 4))] = 16
Updated Q[0x87cd, ((0, 5), (1, 5))] = 22.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((0, 2), (1, 2))] = 22.0, N[0x87ca, ((0, 2), (1, 2))] = 1
Updated Q[0x87cd, ((1, 0), (1, 1))] = 22.0, N[0x87cd, ((1, 0), (1, 1))] = 1

--- Simulation 37 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.893018472824846, 16.893018472824846, 19.893018472824846, 25.893018472824846, 16.893018472824846, 20.893018472824846, 20.893018472824846, 17.893018472824846, 19.893018472824846, 26.893018472824846, 16.893018472824846, 27.723254618206212, 22.893018472824846, 16.893018472824846, 16.893018472824846, 16.893018472824846, 19.893018472824846, 16.893018472824846, 25.33856619904585, 19.893018472824846]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (0, 5)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x8777, Score: 13
Depth 3: State = 0x8777, Legal Moves = [((0, 3), (1, 3)), ((0, 3), (0, 4)), ((0, 6), (0, 7)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8777: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x8774, Score: 16
Depth 4: State = 0x8774, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((0, 6), (0, 7)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8774: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x8675, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.941176470588236, N[0x87cd, ((5, 3), (5, 4))] = 17
Updated Q[0x87cd, ((0, 3), (0, 4))] = 22.0, N[0x87cd, ((0, 3), (0, 4))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 22.0, N[0x87cd, ((0, 1), (1, 1))] = 1
Updated Q[0x8777, ((0, 3), (1, 3))] = 22.0, N[0x8777, ((0, 3), (1, 3))] = 1
Updated Q[0x8774, ((0, 1), (0, 2))] = 22.0, N[0x8774, ((0, 1), (0, 2))] = 1

--- Simulation 38 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.900241540605883, 16.900241540605883, 19.900241540605883, 25.900241540605883, 16.900241540605883, 20.900241540605883, 20.900241540605883, 17.900241540605883, 19.900241540605883, 26.900241540605883, 16.900241540605883, 27.40205274035909, 22.900241540605883, 16.900241540605883, 16.900241540605883, 16.900241540605883, 19.900241540605883, 16.900241540605883, 25.343673679254792, 19.900241540605883]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 16
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 8), (3, 8)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 22
Depth 2: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 8), (3, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x8720, Score: 25
Depth 3: State = 0x8720, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (0, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 5), (3, 5)), ((2, 8), (3, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8720: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0xc9ad, Score: 28
Depth 4: State = 0xc9ad, Legal Moves = [((0, 3), (0, 4)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 5), (3, 5)), ((2, 8), (3, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xc9ad: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0xc9af, Score: 37
End of simulation with depth 5. Reward (Score): 37
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.5, N[0x87cd, ((5, 3), (5, 4))] = 18
Updated Q[0x87cd, ((0, 4), (1, 4))] = 37.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 37.0, N[0x87cd, ((0, 1), (1, 1))] = 1
Updated Q[0x8720, ((0, 2), (1, 2))] = 37.0, N[0x8720, ((0, 2), (1, 2))] = 1
Updated Q[0xc9ad, ((0, 3), (0, 4))] = 37.0, N[0xc9ad, ((0, 3), (0, 4))] = 1

--- Simulation 39 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.9072456998841, 16.9072456998841, 19.9072456998841, 25.9072456998841, 16.9072456998841, 20.9072456998841, 20.9072456998841, 17.9072456998841, 19.9072456998841, 26.9072456998841, 16.9072456998841, 27.94954212259231, 22.9072456998841, 16.9072456998841, 16.9072456998841, 16.9072456998841, 19.9072456998841, 16.9072456998841, 25.34862636777693, 19.9072456998841]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 13
Depth 2: State = 0x87c9, Legal Moves = [((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 1), (3, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 2), (4, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 1), (3, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 2), (4, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 32
End of simulation with depth 5. Reward (Score): 32
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.736842105263158, N[0x87cd, ((5, 3), (5, 4))] = 19
Updated Q[0x87cd, ((1, 1), (1, 2))] = 32.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((0, 4), (1, 4))] = 32.0, N[0x87c9, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 32.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 32.0, N[0x87cd, ((1, 5), (2, 5))] = 1

--- Simulation 40 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.91404327174953, 16.91404327174953, 19.91404327174953, 25.91404327174953, 16.91404327174953, 20.91404327174953, 20.91404327174953, 17.91404327174953, 19.91404327174953, 26.91404327174953, 16.91404327174953, 28.17595374711159, 22.91404327174953, 16.91404327174953, 16.91404327174953, 16.91404327174953, 19.91404327174953, 16.91404327174953, 25.353432976938578, 19.91404327174953]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 13
Depth 2: State = 0x87ca, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x21c9, Score: 16
Depth 3: State = 0x21c9, Legal Moves = [((0, 2), (0, 3)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x21c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0xa791, Score: 22
Depth 4: State = 0xa791, Legal Moves = [((1, 0), (1, 1)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa791: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0xa791, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.6, N[0x87cd, ((5, 3), (5, 4))] = 20
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((1, 2), (2, 2))] = 25.0, N[0x87ca, ((1, 2), (2, 2))] = 1
Updated Q[0x21c9, ((0, 2), (0, 3))] = 25.0, N[0x21c9, ((0, 2), (0, 3))] = 1
Updated Q[0xa791, ((1, 0), (1, 1))] = 25.0, N[0xa791, ((1, 0), (1, 1))] = 1

--- Simulation 41 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.920645582639843, 16.920645582639843, 19.920645582639843, 25.920645582639843, 16.920645582639843, 20.920645582639843, 20.920645582639843, 17.920645582639843, 19.920645582639843, 26.920645582639843, 16.920645582639843, 28.02946940834674, 22.920645582639843, 16.920645582639843, 16.920645582639843, 16.920645582639843, 19.920645582639843, 16.920645582639843, 25.35810151574062, 19.920645582639843]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 22
Depth 3: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((0, 4), (0, 5)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x87cd, Score: 25
Depth 4: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.61904761904762, N[0x87cd, ((5, 3), (5, 4))] = 21
Updated Q[0x87cd, ((0, 3), (1, 3))] = 28.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 28.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 28.0, N[0x87cd, ((0, 1), (1, 1))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 28.0, N[0x87cd, ((0, 6), (0, 7))] = 1

--- Simulation 42 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.927063067650955, 16.927063067650955, 19.927063067650955, 25.927063067650955, 16.927063067650955, 20.927063067650955, 20.927063067650955, 17.927063067650955, 19.927063067650955, 26.927063067650955, 16.927063067650955, 28.03956725602211, 22.927063067650955, 16.927063067650955, 16.927063067650955, 16.927063067650955, 19.927063067650955, 16.927063067650955, 25.36263936291014, 19.927063067650955]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 11
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 6), (1, 6)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x443c, Score: 51
Depth 2: State = 0x443c, Legal Moves = [((0, 2), (1, 2)), ((0, 6), (0, 7)), ((0, 7), (1, 7)), ((1, 6), (1, 7)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((2, 3), (2, 4)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((3, 7), (4, 7)), ((3, 8), (4, 8)), ((4, 7), (4, 8)), ((4, 8), (5, 8)), ((5, 4), (5, 5)), ((7, 4), (8, 4)), ((7, 5), (7, 6)), ((8, 1), (9, 1))]
UCB1 values for moves at state 0x443c: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x433d, Score: 54
Depth 3: State = 0x433d, Legal Moves = [((0, 6), (0, 7)), ((0, 7), (1, 7)), ((1, 6), (1, 7)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((2, 3), (2, 4)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((3, 7), (4, 7)), ((3, 8), (4, 8)), ((4, 7), (4, 8)), ((4, 8), (5, 8)), ((5, 4), (5, 5)), ((7, 4), (8, 4)), ((7, 5), (7, 6)), ((8, 1), (9, 1))]
UCB1 values for moves at state 0x433d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x433d, Score: 57
Depth 4: State = 0x433d, Legal Moves = [((0, 8), (0, 9)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((2, 3), (2, 4)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((3, 7), (4, 7)), ((3, 8), (4, 8)), ((4, 7), (4, 8)), ((4, 8), (5, 8)), ((5, 4), (5, 5)), ((7, 4), (8, 4)), ((7, 5), (7, 6)), ((8, 1), (9, 1))]
UCB1 values for moves at state 0x433d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 8), (0, 9))
New board state after move: 0x433d, Score: 60
End of simulation with depth 5. Reward (Score): 60
Updated Q[0x87cd, ((5, 3), (5, 4))] = 29.09090909090909, N[0x87cd, ((5, 3), (5, 4))] = 22
Updated Q[0x87cd, ((0, 5), (0, 6))] = 60.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x443c, ((0, 2), (1, 2))] = 60.0, N[0x443c, ((0, 2), (1, 2))] = 1
Updated Q[0x433d, ((0, 6), (0, 7))] = 60.0, N[0x433d, ((0, 6), (0, 7))] = 1
Updated Q[0x433d, ((0, 8), (0, 9))] = 60.0, N[0x433d, ((0, 8), (0, 9))] = 1

--- Simulation 43 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.933305360847935, 16.933305360847935, 19.933305360847935, 25.933305360847935, 16.933305360847935, 20.933305360847935, 20.933305360847935, 17.933305360847935, 19.933305360847935, 26.933305360847935, 16.933305360847935, 29.50309117877601, 22.933305360847935, 16.933305360847935, 16.933305360847935, 16.933305360847935, 19.933305360847935, 16.933305360847935, 25.36705333075988, 19.933305360847935]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 8), (1, 9)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (0, 5)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 8), (1, 9)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x861d, Score: 22
Depth 4: State = 0x861d, Legal Moves = [((0, 3), (1, 3)), ((0, 3), (0, 4)), ((1, 5), (2, 5)), ((1, 8), (1, 9)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x861d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x8722, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 29.043478260869566, N[0x87cd, ((5, 3), (5, 4))] = 23
Updated Q[0x87cd, ((0, 7), (0, 8))] = 28.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 28.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 28.0, N[0x87cd, ((0, 1), (1, 1))] = 1
Updated Q[0x861d, ((0, 3), (1, 3))] = 28.0, N[0x861d, ((0, 3), (1, 3))] = 1

--- Simulation 44 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.939381374483514, 16.939381374483514, 19.939381374483514, 25.939381374483514, 16.939381374483514, 20.939381374483514, 20.939381374483514, 17.939381374483514, 19.939381374483514, 26.939381374483514, 16.939381374483514, 29.4478672318032, 22.939381374483514, 16.939381374483514, 16.939381374483514, 16.939381374483514, 19.939381374483514, 16.939381374483514, 25.37134972120418, 19.939381374483514]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 13
Depth 2: State = 0x87cb, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xca03, Score: 16
Depth 3: State = 0xca03, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xca03: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x65ac, Score: 20
Depth 4: State = 0x65ac, Legal Moves = [((0, 0), (1, 0)), ((0, 2), (0, 3)), ((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 8), (2, 9)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x65ac: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x44e9, Score: 23
End of simulation with depth 5. Reward (Score): 23
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.791666666666668, N[0x87cd, ((5, 3), (5, 4))] = 24
Updated Q[0x87cd, ((1, 1), (1, 2))] = 23.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((1, 2), (2, 2))] = 23.0, N[0x87cb, ((1, 2), (2, 2))] = 1
Updated Q[0xca03, ((0, 1), (1, 1))] = 23.0, N[0xca03, ((0, 1), (1, 1))] = 1
Updated Q[0x65ac, ((0, 0), (1, 0))] = 23.0, N[0x65ac, ((0, 0), (1, 0))] = 1

--- Simulation 45 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.945299368713787, 16.945299368713787, 19.945299368713787, 25.945299368713787, 16.945299368713787, 20.945299368713787, 20.945299368713787, 17.945299368713787, 19.945299368713787, 26.945299368713787, 16.945299368713787, 29.188749237525585, 22.945299368713787, 16.945299368713787, 16.945299368713787, 16.945299368713787, 19.945299368713787, 16.945299368713787, 25.37553437505543, 19.945299368713787]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.52, N[0x87cd, ((5, 3), (5, 4))] = 25
Updated Q[0x87cd, ((0, 4), (0, 5))] = 22.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 22.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 7), (0, 8))] = 22.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 22.0, N[0x87cd, ((0, 6), (0, 7))] = 1

--- Simulation 46 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.951067013141866, 16.951067013141866, 19.951067013141866, 25.951067013141866, 16.951067013141866, 20.951067013141866, 20.951067013141866, 17.951067013141866, 19.951067013141866, 26.951067013141866, 16.951067013141866, 28.910213402628372, 22.951067013141866, 16.951067013141866, 16.951067013141866, 16.951067013141866, 19.951067013141866, 16.951067013141866, 25.379612715541995, 19.951067013141866]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 10
Depth 2: State = 0x87c9, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0xa7e4, Score: 13
Depth 3: State = 0xa7e4, Legal Moves = [((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa7e4: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xa7e5, Score: 16
Depth 4: State = 0xa7e5, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa7e5: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x2221, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.153846153846153, N[0x87cd, ((5, 3), (5, 4))] = 26
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((0, 0), (1, 0))] = 19.0, N[0x87c9, ((0, 0), (1, 0))] = 1
Updated Q[0xa7e4, ((1, 2), (2, 2))] = 19.0, N[0xa7e4, ((1, 2), (2, 2))] = 1
Updated Q[0xa7e5, ((0, 0), (1, 0))] = 19.0, N[0xa7e5, ((0, 0), (1, 0))] = 1

--- Simulation 47 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.956691441308287, 16.956691441308287, 19.956691441308287, 25.956691441308287, 16.956691441308287, 20.956691441308287, 20.956691441308287, 17.956691441308287, 19.956691441308287, 26.956691441308287, 16.956691441308287, 28.537584916973497, 22.956691441308287, 16.956691441308287, 16.956691441308287, 16.956691441308287, 19.956691441308287, 16.956691441308287, 25.38358978683877, 19.956691441308287]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x8621, Score: 20
Depth 2: State = 0x8621, Legal Moves = [((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8621: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x871f, Score: 23
Depth 3: State = 0x871f, Legal Moves = [((0, 4), (0, 5)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x871f: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x64ae, Score: 45
Depth 4: State = 0x64ae, Legal Moves = [((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 3), (3, 3)), ((3, 0), (4, 0)), ((3, 2), (3, 3)), ((3, 3), (3, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x64ae: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xc959, Score: 48
End of simulation with depth 5. Reward (Score): 48
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.88888888888889, N[0x87cd, ((5, 3), (5, 4))] = 27
Updated Q[0x87cd, ((1, 1), (1, 2))] = 48.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x8621, ((1, 0), (1, 1))] = 48.0, N[0x8621, ((1, 0), (1, 1))] = 1
Updated Q[0x871f, ((0, 4), (0, 5))] = 48.0, N[0x871f, ((0, 4), (0, 5))] = 1
Updated Q[0x64ae, ((1, 2), (2, 2))] = 48.0, N[0x64ae, ((1, 2), (2, 2))] = 1

--- Simulation 48 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.962179299072858, 16.962179299072858, 19.962179299072858, 25.962179299072858, 16.962179299072858, 20.962179299072858, 20.962179299072858, 17.962179299072858, 19.962179299072858, 26.962179299072858, 16.962179299072858, 29.266510471061565, 22.962179299072858, 16.962179299072858, 16.962179299072858, 16.962179299072858, 19.962179299072858, 16.962179299072858, 25.387470288278287, 19.962179299072858]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 8), (1, 8))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 16
Depth 4: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x43e9, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.535714285714285, N[0x87cd, ((5, 3), (5, 4))] = 28
Updated Q[0x87cd, ((0, 6), (0, 7))] = 19.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((0, 8), (1, 8))] = 19.0, N[0x87cd, ((0, 8), (1, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 19.0, N[0x87cc, ((0, 1), (1, 1))] = 1

--- Simulation 49 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.96753678768858, 16.96753678768858, 19.96753678768858, 25.96753678768858, 16.96753678768858, 20.96753678768858, 20.96753678768858, 17.96753678768858, 19.96753678768858, 26.96753678768858, 16.96753678768858, 28.907543788256774, 22.96753678768858, 16.96753678768858, 16.96753678768858, 16.96753678768858, 19.96753678768858, 16.96753678768858, 25.39125860480859, 19.96753678768858]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 16
Depth 3: State = 0x87c9, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87c9, Score: 19
Depth 4: State = 0x87c9, Legal Moves = [((2, 2), (2, 3)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0xa8e5, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.310344827586206, N[0x87cd, ((5, 3), (5, 4))] = 29
Updated Q[0x87cd, ((0, 7), (1, 7))] = 22.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 5), (2, 5))] = 22.0, N[0x87c9, ((1, 5), (2, 5))] = 1
Updated Q[0x87c9, ((2, 2), (2, 3))] = 22.0, N[0x87c9, ((2, 2), (2, 3))] = 1

--- Simulation 50 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.97276970224875, 16.97276970224875, 19.97276970224875, 25.97276970224875, 16.97276970224875, 20.97276970224875, 20.97276970224875, 17.97276970224875, 19.97276970224875, 26.97276970224875, 16.97276970224875, 28.67667896459073, 22.97276970224875, 16.97276970224875, 16.97276970224875, 16.97276970224875, 19.97276970224875, 16.97276970224875, 25.39495883417946, 19.97276970224875]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 2), (6, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 2), (6, 2)), ((5, 5), (5, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.2, N[0x87cd, ((5, 3), (5, 4))] = 30
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 25.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 25.0, N[0x87cd, ((1, 5), (2, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 25.0, N[0x87cd, ((0, 4), (0, 5))] = 1

--- Simulation 51 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.977883466088976, 16.977883466088976, 19.977883466088976, 25.977883466088976, 16.977883466088976, 20.977883466088976, 20.977883466088976, 17.977883466088976, 19.977883466088976, 26.977883466088976, 16.977883466088976, 28.561110463497812, 22.977883466088976, 16.977883466088976, 16.977883466088976, 16.977883466088976, 19.977883466088976, 16.977883466088976, 25.39857481126827, 19.977883466088976]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 5), (1, 5)), ((0, 7), (0, 8)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.096774193548388, N[0x87cd, ((5, 3), (5, 4))] = 31
Updated Q[0x87cd, ((0, 4), (0, 5))] = 25.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 7), (0, 8))] = 25.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 25.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1

--- Simulation 52 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.98288316164224, 16.98288316164224, 19.98288316164224, 25.98288316164224, 16.98288316164224, 20.98288316164224, 20.98288316164224, 17.98288316164224, 19.98288316164224, 26.98288316164224, 16.98288316164224, 28.45291052267895, 22.98288316164224, 16.98288316164224, 16.98288316164224, 16.98288316164224, 19.98288316164224, 16.98288316164224, 25.40211012989785, 19.98288316164224]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 6), (2, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x8620, Score: 16
Depth 4: State = 0x8620, Legal Moves = [((1, 0), (1, 1)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8620: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x87cd, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.8125, N[0x87cd, ((5, 3), (5, 4))] = 32
Updated Q[0x87cd, ((0, 6), (0, 7))] = 19.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 19.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x8620, ((1, 0), (1, 1))] = 19.0, N[0x8620, ((1, 0), (1, 1))] = 1

--- Simulation 53 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.987773558175434, 16.987773558175434, 19.987773558175434, 25.987773558175434, 16.987773558175434, 20.987773558175434, 20.987773558175434, 17.987773558175434, 19.987773558175434, 26.987773558175434, 16.987773558175434, 28.16389204061229, 22.987773558175434, 16.987773558175434, 16.987773558175434, 16.987773558175434, 19.987773558175434, 16.987773558175434, 25.40556816244916, 19.987773558175434]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x8776, Score: 16
Depth 3: State = 0x8776, Legal Moves = [((0, 0), (0, 1)), ((0, 3), (1, 3)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8776: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0xa93d, Score: 19
Depth 4: State = 0xa93d, Legal Moves = [((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa93d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0xa93d, Score: 44
End of simulation with depth 5. Reward (Score): 44
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.303030303030305, N[0x87cd, ((5, 3), (5, 4))] = 33
Updated Q[0x87cd, ((0, 3), (1, 3))] = 44.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 1), (0, 2))] = 44.0, N[0x87cd, ((0, 1), (0, 2))] = 1
Updated Q[0x8776, ((0, 0), (0, 1))] = 44.0, N[0x8776, ((0, 0), (0, 1))] = 1
Updated Q[0xa93d, ((1, 4), (1, 5))] = 44.0, N[0xa93d, ((1, 4), (1, 5))] = 1

--- Simulation 54 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.992559136776652, 16.992559136776652, 19.992559136776652, 25.992559136776652, 16.992559136776652, 20.992559136776652, 20.992559136776652, 17.992559136776652, 19.992559136776652, 26.992559136776652, 16.992559136776652, 28.649890326913493, 22.992559136776652, 16.992559136776652, 16.992559136776652, 16.992559136776652, 19.992559136776652, 16.992559136776652, 25.408952077529985, 19.992559136776652]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 22
Depth 3: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x64b0, Score: 25
Depth 4: State = 0x64b0, Legal Moves = [((0, 2), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x64b0: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x65af, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.294117647058822, N[0x87cd, ((5, 3), (5, 4))] = 34
Updated Q[0x87cd, ((0, 7), (0, 8))] = 28.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 28.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0x64b0, ((0, 2), (1, 2))] = 28.0, N[0x64b0, ((0, 2), (1, 2))] = 1

--- Simulation 55 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.99724411291266, 16.99724411291266, 19.99724411291266, 25.99724411291266, 16.99724411291266, 20.99724411291266, 20.99724411291266, 17.99724411291266, 19.99724411291266, 26.99724411291266, 16.99724411291266, 28.63664218660755, 22.99724411291266, 16.99724411291266, 16.99724411291266, 16.99724411291266, 19.99724411291266, 16.99724411291266, 25.41226485592545, 19.99724411291266]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x22cc, Score: 25
Depth 3: State = 0x22cc, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (0, 3)), ((1, 0), (1, 1)), ((1, 5), (1, 6)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x22cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x2276, Score: 28
Depth 4: State = 0x2276, Legal Moves = [((0, 1), (1, 1)), ((0, 1), (0, 2)), ((0, 2), (1, 2)), ((0, 2), (0, 3)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2276: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x2277, Score: 31
End of simulation with depth 5. Reward (Score): 31
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.37142857142857, N[0x87cd, ((5, 3), (5, 4))] = 35
Updated Q[0x87cd, ((0, 4), (0, 5))] = 31.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 31.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x22cc, ((0, 1), (1, 1))] = 31.0, N[0x22cc, ((0, 1), (1, 1))] = 1
Updated Q[0x2276, ((0, 1), (1, 1))] = 31.0, N[0x2276, ((0, 1), (1, 1))] = 1

--- Simulation 56 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.001832456833604, 17.001832456833604, 20.001832456833604, 26.001832456833604, 17.001832456833604, 21.001832456833604, 21.001832456833604, 18.001832456833604, 20.001832456833604, 27.001832456833604, 17.001832456833604, 28.709800015057883, 23.001832456833604, 17.001832456833604, 17.001832456833604, 17.001832456833604, 20.001832456833604, 17.001832456833604, 25.41550930502637, 20.001832456833604]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xca06, Score: 13
Depth 3: State = 0xca06, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xca06: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0xa93d, Score: 19
Depth 4: State = 0xa93d, Legal Moves = [((1, 5), (2, 5)), ((2, 3), (3, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa93d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0xa93d, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.194444444444443, N[0x87cd, ((5, 3), (5, 4))] = 36
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 22.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0xca06, ((0, 1), (1, 1))] = 22.0, N[0xca06, ((0, 1), (1, 1))] = 1
Updated Q[0xa93d, ((1, 5), (2, 5))] = 22.0, N[0xa93d, ((1, 5), (2, 5))] = 1

--- Simulation 57 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.00632791206601, 17.00632791206601, 20.00632791206601, 26.00632791206601, 17.00632791206601, 21.00632791206601, 21.00632791206601, 18.00632791206601, 20.00632791206601, 27.00632791206601, 17.00632791206601, 28.52883242978878, 23.00632791206601, 17.00632791206601, 17.00632791206601, 17.00632791206601, 20.00632791206601, 17.00632791206601, 25.418688071905724, 20.00632791206601]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 6), (0, 7)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 16
Depth 4: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.027027027027028, N[0x87cd, ((5, 3), (5, 4))] = 37
Updated Q[0x87cd, ((0, 6), (1, 6))] = 22.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 22.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 22.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1

--- Simulation 58 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.01073401220414, 17.01073401220414, 20.01073401220414, 26.01073401220414, 17.01073401220414, 21.01073401220414, 21.01073401220414, 18.01073401220414, 20.01073401220414, 27.01073401220414, 17.01073401220414, 28.357589662373826, 23.01073401220414, 17.01073401220414, 17.01073401220414, 17.01073401220414, 20.01073401220414, 17.01073401220414, 25.42180365519198, 20.01073401220414]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 10
Depth 2: State = 0x87ca, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (1, 3)), ((0, 3), (0, 4)), ((0, 6), (0, 7)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87ca, Score: 19
Depth 4: State = 0x87ca, Legal Moves = [((0, 4), (0, 5)), ((0, 5), (1, 5)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87ca, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.86842105263158, N[0x87cd, ((5, 3), (5, 4))] = 38
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((0, 3), (1, 3))] = 22.0, N[0x87ca, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 2), (0, 3))] = 22.0, N[0x87cd, ((0, 2), (0, 3))] = 1
Updated Q[0x87ca, ((0, 4), (0, 5))] = 22.0, N[0x87ca, ((0, 4), (0, 5))] = 1

--- Simulation 59 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.01505409618363, 17.01505409618363, 20.01505409618363, 26.01505409618363, 17.01505409618363, 21.01505409618363, 21.01505409618363, 18.01505409618363, 20.01505409618363, 27.01505409618363, 17.01505409618363, 28.19530599176985, 23.01505409618363, 17.01505409618363, 17.01505409618363, 17.01505409618363, 20.01505409618363, 17.01505409618363, 25.424858415869174, 20.01505409618363]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 13
Depth 3: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x8631, Score: 22
Depth 4: State = 0x8631, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8631: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0xcaad, Score: 37
End of simulation with depth 5. Reward (Score): 37
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.102564102564102, N[0x87cd, ((5, 3), (5, 4))] = 39
Updated Q[0x87cd, ((0, 6), (0, 7))] = 37.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 37.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 37.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0x8631, ((0, 1), (0, 2))] = 37.0, N[0x8631, ((0, 1), (0, 2))] = 1

--- Simulation 60 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.019291322198388, 17.019291322198388, 20.019291322198388, 26.019291322198388, 17.019291322198388, 21.019291322198388, 21.019291322198388, 18.019291322198388, 20.019291322198388, 27.019291322198388, 17.019291322198388, 28.425909493982363, 23.019291322198388, 17.019291322198388, 17.019291322198388, 17.019291322198388, 20.019291322198388, 17.019291322198388, 25.42785458711763, 20.019291322198388]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x64ad, Score: 19
Depth 3: State = 0x64ad, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x64ad: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2222, Score: 22
Depth 4: State = 0x2222, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2222: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x22cb, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.025, N[0x87cd, ((5, 3), (5, 4))] = 40
Updated Q[0x87cd, ((0, 7), (0, 8))] = 25.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x64ad, ((0, 0), (0, 1))] = 25.0, N[0x64ad, ((0, 0), (0, 1))] = 1
Updated Q[0x2222, ((0, 1), (1, 1))] = 25.0, N[0x2222, ((0, 1), (1, 1))] = 1

--- Simulation 61 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.02344868040237, 17.02344868040237, 20.02344868040237, 26.02344868040237, 17.02344868040237, 21.02344868040237, 21.02344868040237, 18.02344868040237, 20.02344868040237, 27.02344868040237, 17.02344868040237, 28.344935327926677, 23.02344868040237, 17.02344868040237, 17.02344868040237, 17.02344868040237, 20.02344868040237, 17.02344868040237, 25.430794283295487, 20.02344868040237]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 8), (0, 9)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 8), (0, 9))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 16
Depth 3: State = 0x87cb, Legal Moves = [((0, 1), (0, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x86cb, Score: 19
Depth 4: State = 0x86cb, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x86cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x6503, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.024390243902438, N[0x87cd, ((5, 3), (5, 4))] = 41
Updated Q[0x87cd, ((0, 8), (0, 9))] = 28.0, N[0x87cd, ((0, 8), (0, 9))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((0, 1), (0, 2))] = 28.0, N[0x87cb, ((0, 1), (0, 2))] = 1
Updated Q[0x86cb, ((0, 1), (1, 1))] = 28.0, N[0x86cb, ((0, 1), (1, 1))] = 1

--- Simulation 62 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.02752900452085, 17.02752900452085, 20.02752900452085, 26.02752900452085, 17.02752900452085, 21.02752900452085, 21.02752900452085, 18.02752900452085, 20.02752900452085, 27.02752900452085, 17.02752900452085, 28.34103707587672, 23.02752900452085, 17.02752900452085, 17.02752900452085, 17.02752900452085, 20.02752900452085, 17.02752900452085, 25.433679508149105, 20.02752900452085]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((1, 6), (2, 6)), ((1, 6), (1, 7)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 25
Depth 4: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 4), (3, 5)), ((3, 8), (3, 9)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 31
End of simulation with depth 5. Reward (Score): 31
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.095238095238095, N[0x87cd, ((5, 3), (5, 4))] = 42
Updated Q[0x87cd, ((0, 7), (0, 8))] = 31.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 31.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 7), (1, 7))] = 31.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 31.0, N[0x87cd, ((0, 6), (1, 6))] = 1

--- Simulation 63 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.03153498248125, 17.03153498248125, 20.03153498248125, 26.03153498248125, 17.03153498248125, 21.03153498248125, 21.03153498248125, 18.03153498248125, 20.03153498248125, 27.03153498248125, 17.03153498248125, 28.408710748600132, 23.03153498248125, 17.03153498248125, 17.03153498248125, 17.03153498248125, 20.03153498248125, 17.03153498248125, 25.436512162330185, 20.03153498248125]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((1, 1), (1, 2)), ((1, 7), (1, 8)), ((2, 2), (2, 3)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 7), (1, 8)), ((2, 2), (2, 3)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 7), (1, 8)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.093023255813954, N[0x87cd, ((5, 3), (5, 4))] = 43
Updated Q[0x87cd, ((0, 4), (1, 4))] = 28.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 28.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 28.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1

--- Simulation 64 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.035469166160848, 17.035469166160848, 20.035469166160848, 26.035469166160848, 17.035469166160848, 21.035469166160848, 21.035469166160848, 18.035469166160848, 20.035469166160848, 27.035469166160848, 17.035469166160848, 28.40342939360958, 23.035469166160848, 17.035469166160848, 17.035469166160848, 17.035469166160848, 20.035469166160848, 17.035469166160848, 25.439294050288463, 20.035469166160848]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x8676, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.954545454545453, N[0x87cd, ((5, 3), (5, 4))] = 44
Updated Q[0x87cd, ((0, 4), (0, 5))] = 22.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 22.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 22.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 22.0, N[0x87cd, ((0, 1), (1, 1))] = 1

--- Simulation 65 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.039333980337616, 17.039333980337616, 20.039333980337616, 26.039333980337616, 17.039333980337616, 21.039333980337616, 21.039333980337616, 18.039333980337616, 20.039333980337616, 27.039333980337616, 17.039333980337616, 28.261986619772813, 23.039333980337616, 17.039333980337616, 17.039333980337616, 17.039333980337616, 20.039333980337616, 17.039333980337616, 25.442026886600882, 20.039333980337616]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 19
Depth 4: State = 0x87c9, Legal Moves = [((1, 0), (1, 1)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x87cc, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.822222222222223, N[0x87cd, ((5, 3), (5, 4))] = 45
Updated Q[0x87cd, ((0, 6), (1, 6))] = 22.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 4), (1, 4))] = 22.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 0), (1, 1))] = 22.0, N[0x87c9, ((1, 0), (1, 1))] = 1

--- Simulation 66 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.04313173092085, 17.04313173092085, 20.04313173092085, 26.04313173092085, 17.04313173092085, 21.04313173092085, 21.04313173092085, 18.04313173092085, 20.04313173092085, 27.04313173092085, 17.04313173092085, 28.126794318043945, 23.04313173092085, 17.04313173092085, 17.04313173092085, 17.04313173092085, 20.04313173092085, 17.04313173092085, 25.444712301791544, 20.04313173092085]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 22
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 25
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 8), (4, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 28
Depth 3: State = 0x87cd, Legal Moves = [((0, 3), (0, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 8), (4, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x8676, Score: 31
Depth 4: State = 0x8676, Legal Moves = [((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 8), (4, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8676: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x8676, Score: 34
End of simulation with depth 5. Reward (Score): 34
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.956521739130434, N[0x87cd, ((5, 3), (5, 4))] = 46
Updated Q[0x87cd, ((0, 6), (1, 6))] = 34.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 34.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 3), (0, 4))] = 34.0, N[0x87cd, ((0, 3), (0, 4))] = 1
Updated Q[0x8676, ((0, 3), (1, 3))] = 34.0, N[0x8676, ((0, 3), (1, 3))] = 1

--- Simulation 67 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.046864612529717, 17.046864612529717, 20.046864612529717, 26.046864612529717, 17.046864612529717, 21.046864612529717, 21.046864612529717, 18.046864612529717, 20.046864612529717, 27.046864612529717, 17.046864612529717, 28.25831546158605, 23.046864612529717, 17.046864612529717, 17.046864612529717, 17.046864612529717, 20.046864612529717, 17.046864612529717, 25.447351847690538, 20.046864612529717]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 1), (0, 2)), ((0, 5), (0, 6)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x8777, Score: 19
Depth 3: State = 0x8777, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8777: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x8777, Score: 22
Depth 4: State = 0x8777, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8777: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x8777, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.95744680851064, N[0x87cd, ((5, 3), (5, 4))] = 47
Updated Q[0x87cd, ((0, 3), (1, 3))] = 28.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 1), (0, 2))] = 28.0, N[0x87cd, ((0, 1), (0, 2))] = 1
Updated Q[0x8777, ((0, 6), (1, 6))] = 28.0, N[0x8777, ((0, 6), (1, 6))] = 1
Updated Q[0x8777, ((0, 6), (1, 6))] = 28.0, N[0x8777, ((0, 6), (1, 6))] = 1

--- Simulation 68 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.050534715480566, 17.050534715480566, 20.050534715480566, 26.050534715480566, 17.050534715480566, 21.050534715480566, 21.050534715480566, 18.050534715480566, 20.050534715480566, 27.050534715480566, 17.050534715480566, 28.25654803735035, 23.050534715480566, 17.050534715480566, 17.050534715480566, 17.050534715480566, 20.050534715480566, 17.050534715480566, 25.449947002374735, 20.050534715480566]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 7), (2, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 16
Depth 4: State = 0x87cb, Legal Moves = [((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 7), (2, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cc, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.770833333333332, N[0x87cd, ((5, 3), (5, 4))] = 48
Updated Q[0x87cd, ((0, 7), (1, 7))] = 19.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 19.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((0, 4), (1, 4))] = 19.0, N[0x87cb, ((0, 4), (1, 4))] = 1

--- Simulation 69 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.054144032237296, 17.054144032237296, 20.054144032237296, 26.054144032237296, 17.054144032237296, 21.054144032237296, 21.054144032237296, 18.054144032237296, 20.054144032237296, 27.054144032237296, 17.054144032237296, 28.06732348582495, 23.054144032237296, 17.054144032237296, 17.054144032237296, 17.054144032237296, 20.054144032237296, 17.054144032237296, 25.45249917472887, 20.054144032237296]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 16
Depth 4: State = 0x87ca, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xa93c, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.591836734693878, N[0x87cd, ((5, 3), (5, 4))] = 49
Updated Q[0x87cd, ((0, 5), (1, 5))] = 19.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 19.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((1, 2), (2, 2))] = 19.0, N[0x87ca, ((1, 2), (2, 2))] = 1

--- Simulation 70 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.05769446337333, 17.05769446337333, 20.05769446337333, 26.05769446337333, 17.05769446337333, 21.05769446337333, 21.05769446337333, 18.05769446337333, 20.05769446337333, 27.05769446337333, 17.05769446337333, 27.885793086604355, 23.05769446337333, 17.05769446337333, 17.05769446337333, 17.05769446337333, 20.05769446337333, 17.05769446337333, 25.455009708661297, 20.05769446337333]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x2321, Score: 13
Depth 2: State = 0x2321, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2321: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x22cb, Score: 16
Depth 3: State = 0x22cb, Legal Moves = [((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x22cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x2277, Score: 19
Depth 4: State = 0x2277, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2277: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x2277, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.48, N[0x87cd, ((5, 3), (5, 4))] = 50
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x2321, ((1, 0), (1, 1))] = 22.0, N[0x2321, ((1, 0), (1, 1))] = 1
Updated Q[0x22cb, ((1, 3), (1, 4))] = 22.0, N[0x22cb, ((1, 3), (1, 4))] = 1
Updated Q[0x2277, ((1, 5), (2, 5))] = 22.0, N[0x2277, ((1, 5), (2, 5))] = 1

--- Simulation 71 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.061187823088755, 17.061187823088755, 20.061187823088755, 26.061187823088755, 17.061187823088755, 21.061187823088755, 21.061187823088755, 18.061187823088755, 20.061187823088755, 27.061187823088755, 17.061187823088755, 27.771495977401038, 23.061187823088755, 17.061187823088755, 17.061187823088755, 17.061187823088755, 20.061187823088755, 17.061187823088755, 25.457479887005196, 20.061187823088755]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((3, 2), (3, 3)), ((4, 2), (4, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((3, 7), (3, 8)), ((4, 2), (4, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 5), (5, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((0, 3), (0, 4)), ((0, 6), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((3, 7), (3, 8)), ((4, 2), (4, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 5), (5, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x871f, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.431372549019606, N[0x87cd, ((5, 3), (5, 4))] = 51
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 25.0, N[0x87cd, ((1, 5), (2, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 25.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 3), (0, 4))] = 25.0, N[0x87cd, ((0, 3), (0, 4))] = 1

--- Simulation 72 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.064625844321753, 17.064625844321753, 20.064625844321753, 26.064625844321753, 17.064625844321753, 21.064625844321753, 21.064625844321753, 18.064625844321753, 20.064625844321753, 27.064625844321753, 17.064625844321753, 27.72047799409693, 23.064625844321753, 17.064625844321753, 17.064625844321753, 17.064625844321753, 20.064625844321753, 17.064625844321753, 25.459910935132914, 20.064625844321753]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 13
Depth 3: State = 0x87cb, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x6603, Score: 16
Depth 4: State = 0x6603, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6603: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xc902, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.26923076923077, N[0x87cd, ((5, 3), (5, 4))] = 52
Updated Q[0x87cd, ((0, 6), (0, 7))] = 19.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((0, 0), (1, 0))] = 19.0, N[0x87cb, ((0, 0), (1, 0))] = 1
Updated Q[0x6603, ((1, 2), (2, 2))] = 19.0, N[0x6603, ((1, 2), (2, 2))] = 1

--- Simulation 73 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.06801018348945, 17.06801018348945, 20.06801018348945, 26.06801018348945, 17.06801018348945, 21.06801018348945, 21.06801018348945, 18.06801018348945, 20.06801018348945, 27.06801018348945, 17.06801018348945, 27.55601218287511, 23.06801018348945, 17.06801018348945, 17.06801018348945, 17.06801018348945, 20.06801018348945, 17.06801018348945, 25.462304024308224, 20.06801018348945]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 6), (1, 6)), ((0, 6), (0, 7)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 7), (1, 7)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((0, 7), (1, 7)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 7), (1, 8)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 37
End of simulation with depth 5. Reward (Score): 37
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.452830188679247, N[0x87cd, ((5, 3), (5, 4))] = 53
Updated Q[0x87cd, ((0, 7), (1, 7))] = 37.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 37.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 37.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 37.0, N[0x87cd, ((0, 5), (1, 5))] = 1

--- Simulation 74 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.071342424889806, 17.071342424889806, 20.071342424889806, 26.071342424889806, 17.071342424889806, 21.071342424889806, 21.071342424889806, 18.071342424889806, 20.071342424889806, 27.071342424889806, 17.071342424889806, 27.737350952292957, 23.071342424889806, 17.071342424889806, 17.071342424889806, 17.071342424889806, 20.071342424889806, 17.071342424889806, 25.46466027479897, 20.071342424889806]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x87cb, Score: 22
Depth 4: State = 0x87cb, Legal Moves = [((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cb, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.462962962962962, N[0x87cd, ((5, 3), (5, 4))] = 54
Updated Q[0x87cd, ((0, 6), (1, 6))] = 28.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 28.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x87cb, ((1, 5), (2, 5))] = 28.0, N[0x87cb, ((1, 5), (2, 5))] = 1

--- Simulation 75 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.074624084793236, 17.074624084793236, 20.074624084793236, 26.074624084793236, 17.074624084793236, 21.074624084793236, 21.074624084793236, 18.074624084793236, 20.074624084793236, 27.074624084793236, 17.074624084793236, 27.745283541620292, 23.074624084793236, 17.074624084793236, 17.074624084793236, 17.074624084793236, 20.074624084793236, 17.074624084793236, 25.466980758770234, 20.074624084793236]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x8775, Score: 22
Depth 4: State = 0x8775, Legal Moves = [((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8775: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x8775, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.418181818181818, N[0x87cd, ((5, 3), (5, 4))] = 55
Updated Q[0x87cd, ((0, 4), (0, 5))] = 25.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 4), (1, 4))] = 25.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 25.0, N[0x87cd, ((0, 1), (1, 1))] = 1
Updated Q[0x8775, ((0, 3), (1, 3))] = 25.0, N[0x8775, ((0, 3), (1, 3))] = 1

--- Simulation 76 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.077856615249548, 17.077856615249548, 20.077856615249548, 26.077856615249548, 17.077856615249548, 21.077856615249548, 21.077856615249548, 18.077856615249548, 20.077856615249548, 27.077856615249548, 17.077856615249548, 27.698359947025736, 23.077856615249548, 17.077856615249548, 17.077856615249548, 17.077856615249548, 20.077856615249548, 17.077856615249548, 25.469266502976282, 20.077856615249548]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 2), (0, 3)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87c9, Score: 19
Depth 2: State = 0x87c9, Legal Moves = [((0, 6), (1, 6)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87c9, Score: 22
Depth 3: State = 0x87c9, Legal Moves = [((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x87c9, Score: 25
Depth 4: State = 0x87c9, Legal Moves = [((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x87c9, Score: 31
End of simulation with depth 5. Reward (Score): 31
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.482142857142858, N[0x87cd, ((5, 3), (5, 4))] = 56
Updated Q[0x87cd, ((0, 2), (0, 3))] = 31.0, N[0x87cd, ((0, 2), (0, 3))] = 1
Updated Q[0x87c9, ((0, 6), (1, 6))] = 31.0, N[0x87c9, ((0, 6), (1, 6))] = 1
Updated Q[0x87c9, ((1, 3), (1, 4))] = 31.0, N[0x87c9, ((1, 3), (1, 4))] = 1
Updated Q[0x87c9, ((1, 4), (2, 4))] = 31.0, N[0x87c9, ((1, 4), (2, 4))] = 1

--- Simulation 77 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.081041407633766, 17.081041407633766, 20.081041407633766, 26.081041407633766, 17.081041407633766, 21.081041407633766, 21.081041407633766, 18.081041407633766, 20.081041407633766, 27.081041407633766, 17.081041407633766, 27.76023371268055, 23.081041407633766, 17.081041407633766, 17.081041407633766, 17.081041407633766, 20.081041407633766, 17.081041407633766, 25.471518491267837, 20.081041407633766]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 1), (3, 2)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x6504, Score: 19
Depth 4: State = 0x6504, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6504: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x6504, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.385964912280702, N[0x87cd, ((5, 3), (5, 4))] = 57
Updated Q[0x87cd, ((0, 3), (1, 3))] = 22.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 0), (1, 0))] = 22.0, N[0x87cd, ((0, 0), (1, 0))] = 1
Updated Q[0x6504, ((1, 5), (2, 5))] = 22.0, N[0x6504, ((1, 5), (2, 5))] = 1

--- Simulation 78 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.084179795951798, 17.084179795951798, 20.084179795951798, 26.084179795951798, 17.084179795951798, 21.084179795951798, 21.084179795951798, 18.084179795951798, 20.084179795951798, 27.084179795951798, 17.084179795951798, 27.66202127004864, 23.084179795951798, 17.084179795951798, 17.084179795951798, 17.084179795951798, 20.084179795951798, 17.084179795951798, 25.473737666929512, 20.084179795951798]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((0, 2), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x87cd, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.344827586206897, N[0x87cd, ((5, 3), (5, 4))] = 58
Updated Q[0x87cd, ((0, 7), (0, 8))] = 25.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((0, 7), (1, 7))] = 25.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 2), (1, 2))] = 25.0, N[0x87cd, ((0, 2), (1, 2))] = 1

--- Simulation 79 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.08727305992522, 17.08727305992522, 20.08727305992522, 26.08727305992522, 17.08727305992522, 21.08727305992522, 21.08727305992522, 18.08727305992522, 20.08727305992522, 27.08727305992522, 17.08727305992522, 27.618899966109876, 23.08727305992522, 17.08727305992522, 17.08727305992522, 17.08727305992522, 20.08727305992522, 17.08727305992522, 25.47592493486112, 20.08727305992522]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 16
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 31
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 7), (3, 7)), ((2, 8), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x8677, Score: 40
Depth 3: State = 0x8677, Legal Moves = [((0, 2), (1, 2)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((2, 7), (3, 7)), ((2, 8), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8677: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x861e, Score: 46
Depth 4: State = 0x861e, Legal Moves = [((0, 3), (0, 4)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 7), (3, 7)), ((2, 8), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x861e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x861e, Score: 49
End of simulation with depth 5. Reward (Score): 49
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.71186440677966, N[0x87cd, ((5, 3), (5, 4))] = 59
Updated Q[0x87cd, ((0, 6), (0, 7))] = 49.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 49.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x8677, ((0, 2), (1, 2))] = 49.0, N[0x8677, ((0, 2), (1, 2))] = 1
Updated Q[0x861e, ((0, 3), (0, 4))] = 49.0, N[0x861e, ((0, 3), (0, 4))] = 1

--- Simulation 80 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.090322427872557, 17.090322427872557, 20.090322427872557, 26.090322427872557, 17.090322427872557, 21.090322427872557, 21.090322427872557, 18.090322427872557, 20.090322427872557, 27.090322427872557, 17.090322427872557, 27.98400120726318, 23.090322427872557, 17.090322427872557, 17.090322427872557, 17.090322427872557, 20.090322427872557, 17.090322427872557, 25.478081163615013, 20.090322427872557]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 13
Depth 3: State = 0x87cb, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x86ca, Score: 16
Depth 4: State = 0x86ca, Legal Moves = [((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x86ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x8674, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.566666666666666, N[0x87cd, ((5, 3), (5, 4))] = 60
Updated Q[0x87cd, ((0, 6), (1, 6))] = 19.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((1, 2), (2, 2))] = 19.0, N[0x87cb, ((1, 2), (2, 2))] = 1
Updated Q[0x86ca, ((1, 0), (1, 1))] = 19.0, N[0x86ca, ((1, 0), (1, 1))] = 1

--- Simulation 81 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.09332907940292, 17.09332907940292, 20.09332907940292, 26.09332907940292, 17.09332907940292, 21.09332907940292, 21.09332907940292, 18.09332907940292, 20.09332907940292, 27.09332907940292, 17.09332907940292, 27.836914288755306, 23.09332907940292, 17.09332907940292, 17.09332907940292, 17.09332907940292, 20.09332907940292, 17.09332907940292, 25.4802071873008, 20.09332907940292]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 22
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 28
Depth 2: State = 0x87cc, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (1, 1)), ((1, 3), (1, 4)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((3, 5), (3, 6)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0xa93c, Score: 31
Depth 3: State = 0xa93c, Legal Moves = [((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((3, 5), (3, 6)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa93c: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0xa792, Score: 34
Depth 4: State = 0xa792, Legal Moves = [((0, 3), (0, 4)), ((2, 2), (3, 2)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((3, 5), (3, 6)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa792: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0xa792, Score: 37
End of simulation with depth 5. Reward (Score): 37
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.721311475409838, N[0x87cd, ((5, 3), (5, 4))] = 61
Updated Q[0x87cd, ((1, 1), (1, 2))] = 37.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 0), (1, 0))] = 37.0, N[0x87cc, ((0, 0), (1, 0))] = 1
Updated Q[0xa93c, ((2, 1), (3, 1))] = 37.0, N[0xa93c, ((2, 1), (3, 1))] = 1
Updated Q[0xa792, ((0, 3), (0, 4))] = 37.0, N[0xa792, ((0, 3), (0, 4))] = 1

--- Simulation 82 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.096294147936412, 17.096294147936412, 20.096294147936412, 26.096294147936412, 17.096294147936412, 21.096294147936412, 21.096294147936412, 18.096294147936412, 20.096294147936412, 27.096294147936412, 17.096294147936412, 27.989714437533205, 23.096294147936412, 17.096294147936412, 17.096294147936412, 17.096294147936412, 20.096294147936412, 17.096294147936412, 25.48230380736751, 20.096294147936412]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 35
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((3, 7), (4, 7)), ((4, 3), (4, 4)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (5, 7)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 3), (6, 4)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3)), ((8, 5), (9, 5))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 41
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((3, 7), (4, 7)), ((4, 3), (4, 4)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (5, 7)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 3), (6, 4)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3)), ((8, 5), (9, 5))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 44
Depth 3: State = 0x87cb, Legal Moves = [((1, 4), (1, 5)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 6), (2, 7)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((3, 7), (4, 7)), ((4, 3), (4, 4)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (5, 7)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 3), (6, 4)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3)), ((8, 5), (9, 5))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0x87cb, Score: 53
Depth 4: State = 0x87cb, Legal Moves = [((2, 6), (2, 7)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((3, 3), (3, 4)), ((3, 6), (3, 7)), ((3, 7), (4, 7)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (5, 7)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 3), (6, 4)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3)), ((8, 5), (9, 5))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 6), (2, 7))
New board state after move: 0x87cb, Score: 59
End of simulation with depth 5. Reward (Score): 59
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.225806451612904, N[0x87cd, ((5, 3), (5, 4))] = 62
Updated Q[0x87cd, ((0, 5), (1, 5))] = 59.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 59.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((1, 4), (1, 5))] = 59.0, N[0x87cb, ((1, 4), (1, 5))] = 1
Updated Q[0x87cb, ((2, 6), (2, 7))] = 59.0, N[0x87cb, ((2, 6), (2, 7))] = 1

--- Simulation 83 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.09921872306443, 17.09921872306443, 20.09921872306443, 26.09921872306443, 17.09921872306443, 21.09921872306443, 21.09921872306443, 18.09921872306443, 20.09921872306443, 27.09921872306443, 17.09921872306443, 28.492407496043263, 23.09921872306443, 17.09921872306443, 17.09921872306443, 17.09921872306443, 20.09921872306443, 17.09921872306443, 25.484371794272622, 20.09921872306443]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 16
Depth 2: State = 0x87c9, Legal Moves = [((0, 0), (1, 0)), ((0, 4), (0, 5)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0xa892, Score: 19
Depth 3: State = 0xa892, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa892: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x4492, Score: 25
Depth 4: State = 0x4492, Legal Moves = [((1, 5), (2, 5)), ((2, 8), (2, 9)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x4492: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x4492, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.22222222222222, N[0x87cd, ((5, 3), (5, 4))] = 63
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((0, 0), (1, 0))] = 28.0, N[0x87c9, ((0, 0), (1, 0))] = 1
Updated Q[0xa892, ((1, 1), (1, 2))] = 28.0, N[0xa892, ((1, 1), (1, 2))] = 1
Updated Q[0x4492, ((1, 5), (2, 5))] = 28.0, N[0x4492, ((1, 5), (2, 5))] = 1

--- Simulation 84 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.102103852761942, 17.102103852761942, 20.102103852761942, 26.102103852761942, 17.102103852761942, 21.102103852761942, 21.102103852761942, 18.102103852761942, 20.102103852761942, 27.102103852761942, 17.102103852761942, 28.487062413862166, 23.102103852761942, 17.102103852761942, 17.102103852761942, 17.102103852761942, 20.102103852761942, 17.102103852761942, 25.486411889046337, 20.102103852761942]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((0, 5), (0, 6)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 16
Depth 4: State = 0x87cd, Legal Moves = [((0, 2), (1, 2)), ((0, 2), (0, 3)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 3), (3, 4)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x861e, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.125, N[0x87cd, ((5, 3), (5, 4))] = 64
Updated Q[0x87cd, ((0, 4), (1, 4))] = 22.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 22.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 22.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 2), (1, 2))] = 22.0, N[0x87cd, ((0, 2), (1, 2))] = 1

--- Simulation 85 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.104950545462604, 17.104950545462604, 20.104950545462604, 26.104950545462604, 17.104950545462604, 21.104950545462604, 21.104950545462604, 18.104950545462604, 20.104950545462604, 27.104950545462604, 17.104950545462604, 28.388118818182825, 23.104950545462604, 17.104950545462604, 17.104950545462604, 17.104950545462604, 20.104950545462604, 17.104950545462604, 25.488424804758928, 20.104950545462604]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 13
Depth 2: State = 0x87ca, Legal Moves = [((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 3), (2, 3)), ((1, 3), (1, 4)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.123076923076923, N[0x87cd, ((5, 3), (5, 4))] = 65
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((0, 3), (1, 3))] = 28.0, N[0x87ca, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 28.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 28.0, N[0x87cd, ((1, 5), (2, 5))] = 1

--- Simulation 86 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.107759772006837, 17.107759772006837, 20.107759772006837, 26.107759772006837, 17.107759772006837, 21.107759772006837, 21.107759772006837, 18.107759772006837, 20.107759772006837, 27.107759772006837, 17.107759772006837, 28.3845123469756, 23.107759772006837, 17.107759772006837, 17.107759772006837, 17.107759772006837, 20.107759772006837, 17.107759772006837, 25.490411227898246, 20.107759772006837]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 16
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 7), (2, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 19
Depth 2: State = 0x87ca, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 7), (2, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x22c9, Score: 22
Depth 3: State = 0x22c9, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 7), (2, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x22c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x231f, Score: 25
Depth 4: State = 0x231f, Legal Moves = [((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 7), (2, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x231f: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x231f, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.12121212121212, N[0x87cd, ((5, 3), (5, 4))] = 66
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((1, 2), (2, 2))] = 28.0, N[0x87ca, ((1, 2), (2, 2))] = 1
Updated Q[0x22c9, ((0, 1), (1, 1))] = 28.0, N[0x22c9, ((0, 1), (1, 1))] = 1
Updated Q[0x231f, ((1, 5), (2, 5))] = 28.0, N[0x231f, ((1, 5), (2, 5))] = 1

--- Simulation 87 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.110532467472012, 17.110532467472012, 20.110532467472012, 26.110532467472012, 17.110532467472012, 21.110532467472012, 21.110532467472012, 18.110532467472012, 20.110532467472012, 27.110532467472012, 17.110532467472012, 28.38100070939354, 23.110532467472012, 17.110532467472012, 17.110532467472012, 17.110532467472012, 20.110532467472012, 17.110532467472012, 25.492371819663838, 20.110532467472012]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 22
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 8), (1, 9)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 25
Depth 4: State = 0x87cd, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (0, 4)), ((1, 2), (2, 2)), ((1, 8), (1, 9)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87c9, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.119402985074625, N[0x87cd, ((5, 3), (5, 4))] = 67
Updated Q[0x87cd, ((0, 5), (1, 5))] = 28.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 28.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 2), (0, 3))] = 28.0, N[0x87cd, ((0, 2), (0, 3))] = 1

--- Simulation 88 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.113269532893185, 17.113269532893185, 20.113269532893185, 26.113269532893185, 17.113269532893185, 21.113269532893185, 21.113269532893185, 18.113269532893185, 20.113269532893185, 27.113269532893185, 17.113269532893185, 28.377579949683295, 23.113269532893185, 17.113269532893185, 17.113269532893185, 17.113269532893185, 20.113269532893185, 17.113269532893185, 25.4943072171837, 20.113269532893185]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x86cb, Score: 16
Depth 4: State = 0x86cb, Legal Moves = [((1, 5), (2, 5)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x86cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x86cb, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.985294117647058, N[0x87cd, ((5, 3), (5, 4))] = 68
Updated Q[0x87cd, ((0, 7), (0, 8))] = 19.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 0), (1, 0))] = 19.0, N[0x87cd, ((0, 0), (1, 0))] = 1
Updated Q[0x86cb, ((1, 5), (2, 5))] = 19.0, N[0x86cb, ((1, 5), (2, 5))] = 1

--- Simulation 89 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.1159718368821, 17.1159718368821, 20.1159718368821, 26.1159718368821, 17.1159718368821, 21.1159718368821, 21.1159718368821, 18.1159718368821, 20.1159718368821, 27.1159718368821, 17.1159718368821, 28.241893393655797, 23.1159718368821, 17.1159718368821, 17.1159718368821, 17.1159718368821, 20.1159718368821, 17.1159718368821, 25.496218034659087, 20.1159718368821]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 10
Depth 2: State = 0x87c9, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87c9, Score: 13
Depth 3: State = 0x87c9, Legal Moves = [((0, 4), (0, 5)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((3, 7), (3, 8)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (5, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87c9, Score: 16
Depth 4: State = 0x87c9, Legal Moves = [((1, 3), (2, 3)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((2, 4), (2, 5)), ((3, 7), (3, 8)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (5, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x87cd, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.855072463768117, N[0x87cd, ((5, 3), (5, 4))] = 69
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 5), (2, 5))] = 19.0, N[0x87c9, ((1, 5), (2, 5))] = 1
Updated Q[0x87c9, ((0, 4), (0, 5))] = 19.0, N[0x87c9, ((0, 4), (0, 5))] = 1
Updated Q[0x87c9, ((1, 3), (2, 3))] = 19.0, N[0x87c9, ((1, 3), (2, 3))] = 1

--- Simulation 90 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.11864021715159, 17.11864021715159, 20.11864021715159, 26.11864021715159, 17.11864021715159, 21.11864021715159, 21.11864021715159, 18.11864021715159, 20.11864021715159, 27.11864021715159, 17.11864021715159, 28.110126773691732, 23.11864021715159, 17.11864021715159, 17.11864021715159, 17.11864021715159, 20.11864021715159, 17.11864021715159, 25.49810486444243, 20.11864021715159]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((0, 5), (0, 6)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 16
Depth 4: State = 0x87cd, Legal Moves = [((0, 2), (0, 3)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87c9, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.728571428571428, N[0x87cd, ((5, 3), (5, 4))] = 70
Updated Q[0x87cd, ((0, 4), (1, 4))] = 19.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 19.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 19.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 2), (0, 3))] = 19.0, N[0x87cd, ((0, 2), (0, 3))] = 1

--- Simulation 91 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.1212754819519, 17.1212754819519, 20.1212754819519, 26.1212754819519, 17.1212754819519, 21.1212754819519, 21.1212754819519, 18.1212754819519, 20.1212754819519, 27.1212754819519, 17.1212754819519, 27.982112343002278, 23.1212754819519, 17.1212754819519, 17.1212754819519, 17.1212754819519, 20.1212754819519, 17.1212754819519, 25.49996827805295, 20.1212754819519]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 8), (0, 9)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 25
Depth 4: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.732394366197184, N[0x87cd, ((5, 3), (5, 4))] = 71
Updated Q[0x87cd, ((0, 6), (1, 6))] = 28.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 28.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 28.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 28.0, N[0x87cd, ((0, 6), (1, 6))] = 1

--- Simulation 92 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.123878411424922, 17.123878411424922, 20.123878411424922, 26.123878411424922, 17.123878411424922, 21.123878411424922, 21.123878411424922, 18.123878411424922, 20.123878411424922, 27.123878411424922, 17.123878411424922, 27.984452360488483, 23.123878411424922, 17.123878411424922, 17.123878411424922, 17.123878411424922, 20.123878411424922, 17.123878411424922, 25.501808827134276, 20.123878411424922]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x433e, Score: 16
Depth 4: State = 0x433e, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((0, 4), (0, 5)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x433e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x43e7, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.61111111111111, N[0x87cd, ((5, 3), (5, 4))] = 72
Updated Q[0x87cd, ((0, 7), (0, 8))] = 19.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 19.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x433e, ((0, 1), (1, 1))] = 19.0, N[0x433e, ((0, 1), (1, 1))] = 1

--- Simulation 93 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.126449758881936, 17.126449758881936, 20.126449758881936, 26.126449758881936, 17.126449758881936, 21.126449758881936, 21.126449758881936, 18.126449758881936, 20.126449758881936, 27.126449758881936, 17.126449758881936, 27.861715618504096, 23.126449758881936, 17.126449758881936, 17.126449758881936, 17.126449758881936, 20.126449758881936, 17.126449758881936, 25.503627044357916, 20.126449758881936]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xae3f, Score: 20
Depth 3: State = 0xae3f, Legal Moves = [((0, 3), (1, 3)), ((0, 3), (0, 4)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xae3f: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0xae41, Score: 23
Depth 4: State = 0xae41, Legal Moves = [((1, 0), (1, 1)), ((1, 2), (2, 2)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xae41: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0xaeec, Score: 26
End of simulation with depth 5. Reward (Score): 26
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.589041095890412, N[0x87cd, ((5, 3), (5, 4))] = 73
Updated Q[0x87cd, ((0, 4), (0, 5))] = 26.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 26.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xae3f, ((0, 3), (1, 3))] = 26.0, N[0xae3f, ((0, 3), (1, 3))] = 1
Updated Q[0xae41, ((1, 0), (1, 1))] = 26.0, N[0xae41, ((1, 0), (1, 1))] = 1

--- Simulation 94 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.12899025200992, 17.12899025200992, 20.12899025200992, 26.12899025200992, 17.12899025200992, 21.12899025200992, 21.12899025200992, 18.12899025200992, 20.12899025200992, 27.12899025200992, 17.12899025200992, 27.838220557355033, 23.12899025200992, 17.12899025200992, 17.12899025200992, 17.12899025200992, 20.12899025200992, 17.12899025200992, 25.50542344427627, 20.12899025200992]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x86ca, Score: 46
Depth 4: State = 0x86ca, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((0, 5), (0, 6)), ((0, 6), (0, 7)), ((2, 6), (3, 6)), ((3, 2), (3, 3)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 2), (5, 3)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 7), (6, 8)), ((7, 2), (8, 2)), ((7, 3), (8, 3)), ((7, 5), (8, 5)), ((8, 2), (8, 3)), ((8, 3), (8, 4))]
UCB1 values for moves at state 0x86ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x86cb, Score: 49
End of simulation with depth 5. Reward (Score): 49
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.87837837837838, N[0x87cd, ((5, 3), (5, 4))] = 74
Updated Q[0x87cd, ((0, 6), (0, 7))] = 49.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 49.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 2), (1, 2))] = 49.0, N[0x87cd, ((0, 2), (1, 2))] = 1
Updated Q[0x86ca, ((0, 2), (1, 2))] = 49.0, N[0x86ca, ((0, 2), (1, 2))] = 1

--- Simulation 95 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.13150059401118, 17.13150059401118, 20.13150059401118, 26.13150059401118, 17.13150059401118, 21.13150059401118, 21.13150059401118, 18.13150059401118, 20.13150059401118, 27.13150059401118, 17.13150059401118, 28.126160289413228, 23.13150059401118, 17.13150059401118, 17.13150059401118, 17.13150059401118, 20.13150059401118, 17.13150059401118, 25.50719852412846, 20.13150059401118]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((2, 2), (2, 3)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x21c9, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.8, N[0x87cd, ((5, 3), (5, 4))] = 75
Updated Q[0x87cd, ((0, 6), (0, 7))] = 22.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 22.0, N[0x87cd, ((1, 5), (2, 5))] = 1
Updated Q[0x87cd, ((2, 2), (2, 3))] = 22.0, N[0x87cd, ((2, 2), (2, 3))] = 1

--- Simulation 96 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.133981464680645, 17.133981464680645, 20.133981464680645, 26.133981464680645, 17.133981464680645, 21.133981464680645, 21.133981464680645, 18.133981464680645, 20.133981464680645, 27.133981464680645, 17.133981464680645, 28.04641095461581, 23.133981464680645, 17.133981464680645, 17.133981464680645, 17.133981464680645, 20.133981464680645, 17.133981464680645, 25.508952764602082, 20.133981464680645]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((0, 0), (1, 0)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x86c9, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.763157894736842, N[0x87cd, ((5, 3), (5, 4))] = 76
Updated Q[0x87cd, ((0, 6), (1, 6))] = 25.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 7), (0, 8))] = 25.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 0), (1, 0))] = 25.0, N[0x87cd, ((0, 0), (1, 0))] = 1

--- Simulation 97 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.136433521424863, 17.136433521424863, 20.136433521424863, 26.136433521424863, 17.136433521424863, 21.136433521424863, 21.136433521424863, 18.136433521424863, 20.136433521424863, 27.136433521424863, 17.136433521424863, 28.00822362682852, 23.136433521424863, 17.136433521424863, 17.136433521424863, 17.136433521424863, 20.136433521424863, 17.136433521424863, 25.510686630553774, 20.136433521424863]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 13
Depth 2: State = 0x87c9, Legal Moves = [((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((3, 2), (3, 3)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0x87c9, Score: 16
Depth 3: State = 0x87c9, Legal Moves = [((2, 2), (2, 3)), ((3, 2), (3, 3)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0xa7e6, Score: 19
Depth 4: State = 0xa7e6, Legal Moves = [((1, 0), (1, 1)), ((2, 0), (2, 1)), ((3, 2), (3, 3)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa7e6: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0xa790, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.68831168831169, N[0x87cd, ((5, 3), (5, 4))] = 77
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 4), (1, 5))] = 22.0, N[0x87c9, ((1, 4), (1, 5))] = 1
Updated Q[0x87c9, ((2, 2), (2, 3))] = 22.0, N[0x87c9, ((2, 2), (2, 3))] = 1
Updated Q[0xa7e6, ((1, 0), (1, 1))] = 22.0, N[0xa7e6, ((1, 0), (1, 1))] = 1

--- Simulation 98 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.138857400226435, 17.138857400226435, 20.138857400226435, 26.138857400226435, 17.138857400226435, 21.138857400226435, 21.138857400226435, 18.138857400226435, 20.138857400226435, 27.138857400226435, 17.138857400226435, 27.932057110606458, 23.138857400226435, 17.138857400226435, 17.138857400226435, 17.138857400226435, 20.138857400226435, 17.138857400226435, 25.512400571691142, 20.138857400226435]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x87ca, Score: 13
Depth 3: State = 0x87ca, Legal Moves = [((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 2), (3, 3)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cb, Score: 16
Depth 4: State = 0x87cb, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 2), (3, 3)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cb, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.576923076923077, N[0x87cd, ((5, 3), (5, 4))] = 78
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 19.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x87ca, ((0, 3), (1, 3))] = 19.0, N[0x87ca, ((0, 3), (1, 3))] = 1
Updated Q[0x87cb, ((1, 5), (2, 5))] = 19.0, N[0x87cb, ((1, 5), (2, 5))] = 1

--- Simulation 99 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.14125371655733, 17.14125371655733, 20.14125371655733, 26.14125371655733, 17.14125371655733, 21.14125371655733, 21.14125371655733, 18.14125371655733, 20.14125371655733, 27.14125371655733, 17.14125371655733, 27.81937231767654, 23.14125371655733, 17.14125371655733, 17.14125371655733, 17.14125371655733, 20.14125371655733, 17.14125371655733, 25.514095023218584, 20.14125371655733]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 22
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 3), (1, 4)), ((1, 4), (2, 4)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xca02, Score: 28
Depth 4: State = 0xca02, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xca02: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x443d, Score: 32
End of simulation with depth 5. Reward (Score): 32
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.632911392405063, N[0x87cd, ((5, 3), (5, 4))] = 79
Updated Q[0x87cd, ((0, 5), (1, 5))] = 32.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 32.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 32.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xca02, ((0, 1), (1, 1))] = 32.0, N[0xca02, ((0, 1), (1, 1))] = 1

--- Simulation 100 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.143623066244295, 17.143623066244295, 20.143623066244295, 26.143623066244295, 17.143623066244295, 21.143623066244295, 21.143623066244295, 18.143623066244295, 20.143623066244295, 27.143623066244295, 17.143623066244295, 27.874087830002804, 23.143623066244295, 17.143623066244295, 17.143623066244295, 17.143623066244295, 20.143623066244295, 17.143623066244295, 25.515770406449242, 20.143623066244295]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 2), (0, 3)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87c9, Score: 13
Depth 2: State = 0x87c9, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87c9, Score: 16
Depth 3: State = 0x87c9, Legal Moves = [((1, 5), (1, 6)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (1, 6))
New board state after move: 0x87c9, Score: 22
Depth 4: State = 0x87c9, Legal Moves = [((2, 2), (2, 3)), ((2, 6), (2, 7)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x6502, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.6, N[0x87cd, ((5, 3), (5, 4))] = 80
Updated Q[0x87cd, ((0, 2), (0, 3))] = 25.0, N[0x87cd, ((0, 2), (0, 3))] = 1
Updated Q[0x87c9, ((1, 5), (2, 5))] = 25.0, N[0x87c9, ((1, 5), (2, 5))] = 1
Updated Q[0x87c9, ((1, 5), (1, 6))] = 25.0, N[0x87c9, ((1, 5), (1, 6))] = 1
Updated Q[0x87c9, ((2, 2), (2, 3))] = 25.0, N[0x87c9, ((2, 2), (2, 3))] = 1

Best move selected: ((5, 3), (5, 4))

--- Summary of States Visited ---
State 0x87cd visited 100 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x6504 visited 1 times
State 0x87ca visited 1 times
State 0x87ca visited 1 times
State 0x6603 visited 1 times
State 0x6603 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x22ca visited 1 times
State 0xc9b0 visited 1 times
State 0x6557 visited 1 times
State 0x6557 visited 1 times
State 0x6557 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x2323 visited 1 times
State 0x221e visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x87cb visited 1 times
State 0x87cb visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0xa7e4 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x2374 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xc9af visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x4393 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x6602 visited 1 times
State 0x64ad visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xca06 visited 1 times
State 0x87c9 visited 1 times
State 0x87cb visited 1 times
State 0x86ca visited 1 times
State 0x86ca visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x871e visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0xc9b0 visited 1 times
State 0x8676 visited 1 times
State 0x8676 visited 1 times
State 0x8676 visited 1 times
State 0x65ae visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xcaae visited 1 times
State 0xcaae visited 1 times
State 0x861e visited 1 times
State 0x861e visited 1 times
State 0x861e visited 1 times
State 0x861e visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xa891 visited 1 times
State 0xa891 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x8673 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xa83d visited 1 times
State 0xa93e visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8673 visited 1 times
State 0x8674 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x6659 visited 1 times
State 0x87cd visited 1 times
State 0x8778 visited 1 times
State 0x8677 visited 1 times
State 0x8677 visited 1 times
State 0x87cd visited 1 times
State 0x21ca visited 1 times
State 0x21ca visited 1 times
State 0x21ca visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x44e6 visited 1 times
State 0x44e6 visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x64af visited 1 times
State 0x665b visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xa8e5 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8777 visited 1 times
State 0x8774 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8720 visited 1 times
State 0xc9ad visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x21c9 visited 1 times
State 0xa791 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x443c visited 1 times
State 0x433d visited 1 times
State 0x433d visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x861d visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0xca03 visited 1 times
State 0x65ac visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0xa7e4 visited 1 times
State 0xa7e5 visited 1 times
State 0x87cd visited 1 times
State 0x8621 visited 1 times
State 0x871f visited 1 times
State 0x64ae visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8620 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8776 visited 1 times
State 0xa93d visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x64b0 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x22cc visited 1 times
State 0x2276 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xca06 visited 1 times
State 0xa93d visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x8631 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x64ad visited 1 times
State 0x2222 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x86cb visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8676 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8777 visited 1 times
State 0x8777 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x2321 visited 1 times
State 0x22cb visited 1 times
State 0x2277 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x6603 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8775 visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x6504 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8677 visited 1 times
State 0x861e visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x86ca visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0xa93c visited 1 times
State 0xa792 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x87cb visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0xa892 visited 1 times
State 0x4492 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x22c9 visited 1 times
State 0x231f visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x86cb visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x433e visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xae3f visited 1 times
State 0xae41 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x86ca visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0xa7e6 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87cb visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xca02 visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
