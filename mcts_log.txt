
--- Simulation 1 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 9
Depth 3: State = 0x87ca, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x6504, Score: 12
Depth 4: State = 0x6504, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6504: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x87ca, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 15.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((0, 0), (1, 0))] = 15.0, N[0x87ca, ((0, 0), (1, 0))] = 1
Updated Q[0x6504, ((0, 1), (1, 1))] = 15.0, N[0x6504, ((0, 1), (1, 1))] = 1

--- Simulation 2 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [15.0, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 3
Depth 1: State = 0x87ca, Legal Moves = [((0, 5), (1, 5)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87ca, Score: 6
Depth 2: State = 0x87ca, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x6603, Score: 9
Depth 3: State = 0x6603, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6603: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x6603, Score: 12
Depth 4: State = 0x6603, Legal Moves = [((2, 1), (3, 1)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6603: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x6658, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((0, 5), (1, 5))] = 15.0, N[0x87ca, ((0, 5), (1, 5))] = 1
Updated Q[0x87ca, ((1, 2), (2, 2))] = 15.0, N[0x87ca, ((1, 2), (2, 2))] = 1
Updated Q[0x6603, ((1, 0), (1, 1))] = 15.0, N[0x6603, ((1, 0), (1, 1))] = 1
Updated Q[0x6603, ((2, 1), (3, 1))] = 15.0, N[0x6603, ((2, 1), (3, 1))] = 1

--- Simulation 3 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [15.832554611157697, 15.832554611157697, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (1, 6))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 12
Depth 3: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 3), (4, 3)), ((3, 5), (4, 5)), ((4, 2), (4, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x22ca, Score: 15
Depth 4: State = 0x22ca, Legal Moves = [((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 3), (4, 3)), ((3, 5), (4, 5)), ((4, 2), (4, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x22ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0x22ca, Score: 18
End of simulation with depth 5. Reward (Score): 18
Updated Q[0x87cd, ((1, 5), (1, 6))] = 18.0, N[0x87cd, ((1, 5), (1, 6))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 18.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 18.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 18.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0x22ca, ((1, 4), (1, 5))] = 18.0, N[0x22ca, ((1, 4), (1, 5))] = 1

--- Simulation 4 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.048147073968206, 16.048147073968206, 19.048147073968206, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0xc9b0, Score: 9
Depth 1: State = 0xc9b0, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (0, 5)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xc9b0: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x6557, Score: 12
Depth 2: State = 0x6557, Legal Moves = [((0, 4), (0, 5)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6557: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x6557, Score: 15
Depth 3: State = 0x6557, Legal Moves = [((1, 4), (2, 4)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6557: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x6557, Score: 18
Depth 4: State = 0x6557, Legal Moves = [((0, 3), (1, 3)), ((1, 4), (1, 5)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((3, 2), (3, 3)), ((3, 5), (4, 5)), ((3, 6), (3, 7)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6557: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x6556, Score: 24
End of simulation with depth 5. Reward (Score): 24
Updated Q[0x87cd, ((2, 2), (2, 3))] = 24.0, N[0x87cd, ((2, 2), (2, 3))] = 1
Updated Q[0xc9b0, ((0, 1), (1, 1))] = 24.0, N[0xc9b0, ((0, 1), (1, 1))] = 1
Updated Q[0x6557, ((0, 4), (0, 5))] = 24.0, N[0x6557, ((0, 4), (0, 5))] = 1
Updated Q[0x6557, ((1, 4), (2, 4))] = 24.0, N[0x6557, ((1, 4), (2, 4))] = 1
Updated Q[0x6557, ((0, 3), (1, 3))] = 24.0, N[0x6557, ((0, 3), (1, 3))] = 1

--- Simulation 5 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.177410022515474, 16.177410022515474, 19.177410022515474, 25.177410022515474, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((3, 5), (4, 5))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x2323, Score: 9
Depth 3: State = 0x2323, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 0), (2, 1)), ((2, 5), (2, 6)), ((3, 6), (3, 7)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2323: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x221e, Score: 12
Depth 4: State = 0x221e, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 0), (2, 1)), ((2, 5), (2, 6)), ((3, 6), (3, 7)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x221e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x22c9, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((3, 5), (4, 5))] = 15.0, N[0x87cd, ((3, 5), (4, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 15.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x2323, ((0, 1), (1, 1))] = 15.0, N[0x2323, ((0, 1), (1, 1))] = 1
Updated Q[0x221e, ((1, 0), (1, 1))] = 15.0, N[0x221e, ((1, 0), (1, 1))] = 1

--- Simulation 6 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.268636241179518, 16.268636241179518, 19.268636241179518, 25.268636241179518, 16.268636241179518, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 3), (4, 4))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x87cb, Score: 6
Depth 2: State = 0x87cb, Legal Moves = [((0, 5), (1, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cb, Score: 9
Depth 3: State = 0x87cb, Legal Moves = [((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((3, 5), (4, 5)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (1, 6))
New board state after move: 0x87cb, Score: 12
Depth 4: State = 0x87cb, Legal Moves = [((2, 2), (2, 3)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x6501, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((4, 3), (4, 4))] = 19.0, N[0x87cd, ((4, 3), (4, 4))] = 1
Updated Q[0x87cd, ((0, 2), (1, 2))] = 19.0, N[0x87cd, ((0, 2), (1, 2))] = 1
Updated Q[0x87cb, ((0, 5), (1, 5))] = 19.0, N[0x87cb, ((0, 5), (1, 5))] = 1
Updated Q[0x87cb, ((1, 5), (1, 6))] = 19.0, N[0x87cb, ((1, 5), (1, 6))] = 1
Updated Q[0x87cb, ((2, 2), (2, 3))] = 19.0, N[0x87cb, ((2, 2), (2, 3))] = 1

--- Simulation 7 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.33856619904585, 16.33856619904585, 19.33856619904585, 25.33856619904585, 16.33856619904585, 20.33856619904585, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 4), (4, 5))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((3, 7), (4, 7)), ((4, 2), (5, 2)), ((4, 4), (5, 4)), ((4, 5), (5, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (6, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((3, 7), (4, 7)), ((4, 2), (5, 2)), ((4, 4), (5, 4)), ((4, 5), (5, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (6, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 12
Depth 3: State = 0x87c9, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((3, 7), (4, 7)), ((4, 2), (5, 2)), ((4, 4), (5, 4)), ((4, 5), (5, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (6, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xa7e4, Score: 16
Depth 4: State = 0xa7e4, Legal Moves = [((1, 0), (1, 1)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((3, 7), (4, 7)), ((4, 2), (5, 2)), ((4, 4), (5, 4)), ((4, 5), (5, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (6, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa7e4: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0xa78f, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((4, 4), (4, 5))] = 19.0, N[0x87cd, ((4, 4), (4, 5))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 19.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 2), (2, 2))] = 19.0, N[0x87c9, ((1, 2), (2, 2))] = 1
Updated Q[0xa7e4, ((1, 0), (1, 1))] = 19.0, N[0xa7e4, ((1, 0), (1, 1))] = 1

--- Simulation 8 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.39495883417946, 16.39495883417946, 19.39495883417946, 25.39495883417946, 16.39495883417946, 20.39495883417946, 20.39495883417946, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 6), (5, 6))
New board state after move: 0x87cd, Score: 4
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 7
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 4), (3, 5)), ((3, 5), (3, 6)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 10
Depth 3: State = 0x87cd, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 4), (3, 5)), ((3, 5), (3, 6)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x2374, Score: 13
Depth 4: State = 0x2374, Legal Moves = [((0, 0), (0, 1)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 4), (3, 5)), ((3, 5), (3, 6)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2374: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0xca06, Score: 16
End of simulation with depth 5. Reward (Score): 16
Updated Q[0x87cd, ((4, 6), (5, 6))] = 16.0, N[0x87cd, ((4, 6), (5, 6))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 16.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 16.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 0), (1, 0))] = 16.0, N[0x87cd, ((0, 0), (1, 0))] = 1
Updated Q[0x2374, ((0, 0), (0, 1))] = 16.0, N[0x2374, ((0, 0), (0, 1))] = 1

--- Simulation 9 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.442026886600882, 16.442026886600882, 19.442026886600882, 25.442026886600882, 16.442026886600882, 20.442026886600882, 20.442026886600882, 17.442026886600882, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 6), (4, 7))
New board state after move: 0x87cd, Score: 6
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 9
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 4), (3, 5)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 12
Depth 3: State = 0x87cd, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 4), (3, 5)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0xc9af, Score: 15
Depth 4: State = 0xc9af, Legal Moves = [((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 4), (3, 5)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((3, 6), (3, 7)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 5), (5, 5)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xc9af: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 6), (2, 6))
New board state after move: 0xc9af, Score: 18
End of simulation with depth 5. Reward (Score): 18
Updated Q[0x87cd, ((4, 6), (4, 7))] = 18.0, N[0x87cd, ((4, 6), (4, 7))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 18.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 18.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 0), (1, 0))] = 18.0, N[0x87cd, ((0, 0), (1, 0))] = 1
Updated Q[0xc9af, ((1, 6), (2, 6))] = 18.0, N[0xc9af, ((1, 6), (2, 6))] = 1

--- Simulation 10 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.48230380736751, 16.48230380736751, 19.48230380736751, 25.48230380736751, 16.48230380736751, 20.48230380736751, 20.48230380736751, 17.48230380736751, 19.48230380736751, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((4, 7), (5, 7))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 3), (4, 4)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 10
Depth 2: State = 0x87c9, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 3), (4, 4)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87c9, Score: 13
Depth 3: State = 0x87c9, Legal Moves = [((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 7), (3, 8)), ((4, 3), (4, 4)), ((4, 5), (4, 6)), ((5, 1), (5, 2)), ((5, 5), (5, 6)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x4393, Score: 22
Depth 4: State = 0x4393, Legal Moves = [((0, 3), (1, 3)), ((0, 3), (0, 4)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((3, 3), (4, 3)), ((3, 7), (3, 8)), ((4, 5), (4, 6)), ((5, 5), (5, 6)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x4393: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4393, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((4, 7), (5, 7))] = 25.0, N[0x87cd, ((4, 7), (5, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 5), (2, 5))] = 25.0, N[0x87c9, ((1, 5), (2, 5))] = 1
Updated Q[0x87c9, ((2, 2), (2, 3))] = 25.0, N[0x87c9, ((2, 2), (2, 3))] = 1
Updated Q[0x4393, ((0, 3), (1, 3))] = 25.0, N[0x4393, ((0, 3), (1, 3))] = 1

--- Simulation 11 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.517427129385148, 16.517427129385148, 19.517427129385148, 25.517427129385148, 16.517427129385148, 20.517427129385148, 20.517427129385148, 17.517427129385148, 19.517427129385148, 26.517427129385148, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((5, 1), (5, 2))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 1), (4, 1)), ((3, 2), (4, 2)), ((3, 5), (4, 5)), ((4, 1), (5, 1)), ((4, 1), (4, 2)), ((4, 2), (5, 2)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((2, 2), (2, 3)), ((2, 7), (2, 8)), ((3, 1), (4, 1)), ((3, 2), (4, 2)), ((3, 5), (4, 5)), ((4, 1), (5, 1)), ((4, 1), (4, 2)), ((4, 2), (5, 2)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x6602, Score: 9
Depth 3: State = 0x6602, Legal Moves = [((1, 3), (2, 3)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 1), (4, 1)), ((3, 2), (4, 2)), ((3, 5), (4, 5)), ((4, 1), (5, 1)), ((4, 1), (4, 2)), ((4, 2), (5, 2)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6602: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x64ad, Score: 12
Depth 4: State = 0x64ad, Legal Moves = [((0, 1), (1, 1)), ((1, 1), (1, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 1), (4, 1)), ((3, 1), (3, 2)), ((3, 2), (4, 2)), ((3, 5), (4, 5)), ((4, 1), (5, 1)), ((4, 1), (4, 2)), ((4, 2), (5, 2)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x64ad: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x655b, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((5, 1), (5, 2))] = 15.0, N[0x87cd, ((5, 1), (5, 2))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((2, 2), (2, 3))] = 15.0, N[0x87cd, ((2, 2), (2, 3))] = 1
Updated Q[0x6602, ((1, 3), (2, 3))] = 15.0, N[0x6602, ((1, 3), (2, 3))] = 1
Updated Q[0x64ad, ((0, 1), (1, 1))] = 15.0, N[0x64ad, ((0, 1), (1, 1))] = 1

--- Simulation 12 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.548513891703386, 16.548513891703386, 19.548513891703386, 25.548513891703386, 16.548513891703386, 20.548513891703386, 20.548513891703386, 17.548513891703386, 19.548513891703386, 26.548513891703386, 16.548513891703386, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 5), (0, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xca06, Score: 22
Depth 4: State = 0xca06, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xca06: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x86c9, Score: 31
End of simulation with depth 5. Reward (Score): 31
Updated Q[0x87cd, ((5, 3), (5, 4))] = 31.0, N[0x87cd, ((5, 3), (5, 4))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 31.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 31.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 31.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xca06, ((0, 1), (1, 1))] = 31.0, N[0xca06, ((0, 1), (1, 1))] = 1

--- Simulation 13 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.576358667876065, 16.576358667876065, 19.576358667876065, 25.576358667876065, 16.576358667876065, 20.576358667876065, 20.576358667876065, 17.576358667876065, 19.576358667876065, 26.576358667876065, 16.576358667876065, 32.576358667876065, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((5, 4), (5, 5))
New board state after move: 0x87c9, Score: 6
Depth 1: State = 0x87c9, Legal Moves = [((0, 2), (1, 2)), ((0, 4), (1, 4)), ((0, 5), (1, 5)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (3, 2)), ((2, 5), (2, 6)), ((3, 2), (3, 3)), ((3, 5), (3, 6)), ((3, 6), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (7, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x87cb, Score: 9
Depth 2: State = 0x87cb, Legal Moves = [((0, 3), (1, 3)), ((0, 5), (1, 5)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (3, 2)), ((2, 5), (2, 6)), ((3, 2), (3, 3)), ((3, 5), (3, 6)), ((3, 6), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (7, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x86ca, Score: 12
Depth 3: State = 0x86ca, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 5), (2, 6)), ((3, 2), (3, 3)), ((3, 5), (3, 6)), ((3, 6), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (7, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x86ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x86ca, Score: 15
Depth 4: State = 0x86ca, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (2, 2)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((3, 5), (3, 6)), ((3, 6), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (7, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x86ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x8720, Score: 21
End of simulation with depth 5. Reward (Score): 21
Updated Q[0x87cd, ((5, 4), (5, 5))] = 21.0, N[0x87cd, ((5, 4), (5, 5))] = 1
Updated Q[0x87c9, ((0, 2), (1, 2))] = 21.0, N[0x87c9, ((0, 2), (1, 2))] = 1
Updated Q[0x87cb, ((0, 3), (1, 3))] = 21.0, N[0x87cb, ((0, 3), (1, 3))] = 1
Updated Q[0x86ca, ((0, 5), (1, 5))] = 21.0, N[0x86ca, ((0, 5), (1, 5))] = 1
Updated Q[0x86ca, ((1, 1), (1, 2))] = 21.0, N[0x86ca, ((1, 1), (1, 2))] = 1

--- Simulation 14 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.601545927365663, 16.601545927365663, 19.601545927365663, 25.601545927365663, 16.601545927365663, 20.601545927365663, 20.601545927365663, 17.601545927365663, 19.601545927365663, 26.601545927365663, 16.601545927365663, 32.60154592736566, 22.601545927365663, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((5, 6), (6, 6))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 4), (4, 4)), ((3, 7), (4, 7)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 4), (4, 4)), ((3, 7), (4, 7)), ((3, 7), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 9
Depth 3: State = 0x87cd, Legal Moves = [((1, 0), (1, 1)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 4), (4, 4)), ((3, 7), (4, 7)), ((3, 7), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x871e, Score: 12
Depth 4: State = 0x871e, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (1, 3)), ((1, 6), (1, 7)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 4), (4, 4)), ((3, 7), (4, 7)), ((3, 7), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (6, 7)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x871e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x871f, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((5, 6), (6, 6))] = 15.0, N[0x87cd, ((5, 6), (6, 6))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 0), (1, 1))] = 15.0, N[0x87cd, ((1, 0), (1, 1))] = 1
Updated Q[0x871e, ((0, 2), (0, 3))] = 15.0, N[0x871e, ((0, 2), (0, 3))] = 1

--- Simulation 15 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.624517568269194, 16.624517568269194, 19.624517568269194, 25.624517568269194, 16.624517568269194, 20.624517568269194, 20.624517568269194, 17.624517568269194, 19.624517568269194, 26.624517568269194, 16.624517568269194, 32.6245175682692, 22.624517568269194, 16.624517568269194, inf, inf, inf, inf, inf, inf]
Selected move: ((5, 6), (5, 7))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 7), (6, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (7, 6)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 7), (6, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (7, 6)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 9
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 7), (6, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (7, 6)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 12
Depth 4: State = 0x87c9, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((5, 1), (5, 2)), ((5, 4), (5, 5)), ((5, 7), (6, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 6), (7, 6)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0xca03, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((5, 6), (5, 7))] = 15.0, N[0x87cd, ((5, 6), (5, 7))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 15.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((0, 0), (1, 0))] = 15.0, N[0x87c9, ((0, 0), (1, 0))] = 1

--- Simulation 16 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.645615447515674, 16.645615447515674, 19.645615447515674, 25.645615447515674, 16.645615447515674, 20.645615447515674, 20.645615447515674, 17.645615447515674, 19.645615447515674, 26.645615447515674, 16.645615447515674, 32.645615447515674, 22.645615447515674, 16.645615447515674, 16.645615447515674, inf, inf, inf, inf, inf]
Selected move: ((5, 8), (5, 9))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 9
Depth 3: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0xc9b0, Score: 12
Depth 4: State = 0xc9b0, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (7, 7)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xc9b0: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x87cb, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((5, 8), (5, 9))] = 15.0, N[0x87cd, ((5, 8), (5, 9))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 15.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 15.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0xc9b0, ((0, 1), (1, 1))] = 15.0, N[0xc9b0, ((0, 1), (1, 1))] = 1

--- Simulation 17 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.665109222315394, 16.665109222315394, 19.665109222315394, 25.665109222315394, 16.665109222315394, 20.665109222315394, 20.665109222315394, 17.665109222315394, 19.665109222315394, 26.665109222315394, 16.665109222315394, 32.665109222315394, 22.665109222315394, 16.665109222315394, 16.665109222315394, 16.665109222315394, inf, inf, inf, inf]
Selected move: ((6, 1), (7, 1))
New board state after move: 0x8676, Score: 3
Depth 1: State = 0x8676, Legal Moves = [((0, 5), (1, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (6, 1)), ((5, 2), (6, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 2), (8, 2)), ((8, 2), (9, 2)), ((8, 3), (9, 3))]
UCB1 values for moves at state 0x8676: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x8676, Score: 6
Depth 2: State = 0x8676, Legal Moves = [((1, 2), (1, 3)), ((1, 6), (1, 7)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (6, 1)), ((5, 2), (6, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 2), (8, 2)), ((8, 2), (9, 2)), ((8, 3), (9, 3))]
UCB1 values for moves at state 0x8676: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x8676, Score: 9
Depth 3: State = 0x8676, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((0, 2), (0, 3)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (6, 1)), ((5, 2), (6, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 2), (8, 2)), ((8, 2), (9, 2)), ((8, 3), (9, 3))]
UCB1 values for moves at state 0x8676: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x65ae, Score: 12
Depth 4: State = 0x65ae, Legal Moves = [((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (6, 1)), ((5, 2), (6, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 2), (8, 2)), ((8, 2), (9, 2)), ((8, 3), (9, 3))]
UCB1 values for moves at state 0x65ae: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x22cd, Score: 18
End of simulation with depth 5. Reward (Score): 18
Updated Q[0x87cd, ((6, 1), (7, 1))] = 18.0, N[0x87cd, ((6, 1), (7, 1))] = 1
Updated Q[0x8676, ((0, 5), (1, 5))] = 18.0, N[0x8676, ((0, 5), (1, 5))] = 1
Updated Q[0x8676, ((1, 2), (1, 3))] = 18.0, N[0x8676, ((1, 2), (1, 3))] = 1
Updated Q[0x8676, ((0, 1), (1, 1))] = 18.0, N[0x8676, ((0, 1), (1, 1))] = 1
Updated Q[0x65ae, ((2, 1), (2, 2))] = 18.0, N[0x65ae, ((2, 1), (2, 2))] = 1

--- Simulation 18 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.68321518055661, 16.68321518055661, 19.68321518055661, 25.68321518055661, 16.68321518055661, 20.68321518055661, 20.68321518055661, 17.68321518055661, 19.68321518055661, 26.68321518055661, 16.68321518055661, 32.68321518055661, 22.68321518055661, 16.68321518055661, 16.68321518055661, 16.68321518055661, 19.68321518055661, inf, inf, inf]
Selected move: ((6, 4), (6, 5))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 5), (1, 6)), ((2, 2), (3, 2)), ((3, 2), (3, 3)), ((3, 6), (4, 6)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (7, 1)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 6), (1, 7)), ((2, 2), (3, 2)), ((2, 4), (2, 5)), ((3, 6), (4, 6)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (7, 1)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 9
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((2, 2), (3, 2)), ((3, 6), (4, 6)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (7, 1)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 12
Depth 4: State = 0x87cd, Legal Moves = [((2, 2), (3, 2)), ((3, 6), (4, 6)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (7, 1)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x665a, Score: 15
End of simulation with depth 5. Reward (Score): 15
Updated Q[0x87cd, ((6, 4), (6, 5))] = 15.0, N[0x87cd, ((6, 4), (6, 5))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 15.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 15.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 4), (1, 4))] = 15.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((2, 2), (3, 2))] = 15.0, N[0x87cd, ((2, 2), (3, 2))] = 1

--- Simulation 19 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.70010933704164, 16.70010933704164, 19.70010933704164, 25.70010933704164, 16.70010933704164, 20.70010933704164, 20.70010933704164, 17.70010933704164, 19.70010933704164, 26.70010933704164, 16.70010933704164, 32.70010933704164, 22.70010933704164, 16.70010933704164, 16.70010933704164, 16.70010933704164, 19.70010933704164, 16.70010933704164, inf, inf]
Selected move: ((6, 7), (6, 8))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 9
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xcaae, Score: 21
Depth 3: State = 0xcaae, Legal Moves = [((1, 4), (1, 5)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 4), (2, 5)), ((2, 7), (2, 8)), ((3, 4), (4, 4)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0xcaae: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0xcaae, Score: 24
Depth 4: State = 0xcaae, Legal Moves = [((1, 6), (1, 7)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 4), (2, 5)), ((2, 5), (2, 6)), ((2, 7), (2, 8)), ((3, 4), (4, 4)), ((3, 4), (3, 5)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0xcaae: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 6), (1, 7))
New board state after move: 0xcaae, Score: 27
End of simulation with depth 5. Reward (Score): 27
Updated Q[0x87cd, ((6, 7), (6, 8))] = 27.0, N[0x87cd, ((6, 7), (6, 8))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 27.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 27.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xcaae, ((1, 4), (1, 5))] = 27.0, N[0xcaae, ((1, 4), (1, 5))] = 1
Updated Q[0xcaae, ((1, 6), (1, 7))] = 27.0, N[0xcaae, ((1, 6), (1, 7))] = 1

--- Simulation 20 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.71593676432625, 16.71593676432625, 19.71593676432625, 25.71593676432625, 16.71593676432625, 20.71593676432625, 20.71593676432625, 17.71593676432625, 19.71593676432625, 26.71593676432625, 16.71593676432625, 32.71593676432625, 22.71593676432625, 16.71593676432625, 16.71593676432625, 16.71593676432625, 19.71593676432625, 16.71593676432625, 28.71593676432625, inf]
Selected move: ((7, 3), (8, 3))
New board state after move: 0x861e, Score: 3
Depth 1: State = 0x861e, Legal Moves = [((0, 5), (1, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (6, 2)), ((6, 7), (6, 8)), ((8, 2), (9, 2))]
UCB1 values for moves at state 0x861e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x861e, Score: 6
Depth 2: State = 0x861e, Legal Moves = [((1, 6), (1, 7)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (6, 2)), ((6, 7), (6, 8)), ((8, 2), (9, 2))]
UCB1 values for moves at state 0x861e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 6), (1, 7))
New board state after move: 0x861e, Score: 9
Depth 3: State = 0x861e, Legal Moves = [((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((4, 4), (4, 5)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (6, 2)), ((6, 7), (6, 8)), ((8, 2), (9, 2))]
UCB1 values for moves at state 0x861e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (1, 6))
New board state after move: 0x861e, Score: 12
Depth 4: State = 0x861e, Legal Moves = [((0, 3), (1, 3)), ((1, 8), (1, 9)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 4), (4, 4)), ((3, 5), (4, 5)), ((3, 6), (4, 6)), ((4, 4), (4, 5)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 0), (6, 1)), ((6, 1), (6, 2)), ((6, 7), (6, 8)), ((8, 2), (9, 2))]
UCB1 values for moves at state 0x861e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x861e, Score: 18
End of simulation with depth 5. Reward (Score): 18
Updated Q[0x87cd, ((7, 3), (8, 3))] = 18.0, N[0x87cd, ((7, 3), (8, 3))] = 1
Updated Q[0x861e, ((0, 5), (1, 5))] = 18.0, N[0x861e, ((0, 5), (1, 5))] = 1
Updated Q[0x861e, ((1, 6), (1, 7))] = 18.0, N[0x861e, ((1, 6), (1, 7))] = 1
Updated Q[0x861e, ((1, 5), (1, 6))] = 18.0, N[0x861e, ((1, 5), (1, 6))] = 1
Updated Q[0x861e, ((0, 3), (1, 3))] = 18.0, N[0x861e, ((0, 3), (1, 3))] = 1

--- Simulation 21 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.730818382602287, 16.730818382602287, 19.730818382602287, 25.730818382602287, 16.730818382602287, 20.730818382602287, 20.730818382602287, 17.730818382602287, 19.730818382602287, 26.730818382602287, 16.730818382602287, 32.73081838260229, 22.730818382602287, 16.730818382602287, 16.730818382602287, 16.730818382602287, 19.730818382602287, 16.730818382602287, 28.730818382602287, 19.730818382602287]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 22
Depth 4: State = 0x87c9, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xc9ac, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.0, N[0x87cd, ((5, 3), (5, 4))] = 2
Updated Q[0x87cd, ((0, 7), (1, 7))] = 25.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((0, 7), (0, 8))] = 25.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 2), (2, 2))] = 25.0, N[0x87c9, ((1, 2), (2, 2))] = 1

--- Simulation 22 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.744855993405594, 16.744855993405594, 19.744855993405594, 25.744855993405594, 16.744855993405594, 20.744855993405594, 20.744855993405594, 17.744855993405594, 19.744855993405594, 26.744855993405594, 16.744855993405594, 29.233799505131085, 22.744855993405594, 16.744855993405594, 16.744855993405594, 16.744855993405594, 19.744855993405594, 16.744855993405594, 28.744855993405594, 19.744855993405594]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((3, 6), (4, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xa891, Score: 16
Depth 3: State = 0xa891, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa891: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0xa891, Score: 19
Depth 4: State = 0xa891, Legal Moves = [((1, 5), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa891: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0xa891, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.0, N[0x87cd, ((5, 3), (5, 4))] = 3
Updated Q[0x87cd, ((0, 5), (0, 6))] = 22.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xa891, ((0, 1), (1, 1))] = 22.0, N[0xa891, ((0, 1), (1, 1))] = 1
Updated Q[0xa891, ((1, 5), (2, 5))] = 22.0, N[0xa891, ((1, 5), (2, 5))] = 1

--- Simulation 23 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.7581360736184, 16.7581360736184, 19.7581360736184, 25.7581360736184, 16.7581360736184, 20.7581360736184, 20.7581360736184, 17.7581360736184, 19.7581360736184, 26.7581360736184, 16.7581360736184, 27.015060335375573, 22.7581360736184, 16.7581360736184, 16.7581360736184, 16.7581360736184, 19.7581360736184, 16.7581360736184, 28.7581360736184, 19.7581360736184]
Selected move: ((6, 7), (6, 8))
New board state after move: 0x87cd, Score: 3
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 6
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 12
Depth 3: State = 0x87cb, Legal Moves = [((2, 2), (2, 3)), ((3, 2), (4, 2)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x8673, Score: 18
Depth 4: State = 0x8673, Legal Moves = [((0, 2), (1, 2)), ((1, 0), (1, 1)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (5, 7)), ((5, 8), (6, 8)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 8), (6, 9)), ((7, 3), (8, 3)), ((7, 6), (7, 7)), ((8, 6), (8, 7))]
UCB1 values for moves at state 0x8673: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x8674, Score: 21
End of simulation with depth 5. Reward (Score): 21
Updated Q[0x87cd, ((6, 7), (6, 8))] = 24.0, N[0x87cd, ((6, 7), (6, 8))] = 2
Updated Q[0x87cd, ((0, 5), (1, 5))] = 21.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 21.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((2, 2), (2, 3))] = 21.0, N[0x87cb, ((2, 2), (2, 3))] = 1
Updated Q[0x8673, ((0, 2), (1, 2))] = 21.0, N[0x8673, ((0, 2), (1, 2))] = 1

--- Simulation 24 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.7707326777154, 16.7707326777154, 19.7707326777154, 25.7707326777154, 16.7707326777154, 20.7707326777154, 20.7707326777154, 17.7707326777154, 19.7707326777154, 26.7707326777154, 16.7707326777154, 27.02233298814185, 22.7707326777154, 16.7707326777154, 16.7707326777154, 16.7707326777154, 19.7707326777154, 16.7707326777154, 25.25209708408117, 19.7707326777154]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 25
Depth 3: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 31
Depth 4: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 34
End of simulation with depth 5. Reward (Score): 34
Updated Q[0x87cd, ((5, 3), (5, 4))] = 28.0, N[0x87cd, ((5, 3), (5, 4))] = 4
Updated Q[0x87cd, ((0, 4), (1, 4))] = 34.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 34.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 34.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 34.0, N[0x87cd, ((0, 6), (1, 6))] = 1

--- Simulation 25 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.782709687623857, 16.782709687623857, 19.782709687623857, 25.782709687623857, 16.782709687623857, 20.782709687623857, 20.782709687623857, 17.782709687623857, 19.782709687623857, 26.782709687623857, 16.782709687623857, 28.89135484381193, 22.782709687623857, 16.782709687623857, 16.782709687623857, 16.782709687623857, 19.782709687623857, 16.782709687623857, 25.26056610900578, 19.782709687623857]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xa83d, Score: 19
Depth 3: State = 0xa83d, Legal Moves = [((1, 0), (1, 1)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa83d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0xa93e, Score: 22
Depth 4: State = 0xa93e, Legal Moves = [((0, 1), (1, 1)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa93e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x86c8, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.4, N[0x87cd, ((5, 3), (5, 4))] = 5
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 25.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0xa83d, ((1, 0), (1, 1))] = 25.0, N[0xa83d, ((1, 0), (1, 1))] = 1
Updated Q[0xa93e, ((0, 1), (1, 1))] = 25.0, N[0xa93e, ((0, 1), (1, 1))] = 1

--- Simulation 26 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.794122577994102, 16.794122577994102, 19.794122577994102, 25.794122577994102, 16.794122577994102, 20.794122577994102, 20.794122577994102, 17.794122577994102, 19.794122577994102, 26.794122577994102, 16.794122577994102, 28.202356008872393, 22.794122577994102, 16.794122577994102, 16.794122577994102, 16.794122577994102, 19.794122577994102, 16.794122577994102, 25.268636241179518, 19.794122577994102]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 10
Depth 2: State = 0x87c9, Legal Moves = [((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 16
Depth 4: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 6), (1, 7)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
Error: axis 1 is out of bounds for array of dimension 0
the swap is the following:
Ending simulation.
End of simulation with depth 4. Reward (Score): 26
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.166666666666668, N[0x87cd, ((5, 3), (5, 4))] = 6
Updated Q[0x87cd, ((1, 1), (1, 2))] = 26.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 2), (2, 2))] = 26.0, N[0x87c9, ((1, 2), (2, 2))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 26.0, N[0x87cd, ((1, 5), (2, 5))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 26.0, N[0x87cd, ((0, 3), (1, 3))] = 1

--- Simulation 27 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.80501981651767, 16.80501981651767, 19.80501981651767, 25.80501981651767, 16.80501981651767, 20.80501981651767, 20.80501981651767, 17.80501981651767, 19.80501981651767, 26.80501981651767, 16.80501981651767, 27.903562921013403, 22.80501981651767, 16.80501981651767, 16.80501981651767, 16.80501981651767, 19.80501981651767, 16.80501981651767, 25.27634175243574, 19.80501981651767]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 19
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 22
Depth 3: State = 0x87cd, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (2, 2)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x87cb, Score: 25
Depth 4: State = 0x87cb, Legal Moves = [((0, 2), (0, 3)), ((0, 4), (0, 5)), ((1, 4), (1, 5)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87cd, Score: 31
End of simulation with depth 5. Reward (Score): 31
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.714285714285715, N[0x87cd, ((5, 3), (5, 4))] = 7
Updated Q[0x87cd, ((0, 6), (0, 7))] = 31.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 31.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 2), (1, 2))] = 31.0, N[0x87cd, ((0, 2), (1, 2))] = 1
Updated Q[0x87cb, ((0, 2), (0, 3))] = 31.0, N[0x87cb, ((0, 2), (0, 3))] = 1

--- Simulation 28 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.815443985917586, 16.815443985917586, 19.815443985917586, 25.815443985917586, 16.815443985917586, 20.815443985917586, 20.815443985917586, 17.815443985917586, 19.815443985917586, 26.815443985917586, 16.815443985917586, 28.400459043700828, 22.815443985917586, 16.815443985917586, 16.815443985917586, 16.815443985917586, 19.815443985917586, 16.815443985917586, 25.28371275330666, 19.815443985917586]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 16
Depth 3: State = 0x87ca, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xa8e6, Score: 19
Depth 4: State = 0xa8e6, Legal Moves = [((0, 3), (1, 3)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 0), (2, 1)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa8e6: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0xa791, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.0, N[0x87cd, ((5, 3), (5, 4))] = 8
Updated Q[0x87cd, ((0, 4), (0, 5))] = 22.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((1, 2), (2, 2))] = 22.0, N[0x87ca, ((1, 2), (2, 2))] = 1
Updated Q[0xa8e6, ((0, 3), (1, 3))] = 22.0, N[0xa8e6, ((0, 3), (1, 3))] = 1

--- Simulation 29 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.82543269122014, 16.82543269122014, 19.82543269122014, 25.82543269122014, 16.82543269122014, 20.82543269122014, 20.82543269122014, 17.82543269122014, 19.82543269122014, 26.82543269122014, 16.82543269122014, 27.645387917280686, 22.82543269122014, 16.82543269122014, 16.82543269122014, 16.82543269122014, 19.82543269122014, 16.82543269122014, 25.29077583456137, 19.82543269122014]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 20
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 26
Depth 3: State = 0x87ca, Legal Moves = [((0, 3), (1, 3)), ((0, 3), (0, 4)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87ca, Score: 30
Depth 4: State = 0x87ca, Legal Moves = [((0, 2), (0, 3)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87cd, Score: 33
End of simulation with depth 5. Reward (Score): 33
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.666666666666668, N[0x87cd, ((5, 3), (5, 4))] = 9
Updated Q[0x87cd, ((0, 6), (0, 7))] = 33.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 33.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((0, 3), (1, 3))] = 33.0, N[0x87ca, ((0, 3), (1, 3))] = 1
Updated Q[0x87ca, ((0, 2), (0, 3))] = 33.0, N[0x87ca, ((0, 2), (0, 3))] = 1

--- Simulation 30 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.835019299622342, 16.835019299622342, 19.835019299622342, 25.835019299622342, 16.835019299622342, 20.835019299622342, 20.835019299622342, 17.835019299622342, 19.835019299622342, 26.835019299622342, 16.835019299622342, 28.278339766540782, 22.835019299622342, 16.835019299622342, 16.835019299622342, 16.835019299622342, 19.835019299622342, 16.835019299622342, 25.29755459037115, 19.835019299622342]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 10
Depth 2: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x21cb, Score: 13
Depth 3: State = 0x21cb, Legal Moves = [((0, 2), (0, 3)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x21cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x44a5, Score: 19
Depth 4: State = 0x44a5, Legal Moves = [((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x44a5: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0x44a5, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.1, N[0x87cd, ((5, 3), (5, 4))] = 10
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 22.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0x21cb, ((0, 2), (0, 3))] = 22.0, N[0x21cb, ((0, 2), (0, 3))] = 1
Updated Q[0x44a5, ((1, 4), (1, 5))] = 22.0, N[0x44a5, ((1, 4), (1, 5))] = 1

--- Simulation 31 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.844233548567576, 16.844233548567576, 19.844233548567576, 25.844233548567576, 16.844233548567576, 20.844233548567576, 20.844233548567576, 17.844233548567576, 19.844233548567576, 26.844233548567576, 16.844233548567576, 27.68319785507683, 22.844233548567576, 16.844233548567576, 16.844233548567576, 16.844233548567576, 19.844233548567576, 16.844233548567576, 25.30407004828386, 19.844233548567576]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x655b, Score: 22
Depth 4: State = 0x655b, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (0, 5)), ((1, 0), (1, 1)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x655b: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x65b0, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.90909090909091, N[0x87cd, ((5, 3), (5, 4))] = 11
Updated Q[0x87cd, ((0, 6), (0, 7))] = 25.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 25.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x655b, ((0, 1), (1, 1))] = 25.0, N[0x655b, ((0, 1), (1, 1))] = 1

--- Simulation 32 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.853102049128744, 16.853102049128744, 19.853102049128744, 25.853102049128744, 16.853102049128744, 20.853102049128744, 20.853102049128744, 17.853102049128744, 19.853102049128744, 26.853102049128744, 16.853102049128744, 27.467822199563525, 22.853102049128744, 16.853102049128744, 16.853102049128744, 16.853102049128744, 19.853102049128744, 16.853102049128744, 25.31034102516962, 19.853102049128744]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (1, 7)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 6), (1, 6)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 16
Depth 4: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 7), (1, 7)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.25, N[0x87cd, ((5, 3), (5, 4))] = 12
Updated Q[0x87cd, ((0, 6), (1, 6))] = 19.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 19.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 19.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 19.0, N[0x87cd, ((0, 5), (0, 6))] = 1

--- Simulation 33 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.861648705529518, 16.861648705529518, 19.861648705529518, 25.861648705529518, 16.861648705529518, 20.861648705529518, 20.861648705529518, 17.861648705529518, 19.861648705529518, 26.861648705529518, 16.861648705529518, 26.787411690636993, 22.861648705529518, 16.861648705529518, 16.861648705529518, 16.861648705529518, 19.861648705529518, 16.861648705529518, 25.31638442386708, 19.861648705529518]
Selected move: ((4, 7), (5, 7))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((1, 7), (1, 8)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 3), (4, 4)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 3), (4, 4)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((3, 3), (4, 3)), ((4, 2), (4, 3)), ((4, 3), (4, 4)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 8), (1, 9)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((3, 3), (4, 3)), ((4, 2), (4, 3)), ((4, 3), (4, 4)), ((5, 5), (6, 5)), ((5, 6), (6, 6)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((4, 7), (5, 7))] = 23.5, N[0x87cd, ((4, 7), (5, 7))] = 2
Updated Q[0x87cd, ((0, 7), (1, 7))] = 22.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 4), (2, 4))] = 22.0, N[0x87cd, ((1, 4), (2, 4))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 22.0, N[0x87cd, ((0, 4), (0, 5))] = 1

--- Simulation 34 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.86989506696672, 16.86989506696672, 19.86989506696672, 25.86989506696672, 16.86989506696672, 20.86989506696672, 20.86989506696672, 17.86989506696672, 19.86989506696672, 24.822215481959443, 16.86989506696672, 26.789792210134795, 22.86989506696672, 16.86989506696672, 16.86989506696672, 16.86989506696672, 19.86989506696672, 16.86989506696672, 25.322215481959443, 19.86989506696672]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 19
Depth 3: State = 0x87cb, Legal Moves = [((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x87ca, Score: 25
Depth 4: State = 0x87ca, Legal Moves = [((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x87ca, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.384615384615383, N[0x87cd, ((5, 3), (5, 4))] = 13
Updated Q[0x87cd, ((0, 4), (0, 5))] = 28.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((1, 2), (1, 3))] = 28.0, N[0x87cb, ((1, 2), (1, 3))] = 1
Updated Q[0x87ca, ((1, 3), (1, 4))] = 28.0, N[0x87ca, ((1, 3), (1, 4))] = 1

--- Simulation 35 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.877860624385143, 16.877860624385143, 19.877860624385143, 25.877860624385143, 16.877860624385143, 20.877860624385143, 20.877860624385143, 17.877860624385143, 19.877860624385143, 24.82784798162594, 16.877860624385143, 26.905440213030417, 22.877860624385143, 16.877860624385143, 16.877860624385143, 16.877860624385143, 19.877860624385143, 16.877860624385143, 25.32784798162594, 19.877860624385143]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 5), (0, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 1), (3, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x22cd, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.071428571428573, N[0x87cd, ((5, 3), (5, 4))] = 14
Updated Q[0x87cd, ((0, 4), (0, 5))] = 22.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 22.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 22.0, N[0x87cd, ((1, 2), (2, 2))] = 1

--- Simulation 36 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.88556306218843, 16.88556306218843, 19.88556306218843, 25.88556306218843, 16.88556306218843, 20.88556306218843, 20.88556306218843, 17.88556306218843, 19.88556306218843, 24.83329442762831, 16.88556306218843, 26.575366497133246, 22.88556306218843, 16.88556306218843, 16.88556306218843, 16.88556306218843, 19.88556306218843, 16.88556306218843, 25.33329442762831, 19.88556306218843]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 10
Depth 2: State = 0x87c9, Legal Moves = [((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87ca, Score: 13
Depth 3: State = 0x87ca, Legal Moves = [((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x87cd, Score: 16
Depth 4: State = 0x87cd, Legal Moves = [((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0x87cd, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 25.6, N[0x87cd, ((5, 3), (5, 4))] = 15
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((0, 4), (1, 4))] = 19.0, N[0x87c9, ((0, 4), (1, 4))] = 1
Updated Q[0x87ca, ((0, 2), (1, 2))] = 19.0, N[0x87ca, ((0, 2), (1, 2))] = 1
Updated Q[0x87cd, ((1, 4), (1, 5))] = 19.0, N[0x87cd, ((1, 4), (1, 5))] = 1

--- Simulation 37 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.893018472824846, 16.893018472824846, 19.893018472824846, 25.893018472824846, 16.893018472824846, 20.893018472824846, 20.893018472824846, 17.893018472824846, 19.893018472824846, 24.83856619904585, 16.893018472824846, 26.088775267954244, 22.893018472824846, 16.893018472824846, 16.893018472824846, 16.893018472824846, 19.893018472824846, 16.893018472824846, 25.33856619904585, 19.893018472824846]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 16
Depth 4: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 3), (1, 4)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 3), (3, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 25.1875, N[0x87cd, ((5, 3), (5, 4))] = 16
Updated Q[0x87cd, ((0, 4), (0, 5))] = 19.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 4), (1, 4))] = 19.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 4), (1, 4))] = 19.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1

--- Simulation 38 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.900241540605883, 16.900241540605883, 19.900241540605883, 25.900241540605883, 16.900241540605883, 20.900241540605883, 20.900241540605883, 17.900241540605883, 19.900241540605883, 24.843673679254792, 16.900241540605883, 25.662560385151473, 22.900241540605883, 16.900241540605883, 16.900241540605883, 16.900241540605883, 19.900241540605883, 16.900241540605883, 25.343673679254792, 19.900241540605883]
Selected move: ((2, 2), (2, 3))
New board state after move: 0xc901, Score: 9
Depth 1: State = 0xc901, Legal Moves = [((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xc901: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x655a, Score: 12
Depth 2: State = 0x655a, Legal Moves = [((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x655a: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x655a, Score: 18
Depth 3: State = 0x655a, Legal Moves = [((0, 5), (0, 6)), ((1, 4), (1, 5)), ((2, 1), (3, 1)), ((2, 4), (2, 5)), ((3, 5), (4, 5)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x655a: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x655a, Score: 21
Depth 4: State = 0x655a, Legal Moves = [((0, 3), (1, 3)), ((1, 4), (1, 5)), ((2, 1), (3, 1)), ((2, 4), (2, 5)), ((3, 5), (4, 5)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x655a: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x6557, Score: 27
End of simulation with depth 5. Reward (Score): 27
Updated Q[0x87cd, ((2, 2), (2, 3))] = 25.5, N[0x87cd, ((2, 2), (2, 3))] = 2
Updated Q[0xc901, ((2, 2), (3, 2))] = 27.0, N[0xc901, ((2, 2), (3, 2))] = 1
Updated Q[0x655a, ((2, 3), (2, 4))] = 27.0, N[0x655a, ((2, 3), (2, 4))] = 1
Updated Q[0x655a, ((0, 5), (0, 6))] = 27.0, N[0x655a, ((0, 5), (0, 6))] = 1
Updated Q[0x655a, ((0, 3), (1, 3))] = 27.0, N[0x655a, ((0, 3), (1, 3))] = 1

--- Simulation 39 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.9072456998841, 16.9072456998841, 19.9072456998841, 26.84862636777693, 16.9072456998841, 20.9072456998841, 20.9072456998841, 17.9072456998841, 19.9072456998841, 24.84862636777693, 16.9072456998841, 25.664311424971025, 22.9072456998841, 16.9072456998841, 16.9072456998841, 16.9072456998841, 19.9072456998841, 16.9072456998841, 25.34862636777693, 19.9072456998841]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x2273, Score: 9
Depth 1: State = 0x2273, Legal Moves = [((1, 4), (2, 4)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2273: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x2273, Score: 15
Depth 2: State = 0x2273, Legal Moves = [((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 6), (3, 6)), ((3, 4), (3, 5)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((3, 6), (3, 7)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2273: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x871f, Score: 18
Depth 3: State = 0x871f, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 6), (3, 6)), ((3, 4), (3, 5)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((3, 6), (3, 7)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x871f: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x871f, Score: 21
Depth 4: State = 0x871f, Legal Moves = [((2, 5), (3, 5)), ((2, 6), (3, 6)), ((3, 1), (4, 1)), ((3, 4), (3, 5)), ((3, 5), (4, 5)), ((3, 5), (3, 6)), ((3, 6), (3, 7)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x871f: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 5), (3, 5))
New board state after move: 0x871f, Score: 24
End of simulation with depth 5. Reward (Score): 24
Updated Q[0x87cd, ((2, 2), (2, 3))] = 25.0, N[0x87cd, ((2, 2), (2, 3))] = 3
Updated Q[0x2273, ((1, 4), (2, 4))] = 24.0, N[0x2273, ((1, 4), (2, 4))] = 1
Updated Q[0x2273, ((2, 2), (3, 2))] = 24.0, N[0x2273, ((2, 2), (3, 2))] = 1
Updated Q[0x871f, ((1, 2), (2, 2))] = 24.0, N[0x871f, ((1, 2), (2, 2))] = 1
Updated Q[0x871f, ((2, 5), (3, 5))] = 24.0, N[0x871f, ((2, 5), (3, 5))] = 1

--- Simulation 40 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.91404327174953, 16.91404327174953, 19.91404327174953, 26.105073398185183, 16.91404327174953, 20.91404327174953, 20.91404327174953, 17.91404327174953, 19.91404327174953, 24.853432976938578, 16.91404327174953, 25.666010817937384, 22.91404327174953, 16.91404327174953, 16.91404327174953, 16.91404327174953, 19.91404327174953, 16.91404327174953, 25.353432976938578, 19.91404327174953]
Selected move: ((2, 2), (2, 3))
New board state after move: 0xa893, Score: 15
Depth 1: State = 0xa893, Legal Moves = [((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 3), (3, 4)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa893: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0xa892, Score: 18
Depth 2: State = 0xa892, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (1, 1)), ((0, 3), (0, 4)), ((1, 0), (2, 0)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 3), (3, 4)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa892: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x8674, Score: 21
Depth 3: State = 0x8674, Legal Moves = [((1, 2), (2, 2)), ((2, 0), (3, 0)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 3), (3, 4)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8674: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x8675, Score: 24
Depth 4: State = 0x8675, Legal Moves = [((2, 3), (2, 4)), ((2, 4), (3, 4)), ((2, 7), (2, 8)), ((3, 1), (4, 1)), ((3, 1), (3, 2)), ((3, 2), (4, 2)), ((3, 3), (3, 4)), ((3, 4), (4, 4)), ((3, 5), (4, 5)), ((4, 1), (4, 2)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8675: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x8675, Score: 27
End of simulation with depth 5. Reward (Score): 27
Updated Q[0x87cd, ((2, 2), (2, 3))] = 25.5, N[0x87cd, ((2, 2), (2, 3))] = 4
Updated Q[0xa893, ((2, 1), (2, 2))] = 27.0, N[0xa893, ((2, 1), (2, 2))] = 1
Updated Q[0xa892, ((0, 0), (1, 0))] = 27.0, N[0xa892, ((0, 0), (1, 0))] = 1
Updated Q[0x8674, ((1, 2), (2, 2))] = 27.0, N[0x8674, ((1, 2), (2, 2))] = 1
Updated Q[0x8675, ((2, 3), (2, 4))] = 27.0, N[0x8675, ((2, 3), (2, 4))] = 1

--- Simulation 41 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.920645582639843, 16.920645582639843, 19.920645582639843, 26.46032279131992, 16.920645582639843, 20.920645582639843, 20.920645582639843, 17.920645582639843, 19.920645582639843, 24.85810151574062, 16.920645582639843, 25.66766139565996, 22.920645582639843, 16.920645582639843, 16.920645582639843, 16.920645582639843, 19.920645582639843, 16.920645582639843, 25.35810151574062, 19.920645582639843]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x6504, Score: 9
Depth 1: State = 0x6504, Legal Moves = [((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6504: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x6502, Score: 12
Depth 2: State = 0x6502, Legal Moves = [((1, 0), (2, 0)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 1), (3, 2)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6502: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x65ae, Score: 15
Depth 3: State = 0x65ae, Legal Moves = [((1, 0), (2, 0)), ((1, 3), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x65ae: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0xa7e5, Score: 18
Depth 4: State = 0xa7e5, Legal Moves = [((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa7e5: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0xa8e6, Score: 27
End of simulation with depth 5. Reward (Score): 27
Updated Q[0x87cd, ((2, 2), (2, 3))] = 25.8, N[0x87cd, ((2, 2), (2, 3))] = 5
Updated Q[0x6504, ((2, 1), (2, 2))] = 27.0, N[0x6504, ((2, 1), (2, 2))] = 1
Updated Q[0x6502, ((1, 0), (2, 0))] = 27.0, N[0x6502, ((1, 0), (2, 0))] = 1
Updated Q[0x65ae, ((1, 0), (2, 0))] = 27.0, N[0x65ae, ((1, 0), (2, 0))] = 1
Updated Q[0xa7e5, ((2, 1), (2, 2))] = 27.0, N[0xa7e5, ((2, 1), (2, 2))] = 1

--- Simulation 42 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.927063067650955, 16.927063067650955, 19.927063067650955, 26.661808803239364, 16.927063067650955, 20.927063067650955, 20.927063067650955, 17.927063067650955, 19.927063067650955, 24.86263936291014, 16.927063067650955, 25.669265766912737, 22.927063067650955, 16.927063067650955, 16.927063067650955, 16.927063067650955, 19.927063067650955, 16.927063067650955, 25.36263936291014, 19.927063067650955]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x443b, Score: 9
Depth 1: State = 0x443b, Legal Moves = [((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x443b: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x433a, Score: 12
Depth 2: State = 0x433a, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (3, 0)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x433a: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x433d, Score: 15
Depth 3: State = 0x433d, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (3, 0)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x433d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x433d, Score: 18
Depth 4: State = 0x433d, Legal Moves = [((2, 0), (3, 0)), ((2, 3), (3, 3)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x433d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 0), (3, 0))
New board state after move: 0x433d, Score: 21
End of simulation with depth 5. Reward (Score): 21
Updated Q[0x87cd, ((2, 2), (2, 3))] = 25.0, N[0x87cd, ((2, 2), (2, 3))] = 6
Updated Q[0x443b, ((2, 2), (3, 2))] = 21.0, N[0x443b, ((2, 2), (3, 2))] = 1
Updated Q[0x433a, ((0, 3), (1, 3))] = 21.0, N[0x433a, ((0, 3), (1, 3))] = 1
Updated Q[0x433d, ((1, 2), (1, 3))] = 21.0, N[0x433d, ((1, 2), (1, 3))] = 1
Updated Q[0x433d, ((2, 0), (3, 0))] = 21.0, N[0x433d, ((2, 0), (3, 0))] = 1

--- Simulation 43 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.933305360847935, 16.933305360847935, 19.933305360847935, 25.789268608510792, 16.933305360847935, 20.933305360847935, 20.933305360847935, 17.933305360847935, 19.933305360847935, 24.86705333075988, 16.933305360847935, 25.670826340211985, 22.933305360847935, 16.933305360847935, 16.933305360847935, 16.933305360847935, 19.933305360847935, 16.933305360847935, 25.36705333075988, 19.933305360847935]
Selected move: ((2, 2), (2, 3))
New board state after move: 0xc957, Score: 6
Depth 1: State = 0xc957, Legal Moves = [((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xc957: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x65b0, Score: 9
Depth 2: State = 0x65b0, Legal Moves = [((1, 3), (2, 3)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x65b0: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x8620, Score: 15
Depth 3: State = 0x8620, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8620: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0xa93b, Score: 24
Depth 4: State = 0xa93b, Legal Moves = [((0, 4), (1, 4)), ((1, 4), (1, 5)), ((2, 1), (3, 1)), ((2, 7), (2, 8)), ((3, 0), (3, 1)), ((3, 1), (3, 2)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa93b: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0xa93e, Score: 27
End of simulation with depth 5. Reward (Score): 27
Updated Q[0x87cd, ((2, 2), (2, 3))] = 25.285714285714285, N[0x87cd, ((2, 2), (2, 3))] = 7
Updated Q[0xc957, ((2, 2), (3, 2))] = 27.0, N[0xc957, ((2, 2), (3, 2))] = 1
Updated Q[0x65b0, ((1, 3), (2, 3))] = 27.0, N[0x65b0, ((1, 3), (2, 3))] = 1
Updated Q[0x8620, ((1, 0), (1, 1))] = 27.0, N[0x8620, ((1, 0), (1, 1))] = 1
Updated Q[0xa93b, ((0, 4), (1, 4))] = 27.0, N[0xa93b, ((0, 4), (1, 4))] = 1

--- Simulation 44 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.939381374483514, 16.939381374483514, 19.939381374483514, 26.018731544884858, 16.939381374483514, 20.939381374483514, 20.939381374483514, 17.939381374483514, 19.939381374483514, 24.87134972120418, 16.939381374483514, 25.67234534362088, 22.939381374483514, 16.939381374483514, 16.939381374483514, 16.939381374483514, 19.939381374483514, 16.939381374483514, 25.37134972120418, 19.939381374483514]
Selected move: ((2, 2), (2, 3))
New board state after move: 0xc956, Score: 6
Depth 1: State = 0xc956, Legal Moves = [((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xc956: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x6557, Score: 9
Depth 2: State = 0x6557, Legal Moves = [((0, 2), (0, 3)), ((1, 2), (2, 2)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6557: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0xa83c, Score: 12
Depth 3: State = 0xa83c, Legal Moves = [((1, 2), (2, 2)), ((2, 3), (2, 4)), ((2, 7), (2, 8)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa83c: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xa83d, Score: 15
Depth 4: State = 0xa83d, Legal Moves = [((1, 1), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 7), (2, 8)), ((3, 1), (4, 1)), ((3, 4), (4, 4)), ((3, 5), (4, 5)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa83d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x21c9, Score: 21
End of simulation with depth 5. Reward (Score): 21
Updated Q[0x87cd, ((2, 2), (2, 3))] = 24.75, N[0x87cd, ((2, 2), (2, 3))] = 8
Updated Q[0xc956, ((2, 2), (3, 2))] = 21.0, N[0xc956, ((2, 2), (3, 2))] = 1
Updated Q[0x6557, ((0, 2), (0, 3))] = 21.0, N[0x6557, ((0, 2), (0, 3))] = 1
Updated Q[0xa83c, ((1, 2), (2, 2))] = 21.0, N[0xa83c, ((1, 2), (2, 2))] = 1
Updated Q[0xa83d, ((1, 1), (2, 1))] = 21.0, N[0xa83d, ((1, 1), (2, 1))] = 1

--- Simulation 45 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.945299368713787, 16.945299368713787, 19.945299368713787, 25.437767187527715, 16.945299368713787, 20.945299368713787, 20.945299368713787, 17.945299368713787, 19.945299368713787, 24.87553437505543, 16.945299368713787, 25.673824842178448, 22.945299368713787, 16.945299368713787, 16.945299368713787, 16.945299368713787, 19.945299368713787, 16.945299368713787, 25.37553437505543, 19.945299368713787]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 2), (0, 3)), ((0, 5), (0, 6)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87c9, Score: 13
Depth 3: State = 0x87c9, Legal Moves = [((0, 5), (0, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87c9, Score: 19
Depth 4: State = 0x87c9, Legal Moves = [((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x2322, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 25.0, N[0x87cd, ((5, 3), (5, 4))] = 17
Updated Q[0x87cd, ((0, 4), (1, 4))] = 22.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 2), (0, 3))] = 22.0, N[0x87cd, ((0, 2), (0, 3))] = 1
Updated Q[0x87c9, ((0, 5), (0, 6))] = 22.0, N[0x87c9, ((0, 5), (0, 6))] = 1
Updated Q[0x87c9, ((2, 2), (2, 3))] = 22.0, N[0x87c9, ((2, 2), (2, 3))] = 1

--- Simulation 46 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.951067013141866, 16.951067013141866, 19.951067013141866, 25.439806357770998, 16.951067013141866, 20.951067013141866, 20.951067013141866, 17.951067013141866, 19.951067013141866, 24.879612715541995, 16.951067013141866, 25.473203257520133, 22.951067013141866, 16.951067013141866, 16.951067013141866, 16.951067013141866, 19.951067013141866, 16.951067013141866, 25.379612715541995, 19.951067013141866]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((0, 4), (0, 5)), ((0, 6), (0, 7)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x8620, Score: 22
Depth 4: State = 0x8620, Legal Moves = [((1, 0), (1, 1)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8620: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x8776, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 25.0, N[0x87cd, ((5, 3), (5, 4))] = 18
Updated Q[0x87cd, ((0, 4), (1, 4))] = 25.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 25.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x8620, ((1, 0), (1, 1))] = 25.0, N[0x8620, ((1, 0), (1, 1))] = 1

--- Simulation 47 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.956691441308287, 16.956691441308287, 19.956691441308287, 25.441794893419384, 16.956691441308287, 20.956691441308287, 20.956691441308287, 17.956691441308287, 19.956691441308287, 24.88358978683877, 16.956691441308287, 25.461196595612922, 22.956691441308287, 16.956691441308287, 16.956691441308287, 16.956691441308287, 19.956691441308287, 16.956691441308287, 25.38358978683877, 19.956691441308287]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((3, 6), (4, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 19
Depth 3: State = 0x87cc, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (1, 1)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0xa893, Score: 22
Depth 4: State = 0xa893, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa893: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0xa893, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 25.0, N[0x87cd, ((5, 3), (5, 4))] = 19
Updated Q[0x87cd, ((0, 5), (0, 6))] = 25.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 0), (1, 0))] = 25.0, N[0x87cc, ((0, 0), (1, 0))] = 1
Updated Q[0xa893, ((1, 5), (2, 5))] = 25.0, N[0xa893, ((1, 5), (2, 5))] = 1

--- Simulation 48 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.962179299072858, 16.962179299072858, 19.962179299072858, 25.443735144139144, 16.962179299072858, 20.962179299072858, 20.962179299072858, 17.962179299072858, 19.962179299072858, 24.887470288278287, 16.962179299072858, 25.450154803882423, 22.962179299072858, 16.962179299072858, 16.962179299072858, 16.962179299072858, 19.962179299072858, 16.962179299072858, 25.387470288278287, 19.962179299072858]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 3), (0, 4)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0xa793, Score: 53
Depth 3: State = 0xa793, Legal Moves = [((2, 5), (2, 6)), ((3, 5), (3, 6)), ((3, 8), (3, 9)), ((4, 0), (4, 1)), ((4, 7), (5, 7)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 1), (6, 2)), ((6, 2), (6, 3)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 6), (6, 7)), ((6, 7), (6, 8))]
UCB1 values for moves at state 0xa793: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 5), (2, 6))
New board state after move: 0xa793, Score: 56
Depth 4: State = 0xa793, Legal Moves = [((0, 5), (0, 6)), ((3, 5), (3, 6)), ((3, 8), (3, 9)), ((4, 0), (4, 1)), ((4, 7), (5, 7)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 1), (6, 2)), ((6, 2), (6, 3)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 6), (6, 7)), ((6, 7), (6, 8))]
UCB1 values for moves at state 0xa793: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0xa793, Score: 59
End of simulation with depth 5. Reward (Score): 59
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.7, N[0x87cd, ((5, 3), (5, 4))] = 20
Updated Q[0x87cd, ((1, 1), (1, 2))] = 59.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 3), (0, 4))] = 59.0, N[0x87cd, ((0, 3), (0, 4))] = 1
Updated Q[0xa793, ((2, 5), (2, 6))] = 59.0, N[0xa793, ((2, 5), (2, 6))] = 1
Updated Q[0xa793, ((0, 5), (0, 6))] = 59.0, N[0xa793, ((0, 5), (0, 6))] = 1

--- Simulation 49 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.96753678768858, 16.96753678768858, 19.96753678768858, 25.445629302404296, 16.96753678768858, 20.96753678768858, 20.96753678768858, 17.96753678768858, 19.96753678768858, 24.89125860480859, 16.96753678768858, 27.139954600550322, 22.96753678768858, 16.96753678768858, 16.96753678768858, 16.96753678768858, 19.96753678768858, 16.96753678768858, 25.39125860480859, 19.96753678768858]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((0, 3), (0, 4)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x8675, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.61904761904762, N[0x87cd, ((5, 3), (5, 4))] = 21
Updated Q[0x87cd, ((0, 5), (0, 6))] = 25.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 25.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 25.0, N[0x87cd, ((1, 5), (2, 5))] = 1
Updated Q[0x87cd, ((0, 3), (0, 4))] = 25.0, N[0x87cd, ((0, 3), (0, 4))] = 1

--- Simulation 50 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.97276970224875, 16.97276970224875, 19.97276970224875, 25.447479417089728, 16.97276970224875, 20.97276970224875, 20.97276970224875, 17.97276970224875, 19.97276970224875, 24.89495883417946, 16.97276970224875, 27.04954126139383, 22.97276970224875, 16.97276970224875, 16.97276970224875, 16.97276970224875, 19.97276970224875, 16.97276970224875, 25.39495883417946, 19.97276970224875]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 19
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xcaaf, Score: 25
Depth 2: State = 0xcaaf, Legal Moves = [((1, 0), (1, 1)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((2, 0), (2, 1)), ((2, 7), (2, 8)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xcaaf: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0xca04, Score: 28
Depth 3: State = 0xca04, Legal Moves = [((1, 6), (1, 7)), ((1, 7), (2, 7)), ((2, 1), (2, 2)), ((2, 7), (2, 8)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xca04: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 6), (1, 7))
New board state after move: 0xca04, Score: 34
Depth 4: State = 0xca04, Legal Moves = [((0, 4), (1, 4)), ((0, 7), (1, 7)), ((0, 8), (1, 8)), ((1, 3), (1, 4)), ((2, 1), (2, 2)), ((2, 6), (3, 6)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xca04: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0xca04, Score: 37
End of simulation with depth 5. Reward (Score): 37
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.09090909090909, N[0x87cd, ((5, 3), (5, 4))] = 22
Updated Q[0x87cd, ((1, 1), (1, 2))] = 37.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xcaaf, ((1, 0), (1, 1))] = 37.0, N[0xcaaf, ((1, 0), (1, 1))] = 1
Updated Q[0xca04, ((1, 6), (1, 7))] = 37.0, N[0xca04, ((1, 6), (1, 7))] = 1
Updated Q[0xca04, ((0, 4), (1, 4))] = 37.0, N[0xca04, ((0, 4), (1, 4))] = 1

--- Simulation 51 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.977883466088976, 16.977883466088976, 19.977883466088976, 25.449287405634134, 16.977883466088976, 20.977883466088976, 20.977883466088976, 17.977883466088976, 19.977883466088976, 24.89857481126827, 16.977883466088976, 27.512595262747176, 22.977883466088976, 16.977883466088976, 16.977883466088976, 16.977883466088976, 19.977883466088976, 16.977883466088976, 25.39857481126827, 19.977883466088976]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (0, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87c9, Score: 13
Depth 3: State = 0x87c9, Legal Moves = [((0, 2), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x86c8, Score: 16
Depth 4: State = 0x86c8, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x86c8: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x86c8, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.73913043478261, N[0x87cd, ((5, 3), (5, 4))] = 23
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 2), (0, 3))] = 19.0, N[0x87cd, ((0, 2), (0, 3))] = 1
Updated Q[0x87c9, ((0, 2), (1, 2))] = 19.0, N[0x87c9, ((0, 2), (1, 2))] = 1
Updated Q[0x86c8, ((0, 3), (1, 3))] = 19.0, N[0x86c8, ((0, 3), (1, 3))] = 1

--- Simulation 52 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.98288316164224, 16.98288316164224, 19.98288316164224, 25.451055064948925, 16.98288316164224, 20.98288316164224, 20.98288316164224, 17.98288316164224, 19.98288316164224, 24.90211012989785, 16.98288316164224, 27.152590155376082, 22.98288316164224, 16.98288316164224, 16.98288316164224, 16.98288316164224, 19.98288316164224, 16.98288316164224, 25.40211012989785, 19.98288316164224]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 4), (2, 4)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 17
Depth 2: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((0, 7), (0, 8)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 20
Depth 3: State = 0x87cd, Legal Moves = [((0, 2), (1, 2)), ((0, 7), (0, 8)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x8674, Score: 23
Depth 4: State = 0x8674, Legal Moves = [((0, 7), (0, 8)), ((0, 8), (1, 8)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8674: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x8674, Score: 35
End of simulation with depth 5. Reward (Score): 35
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.083333333333332, N[0x87cd, ((5, 3), (5, 4))] = 24
Updated Q[0x87cd, ((0, 4), (1, 4))] = 35.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 3), (1, 3))] = 35.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 2), (1, 2))] = 35.0, N[0x87cd, ((0, 2), (1, 2))] = 1
Updated Q[0x8674, ((0, 7), (0, 8))] = 35.0, N[0x8674, ((0, 7), (0, 8))] = 1

--- Simulation 53 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.987773558175434, 16.987773558175434, 19.987773558175434, 25.452784081224582, 16.987773558175434, 20.987773558175434, 20.987773558175434, 17.987773558175434, 19.987773558175434, 24.90556816244916, 16.987773558175434, 27.489085911810527, 22.987773558175434, 16.987773558175434, 16.987773558175434, 16.987773558175434, 19.987773558175434, 16.987773558175434, 25.40556816244916, 19.987773558175434]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 10
Depth 2: State = 0x87c9, Legal Moves = [((1, 2), (2, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x87c9, Score: 13
Depth 3: State = 0x87c9, Legal Moves = [((0, 2), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((3, 1), (4, 1)), ((3, 1), (3, 2)), ((3, 2), (4, 2)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x2222, Score: 19
Depth 4: State = 0x2222, Legal Moves = [((1, 0), (1, 1)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((3, 1), (4, 1)), ((3, 1), (3, 2)), ((3, 2), (4, 2)), ((4, 1), (4, 2)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2222: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x21cc, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.88, N[0x87cd, ((5, 3), (5, 4))] = 25
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 2), (2, 2))] = 22.0, N[0x87c9, ((1, 2), (2, 2))] = 1
Updated Q[0x87c9, ((0, 2), (1, 2))] = 22.0, N[0x87c9, ((0, 2), (1, 2))] = 1
Updated Q[0x2222, ((1, 0), (1, 1))] = 22.0, N[0x2222, ((1, 0), (1, 1))] = 1

--- Simulation 54 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.992559136776652, 16.992559136776652, 19.992559136776652, 25.45447603876499, 16.992559136776652, 20.992559136776652, 20.992559136776652, 17.992559136776652, 19.992559136776652, 24.908952077529985, 16.992559136776652, 27.27851182735533, 22.992559136776652, 16.992559136776652, 16.992559136776652, 16.992559136776652, 19.992559136776652, 16.992559136776652, 25.408952077529985, 19.992559136776652]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 10
Depth 2: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x8620, Score: 13
Depth 3: State = 0x8620, Legal Moves = [((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8620: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x8620, Score: 16
Depth 4: State = 0x8620, Legal Moves = [((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8620: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x8621, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.692307692307693, N[0x87cd, ((5, 3), (5, 4))] = 26
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 22.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0x8620, ((1, 0), (1, 1))] = 22.0, N[0x8620, ((1, 0), (1, 1))] = 1
Updated Q[0x8620, ((0, 3), (1, 3))] = 22.0, N[0x8620, ((0, 3), (1, 3))] = 1

--- Simulation 55 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [16.99724411291266, 16.99724411291266, 19.99724411291266, 25.456132427962725, 16.99724411291266, 20.99724411291266, 20.99724411291266, 17.99724411291266, 19.99724411291266, 24.91226485592545, 16.99724411291266, 27.083999488659614, 22.99724411291266, 16.99724411291266, 16.99724411291266, 16.99724411291266, 19.99724411291266, 16.99724411291266, 25.41226485592545, 19.99724411291266]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 11
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 14
Depth 2: State = 0x87cd, Legal Moves = [((0, 1), (0, 2)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x8776, Score: 17
Depth 3: State = 0x8776, Legal Moves = [((0, 0), (0, 1)), ((0, 3), (1, 3)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((0, 6), (0, 7)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8776: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0xa93d, Score: 20
Depth 4: State = 0xa93d, Legal Moves = [((0, 6), (0, 7)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa93d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0xa93d, Score: 23
End of simulation with depth 5. Reward (Score): 23
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.555555555555557, N[0x87cd, ((5, 3), (5, 4))] = 27
Updated Q[0x87cd, ((0, 3), (1, 3))] = 23.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 1), (0, 2))] = 23.0, N[0x87cd, ((0, 1), (0, 2))] = 1
Updated Q[0x8776, ((0, 0), (0, 1))] = 23.0, N[0x8776, ((0, 0), (0, 1))] = 1
Updated Q[0xa93d, ((0, 6), (0, 7))] = 23.0, N[0xa93d, ((0, 6), (0, 7))] = 1

--- Simulation 56 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.001832456833604, 17.001832456833604, 20.001832456833604, 25.457754652513184, 17.001832456833604, 21.001832456833604, 21.001832456833604, 18.001832456833604, 20.001832456833604, 24.91550930502637, 17.001832456833604, 26.94080839149736, 23.001832456833604, 17.001832456833604, 17.001832456833604, 17.001832456833604, 20.001832456833604, 17.001832456833604, 25.41550930502637, 20.001832456833604]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x21cc, Score: 19
Depth 4: State = 0x21cc, Legal Moves = [((0, 5), (0, 6)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x21cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x21cc, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.392857142857142, N[0x87cd, ((5, 3), (5, 4))] = 28
Updated Q[0x87cd, ((0, 6), (0, 7))] = 22.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 22.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x21cc, ((0, 5), (0, 6))] = 22.0, N[0x21cc, ((0, 5), (0, 6))] = 1

--- Simulation 57 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.00632791206601, 17.00632791206601, 20.00632791206601, 25.45934403595286, 17.00632791206601, 21.00632791206601, 21.00632791206601, 18.00632791206601, 20.00632791206601, 24.918688071905724, 17.00632791206601, 26.772017478841008, 23.00632791206601, 17.00632791206601, 17.00632791206601, 17.00632791206601, 20.00632791206601, 17.00632791206601, 25.418688071905724, 20.00632791206601]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 22
Depth 3: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x64b0, Score: 25
Depth 4: State = 0x64b0, Legal Moves = [((0, 2), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x64b0: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x65af, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.448275862068964, N[0x87cd, ((5, 3), (5, 4))] = 29
Updated Q[0x87cd, ((0, 7), (0, 8))] = 28.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 28.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0x64b0, ((0, 2), (1, 2))] = 28.0, N[0x64b0, ((0, 2), (1, 2))] = 1

--- Simulation 58 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.01073401220414, 17.01073401220414, 20.01073401220414, 25.46090182759599, 17.01073401220414, 21.01073401220414, 21.01073401220414, 18.01073401220414, 20.01073401220414, 24.92180365519198, 17.01073401220414, 26.821659794449314, 23.01073401220414, 17.01073401220414, 17.01073401220414, 17.01073401220414, 20.01073401220414, 17.01073401220414, 25.42180365519198, 20.01073401220414]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x22cc, Score: 25
Depth 3: State = 0x22cc, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (0, 3)), ((1, 0), (1, 1)), ((1, 5), (1, 6)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x22cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x2276, Score: 28
Depth 4: State = 0x2276, Legal Moves = [((0, 1), (1, 1)), ((0, 1), (0, 2)), ((0, 2), (1, 2)), ((0, 2), (0, 3)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2276: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x2277, Score: 31
End of simulation with depth 5. Reward (Score): 31
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.6, N[0x87cd, ((5, 3), (5, 4))] = 30
Updated Q[0x87cd, ((0, 4), (0, 5))] = 31.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 31.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x22cc, ((0, 1), (1, 1))] = 31.0, N[0x22cc, ((0, 1), (1, 1))] = 1
Updated Q[0x2276, ((0, 1), (1, 1))] = 31.0, N[0x2276, ((0, 1), (1, 1))] = 1

--- Simulation 59 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.01505409618363, 17.01505409618363, 20.01505409618363, 25.462429207934587, 17.01505409618363, 21.01505409618363, 21.01505409618363, 18.01505409618363, 20.01505409618363, 24.924858415869174, 17.01505409618363, 26.96789686102432, 23.01505409618363, 17.01505409618363, 17.01505409618363, 17.01505409618363, 20.01505409618363, 17.01505409618363, 25.424858415869174, 20.01505409618363]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xca06, Score: 13
Depth 3: State = 0xca06, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xca06: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0xa93d, Score: 19
Depth 4: State = 0xa93d, Legal Moves = [((1, 5), (2, 5)), ((2, 3), (3, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa93d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0xa93d, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.451612903225808, N[0x87cd, ((5, 3), (5, 4))] = 31
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 22.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0xca06, ((0, 1), (1, 1))] = 22.0, N[0xca06, ((0, 1), (1, 1))] = 1
Updated Q[0xa93d, ((1, 5), (2, 5))] = 22.0, N[0xa93d, ((1, 5), (2, 5))] = 1

--- Simulation 60 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.019291322198388, 17.019291322198388, 20.019291322198388, 25.463927293558815, 17.019291322198388, 21.019291322198388, 21.019291322198388, 18.019291322198388, 20.019291322198388, 24.92785458711763, 17.019291322198388, 26.814288331029296, 23.019291322198388, 17.019291322198388, 17.019291322198388, 17.019291322198388, 20.019291322198388, 17.019291322198388, 25.42785458711763, 20.019291322198388]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 6), (0, 7)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 16
Depth 4: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.3125, N[0x87cd, ((5, 3), (5, 4))] = 32
Updated Q[0x87cd, ((0, 6), (1, 6))] = 22.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 22.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 22.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1

--- Simulation 61 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.02344868040237, 17.02344868040237, 20.02344868040237, 25.465397141647745, 17.02344868040237, 21.02344868040237, 21.02344868040237, 18.02344868040237, 20.02344868040237, 24.930794283295487, 17.02344868040237, 26.67019857082387, 23.02344868040237, 17.02344868040237, 17.02344868040237, 17.02344868040237, 20.02344868040237, 17.02344868040237, 25.430794283295487, 20.02344868040237]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 10
Depth 2: State = 0x87ca, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (1, 3)), ((0, 3), (0, 4)), ((0, 6), (0, 7)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87ca, Score: 19
Depth 4: State = 0x87ca, Legal Moves = [((0, 4), (0, 5)), ((0, 5), (1, 5)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87ca, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.181818181818183, N[0x87cd, ((5, 3), (5, 4))] = 33
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((0, 3), (1, 3))] = 22.0, N[0x87ca, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 2), (0, 3))] = 22.0, N[0x87cd, ((0, 2), (0, 3))] = 1
Updated Q[0x87ca, ((0, 4), (0, 5))] = 22.0, N[0x87ca, ((0, 4), (0, 5))] = 1

--- Simulation 62 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.02752900452085, 17.02752900452085, 20.02752900452085, 25.466839754074552, 17.02752900452085, 21.02752900452085, 21.02752900452085, 18.02752900452085, 20.02752900452085, 24.933679508149105, 17.02752900452085, 26.534765678307362, 23.02752900452085, 17.02752900452085, 17.02752900452085, 17.02752900452085, 20.02752900452085, 17.02752900452085, 25.433679508149105, 20.02752900452085]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 13
Depth 3: State = 0x87cc, Legal Moves = [((0, 1), (1, 1)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x8631, Score: 22
Depth 4: State = 0x8631, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8631: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0xcaad, Score: 37
End of simulation with depth 5. Reward (Score): 37
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.5, N[0x87cd, ((5, 3), (5, 4))] = 34
Updated Q[0x87cd, ((0, 6), (0, 7))] = 37.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 37.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 1), (1, 1))] = 37.0, N[0x87cc, ((0, 1), (1, 1))] = 1
Updated Q[0x8631, ((0, 1), (0, 2))] = 37.0, N[0x8631, ((0, 1), (0, 2))] = 1

--- Simulation 63 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.03153498248125, 17.03153498248125, 20.03153498248125, 25.468256081165094, 17.03153498248125, 21.03153498248125, 21.03153498248125, 18.03153498248125, 20.03153498248125, 24.936512162330185, 17.03153498248125, 26.848405375163047, 23.03153498248125, 17.03153498248125, 17.03153498248125, 17.03153498248125, 20.03153498248125, 17.03153498248125, 25.436512162330185, 20.03153498248125]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x64ad, Score: 19
Depth 3: State = 0x64ad, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x64ad: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2222, Score: 22
Depth 4: State = 0x2222, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2222: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x22cb, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.457142857142856, N[0x87cd, ((5, 3), (5, 4))] = 35
Updated Q[0x87cd, ((0, 7), (0, 8))] = 25.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x64ad, ((0, 0), (0, 1))] = 25.0, N[0x64ad, ((0, 0), (0, 1))] = 1
Updated Q[0x2222, ((0, 1), (1, 1))] = 25.0, N[0x2222, ((0, 1), (1, 1))] = 1

--- Simulation 64 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.035469166160848, 17.035469166160848, 20.035469166160848, 25.46964702514423, 17.035469166160848, 21.035469166160848, 21.035469166160848, 18.035469166160848, 20.035469166160848, 24.939294050288463, 17.035469166160848, 26.801199942372765, 23.035469166160848, 17.035469166160848, 17.035469166160848, 17.035469166160848, 20.035469166160848, 17.035469166160848, 25.439294050288463, 20.035469166160848]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 8), (0, 9)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 8), (0, 9))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 16
Depth 3: State = 0x87cb, Legal Moves = [((0, 1), (0, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x86cb, Score: 19
Depth 4: State = 0x86cb, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x86cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x6503, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.5, N[0x87cd, ((5, 3), (5, 4))] = 36
Updated Q[0x87cd, ((0, 8), (0, 9))] = 28.0, N[0x87cd, ((0, 8), (0, 9))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((0, 1), (0, 2))] = 28.0, N[0x87cb, ((0, 1), (0, 2))] = 1
Updated Q[0x86cb, ((0, 1), (1, 1))] = 28.0, N[0x86cb, ((0, 1), (1, 1))] = 1

--- Simulation 65 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.039333980337616, 17.039333980337616, 20.039333980337616, 25.471013443300443, 17.039333980337616, 21.039333980337616, 21.039333980337616, 18.039333980337616, 20.039333980337616, 24.942026886600882, 17.039333980337616, 26.839888996722937, 23.039333980337616, 17.039333980337616, 17.039333980337616, 17.039333980337616, 20.039333980337616, 17.039333980337616, 25.442026886600882, 20.039333980337616]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((1, 6), (2, 6)), ((1, 6), (1, 7)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 25
Depth 4: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 4), (3, 5)), ((3, 8), (3, 9)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 31
End of simulation with depth 5. Reward (Score): 31
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.62162162162162, N[0x87cd, ((5, 3), (5, 4))] = 37
Updated Q[0x87cd, ((0, 7), (0, 8))] = 31.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 31.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 7), (1, 7))] = 31.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 31.0, N[0x87cd, ((0, 6), (1, 6))] = 1

--- Simulation 66 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.04313173092085, 17.04313173092085, 20.04313173092085, 25.47235615089577, 17.04313173092085, 21.04313173092085, 21.04313173092085, 18.04313173092085, 20.04313173092085, 24.944712301791544, 17.04313173092085, 26.957510409116452, 23.04313173092085, 17.04313173092085, 17.04313173092085, 17.04313173092085, 20.04313173092085, 17.04313173092085, 25.444712301791544, 20.04313173092085]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((1, 1), (1, 2)), ((1, 7), (1, 8)), ((2, 2), (2, 3)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 7), (1, 8)), ((2, 2), (2, 3)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 7), (1, 8)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.657894736842106, N[0x87cd, ((5, 3), (5, 4))] = 38
Updated Q[0x87cd, ((0, 4), (1, 4))] = 28.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 28.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 28.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1

--- Simulation 67 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.046864612529717, 17.046864612529717, 20.046864612529717, 25.473675923845267, 17.046864612529717, 21.046864612529717, 21.046864612529717, 18.046864612529717, 20.046864612529717, 24.947351847690538, 17.046864612529717, 26.989940023148943, 23.046864612529717, 17.046864612529717, 17.046864612529717, 17.046864612529717, 20.046864612529717, 17.046864612529717, 25.447351847690538, 20.046864612529717]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x8676, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.53846153846154, N[0x87cd, ((5, 3), (5, 4))] = 39
Updated Q[0x87cd, ((0, 4), (0, 5))] = 22.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 22.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 22.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 22.0, N[0x87cd, ((0, 1), (1, 1))] = 1

--- Simulation 68 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.050534715480566, 17.050534715480566, 20.050534715480566, 25.474973501187367, 17.050534715480566, 21.050534715480566, 21.050534715480566, 18.050534715480566, 20.050534715480566, 24.949947002374735, 17.050534715480566, 26.866809876764684, 23.050534715480566, 17.050534715480566, 17.050534715480566, 17.050534715480566, 20.050534715480566, 17.050534715480566, 25.449947002374735, 20.050534715480566]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 19
Depth 4: State = 0x87c9, Legal Moves = [((1, 0), (1, 1)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x87cc, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.425, N[0x87cd, ((5, 3), (5, 4))] = 40
Updated Q[0x87cd, ((0, 6), (1, 6))] = 22.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 4), (1, 4))] = 22.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((1, 0), (1, 1))] = 22.0, N[0x87c9, ((1, 0), (1, 1))] = 1

--- Simulation 69 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.054144032237296, 17.054144032237296, 20.054144032237296, 25.476249587364435, 17.054144032237296, 21.054144032237296, 21.054144032237296, 18.054144032237296, 20.054144032237296, 24.95249917472887, 17.054144032237296, 26.74978868919561, 23.054144032237296, 17.054144032237296, 17.054144032237296, 17.054144032237296, 20.054144032237296, 17.054144032237296, 25.45249917472887, 20.054144032237296]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 22
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 25
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 8), (4, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 28
Depth 3: State = 0x87cd, Legal Moves = [((0, 3), (0, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 8), (4, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x8676, Score: 31
Depth 4: State = 0x8676, Legal Moves = [((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((3, 8), (4, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8676: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x8676, Score: 34
End of simulation with depth 5. Reward (Score): 34
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.609756097560975, N[0x87cd, ((5, 3), (5, 4))] = 41
Updated Q[0x87cd, ((0, 6), (1, 6))] = 34.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 34.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 3), (0, 4))] = 34.0, N[0x87cd, ((0, 3), (0, 4))] = 1
Updated Q[0x8676, ((0, 3), (1, 3))] = 34.0, N[0x8676, ((0, 3), (1, 3))] = 1

--- Simulation 70 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.05769446337333, 17.05769446337333, 20.05769446337333, 25.477504854330647, 17.05769446337333, 21.05769446337333, 21.05769446337333, 18.05769446337333, 20.05769446337333, 24.955009708661297, 17.05769446337333, 26.931113982723346, 23.05769446337333, 17.05769446337333, 17.05769446337333, 17.05769446337333, 20.05769446337333, 17.05769446337333, 25.455009708661297, 20.05769446337333]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 1), (0, 2)), ((0, 5), (0, 6)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x8777, Score: 19
Depth 3: State = 0x8777, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8777: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x8777, Score: 22
Depth 4: State = 0x8777, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8777: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x8777, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.642857142857142, N[0x87cd, ((5, 3), (5, 4))] = 42
Updated Q[0x87cd, ((0, 3), (1, 3))] = 28.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((0, 1), (0, 2))] = 28.0, N[0x87cd, ((0, 1), (0, 2))] = 1
Updated Q[0x8777, ((0, 6), (1, 6))] = 28.0, N[0x8777, ((0, 6), (1, 6))] = 1
Updated Q[0x8777, ((0, 6), (1, 6))] = 28.0, N[0x8777, ((0, 6), (1, 6))] = 1

--- Simulation 71 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.061187823088755, 17.061187823088755, 20.061187823088755, 25.4787399435026, 17.061187823088755, 21.061187823088755, 21.061187823088755, 18.061187823088755, 20.061187823088755, 24.957479887005196, 17.061187823088755, 26.960905328860807, 23.061187823088755, 17.061187823088755, 17.061187823088755, 17.061187823088755, 20.061187823088755, 17.061187823088755, 25.457479887005196, 20.061187823088755]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 7), (2, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 16
Depth 4: State = 0x87cb, Legal Moves = [((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 7), (2, 8)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cc, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.46511627906977, N[0x87cd, ((5, 3), (5, 4))] = 43
Updated Q[0x87cd, ((0, 7), (1, 7))] = 19.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 19.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((0, 4), (1, 4))] = 19.0, N[0x87cb, ((0, 4), (1, 4))] = 1

--- Simulation 72 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.064625844321753, 17.064625844321753, 20.064625844321753, 25.479955467566455, 17.064625844321753, 21.064625844321753, 21.064625844321753, 18.064625844321753, 20.064625844321753, 24.959910935132914, 17.064625844321753, 26.779968768600583, 23.064625844321753, 17.064625844321753, 17.064625844321753, 17.064625844321753, 20.064625844321753, 17.064625844321753, 25.459910935132914, 20.064625844321753]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87ca, Score: 16
Depth 4: State = 0x87ca, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xa93c, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.295454545454547, N[0x87cd, ((5, 3), (5, 4))] = 44
Updated Q[0x87cd, ((0, 5), (1, 5))] = 19.0, N[0x87cd, ((0, 5), (1, 5))] = 1
Updated Q[0x87cd, ((0, 6), (0, 7))] = 19.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87ca, ((1, 2), (2, 2))] = 19.0, N[0x87ca, ((1, 2), (2, 2))] = 1

--- Simulation 73 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.06801018348945, 17.06801018348945, 20.06801018348945, 25.481152012154112, 17.06801018348945, 21.06801018348945, 21.06801018348945, 18.06801018348945, 20.06801018348945, 24.962304024308224, 17.06801018348945, 26.607218810966753, 23.06801018348945, 17.06801018348945, 17.06801018348945, 17.06801018348945, 20.06801018348945, 17.06801018348945, 25.462304024308224, 20.06801018348945]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x2321, Score: 13
Depth 2: State = 0x2321, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2321: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x22cb, Score: 16
Depth 3: State = 0x22cb, Legal Moves = [((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x22cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x2277, Score: 19
Depth 4: State = 0x2277, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2277: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x2277, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.2, N[0x87cd, ((5, 3), (5, 4))] = 45
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x2321, ((1, 0), (1, 1))] = 22.0, N[0x2321, ((1, 0), (1, 1))] = 1
Updated Q[0x22cb, ((1, 3), (1, 4))] = 22.0, N[0x22cb, ((1, 3), (1, 4))] = 1
Updated Q[0x2277, ((1, 5), (2, 5))] = 22.0, N[0x2277, ((1, 5), (2, 5))] = 1

--- Simulation 74 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.071342424889806, 17.071342424889806, 20.071342424889806, 25.482330137399487, 17.071342424889806, 21.071342424889806, 21.071342424889806, 18.071342424889806, 20.071342424889806, 24.96466027479897, 17.071342424889806, 26.50877749778219, 23.071342424889806, 17.071342424889806, 17.071342424889806, 17.071342424889806, 20.071342424889806, 17.071342424889806, 25.46466027479897, 20.071342424889806]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((1, 5), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((3, 2), (3, 3)), ((4, 2), (4, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((3, 7), (3, 8)), ((4, 2), (4, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 5), (5, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((0, 3), (0, 4)), ((0, 6), (1, 6)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 8), (2, 9)), ((3, 7), (3, 8)), ((4, 2), (4, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 5), (5, 6)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x871f, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.17391304347826, N[0x87cd, ((5, 3), (5, 4))] = 46
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 25.0, N[0x87cd, ((1, 5), (2, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 25.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 3), (0, 4))] = 25.0, N[0x87cd, ((0, 3), (0, 4))] = 1

--- Simulation 75 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.074624084793236, 17.074624084793236, 20.074624084793236, 25.483490379385117, 17.074624084793236, 21.074624084793236, 21.074624084793236, 18.074624084793236, 20.074624084793236, 24.966980758770234, 17.074624084793236, 26.47979967682624, 23.074624084793236, 17.074624084793236, 17.074624084793236, 17.074624084793236, 20.074624084793236, 17.074624084793236, 25.466980758770234, 20.074624084793236]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 13
Depth 3: State = 0x87cb, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x6603, Score: 16
Depth 4: State = 0x6603, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((1, 7), (1, 8)), ((1, 8), (2, 8)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 7), (2, 8)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6603: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xc902, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.02127659574468, N[0x87cd, ((5, 3), (5, 4))] = 47
Updated Q[0x87cd, ((0, 6), (0, 7))] = 19.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((0, 0), (1, 0))] = 19.0, N[0x87cb, ((0, 0), (1, 0))] = 1
Updated Q[0x6603, ((1, 2), (2, 2))] = 19.0, N[0x6603, ((1, 2), (2, 2))] = 1

--- Simulation 76 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.077856615249548, 17.077856615249548, 20.077856615249548, 25.48463325148814, 17.077856615249548, 21.077856615249548, 21.077856615249548, 18.077856615249548, 20.077856615249548, 24.969266502976282, 17.077856615249548, 26.3243631332619, 23.077856615249548, 17.077856615249548, 17.077856615249548, 17.077856615249548, 20.077856615249548, 17.077856615249548, 25.469266502976282, 20.077856615249548]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 6), (1, 6)), ((0, 6), (0, 7)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 8), (2, 9)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 7), (1, 7)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((0, 7), (1, 7)), ((0, 8), (1, 8)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((1, 7), (1, 8)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (1, 5))
New board state after move: 0x87cd, Score: 37
End of simulation with depth 5. Reward (Score): 37
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.25, N[0x87cd, ((5, 3), (5, 4))] = 48
Updated Q[0x87cd, ((0, 7), (1, 7))] = 37.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((0, 5), (0, 6))] = 37.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 37.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 5), (1, 5))] = 37.0, N[0x87cd, ((0, 5), (1, 5))] = 1

--- Simulation 77 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.081041407633766, 17.081041407633766, 20.081041407633766, 25.48575924563392, 17.081041407633766, 21.081041407633766, 21.081041407633766, 18.081041407633766, 20.081041407633766, 24.971518491267837, 17.081041407633766, 26.550372454223027, 23.081041407633766, 17.081041407633766, 17.081041407633766, 17.081041407633766, 20.081041407633766, 17.081041407633766, 25.471518491267837, 20.081041407633766]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((1, 2), (2, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x87cb, Score: 22
Depth 4: State = 0x87cb, Legal Moves = [((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cb, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.285714285714285, N[0x87cd, ((5, 3), (5, 4))] = 49
Updated Q[0x87cd, ((0, 6), (1, 6))] = 28.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 28.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 2), (2, 2))] = 28.0, N[0x87cd, ((1, 2), (2, 2))] = 1
Updated Q[0x87cb, ((1, 5), (2, 5))] = 28.0, N[0x87cb, ((1, 5), (2, 5))] = 1

--- Simulation 78 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.084179795951798, 17.084179795951798, 20.084179795951798, 25.486868833464754, 17.084179795951798, 21.084179795951798, 21.084179795951798, 18.084179795951798, 20.084179795951798, 24.973737666929512, 17.084179795951798, 26.583454256564544, 23.084179795951798, 17.084179795951798, 17.084179795951798, 17.084179795951798, 20.084179795951798, 17.084179795951798, 25.473737666929512, 20.084179795951798]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 19
Depth 3: State = 0x87cd, Legal Moves = [((0, 1), (1, 1)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x8775, Score: 22
Depth 4: State = 0x8775, Legal Moves = [((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8775: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x8775, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.26, N[0x87cd, ((5, 3), (5, 4))] = 50
Updated Q[0x87cd, ((0, 4), (0, 5))] = 25.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 4), (1, 4))] = 25.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 1), (1, 1))] = 25.0, N[0x87cd, ((0, 1), (1, 1))] = 1
Updated Q[0x8775, ((0, 3), (1, 3))] = 25.0, N[0x8775, ((0, 3), (1, 3))] = 1

--- Simulation 79 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.08727305992522, 17.08727305992522, 20.08727305992522, 25.48796246743056, 17.08727305992522, 21.08727305992522, 21.08727305992522, 18.08727305992522, 20.08727305992522, 24.97592493486112, 17.08727305992522, 26.555184986972225, 23.08727305992522, 17.08727305992522, 17.08727305992522, 17.08727305992522, 20.08727305992522, 17.08727305992522, 25.47592493486112, 20.08727305992522]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 2), (0, 3)), ((1, 1), (1, 2)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87c9, Score: 19
Depth 2: State = 0x87c9, Legal Moves = [((0, 6), (1, 6)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87c9, Score: 22
Depth 3: State = 0x87c9, Legal Moves = [((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x87c9, Score: 25
Depth 4: State = 0x87c9, Legal Moves = [((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x87c9, Score: 31
End of simulation with depth 5. Reward (Score): 31
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.352941176470587, N[0x87cd, ((5, 3), (5, 4))] = 51
Updated Q[0x87cd, ((0, 2), (0, 3))] = 31.0, N[0x87cd, ((0, 2), (0, 3))] = 1
Updated Q[0x87c9, ((0, 6), (1, 6))] = 31.0, N[0x87c9, ((0, 6), (1, 6))] = 1
Updated Q[0x87c9, ((1, 3), (1, 4))] = 31.0, N[0x87c9, ((1, 3), (1, 4))] = 1
Updated Q[0x87c9, ((1, 4), (2, 4))] = 31.0, N[0x87c9, ((1, 4), (2, 4))] = 1

--- Simulation 80 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.090322427872557, 17.090322427872557, 20.090322427872557, 25.489040581807508, 17.090322427872557, 21.090322427872557, 21.090322427872557, 18.090322427872557, 20.090322427872557, 24.978081163615013, 17.090322427872557, 26.645644862965288, 23.090322427872557, 17.090322427872557, 17.090322427872557, 17.090322427872557, 20.090322427872557, 17.090322427872557, 25.478081163615013, 20.090322427872557]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 1), (3, 2)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x6504, Score: 19
Depth 4: State = 0x6504, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((3, 6), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6504: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x6504, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.26923076923077, N[0x87cd, ((5, 3), (5, 4))] = 52
Updated Q[0x87cd, ((0, 3), (1, 3))] = 22.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 0), (1, 0))] = 22.0, N[0x87cd, ((0, 0), (1, 0))] = 1
Updated Q[0x6504, ((1, 5), (2, 5))] = 22.0, N[0x6504, ((1, 5), (2, 5))] = 1

--- Simulation 81 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.09332907940292, 17.09332907940292, 20.09332907940292, 25.4901035936504, 17.09332907940292, 21.09332907940292, 21.09332907940292, 18.09332907940292, 20.09332907940292, 24.9802071873008, 17.09332907940292, 26.559523282007966, 23.09332907940292, 17.09332907940292, 17.09332907940292, 17.09332907940292, 20.09332907940292, 17.09332907940292, 25.4802071873008, 20.09332907940292]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((0, 2), (1, 2)), ((1, 5), (2, 5)), ((1, 7), (2, 7)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x87cd, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.245283018867923, N[0x87cd, ((5, 3), (5, 4))] = 53
Updated Q[0x87cd, ((0, 7), (0, 8))] = 25.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((0, 7), (1, 7))] = 25.0, N[0x87cd, ((0, 7), (1, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 2), (1, 2))] = 25.0, N[0x87cd, ((0, 2), (1, 2))] = 1

--- Simulation 82 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.096294147936412, 17.096294147936412, 20.096294147936412, 25.491151903683754, 17.096294147936412, 21.096294147936412, 21.096294147936412, 18.096294147936412, 20.096294147936412, 24.98230380736751, 17.096294147936412, 26.533231165230806, 23.096294147936412, 17.096294147936412, 17.096294147936412, 17.096294147936412, 20.096294147936412, 17.096294147936412, 25.48230380736751, 20.096294147936412]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 16
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 31
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 7), (3, 7)), ((2, 8), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x8677, Score: 40
Depth 3: State = 0x8677, Legal Moves = [((0, 2), (1, 2)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((2, 7), (3, 7)), ((2, 8), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x8677: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x861e, Score: 46
Depth 4: State = 0x861e, Legal Moves = [((0, 3), (0, 4)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 1), (1, 2)), ((1, 4), (2, 4)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (2, 5)), ((2, 7), (3, 7)), ((2, 8), (3, 8)), ((4, 3), (4, 4)), ((4, 4), (5, 4)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x861e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x861e, Score: 49
End of simulation with depth 5. Reward (Score): 49
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.666666666666668, N[0x87cd, ((5, 3), (5, 4))] = 54
Updated Q[0x87cd, ((0, 6), (0, 7))] = 49.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 49.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x8677, ((0, 2), (1, 2))] = 49.0, N[0x8677, ((0, 2), (1, 2))] = 1
Updated Q[0x861e, ((0, 3), (0, 4))] = 49.0, N[0x861e, ((0, 3), (0, 4))] = 1

--- Simulation 83 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.09921872306443, 17.09921872306443, 20.09921872306443, 25.492185897136313, 17.09921872306443, 21.09921872306443, 21.09921872306443, 18.09921872306443, 20.09921872306443, 24.984371794272622, 17.09921872306443, 26.952334151666932, 23.09921872306443, 17.09921872306443, 17.09921872306443, 17.09921872306443, 20.09921872306443, 17.09921872306443, 25.484371794272622, 20.09921872306443]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 13
Depth 3: State = 0x87cb, Legal Moves = [((1, 2), (2, 2)), ((1, 2), (1, 3)), ((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x86ca, Score: 16
Depth 4: State = 0x86ca, Legal Moves = [((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (3, 0)), ((2, 0), (2, 1)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x86ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x8674, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.527272727272727, N[0x87cd, ((5, 3), (5, 4))] = 55
Updated Q[0x87cd, ((0, 6), (1, 6))] = 19.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((1, 2), (2, 2))] = 19.0, N[0x87cb, ((1, 2), (2, 2))] = 1
Updated Q[0x86ca, ((1, 0), (1, 1))] = 19.0, N[0x86ca, ((1, 0), (1, 1))] = 1

--- Simulation 84 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.102103852761942, 17.102103852761942, 20.102103852761942, 25.49320594452317, 17.102103852761942, 21.102103852761942, 21.102103852761942, 18.102103852761942, 20.102103852761942, 24.986411889046337, 17.102103852761942, 26.810720352955837, 23.102103852761942, 17.102103852761942, 17.102103852761942, 17.102103852761942, 20.102103852761942, 17.102103852761942, 25.486411889046337, 20.102103852761942]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 22
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 28
Depth 2: State = 0x87cc, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (1, 1)), ((1, 3), (1, 4)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((3, 5), (3, 6)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cc: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0xa93c, Score: 31
Depth 3: State = 0xa93c, Legal Moves = [((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((3, 5), (3, 6)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa93c: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0xa792, Score: 34
Depth 4: State = 0xa792, Legal Moves = [((0, 3), (0, 4)), ((2, 2), (3, 2)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((3, 5), (3, 6)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa792: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0xa792, Score: 37
End of simulation with depth 5. Reward (Score): 37
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.714285714285715, N[0x87cd, ((5, 3), (5, 4))] = 56
Updated Q[0x87cd, ((1, 1), (1, 2))] = 37.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cc, ((0, 0), (1, 0))] = 37.0, N[0x87cc, ((0, 0), (1, 0))] = 1
Updated Q[0xa93c, ((2, 1), (3, 1))] = 37.0, N[0xa93c, ((2, 1), (3, 1))] = 1
Updated Q[0xa792, ((0, 3), (0, 4))] = 37.0, N[0xa792, ((0, 3), (0, 4))] = 1

--- Simulation 85 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.104950545462604, 17.104950545462604, 20.104950545462604, 25.494212402379464, 17.104950545462604, 21.104950545462604, 21.104950545462604, 18.104950545462604, 20.104950545462604, 24.988424804758928, 17.104950545462604, 26.995571562758002, 23.104950545462604, 17.104950545462604, 17.104950545462604, 17.104950545462604, 20.104950545462604, 17.104950545462604, 25.488424804758928, 20.104950545462604]
Selected move: ((5, 3), (5, 4))
Error: axis 6 is out of bounds for array of dimension 0
the swap is the following:
Ending simulation.
End of simulation with depth 0. Reward (Score): 12
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.45614035087719, N[0x87cd, ((5, 3), (5, 4))] = 57

--- Simulation 86 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.107759772006837, 17.107759772006837, 20.107759772006837, 25.495205613949125, 17.107759772006837, 21.107759772006837, 21.107759772006837, 18.107759772006837, 20.107759772006837, 24.990411227898246, 17.107759772006837, 26.7353199527715, 23.107759772006837, 17.107759772006837, 17.107759772006837, 17.107759772006837, 20.107759772006837, 17.107759772006837, 25.490411227898246, 20.107759772006837]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xa8e7, Score: 13
Depth 2: State = 0xa8e7, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (0, 4)), ((1, 0), (1, 1)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa8e7: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x221e, Score: 16
Depth 3: State = 0x221e, Legal Moves = [((0, 3), (0, 4)), ((1, 0), (1, 1)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x221e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x2222, Score: 22
Depth 4: State = 0x2222, Legal Moves = [((0, 4), (1, 4)), ((1, 0), (1, 1)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 4), (2, 5)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2222: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x2222, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.43103448275862, N[0x87cd, ((5, 3), (5, 4))] = 58
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xa8e7, ((0, 2), (1, 2))] = 25.0, N[0xa8e7, ((0, 2), (1, 2))] = 1
Updated Q[0x221e, ((0, 3), (0, 4))] = 25.0, N[0x221e, ((0, 3), (0, 4))] = 1
Updated Q[0x2222, ((0, 4), (1, 4))] = 25.0, N[0x2222, ((0, 4), (1, 4))] = 1

--- Simulation 87 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.110532467472012, 17.110532467472012, 20.110532467472012, 25.49618590983192, 17.110532467472012, 21.110532467472012, 21.110532467472012, 18.110532467472012, 20.110532467472012, 24.992371819663838, 17.110532467472012, 26.708160972496998, 23.110532467472012, 17.110532467472012, 17.110532467472012, 17.110532467472012, 20.110532467472012, 17.110532467472012, 25.492371819663838, 20.110532467472012]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 8), (1, 9)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((1, 8), (1, 9)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 22
Depth 4: State = 0x87cd, Legal Moves = [((1, 5), (1, 6)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (1, 6))
New board state after move: 0x87cd, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.406779661016948, N[0x87cd, ((5, 3), (5, 4))] = 59
Updated Q[0x87cd, ((0, 7), (0, 8))] = 25.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 25.0, N[0x87cd, ((1, 5), (2, 5))] = 1
Updated Q[0x87cd, ((1, 5), (1, 6))] = 25.0, N[0x87cd, ((1, 5), (1, 6))] = 1

--- Simulation 88 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.113269532893185, 17.113269532893185, 20.113269532893185, 25.49715360859185, 17.113269532893185, 21.113269532893185, 21.113269532893185, 18.113269532893185, 20.113269532893185, 24.9943072171837, 17.113269532893185, 26.681903920113268, 23.113269532893185, 17.113269532893185, 17.113269532893185, 17.113269532893185, 20.113269532893185, 17.113269532893185, 25.4943072171837, 20.113269532893185]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 16
Depth 1: State = 0x87cd, Legal Moves = [((0, 3), (1, 3)), ((0, 6), (0, 7)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87ca, Score: 31
Depth 2: State = 0x87ca, Legal Moves = [((0, 6), (0, 7)), ((0, 7), (1, 7)), ((1, 5), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87ca, Score: 34
Depth 3: State = 0x87ca, Legal Moves = [((0, 7), (1, 7)), ((0, 8), (1, 8)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (1, 7))
New board state after move: 0x87ca, Score: 37
Depth 4: State = 0x87ca, Legal Moves = [((1, 5), (2, 5)), ((1, 6), (1, 7)), ((1, 7), (2, 7)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87ca: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87ca, Score: 40
End of simulation with depth 5. Reward (Score): 40
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.633333333333333, N[0x87cd, ((5, 3), (5, 4))] = 60
Updated Q[0x87cd, ((0, 3), (1, 3))] = 40.0, N[0x87cd, ((0, 3), (1, 3))] = 1
Updated Q[0x87ca, ((0, 6), (0, 7))] = 40.0, N[0x87ca, ((0, 6), (0, 7))] = 1
Updated Q[0x87ca, ((0, 7), (1, 7))] = 40.0, N[0x87ca, ((0, 7), (1, 7))] = 1
Updated Q[0x87ca, ((1, 5), (2, 5))] = 40.0, N[0x87ca, ((1, 5), (2, 5))] = 1

--- Simulation 89 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.1159718368821, 17.1159718368821, 20.1159718368821, 25.498109017329543, 17.1159718368821, 21.1159718368821, 21.1159718368821, 18.1159718368821, 20.1159718368821, 24.996218034659087, 17.1159718368821, 26.906504122842943, 23.1159718368821, 17.1159718368821, 17.1159718368821, 17.1159718368821, 20.1159718368821, 17.1159718368821, 25.496218034659087, 20.1159718368821]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0xa7e5, Score: 19
Depth 4: State = 0xa7e5, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (1, 3)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((2, 6), (2, 7)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa7e5: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0xa7e4, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.557377049180328, N[0x87cd, ((5, 3), (5, 4))] = 61
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 22.0, N[0x87cd, ((1, 5), (2, 5))] = 1
Updated Q[0x87cd, ((2, 2), (2, 3))] = 22.0, N[0x87cd, ((2, 2), (2, 3))] = 1
Updated Q[0xa7e5, ((0, 2), (0, 3))] = 22.0, N[0xa7e5, ((0, 2), (0, 3))] = 1

--- Simulation 90 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.11864021715159, 17.11864021715159, 20.11864021715159, 25.499052432221216, 17.11864021715159, 21.11864021715159, 21.11864021715159, 18.11864021715159, 20.11864021715159, 24.99810486444243, 17.11864021715159, 26.828641132284773, 23.11864021715159, 17.11864021715159, 17.11864021715159, 17.11864021715159, 20.11864021715159, 17.11864021715159, 25.49810486444243, 20.11864021715159]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 13
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 16
Depth 2: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 8), (2, 9)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 37
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 40
Depth 4: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cc, Score: 46
End of simulation with depth 5. Reward (Score): 46
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.870967741935484, N[0x87cd, ((5, 3), (5, 4))] = 62
Updated Q[0x87cd, ((0, 4), (0, 5))] = 46.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 7), (0, 8))] = 46.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 46.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 46.0, N[0x87cd, ((1, 1), (1, 2))] = 1

--- Simulation 91 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.1212754819519, 17.1212754819519, 20.1212754819519, 25.499984139026473, 17.1212754819519, 21.1212754819519, 21.1212754819519, 18.1212754819519, 20.1212754819519, 24.99996827805295, 17.1212754819519, 27.140369997545765, 23.1212754819519, 17.1212754819519, 17.1212754819519, 17.1212754819519, 20.1212754819519, 17.1212754819519, 25.49996827805295, 20.1212754819519]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 5), (0, 6)), ((0, 6), (1, 6)), ((0, 6), (0, 7)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((3, 5), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 5), (0, 6))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x43e5, Score: 19
Depth 3: State = 0x43e5, Legal Moves = [((0, 1), (0, 2)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x43e5: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x433e, Score: 29
Depth 4: State = 0x433e, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((3, 2), (3, 3)), ((4, 3), (5, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 2), (5, 3)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8))]
UCB1 values for moves at state 0x433e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x4493, Score: 35
End of simulation with depth 5. Reward (Score): 35
Updated Q[0x87cd, ((5, 3), (5, 4))] = 27.0, N[0x87cd, ((5, 3), (5, 4))] = 63
Updated Q[0x87cd, ((0, 5), (0, 6))] = 35.0, N[0x87cd, ((0, 5), (0, 6))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 35.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x43e5, ((0, 1), (0, 2))] = 35.0, N[0x43e5, ((0, 1), (0, 2))] = 1
Updated Q[0x433e, ((0, 1), (1, 1))] = 35.0, N[0x433e, ((0, 1), (1, 1))] = 1

--- Simulation 92 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.123878411424922, 17.123878411424922, 20.123878411424922, 25.500904413567138, 17.123878411424922, 21.123878411424922, 21.123878411424922, 18.123878411424922, 20.123878411424922, 25.001808827134276, 17.123878411424922, 27.267583528169965, 23.123878411424922, 17.123878411424922, 17.123878411424922, 17.123878411424922, 20.123878411424922, 17.123878411424922, 25.501808827134276, 20.123878411424922]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((0, 4), (0, 5)), ((0, 6), (0, 7)), ((0, 7), (1, 7)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 7), (0, 8))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cb, Score: 16
Depth 4: State = 0x87cb, Legal Moves = [((1, 0), (1, 1)), ((1, 5), (2, 5)), ((1, 6), (2, 6)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 5), (2, 6)), ((2, 6), (3, 6)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cb: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x8621, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.875, N[0x87cd, ((5, 3), (5, 4))] = 64
Updated Q[0x87cd, ((0, 4), (1, 4))] = 19.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((0, 7), (0, 8))] = 19.0, N[0x87cd, ((0, 7), (0, 8))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cb, ((1, 0), (1, 1))] = 19.0, N[0x87cb, ((1, 0), (1, 1))] = 1

--- Simulation 93 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.126449758881936, 17.126449758881936, 20.126449758881936, 25.501813522178956, 17.126449758881936, 21.126449758881936, 21.126449758881936, 18.126449758881936, 20.126449758881936, 25.003627044357916, 17.126449758881936, 27.14080621986024, 23.126449758881936, 17.126449758881936, 17.126449758881936, 17.126449758881936, 20.126449758881936, 17.126449758881936, 25.503627044357916, 20.126449758881936]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87c9, Score: 13
Depth 2: State = 0x87c9, Legal Moves = [((0, 0), (1, 0)), ((0, 4), (0, 5)), ((1, 3), (1, 4)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0xcab0, Score: 16
Depth 3: State = 0xcab0, Legal Moves = [((1, 2), (2, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xcab0: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0xcaad, Score: 19
Depth 4: State = 0xcaad, Legal Moves = [((0, 0), (1, 0)), ((0, 2), (1, 2)), ((0, 4), (0, 5)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xcaad: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x2321, Score: 22
End of simulation with depth 5. Reward (Score): 22
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.8, N[0x87cd, ((5, 3), (5, 4))] = 65
Updated Q[0x87cd, ((1, 1), (1, 2))] = 22.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87c9, ((0, 0), (1, 0))] = 22.0, N[0x87c9, ((0, 0), (1, 0))] = 1
Updated Q[0xcab0, ((1, 2), (2, 2))] = 22.0, N[0xcab0, ((1, 2), (2, 2))] = 1
Updated Q[0xcaad, ((0, 0), (1, 0))] = 22.0, N[0xcaad, ((0, 0), (1, 0))] = 1

--- Simulation 94 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.12899025200992, 17.12899025200992, 20.12899025200992, 25.502711722138134, 17.12899025200992, 21.12899025200992, 21.12899025200992, 18.12899025200992, 20.12899025200992, 25.00542344427627, 17.12899025200992, 27.064068740851063, 23.12899025200992, 17.12899025200992, 17.12899025200992, 17.12899025200992, 20.12899025200992, 17.12899025200992, 25.50542344427627, 20.12899025200992]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (0, 7)), ((0, 7), (1, 7)), ((0, 7), (0, 8)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (0, 7))
New board state after move: 0x87cd, Score: 19
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 5), (1, 5)), ((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 22
Depth 3: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 25
Depth 4: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((0, 8), (0, 9)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((1, 6), (1, 7)), ((2, 2), (2, 3)), ((2, 6), (2, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 28
End of simulation with depth 5. Reward (Score): 28
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.818181818181817, N[0x87cd, ((5, 3), (5, 4))] = 66
Updated Q[0x87cd, ((0, 6), (0, 7))] = 28.0, N[0x87cd, ((0, 6), (0, 7))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 28.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 6), (1, 6))] = 28.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 28.0, N[0x87cd, ((0, 4), (0, 5))] = 1

--- Simulation 95 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.13150059401118, 17.13150059401118, 20.13150059401118, 25.503599262064228, 17.13150059401118, 21.13150059401118, 21.13150059401118, 18.13150059401118, 20.13150059401118, 25.00719852412846, 17.13150059401118, 27.080551404321987, 23.13150059401118, 17.13150059401118, 17.13150059401118, 17.13150059401118, 20.13150059401118, 17.13150059401118, 25.50719852412846, 20.13150059401118]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x443a, Score: 13
Depth 3: State = 0x443a, Legal Moves = [((0, 4), (0, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x443a: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x443a, Score: 16
Depth 4: State = 0x443a, Legal Moves = [((0, 3), (1, 3)), ((0, 5), (0, 6)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x443a: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x44e7, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.70149253731343, N[0x87cd, ((5, 3), (5, 4))] = 67
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((0, 0), (1, 0))] = 19.0, N[0x87cd, ((0, 0), (1, 0))] = 1
Updated Q[0x443a, ((0, 4), (0, 5))] = 19.0, N[0x443a, ((0, 4), (0, 5))] = 1
Updated Q[0x443a, ((0, 3), (1, 3))] = 19.0, N[0x443a, ((0, 3), (1, 3))] = 1

--- Simulation 96 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.133981464680645, 17.133981464680645, 20.133981464680645, 25.504476382301043, 17.133981464680645, 21.133981464680645, 21.133981464680645, 18.133981464680645, 20.133981464680645, 25.008952764602082, 17.133981464680645, 26.96219986712012, 23.133981464680645, 17.133981464680645, 17.133981464680645, 17.133981464680645, 20.133981464680645, 17.133981464680645, 25.508952764602082, 20.133981464680645]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0xa8e6, Score: 19
Depth 2: State = 0xa8e6, Legal Moves = [((1, 0), (1, 1)), ((1, 5), (2, 5)), ((2, 0), (2, 1)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa8e6: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0xa93c, Score: 28
Depth 3: State = 0xa93c, Legal Moves = [((0, 1), (1, 1)), ((1, 5), (2, 5)), ((2, 3), (3, 3)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((3, 0), (4, 0)), ((3, 2), (3, 3)), ((3, 3), (3, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0xa93c: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x43e5, Score: 31
Depth 4: State = 0x43e5, Legal Moves = [((0, 2), (1, 2)), ((1, 5), (2, 5)), ((2, 3), (3, 3)), ((2, 6), (3, 6)), ((2, 7), (3, 7)), ((3, 0), (4, 0)), ((3, 2), (3, 3)), ((3, 3), (3, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x43e5: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x433a, Score: 37
End of simulation with depth 5. Reward (Score): 37
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.852941176470583, N[0x87cd, ((5, 3), (5, 4))] = 68
Updated Q[0x87cd, ((1, 1), (1, 2))] = 37.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0xa8e6, ((1, 0), (1, 1))] = 37.0, N[0xa8e6, ((1, 0), (1, 1))] = 1
Updated Q[0xa93c, ((0, 1), (1, 1))] = 37.0, N[0xa93c, ((0, 1), (1, 1))] = 1
Updated Q[0x43e5, ((0, 2), (1, 2))] = 37.0, N[0x43e5, ((0, 2), (1, 2))] = 1

--- Simulation 97 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.136433521424863, 17.136433521424863, 20.136433521424863, 25.50534331527689, 17.136433521424863, 21.136433521424863, 21.136433521424863, 18.136433521424863, 20.136433521424863, 25.010686630553774, 17.136433521424863, 27.11202179620426, 23.136433521424863, 17.136433521424863, 17.136433521424863, 17.136433521424863, 20.136433521424863, 17.136433521424863, 25.510686630553774, 20.136433521424863]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 2), (0, 3)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x87c9, Score: 13
Depth 2: State = 0x87c9, Legal Moves = [((0, 3), (1, 3)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x87c9, Score: 16
Depth 3: State = 0x87c9, Legal Moves = [((1, 5), (2, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((2, 5), (3, 5)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87c9, Score: 19
Depth 4: State = 0x87c9, Legal Moves = [((0, 4), (0, 5)), ((2, 2), (2, 3)), ((2, 4), (2, 5)), ((4, 4), (5, 4)), ((4, 5), (4, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87c9: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87c9, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.826086956521735, N[0x87cd, ((5, 3), (5, 4))] = 69
Updated Q[0x87cd, ((0, 2), (0, 3))] = 25.0, N[0x87cd, ((0, 2), (0, 3))] = 1
Updated Q[0x87c9, ((0, 3), (1, 3))] = 25.0, N[0x87c9, ((0, 3), (1, 3))] = 1
Updated Q[0x87c9, ((1, 5), (2, 5))] = 25.0, N[0x87c9, ((1, 5), (2, 5))] = 1
Updated Q[0x87c9, ((0, 4), (0, 5))] = 25.0, N[0x87c9, ((0, 4), (0, 5))] = 1

--- Simulation 98 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.138857400226435, 17.138857400226435, 20.138857400226435, 25.50620028584557, 17.138857400226435, 21.138857400226435, 21.138857400226435, 18.138857400226435, 20.138857400226435, 25.012400571691142, 17.138857400226435, 27.083575129276806, 23.138857400226435, 17.138857400226435, 17.138857400226435, 17.138857400226435, 20.138857400226435, 17.138857400226435, 25.512400571691142, 20.138857400226435]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (1, 5)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x6503, Score: 20
Depth 2: State = 0x6503, Legal Moves = [((1, 4), (1, 5)), ((1, 5), (2, 5)), ((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6503: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 4), (1, 5))
New board state after move: 0x6503, Score: 26
Depth 3: State = 0x6503, Legal Moves = [((3, 2), (3, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x6503: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((3, 2), (3, 3))
New board state after move: 0x2320, Score: 29
Depth 4: State = 0x2320, Legal Moves = [((2, 2), (2, 3)), ((3, 0), (4, 0)), ((3, 2), (3, 3)), ((3, 3), (4, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x2320: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x231e, Score: 35
End of simulation with depth 5. Reward (Score): 35
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.94285714285714, N[0x87cd, ((5, 3), (5, 4))] = 70
Updated Q[0x87cd, ((1, 1), (1, 2))] = 35.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x6503, ((1, 4), (1, 5))] = 35.0, N[0x6503, ((1, 4), (1, 5))] = 1
Updated Q[0x6503, ((3, 2), (3, 3))] = 35.0, N[0x6503, ((3, 2), (3, 3))] = 1
Updated Q[0x2320, ((2, 2), (2, 3))] = 35.0, N[0x2320, ((2, 2), (2, 3))] = 1

--- Simulation 99 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.14125371655733, 17.14125371655733, 20.14125371655733, 25.507047511609294, 17.14125371655733, 21.14125371655733, 21.14125371655733, 18.14125371655733, 20.14125371655733, 25.014095023218584, 17.14125371655733, 27.198785913044432, 23.14125371655733, 17.14125371655733, 17.14125371655733, 17.14125371655733, 20.14125371655733, 17.14125371655733, 25.514095023218584, 20.14125371655733]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 10
Depth 1: State = 0x87cd, Legal Moves = [((0, 6), (1, 6)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 6), (1, 6))
New board state after move: 0x87cd, Score: 13
Depth 2: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 16
Depth 3: State = 0x87cd, Legal Moves = [((0, 4), (0, 5)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((3, 4), (4, 4)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (0, 5))
New board state after move: 0x87cd, Score: 19
Depth 4: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x44e6, Score: 25
End of simulation with depth 5. Reward (Score): 25
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.915492957746476, N[0x87cd, ((5, 3), (5, 4))] = 71
Updated Q[0x87cd, ((0, 6), (1, 6))] = 25.0, N[0x87cd, ((0, 6), (1, 6))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 25.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((0, 4), (0, 5))] = 25.0, N[0x87cd, ((0, 4), (0, 5))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 25.0, N[0x87cd, ((1, 1), (1, 2))] = 1

--- Simulation 100 ---
Depth 0: State = 0x87cd, Legal Moves = [((0, 5), (1, 5)), ((1, 1), (1, 2)), ((1, 5), (1, 6)), ((2, 2), (2, 3)), ((3, 5), (4, 5)), ((4, 3), (4, 4)), ((4, 4), (4, 5)), ((4, 6), (5, 6)), ((4, 6), (4, 7)), ((4, 7), (5, 7)), ((5, 1), (5, 2)), ((5, 3), (5, 4)), ((5, 4), (5, 5)), ((5, 6), (6, 6)), ((5, 6), (5, 7)), ((5, 8), (5, 9)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [17.143623066244295, 17.143623066244295, 20.143623066244295, 25.50788520322462, 17.143623066244295, 21.143623066244295, 21.143623066244295, 18.143623066244295, 20.143623066244295, 25.015770406449242, 17.143623066244295, 27.169894211456477, 23.143623066244295, 17.143623066244295, 17.143623066244295, 17.143623066244295, 20.143623066244295, 17.143623066244295, 25.515770406449242, 20.143623066244295]
Selected move: ((5, 3), (5, 4))
New board state after move: 0x87cd, Score: 7
Depth 1: State = 0x87cd, Legal Moves = [((0, 4), (1, 4)), ((0, 4), (0, 5)), ((0, 6), (0, 7)), ((0, 7), (1, 7)), ((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x87cd, Score: 10
Depth 2: State = 0x87cd, Legal Moves = [((1, 1), (1, 2)), ((1, 5), (2, 5)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x87cd, Score: 13
Depth 3: State = 0x87cd, Legal Moves = [((1, 5), (2, 5)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 5), (6, 5)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 5), (2, 5))
New board state after move: 0x87cd, Score: 16
Depth 4: State = 0x87cd, Legal Moves = [((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 2), (2, 3)), ((4, 4), (5, 4)), ((4, 4), (4, 5)), ((4, 5), (4, 6)), ((4, 6), (5, 6)), ((4, 8), (4, 9)), ((5, 1), (5, 2)), ((5, 7), (6, 7)), ((6, 1), (7, 1)), ((6, 4), (6, 5)), ((6, 5), (6, 6)), ((6, 6), (7, 6)), ((6, 7), (6, 8)), ((7, 3), (8, 3))]
UCB1 values for moves at state 0x87cd: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x8620, Score: 19
End of simulation with depth 5. Reward (Score): 19
Updated Q[0x87cd, ((5, 3), (5, 4))] = 26.805555555555554, N[0x87cd, ((5, 3), (5, 4))] = 72
Updated Q[0x87cd, ((0, 4), (1, 4))] = 19.0, N[0x87cd, ((0, 4), (1, 4))] = 1
Updated Q[0x87cd, ((1, 1), (1, 2))] = 19.0, N[0x87cd, ((1, 1), (1, 2))] = 1
Updated Q[0x87cd, ((1, 5), (2, 5))] = 19.0, N[0x87cd, ((1, 5), (2, 5))] = 1
Updated Q[0x87cd, ((2, 1), (2, 2))] = 19.0, N[0x87cd, ((2, 1), (2, 2))] = 1

Best move selected: ((5, 3), (5, 4))

--- Summary of States Visited ---
State 0x87cd visited 100 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x6504 visited 1 times
State 0x87ca visited 1 times
State 0x87ca visited 1 times
State 0x6603 visited 1 times
State 0x6603 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x22ca visited 1 times
State 0xc9b0 visited 1 times
State 0x6557 visited 1 times
State 0x6557 visited 1 times
State 0x6557 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x2323 visited 1 times
State 0x221e visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x87cb visited 1 times
State 0x87cb visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0xa7e4 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x2374 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xc9af visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x4393 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x6602 visited 1 times
State 0x64ad visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xca06 visited 1 times
State 0x87c9 visited 1 times
State 0x87cb visited 1 times
State 0x86ca visited 1 times
State 0x86ca visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x871e visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0xc9b0 visited 1 times
State 0x8676 visited 1 times
State 0x8676 visited 1 times
State 0x8676 visited 1 times
State 0x65ae visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xcaae visited 1 times
State 0xcaae visited 1 times
State 0x861e visited 1 times
State 0x861e visited 1 times
State 0x861e visited 1 times
State 0x861e visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xa891 visited 1 times
State 0xa891 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x8673 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xa83d visited 1 times
State 0xa93e visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0xa8e6 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x21cb visited 1 times
State 0x44a5 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x655b visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xc901 visited 1 times
State 0x655a visited 1 times
State 0x655a visited 1 times
State 0x655a visited 1 times
State 0x2273 visited 1 times
State 0x2273 visited 1 times
State 0x871f visited 1 times
State 0x871f visited 1 times
State 0xa893 visited 1 times
State 0xa892 visited 1 times
State 0x8674 visited 1 times
State 0x8675 visited 1 times
State 0x6504 visited 1 times
State 0x6502 visited 1 times
State 0x65ae visited 1 times
State 0xa7e5 visited 1 times
State 0x443b visited 1 times
State 0x433a visited 1 times
State 0x433d visited 1 times
State 0x433d visited 1 times
State 0xc957 visited 1 times
State 0x65b0 visited 1 times
State 0x8620 visited 1 times
State 0xa93b visited 1 times
State 0xc956 visited 1 times
State 0x6557 visited 1 times
State 0xa83c visited 1 times
State 0xa83d visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8620 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0xa893 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xa793 visited 1 times
State 0xa793 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xcaaf visited 1 times
State 0xca04 visited 1 times
State 0xca04 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x86c8 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8674 visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x2222 visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x8620 visited 1 times
State 0x8620 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8776 visited 1 times
State 0xa93d visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x21cc visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x64b0 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x22cc visited 1 times
State 0x2276 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xca06 visited 1 times
State 0xa93d visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0x8631 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x64ad visited 1 times
State 0x2222 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x86cb visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8676 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8777 visited 1 times
State 0x8777 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x2321 visited 1 times
State 0x22cb visited 1 times
State 0x2277 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x6603 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8775 visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x6504 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x8677 visited 1 times
State 0x861e visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x86ca visited 1 times
State 0x87cd visited 1 times
State 0x87cc visited 1 times
State 0xa93c visited 1 times
State 0xa792 visited 1 times
State 0x87cd visited 1 times
State 0xa8e7 visited 1 times
State 0x221e visited 1 times
State 0x2222 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87ca visited 1 times
State 0x87ca visited 1 times
State 0x87ca visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0xa7e5 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x43e5 visited 1 times
State 0x433e visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cb visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0xcab0 visited 1 times
State 0xcaad visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x443a visited 1 times
State 0x443a visited 1 times
State 0x87cd visited 1 times
State 0xa8e6 visited 1 times
State 0xa93c visited 1 times
State 0x43e5 visited 1 times
State 0x87cd visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87c9 visited 1 times
State 0x87cd visited 1 times
State 0x6503 visited 1 times
State 0x6503 visited 1 times
State 0x2320 visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
State 0x87cd visited 1 times
