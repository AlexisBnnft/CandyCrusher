
--- Simulation 1 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43d2, Score: 5600
Depth 1: State = 0x43d2, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43d2: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x11a9, Score: 11200
Depth 2: State = 0x11a9, Legal Moves = [((1, 1), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x11a9: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x144f, Score: 14000
Depth 3: State = 0x144f, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (1, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x144f: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x36b8, Score: 16800
Depth 4: State = 0x36b8, Legal Moves = [((2, 1), (2, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x36b8: [inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x36b8, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x43d2, ((2, 0), (2, 1))] = 19600, N[0x43d2, ((2, 0), (2, 1))] = 1
Updated Q[0x11a9, ((1, 1), (2, 1))] = 19600, N[0x11a9, ((1, 1), (2, 1))] = 1
Updated Q[0x144f, ((0, 0), (0, 1))] = 19600, N[0x144f, ((0, 0), (0, 1))] = 1
Updated Q[0x36b8, ((2, 1), (2, 2))] = 19600, N[0x36b8, ((2, 1), (2, 2))] = 1

--- Simulation 2 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d78, Score: 5600
Depth 1: State = 0x3d78, Legal Moves = [((0, 0), (0, 1)), ((1, 1), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d78: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x510b, Score: 8400
Depth 2: State = 0x510b, Legal Moves = [((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x510b: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x50e9, Score: 11200
Depth 3: State = 0x50e9, Legal Moves = [((1, 1), (1, 2)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x50e9: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x5171, Score: 14000
Depth 4: State = 0x5171, Legal Moves = [((1, 2), (2, 2)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x5171: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x53ee, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3d78, ((0, 0), (0, 1))] = 16800, N[0x3d78, ((0, 0), (0, 1))] = 1
Updated Q[0x510b, ((1, 1), (1, 2))] = 16800, N[0x510b, ((1, 1), (1, 2))] = 1
Updated Q[0x50e9, ((1, 1), (1, 2))] = 16800, N[0x50e9, ((1, 1), (1, 2))] = 1
Updated Q[0x5171, ((1, 2), (2, 2))] = 16800, N[0x5171, ((1, 2), (2, 2))] = 1

--- Simulation 3 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 16801.16557645562, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x45ad, Score: 8400
Depth 2: State = 0x45ad, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45ad: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4917, Score: 16100
Depth 3: State = 0x4917, Legal Moves = [((0, 1), (0, 2)), ((0, 1), (1, 1)), ((0, 4), (1, 4)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4917: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4acf, Score: 18900
Depth 4: State = 0x4acf, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4acf: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a4f, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 21700, N[0x3c25, ((2, 3), (2, 4))] = 1
Updated Q[0x3c25, ((0, 0), (0, 1))] = 21700, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x45ad, ((1, 3), (2, 3))] = 21700, N[0x45ad, ((1, 3), (2, 3))] = 1
Updated Q[0x4917, ((0, 1), (0, 2))] = 21700, N[0x4917, ((0, 1), (0, 2))] = 1
Updated Q[0x4acf, ((1, 3), (2, 3))] = 21700, N[0x4acf, ((1, 3), (2, 3))] = 1

--- Simulation 4 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.467405903557, 16801.467405903557, 21701.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c29, Score: 5600
Depth 1: State = 0x3c29, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c29: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3c22, Score: 8400
Depth 2: State = 0x3c22, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c22: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x382a, Score: 11200
Depth 3: State = 0x382a, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x382a: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x57cb, Score: 14000
Depth 4: State = 0x57cb, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x57cb: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x57cb, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (3, 3))] = 16800, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3c29, ((1, 3), (1, 4))] = 16800, N[0x3c29, ((1, 3), (1, 4))] = 1
Updated Q[0x3c22, ((2, 0), (2, 1))] = 16800, N[0x3c22, ((2, 0), (2, 1))] = 1
Updated Q[0x382a, ((0, 1), (1, 1))] = 16800, N[0x382a, ((0, 1), (1, 1))] = 1
Updated Q[0x57cb, ((1, 0), (1, 1))] = 16800, N[0x57cb, ((1, 0), (1, 1))] = 1

--- Simulation 5 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.648374031523, 16801.648374031523, 21701.648374031523, 16801.648374031523, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x2ee9, Score: 5600
Depth 1: State = 0x2ee9, Legal Moves = [((2, 3), (2, 4)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x2ee9: [inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x2ee8, Score: 8400
Depth 2: State = 0x2ee8, Legal Moves = [((1, 3), (2, 3)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x2ee8: [inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x2a8d, Score: 14000
Depth 3: State = 0x2a8d, Legal Moves = [((1, 1), (1, 2)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x2a8d: [inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x2b11, Score: 16800
Depth 4: State = 0x2b11, Legal Moves = [((2, 4), (3, 4))]
UCB1 values for moves at state 0x2b11: [inf]
Selected move: ((2, 4), (3, 4))
New board state after move: 0x2b13, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((3, 0), (3, 1))] = 19600, N[0x3c25, ((3, 0), (3, 1))] = 1
Updated Q[0x2ee9, ((2, 3), (2, 4))] = 19600, N[0x2ee9, ((2, 3), (2, 4))] = 1
Updated Q[0x2ee8, ((1, 3), (2, 3))] = 19600, N[0x2ee8, ((1, 3), (2, 3))] = 1
Updated Q[0x2a8d, ((1, 1), (1, 2))] = 19600, N[0x2a8d, ((1, 1), (1, 2))] = 1
Updated Q[0x2b11, ((2, 4), (3, 4))] = 19600, N[0x2b11, ((2, 4), (3, 4))] = 1

--- Simulation 6 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.77609073765, 16801.77609073765, 21701.77609073765, 16801.77609073765, 19601.77609073765]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a6c, Score: 11200
Depth 2: State = 0x4a6c, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a6c: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4934, Score: 14000
Depth 3: State = 0x4934, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4934: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x43e9, Score: 16800
Depth 4: State = 0x43e9, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1))]
UCB1 values for moves at state 0x43e9: [inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x108f, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 41300, N[0x3c25, ((2, 3), (2, 4))] = 2
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a6c, ((1, 3), (2, 3))] = 19600, N[0x4a6c, ((1, 3), (2, 3))] = 1
Updated Q[0x4934, ((2, 0), (2, 1))] = 19600, N[0x4934, ((2, 0), (2, 1))] = 1
Updated Q[0x43e9, ((1, 0), (2, 0))] = 19600, N[0x43e9, ((1, 0), (2, 0))] = 1

--- Simulation 7 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.873992678666, 16801.873992678666, 20651.325112930976, 16801.873992678666, 19601.873992678666]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x3bb9, Score: 14000
Depth 2: State = 0x3bb9, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb9: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3983, Score: 16800
Depth 3: State = 0x3983, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3983: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3983, Score: 25200
Depth 4: State = 0x3983, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3983: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0xf299, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 69300, N[0x3c25, ((2, 3), (2, 4))] = 3
Updated Q[0x3c25, ((0, 0), (0, 1))] = 28000, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x3bb9, ((1, 3), (2, 3))] = 28000, N[0x3bb9, ((1, 3), (2, 3))] = 1
Updated Q[0x3983, ((1, 3), (1, 4))] = 28000, N[0x3983, ((1, 3), (1, 4))] = 1
Updated Q[0x3983, ((1, 2), (1, 3))] = 28000, N[0x3983, ((1, 2), (1, 3))] = 1

--- Simulation 8 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.95294236785, 16801.95294236785, 23101.12753180179, 16801.95294236785, 19601.95294236785]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47ed, Score: 8400
Depth 2: State = 0x47ed, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47ed: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4525, Score: 14000
Depth 3: State = 0x4525, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x4525: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4522, Score: 16800
Depth 4: State = 0x4522, Legal Moves = [((0, 3), (0, 4)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x4522: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x452c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 88900, N[0x3c25, ((2, 3), (2, 4))] = 4
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x47ed, ((1, 3), (2, 3))] = 19600, N[0x47ed, ((1, 3), (2, 3))] = 1
Updated Q[0x4525, ((0, 3), (1, 3))] = 19600, N[0x4525, ((0, 3), (1, 3))] = 1
Updated Q[0x4522, ((0, 3), (0, 4))] = 19600, N[0x4522, ((0, 3), (0, 4))] = 1

--- Simulation 9 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.01883764124, 16802.01883764124, 22226.00941882062, 16802.01883764124, 19602.01883764124]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46dc, Score: 8400
Depth 2: State = 0x46dc, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46dc: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x453b, Score: 19600
Depth 3: State = 0x453b, Legal Moves = [((2, 1), (2, 2)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x453b: [inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x455d, Score: 22400
Depth 4: State = 0x455d, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x455d: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x4524, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 114100, N[0x3c25, ((2, 3), (2, 4))] = 5
Updated Q[0x3c24, ((0, 0), (0, 1))] = 25200, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46dc, ((1, 3), (2, 3))] = 25200, N[0x46dc, ((1, 3), (2, 3))] = 1
Updated Q[0x453b, ((2, 1), (2, 2))] = 25200, N[0x453b, ((2, 1), (2, 2))] = 1
Updated Q[0x455d, ((0, 2), (0, 3))] = 25200, N[0x455d, ((0, 2), (0, 3))] = 1

--- Simulation 10 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.075225330314, 16802.075225330314, 22820.928068981444, 16802.075225330314, 19602.075225330314]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a47, Score: 8400
Depth 2: State = 0x4a47, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a47: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x46ff, Score: 11200
Depth 3: State = 0x46ff, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46ff: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x46ff, Score: 14000
Depth 4: State = 0x46ff, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46ff: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4700, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 130900, N[0x3c25, ((2, 3), (2, 4))] = 6
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a47, ((1, 3), (2, 3))] = 16800, N[0x4a47, ((1, 3), (2, 3))] = 1
Updated Q[0x46ff, ((0, 3), (1, 3))] = 16800, N[0x46ff, ((0, 3), (1, 3))] = 1
Updated Q[0x46ff, ((1, 3), (1, 4))] = 16800, N[0x46ff, ((1, 3), (1, 4))] = 1

--- Simulation 11 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.12439798114, 16802.12439798114, 21817.533948510732, 16802.12439798114, 19602.12439798114]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43d6, Score: 8400
Depth 2: State = 0x43d6, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43d6: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x47a9, Score: 11200
Depth 3: State = 0x47a9, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47a9: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x47a2, Score: 14000
Depth 4: State = 0x47a2, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47a2: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x479f, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 147700, N[0x3c25, ((2, 3), (2, 4))] = 7
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x43d6, ((1, 3), (2, 3))] = 16800, N[0x43d6, ((1, 3), (2, 3))] = 1
Updated Q[0x47a9, ((0, 3), (1, 3))] = 16800, N[0x47a9, ((0, 3), (1, 3))] = 1
Updated Q[0x47a2, ((0, 2), (0, 3))] = 16800, N[0x47a2, ((0, 2), (0, 3))] = 1

--- Simulation 12 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.167919448384, 16802.167919448384, 21100.819396531835, 16802.167919448384, 19602.167919448384]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c5e, Score: 8400
Depth 1: State = 0x3c5e, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5e: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x397b, Score: 11200
Depth 2: State = 0x397b, Legal Moves = [((0, 1), (0, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x397b: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3b0a, Score: 14000
Depth 3: State = 0x3b0a, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3b0a: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3b0a, Score: 16800
Depth 4: State = 0x3b0a, Legal Moves = [((1, 1), (2, 1)), ((2, 2), (3, 2))]
UCB1 values for moves at state 0x3b0a: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3c3b, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 170100, N[0x3c25, ((2, 3), (2, 4))] = 8
Updated Q[0x3c5e, ((0, 3), (1, 3))] = 22400, N[0x3c5e, ((0, 3), (1, 3))] = 1
Updated Q[0x397b, ((0, 1), (0, 2))] = 22400, N[0x397b, ((0, 1), (0, 2))] = 1
Updated Q[0x3b0a, ((2, 0), (2, 1))] = 22400, N[0x3b0a, ((2, 0), (2, 1))] = 1
Updated Q[0x3b0a, ((1, 1), (2, 1))] = 22400, N[0x3b0a, ((1, 1), (2, 1))] = 1

--- Simulation 13 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.206902135025, 16802.206902135025, 21263.280257732546, 16802.206902135025, 19602.206902135025]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x464c, Score: 8400
Depth 2: State = 0x464c, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x464c: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x469a, Score: 11200
Depth 3: State = 0x469a, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x469a: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x47ec, Score: 14000
Depth 4: State = 0x47ec, Legal Moves = [((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x47ec: [inf, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x47e2, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 186900, N[0x3c25, ((2, 3), (2, 4))] = 9
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x464c, ((0, 1), (1, 1))] = 16800, N[0x464c, ((0, 1), (1, 1))] = 1
Updated Q[0x469a, ((1, 1), (2, 1))] = 16800, N[0x469a, ((1, 1), (2, 1))] = 1
Updated Q[0x47ec, ((2, 3), (3, 3))] = 16800, N[0x47ec, ((2, 3), (3, 3))] = 1

--- Simulation 14 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.242164298314, 16802.242164298314, 20767.414054766105, 16802.242164298314, 19602.242164298314]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x482a, Score: 8400
Depth 2: State = 0x482a, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x482a: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x46b9, Score: 11200
Depth 3: State = 0x46b9, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46b9: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x441d, Score: 14000
Depth 4: State = 0x441d, Legal Moves = [((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x441d: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x43cf, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 203700, N[0x3c25, ((2, 3), (2, 4))] = 10
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x482a, ((1, 3), (2, 3))] = 16800, N[0x482a, ((1, 3), (2, 3))] = 1
Updated Q[0x46b9, ((1, 3), (2, 3))] = 16800, N[0x46b9, ((1, 3), (2, 3))] = 1
Updated Q[0x441d, ((1, 1), (1, 2))] = 16800, N[0x441d, ((1, 1), (1, 2))] = 1

--- Simulation 15 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.274324595575, 16802.274324595575, 20370.719204586057, 16802.274324595575, 19602.274324595575]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a51, Score: 8400
Depth 2: State = 0x4a51, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a51: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4a65, Score: 11200
Depth 3: State = 0x4a65, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a65: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4a70, Score: 14000
Depth 4: State = 0x4a70, Legal Moves = [((0, 3), (0, 4)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a70: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x4a70, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 220500, N[0x3c25, ((2, 3), (2, 4))] = 11
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a51, ((1, 3), (1, 4))] = 16800, N[0x4a51, ((1, 3), (1, 4))] = 1
Updated Q[0x4a65, ((1, 2), (1, 3))] = 16800, N[0x4a65, ((1, 2), (1, 3))] = 1
Updated Q[0x4a70, ((0, 3), (0, 4))] = 16800, N[0x4a70, ((0, 3), (0, 4))] = 1

--- Simulation 16 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.303861626522, 16802.303861626522, 20046.149185871276, 16802.303861626522, 19602.303861626522]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bbf, Score: 8400
Depth 1: State = 0x3bbf, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbf: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3b19, Score: 11200
Depth 2: State = 0x3b19, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3b19: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x53b7, Score: 16800
Depth 3: State = 0x53b7, Legal Moves = [((2, 1), (2, 2))]
UCB1 values for moves at state 0x53b7: [inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x5430, Score: 22400
Depth 4: State = 0x5430, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 242900, N[0x3c25, ((2, 3), (2, 4))] = 12
Updated Q[0x3bbf, ((1, 3), (1, 4))] = 22400, N[0x3bbf, ((1, 3), (1, 4))] = 1
Updated Q[0x3b19, ((2, 0), (2, 1))] = 22400, N[0x3b19, ((2, 0), (2, 1))] = 1
Updated Q[0x53b7, ((2, 1), (2, 2))] = 22400, N[0x53b7, ((2, 1), (2, 2))] = 1

--- Simulation 17 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.33115291124, 16802.33115291124, 20242.339612547083, 16802.33115291124, 19602.33115291124]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4590, Score: 8400
Depth 2: State = 0x4590, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4590: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4836, Score: 11200
Depth 3: State = 0x4836, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4836: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4836, Score: 14000
Depth 4: State = 0x4836, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 256900, N[0x3c25, ((2, 3), (2, 4))] = 13
Updated Q[0x3c24, ((0, 0), (0, 1))] = 14000, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4590, ((1, 3), (1, 4))] = 14000, N[0x4590, ((1, 3), (1, 4))] = 1
Updated Q[0x4836, ((2, 0), (2, 1))] = 14000, N[0x4836, ((2, 0), (2, 1))] = 1

--- Simulation 18 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.35650125278, 16802.35650125278, 19762.19203739212, 16802.35650125278, 19602.35650125278]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4833, Score: 8400
Depth 2: State = 0x4833, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4833: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x3695, Score: 11200
Depth 3: State = 0x3695, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3695: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c43, Score: 16800
Depth 4: State = 0x3c43, Legal Moves = [((0, 0), (1, 0)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3c43: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x4673, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 279300, N[0x3c25, ((2, 3), (2, 4))] = 14
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4833, ((0, 0), (0, 1))] = 22400, N[0x4833, ((0, 0), (0, 1))] = 1
Updated Q[0x3695, ((1, 3), (2, 3))] = 22400, N[0x3695, ((1, 3), (2, 3))] = 1
Updated Q[0x3c43, ((0, 0), (1, 0))] = 22400, N[0x3c43, ((0, 0), (1, 0))] = 1

--- Simulation 19 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.38015307186, 16802.38015307186, 19950.63612266593, 16802.38015307186, 19602.38015307186]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a55, Score: 8400
Depth 2: State = 0x4a55, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a55: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4547, Score: 11200
Depth 3: State = 0x4547, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4547: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1d52, Score: 19600
Depth 4: State = 0x1d52, Legal Moves = [((0, 1), (1, 1))]
UCB1 values for moves at state 0x1d52: [inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x214b, Score: 30000
End of simulation with depth 5. Reward (Score): 30000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 309300, N[0x3c25, ((2, 3), (2, 4))] = 15
Updated Q[0x3c25, ((0, 0), (0, 1))] = 30000, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4a55, ((1, 3), (1, 4))] = 30000, N[0x4a55, ((1, 3), (1, 4))] = 1
Updated Q[0x4547, ((2, 0), (2, 1))] = 30000, N[0x4547, ((2, 0), (2, 1))] = 1
Updated Q[0x1d52, ((0, 1), (1, 1))] = 30000, N[0x1d52, ((0, 1), (1, 1))] = 1

--- Simulation 20 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.402311470058, 16802.402311470058, 20620.620274154397, 16802.402311470058, 19602.402311470058]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x493c, Score: 8400
Depth 2: State = 0x493c, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x493c: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4aaa, Score: 11200
Depth 3: State = 0x4aaa, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aaa: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x46b2, Score: 14000
Depth 4: State = 0x46b2, Legal Moves = [((0, 1), (1, 1))]
UCB1 values for moves at state 0x46b2: [inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x48f5, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 326100, N[0x3c25, ((2, 3), (2, 4))] = 16
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x493c, ((1, 3), (2, 3))] = 16800, N[0x493c, ((1, 3), (2, 3))] = 1
Updated Q[0x4aaa, ((2, 0), (2, 1))] = 16800, N[0x4aaa, ((2, 0), (2, 1))] = 1
Updated Q[0x46b2, ((0, 1), (1, 1))] = 16800, N[0x46b2, ((0, 1), (1, 1))] = 1

--- Simulation 21 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.423145735644, 16802.423145735644, 20381.85578643391, 16802.423145735644, 19602.423145735644]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x45ac, Score: 8400
Depth 2: State = 0x45ac, Legal Moves = [((0, 3), (0, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x45ac: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x45a9, Score: 11200
Depth 3: State = 0x45a9, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a9: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4503, Score: 14000
Depth 4: State = 0x4503, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4503: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x466e, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 345700, N[0x3c25, ((2, 3), (2, 4))] = 17
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x45ac, ((0, 3), (0, 4))] = 19600, N[0x45ac, ((0, 3), (0, 4))] = 1
Updated Q[0x45a9, ((1, 2), (2, 2))] = 19600, N[0x45a9, ((1, 2), (2, 2))] = 1
Updated Q[0x4503, ((0, 3), (1, 3))] = 19600, N[0x4503, ((0, 3), (1, 3))] = 1

--- Simulation 22 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.442798390766, 16802.442798390766, 20335.8865832816, 16802.442798390766, 19602.442798390766]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c5d, Score: 8400
Depth 1: State = 0x3c5d, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5d: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c28, Score: 11200
Depth 2: State = 0x3c28, Legal Moves = [((0, 1), (0, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c28: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3b11, Score: 14000
Depth 3: State = 0x3b11, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3b11: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d95, Score: 22400
Depth 4: State = 0x3d95, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d95: [inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x399d, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 370900, N[0x3c25, ((2, 3), (2, 4))] = 18
Updated Q[0x3c5d, ((0, 2), (1, 2))] = 25200, N[0x3c5d, ((0, 2), (1, 2))] = 1
Updated Q[0x3c28, ((0, 1), (0, 2))] = 25200, N[0x3c28, ((0, 1), (0, 2))] = 1
Updated Q[0x3b11, ((2, 0), (2, 1))] = 25200, N[0x3b11, ((2, 0), (2, 1))] = 1
Updated Q[0x3d95, ((1, 1), (1, 2))] = 25200, N[0x3d95, ((1, 1), (1, 2))] = 1

--- Simulation 23 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.461390503067, 16802.461390503067, 20606.135710860843, 16802.461390503067, 19602.461390503067]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4565, Score: 8400
Depth 2: State = 0x4565, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4565: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a8f, Score: 11200
Depth 3: State = 0x4a8f, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a8f: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4a88, Score: 14000
Depth 4: State = 0x4a88, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a88: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4aad, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 390500, N[0x3c25, ((2, 3), (2, 4))] = 19
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4565, ((1, 3), (2, 3))] = 19600, N[0x4565, ((1, 3), (2, 3))] = 1
Updated Q[0x4a8f, ((1, 2), (1, 3))] = 19600, N[0x4a8f, ((1, 2), (1, 3))] = 1
Updated Q[0x4a88, ((1, 2), (2, 2))] = 19600, N[0x4a88, ((1, 2), (2, 2))] = 1

--- Simulation 24 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.479025748802, 16802.479025748802, 20553.200306458817, 16802.479025748802, 19602.479025748802]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x480b, Score: 8400
Depth 2: State = 0x480b, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x480b: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x11ea, Score: 14000
Depth 3: State = 0x11ea, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x11ea: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x5547, Score: 16800
Depth 4: State = 0x5547, Legal Moves = [((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5547: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x558d, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 412900, N[0x3c25, ((2, 3), (2, 4))] = 20
Updated Q[0x3c25, ((0, 0), (0, 1))] = 22400, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x480b, ((0, 3), (1, 3))] = 22400, N[0x480b, ((0, 3), (1, 3))] = 1
Updated Q[0x11ea, ((0, 0), (1, 0))] = 22400, N[0x11ea, ((0, 0), (1, 0))] = 1
Updated Q[0x5547, ((1, 1), (1, 2))] = 22400, N[0x5547, ((1, 1), (1, 2))] = 1

--- Simulation 25 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.495793562673, 16802.495793562673, 20645.558076406396, 16802.495793562673, 19602.495793562673]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4437, Score: 8400
Depth 2: State = 0x4437, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4437: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x43ce, Score: 14000
Depth 3: State = 0x43ce, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43ce: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x43ce, Score: 16800
Depth 4: State = 0x43ce, Legal Moves = [((1, 1), (2, 1)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((3, 2), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x43ce: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x14b0, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 435300, N[0x3c25, ((2, 3), (2, 4))] = 21
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4437, ((1, 3), (2, 3))] = 22400, N[0x4437, ((1, 3), (2, 3))] = 1
Updated Q[0x43ce, ((2, 0), (2, 1))] = 22400, N[0x43ce, ((2, 0), (2, 1))] = 1
Updated Q[0x43ce, ((1, 1), (2, 1))] = 22400, N[0x43ce, ((1, 1), (2, 1))] = 1

--- Simulation 26 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.51177160919, 16802.51177160919, 20729.11954207274, 16802.51177160919, 19602.51177160919]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4702, Score: 8400
Depth 2: State = 0x4702, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4702: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4934, Score: 11200
Depth 3: State = 0x4934, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4934: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x47e1, Score: 14000
Depth 4: State = 0x47e1, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 449300, N[0x3c25, ((2, 3), (2, 4))] = 22
Updated Q[0x3c24, ((0, 0), (0, 1))] = 14000, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4702, ((1, 3), (1, 4))] = 14000, N[0x4702, ((1, 3), (1, 4))] = 1
Updated Q[0x4934, ((1, 1), (2, 1))] = 14000, N[0x4934, ((1, 1), (2, 1))] = 1

--- Simulation 27 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.527027743126, 16802.527027743126, 20423.266036852358, 16802.527027743126, 19602.527027743126]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bbf, Score: 8400
Depth 1: State = 0x3bbf, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbf: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3866, Score: 14000
Depth 2: State = 0x3866, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3866: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3b0b, Score: 16800
Depth 3: State = 0x3b0b, Legal Moves = [((2, 1), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3b0b: [inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x5671, Score: 19600
Depth 4: State = 0x5671, Legal Moves = [((1, 3), (2, 3)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x5671: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x56c6, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 471700, N[0x3c25, ((2, 3), (2, 4))] = 23
Updated Q[0x3bbf, ((1, 3), (2, 3))] = 22400, N[0x3bbf, ((1, 3), (2, 3))] = 1
Updated Q[0x3866, ((2, 0), (2, 1))] = 22400, N[0x3866, ((2, 0), (2, 1))] = 1
Updated Q[0x3b0b, ((2, 1), (3, 1))] = 22400, N[0x3b0b, ((2, 1), (3, 1))] = 1
Updated Q[0x5671, ((1, 3), (2, 3))] = 22400, N[0x5671, ((1, 3), (2, 3))] = 1

--- Simulation 28 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.541621580283, 16802.541621580283, 20509.22561690848, 16802.541621580283, 19602.541621580283]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46c2, Score: 8400
Depth 2: State = 0x46c2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46c2: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x454a, Score: 11200
Depth 3: State = 0x454a, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x454a: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4942, Score: 16800
Depth 4: State = 0x4942, Legal Moves = [((0, 2), (0, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2))]
UCB1 values for moves at state 0x4942: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x1dd2, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 491300, N[0x3c25, ((2, 3), (2, 4))] = 24
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46c2, ((1, 3), (2, 3))] = 19600, N[0x46c2, ((1, 3), (2, 3))] = 1
Updated Q[0x454a, ((1, 1), (2, 1))] = 19600, N[0x454a, ((1, 1), (2, 1))] = 1
Updated Q[0x4942, ((0, 2), (0, 3))] = 19600, N[0x4942, ((0, 2), (0, 3))] = 1

--- Simulation 29 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.55560576771, 16802.55560576771, 20471.354994176214, 16802.55560576771, 19602.55560576771]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x456b, Score: 8400
Depth 2: State = 0x456b, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x456b: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x45a5, Score: 11200
Depth 3: State = 0x45a5, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a5: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x45a8, Score: 14000
Depth 4: State = 0x45a8, Legal Moves = [((1, 0), (1, 1)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a8: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x4a98, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 508100, N[0x3c25, ((2, 3), (2, 4))] = 25
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x456b, ((1, 2), (2, 2))] = 16800, N[0x456b, ((1, 2), (2, 2))] = 1
Updated Q[0x45a5, ((1, 2), (1, 3))] = 16800, N[0x45a5, ((1, 2), (1, 3))] = 1
Updated Q[0x45a8, ((1, 0), (1, 1))] = 16800, N[0x45a8, ((1, 0), (1, 1))] = 1

--- Simulation 30 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.569027019472, 16802.569027019472, 20324.513805403894, 16802.569027019472, 19602.569027019472]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c47, Score: 8400
Depth 1: State = 0x3c47, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c47: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3a8e, Score: 11200
Depth 2: State = 0x3a8e, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3a8e: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x384e, Score: 14000
Depth 3: State = 0x384e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x384e: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d71, Score: 31600
Depth 4: State = 0x3d71, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d71: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3d4b, Score: 52600
End of simulation with depth 5. Reward (Score): 52600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 560700, N[0x3c25, ((2, 3), (2, 4))] = 26
Updated Q[0x3c47, ((0, 0), (1, 0))] = 52600, N[0x3c47, ((0, 0), (1, 0))] = 1
Updated Q[0x3a8e, ((0, 1), (0, 2))] = 52600, N[0x3a8e, ((0, 1), (0, 2))] = 1
Updated Q[0x384e, ((1, 3), (2, 3))] = 52600, N[0x384e, ((1, 3), (2, 3))] = 1
Updated Q[0x3d71, ((1, 1), (2, 1))] = 52600, N[0x3d71, ((1, 1), (2, 1))] = 1

--- Simulation 31 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.581926967996, 16802.581926967996, 21565.89097292279, 16802.581926967996, 19602.581926967996]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43f1, Score: 8400
Depth 2: State = 0x43f1, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43f1: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x43cb, Score: 11200
Depth 3: State = 0x43cb, Legal Moves = [((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43cb: [inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x441c, Score: 16800
Depth 4: State = 0x441c, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x441c: [inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x441c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 580300, N[0x3c25, ((2, 3), (2, 4))] = 27
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x43f1, ((1, 2), (2, 2))] = 19600, N[0x43f1, ((1, 2), (2, 2))] = 1
Updated Q[0x43cb, ((0, 4), (1, 4))] = 19600, N[0x43cb, ((0, 4), (1, 4))] = 1
Updated Q[0x441c, ((0, 4), (1, 4))] = 19600, N[0x441c, ((0, 4), (1, 4))] = 1

--- Simulation 32 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.59434286878, 16802.59434286878, 21493.09187411048, 16802.59434286878, 19602.59434286878]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47c2, Score: 8400
Depth 2: State = 0x47c2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c2: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x442c, Score: 11200
Depth 3: State = 0x442c, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x442c: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x48f5, Score: 14000
Depth 4: State = 0x48f5, Legal Moves = [((0, 2), (0, 3)), ((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f5: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x499b, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 597100, N[0x3c25, ((2, 3), (2, 4))] = 28
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47c2, ((1, 3), (2, 3))] = 16800, N[0x47c2, ((1, 3), (2, 3))] = 1
Updated Q[0x442c, ((0, 1), (0, 2))] = 16800, N[0x442c, ((0, 1), (0, 2))] = 1
Updated Q[0x48f5, ((0, 2), (0, 3))] = 16800, N[0x48f5, ((0, 2), (0, 3))] = 1

--- Simulation 33 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.60630818774, 16802.60630818774, 21325.49254595034, 16802.60630818774, 19602.60630818774]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d0a, Score: 14000
Depth 2: State = 0x3d0a, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d0a: [inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x3d08, Score: 19600
Depth 3: State = 0x3d08, Legal Moves = [((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d08: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3d3a, Score: 22400
Depth 4: State = 0x3d3a, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d3a: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3d0a, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 622300, N[0x3c25, ((2, 3), (2, 4))] = 29
Updated Q[0x3c24, ((1, 3), (2, 3))] = 25200, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3d0a, ((1, 1), (1, 2))] = 25200, N[0x3d0a, ((1, 1), (1, 2))] = 1
Updated Q[0x3d08, ((0, 3), (1, 3))] = 25200, N[0x3d08, ((0, 3), (1, 3))] = 1
Updated Q[0x3d3a, ((0, 3), (1, 3))] = 25200, N[0x3d3a, ((0, 3), (1, 3))] = 1

--- Simulation 34 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.617853093754, 16802.617853093754, 21459.106812770715, 16802.617853093754, 19602.617853093754]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x458d, Score: 8400
Depth 2: State = 0x458d, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x458d: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1dd9, Score: 11200
Depth 3: State = 0x1dd9, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1dd9: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x21f7, Score: 14000
Depth 4: State = 0x21f7, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x21f7: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x49ab, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 641900, N[0x3c25, ((2, 3), (2, 4))] = 30
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x458d, ((0, 0), (0, 1))] = 19600, N[0x458d, ((0, 0), (0, 1))] = 1
Updated Q[0x1dd9, ((1, 3), (2, 3))] = 19600, N[0x1dd9, ((1, 3), (2, 3))] = 1
Updated Q[0x21f7, ((0, 0), (0, 1))] = 19600, N[0x21f7, ((0, 0), (0, 1))] = 1

--- Simulation 35 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.62900487414, 16802.62900487414, 21397.14665509112, 16802.62900487414, 19602.62900487414]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bb8, Score: 8400
Depth 1: State = 0x3bb8, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb8: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3bb8, Score: 11200
Depth 2: State = 0x3bb8, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb8: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3b0f, Score: 14000
Depth 3: State = 0x3b0f, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3b0f: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x36d3, Score: 16800
Depth 4: State = 0x36d3, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d3: [inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x15bc, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 661500, N[0x3c25, ((2, 3), (2, 4))] = 31
Updated Q[0x3bb8, ((0, 4), (1, 4))] = 19600, N[0x3bb8, ((0, 4), (1, 4))] = 1
Updated Q[0x3bb8, ((1, 3), (2, 3))] = 19600, N[0x3bb8, ((1, 3), (2, 3))] = 1
Updated Q[0x3b0f, ((1, 3), (2, 3))] = 19600, N[0x3b0f, ((1, 3), (2, 3))] = 1
Updated Q[0x36d3, ((0, 1), (1, 1))] = 19600, N[0x36d3, ((0, 1), (1, 1))] = 1

--- Simulation 36 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.639788287062, 16802.639788287062, 21339.18379739194, 16802.639788287062, 19602.639788287062]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c62, Score: 11200
Depth 2: State = 0x3c62, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c62: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x380b, Score: 16800
Depth 3: State = 0x380b, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x380b: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x36bb, Score: 33300
Depth 4: State = 0x36bb, Legal Moves = [((1, 1), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (2, 3))]
UCB1 values for moves at state 0x36bb: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x54e1, Score: 44200
End of simulation with depth 5. Reward (Score): 44200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 705700, N[0x3c25, ((2, 3), (2, 4))] = 32
Updated Q[0x3c25, ((1, 2), (2, 2))] = 44200, N[0x3c25, ((1, 2), (2, 2))] = 1
Updated Q[0x3c62, ((2, 0), (2, 1))] = 44200, N[0x3c62, ((2, 0), (2, 1))] = 1
Updated Q[0x380b, ((1, 3), (1, 4))] = 44200, N[0x380b, ((1, 3), (1, 4))] = 1
Updated Q[0x36bb, ((1, 1), (2, 1))] = 44200, N[0x36bb, ((1, 1), (2, 1))] = 1

--- Simulation 37 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.650225861955, 16802.650225861955, 22053.593498169666, 16802.650225861955, 19602.650225861955]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bb5, Score: 13200
Depth 1: State = 0x3bb5, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb5: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3bd7, Score: 16000
Depth 2: State = 0x3bd7, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bd7: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3bda, Score: 18800
Depth 3: State = 0x3bda, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bda: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3c43, Score: 30000
Depth 4: State = 0x3c43, Legal Moves = [((0, 0), (1, 0)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c43: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x5787, Score: 32800
End of simulation with depth 5. Reward (Score): 32800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 738500, N[0x3c25, ((2, 3), (2, 4))] = 33
Updated Q[0x3bb5, ((0, 1), (1, 1))] = 32800, N[0x3bb5, ((0, 1), (1, 1))] = 1
Updated Q[0x3bd7, ((1, 2), (1, 3))] = 32800, N[0x3bd7, ((1, 2), (1, 3))] = 1
Updated Q[0x3bda, ((1, 2), (1, 3))] = 32800, N[0x3bda, ((1, 2), (1, 3))] = 1
Updated Q[0x3c43, ((0, 0), (1, 0))] = 32800, N[0x3c43, ((0, 0), (1, 0))] = 1

--- Simulation 38 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.66033815685, 16802.66033815685, 22379.250984218274, 16802.66033815685, 19602.66033815685]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c06, Score: 11200
Depth 1: State = 0x3c06, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c06: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3c06, Score: 14000
Depth 2: State = 0x3c06, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c06: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x214a, Score: 16800
Depth 3: State = 0x214a, Legal Moves = [((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x214a: [inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x218d, Score: 19600
Depth 4: State = 0x218d, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x218d: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1ee7, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 760900, N[0x3c25, ((2, 3), (2, 4))] = 34
Updated Q[0x3c06, ((1, 3), (1, 4))] = 22400, N[0x3c06, ((1, 3), (1, 4))] = 1
Updated Q[0x3c06, ((1, 2), (1, 3))] = 22400, N[0x3c06, ((1, 2), (1, 3))] = 1
Updated Q[0x214a, ((0, 4), (1, 4))] = 22400, N[0x214a, ((0, 4), (1, 4))] = 1
Updated Q[0x218d, ((2, 0), (2, 1))] = 22400, N[0x218d, ((2, 0), (2, 1))] = 1

--- Simulation 39 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.670143979838, 16802.670143979838, 22379.86969062055, 16802.670143979838, 19602.670143979838]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43c8, Score: 8400
Depth 2: State = 0x43c8, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43c8: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4aae, Score: 11200
Depth 3: State = 0x4aae, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aae: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x4a71, Score: 14000
Depth 4: State = 0x4a71, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a71: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4588, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 780500, N[0x3c25, ((2, 3), (2, 4))] = 35
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x43c8, ((0, 2), (1, 2))] = 19600, N[0x43c8, ((0, 2), (1, 2))] = 1
Updated Q[0x4aae, ((0, 2), (0, 3))] = 19600, N[0x4aae, ((0, 2), (0, 3))] = 1
Updated Q[0x4a71, ((1, 1), (2, 1))] = 19600, N[0x4a71, ((1, 1), (2, 1))] = 1

--- Simulation 40 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.67966058045, 16802.67966058045, 22300.45294530816, 16802.67966058045, 19602.67966058045]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x43d5, Score: 16100
Depth 2: State = 0x43d5, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43d5: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4419, Score: 18900
Depth 3: State = 0x4419, Legal Moves = [((0, 2), (1, 2)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4419: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3d9d, Score: 21700
Depth 4: State = 0x3d9d, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d9d: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3af7, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 805000, N[0x3c25, ((2, 3), (2, 4))] = 36
Updated Q[0x3c24, ((1, 3), (1, 4))] = 24500, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x43d5, ((1, 2), (1, 3))] = 24500, N[0x43d5, ((1, 2), (1, 3))] = 1
Updated Q[0x4419, ((0, 2), (1, 2))] = 24500, N[0x4419, ((0, 2), (1, 2))] = 1
Updated Q[0x3d9d, ((2, 0), (2, 1))] = 24500, N[0x3d9d, ((2, 0), (2, 1))] = 1

--- Simulation 41 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.688903815695, 16802.688903815695, 22361.559261747057, 16802.688903815695, 19602.688903815695]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46dd, Score: 8400
Depth 2: State = 0x46dd, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46dd: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4af4, Score: 14000
Depth 3: State = 0x4af4, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4af4: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x484f, Score: 16800
Depth 4: State = 0x484f, Legal Moves = [((3, 0), (3, 1))]
UCB1 values for moves at state 0x484f: [inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x53f4, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 827400, N[0x3c25, ((2, 3), (2, 4))] = 37
Updated Q[0x3c25, ((0, 0), (0, 1))] = 22400, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x46dd, ((1, 3), (2, 3))] = 22400, N[0x46dd, ((1, 3), (2, 3))] = 1
Updated Q[0x4af4, ((1, 1), (2, 1))] = 22400, N[0x4af4, ((1, 1), (2, 1))] = 1
Updated Q[0x484f, ((3, 0), (3, 1))] = 22400, N[0x484f, ((3, 0), (3, 1))] = 1

--- Simulation 42 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.69788829471, 16802.69788829471, 22362.605692265675, 16802.69788829471, 19602.69788829471]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22400.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3b16, Score: 11200
Depth 2: State = 0x3b16, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3b16: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x29e8, Score: 14000
Depth 3: State = 0x29e8, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x29e8: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x214e, Score: 16800
Depth 4: State = 0x214e, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 0), (4, 0))]
UCB1 values for moves at state 0x214e: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2147, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 847000, N[0x3c25, ((2, 3), (2, 4))] = 38
Updated Q[0x3c25, ((1, 3), (2, 3))] = 19600, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3b16, ((0, 2), (0, 3))] = 19600, N[0x3b16, ((0, 2), (0, 3))] = 1
Updated Q[0x29e8, ((1, 2), (1, 3))] = 19600, N[0x29e8, ((1, 2), (1, 3))] = 1
Updated Q[0x214e, ((1, 2), (1, 3))] = 19600, N[0x214e, ((1, 2), (1, 3))] = 1

--- Simulation 43 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.706627505187, 16802.706627505187, 22289.91275717089, 16802.706627505187, 19602.706627505187]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c5e, Score: 8400
Depth 1: State = 0x3c5e, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5e: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x36d3, Score: 11200
Depth 2: State = 0x36d3, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d3: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3674, Score: 14000
Depth 3: State = 0x3674, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3674: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3997, Score: 16800
Depth 4: State = 0x3997, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3997: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3c6c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 866600, N[0x3c25, ((2, 3), (2, 4))] = 39
Updated Q[0x3c5e, ((0, 3), (1, 3))] = 19600, N[0x3c5e, ((0, 3), (1, 3))] = 1
Updated Q[0x36d3, ((0, 3), (1, 3))] = 19600, N[0x36d3, ((0, 3), (1, 3))] = 1
Updated Q[0x3674, ((1, 3), (2, 3))] = 19600, N[0x3674, ((1, 3), (2, 3))] = 1
Updated Q[0x3997, ((0, 3), (1, 3))] = 19600, N[0x3997, ((0, 3), (1, 3))] = 1

--- Simulation 44 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.715133924277, 16802.715133924277, 22220.947589895448, 16802.715133924277, 19602.715133924277]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x49a2, Score: 8400
Depth 2: State = 0x49a2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x49a2: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a4f, Score: 11200
Depth 3: State = 0x4a4f, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a4f: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4a52, Score: 14000
Depth 4: State = 0x4a52, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a52: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x47c1, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 883400, N[0x3c25, ((2, 3), (2, 4))] = 40
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x49a2, ((1, 3), (2, 3))] = 16800, N[0x49a2, ((1, 3), (2, 3))] = 1
Updated Q[0x4a4f, ((0, 3), (1, 3))] = 16800, N[0x4a4f, ((0, 3), (1, 3))] = 1
Updated Q[0x4a52, ((0, 1), (1, 1))] = 16800, N[0x4a52, ((0, 1), (1, 1))] = 1

--- Simulation 45 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.7234191162, 16802.7234191162, 22085.43061037152, 16802.7234191162, 19602.7234191162]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c40, Score: 8400
Depth 1: State = 0x3c40, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c40: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x4acf, Score: 11200
Depth 2: State = 0x4acf, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4acf: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x443b, Score: 14000
Depth 3: State = 0x443b, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443b: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0xf65e, Score: 16800
Depth 4: State = 0xf65e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0xf65e: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x11d1, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 903000, N[0x3c25, ((2, 3), (2, 4))] = 41
Updated Q[0x3c40, ((0, 0), (1, 0))] = 19600, N[0x3c40, ((0, 0), (1, 0))] = 1
Updated Q[0x4acf, ((1, 3), (2, 3))] = 19600, N[0x4acf, ((1, 3), (2, 3))] = 1
Updated Q[0x443b, ((0, 0), (0, 1))] = 19600, N[0x443b, ((0, 0), (0, 1))] = 1
Updated Q[0xf65e, ((1, 3), (2, 3))] = 19600, N[0xf65e, ((1, 3), (2, 3))] = 1

--- Simulation 46 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.7314938184, 16802.7314938184, 22024.816831567634, 16802.7314938184, 19602.7314938184]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x491d, Score: 8400
Depth 2: State = 0x491d, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x491d: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x443b, Score: 14000
Depth 3: State = 0x443b, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443b: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x104b, Score: 16800
Depth 4: State = 0x104b, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x104b: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x117c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 922600, N[0x3c25, ((2, 3), (2, 4))] = 42
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x491d, ((1, 3), (2, 3))] = 19600, N[0x491d, ((1, 3), (2, 3))] = 1
Updated Q[0x443b, ((0, 0), (0, 1))] = 19600, N[0x443b, ((0, 0), (0, 1))] = 1
Updated Q[0x104b, ((0, 1), (0, 2))] = 19600, N[0x104b, ((0, 1), (0, 2))] = 1

--- Simulation 47 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.739368017832, 16802.739368017832, 21967.0893603286, 16802.739368017832, 19602.739368017832]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a99, Score: 8400
Depth 2: State = 0x4a99, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a99: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4913, Score: 11200
Depth 3: State = 0x4913, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4913: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1d88, Score: 16800
Depth 4: State = 0x1d88, Legal Moves = [((0, 2), (1, 2)), ((1, 0), (1, 1)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1d88: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0xf3d9, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 942200, N[0x3c25, ((2, 3), (2, 4))] = 43
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4a99, ((1, 3), (2, 3))] = 19600, N[0x4a99, ((1, 3), (2, 3))] = 1
Updated Q[0x4913, ((2, 0), (2, 1))] = 19600, N[0x4913, ((2, 0), (2, 1))] = 1
Updated Q[0x1d88, ((0, 2), (1, 2))] = 19600, N[0x1d88, ((0, 2), (1, 2))] = 1

--- Simulation 48 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.7470510187, 16802.7470510187, 21912.046828329727, 16802.7470510187, 19602.7470510187]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4913, Score: 8400
Depth 2: State = 0x4913, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4913: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x44f8, Score: 11200
Depth 3: State = 0x44f8, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x44f8: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x43c7, Score: 14000
Depth 4: State = 0x43c7, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x43c7: [inf, inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4a65, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 959000, N[0x3c25, ((2, 3), (2, 4))] = 44
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4913, ((0, 3), (1, 3))] = 16800, N[0x4913, ((0, 3), (1, 3))] = 1
Updated Q[0x44f8, ((0, 1), (0, 2))] = 16800, N[0x44f8, ((0, 1), (0, 2))] = 1
Updated Q[0x43c7, ((2, 0), (2, 1))] = 16800, N[0x43c7, ((2, 0), (2, 1))] = 1

--- Simulation 49 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.754551502763, 16802.754551502763, 21795.8698097182, 16802.754551502763, 19602.754551502763]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c6c, Score: 8400
Depth 1: State = 0x3c6c, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6c: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3919, Score: 14000
Depth 2: State = 0x3919, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3919: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3916, Score: 16800
Depth 3: State = 0x3916, Legal Moves = [((0, 1), (0, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3916: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x36be, Score: 19600
Depth 4: State = 0x36be, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x36be: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x36b1, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 981400, N[0x3c25, ((2, 3), (2, 4))] = 45
Updated Q[0x3c6c, ((1, 3), (2, 3))] = 22400, N[0x3c6c, ((1, 3), (2, 3))] = 1
Updated Q[0x3919, ((0, 3), (1, 3))] = 22400, N[0x3919, ((0, 3), (1, 3))] = 1
Updated Q[0x3916, ((0, 1), (0, 2))] = 22400, N[0x3916, ((0, 1), (0, 2))] = 1
Updated Q[0x36be, ((0, 3), (1, 3))] = 22400, N[0x36be, ((0, 3), (1, 3))] = 1

--- Simulation 50 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.761877583147, 16802.761877583147, 21809.300605290322, 16802.761877583147, 19602.761877583147]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43f3, Score: 8400
Depth 2: State = 0x43f3, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43f3: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4a87, Score: 16800
Depth 3: State = 0x4a87, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a87: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x45ab, Score: 24400
Depth 4: State = 0x45ab, Legal Moves = [((2, 0), (2, 1)), ((4, 0), (4, 1)), ((4, 1), (4, 2)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x45ab: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x10bb, Score: 27200
End of simulation with depth 5. Reward (Score): 27200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1008600, N[0x3c25, ((2, 3), (2, 4))] = 46
Updated Q[0x3c24, ((0, 0), (0, 1))] = 27200, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43f3, ((1, 2), (2, 2))] = 27200, N[0x43f3, ((1, 2), (2, 2))] = 1
Updated Q[0x4a87, ((2, 0), (2, 1))] = 27200, N[0x4a87, ((2, 0), (2, 1))] = 1
Updated Q[0x45ab, ((2, 0), (2, 1))] = 27200, N[0x45ab, ((2, 0), (2, 1))] = 1

--- Simulation 51 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.769036852525, 16802.769036852525, 21926.495228731943, 16802.769036852525, 19602.769036852525]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47c2, Score: 8400
Depth 2: State = 0x47c2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x47c2: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4858, Score: 11200
Depth 3: State = 0x4858, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x4858: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x493b, Score: 14000
Depth 4: State = 0x493b, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x493b: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4937, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1028200, N[0x3c25, ((2, 3), (2, 4))] = 47
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47c2, ((1, 3), (2, 3))] = 19600, N[0x47c2, ((1, 3), (2, 3))] = 1
Updated Q[0x4858, ((1, 1), (2, 1))] = 19600, N[0x4858, ((1, 1), (2, 1))] = 1
Updated Q[0x493b, ((1, 3), (1, 4))] = 19600, N[0x493b, ((1, 3), (1, 4))] = 1

--- Simulation 52 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.776036426298, 16802.776036426298, 21877.00067121057, 16802.776036426298, 19602.776036426298]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4570, Score: 8400
Depth 2: State = 0x4570, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4570: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4582, Score: 11200
Depth 3: State = 0x4582, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4582: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x44f8, Score: 14000
Depth 4: State = 0x44f8, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x44f8: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x47a5, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1045000, N[0x3c25, ((2, 3), (2, 4))] = 48
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4570, ((0, 2), (1, 2))] = 16800, N[0x4570, ((0, 2), (1, 2))] = 1
Updated Q[0x4582, ((1, 2), (2, 2))] = 16800, N[0x4582, ((1, 2), (2, 2))] = 1
Updated Q[0x44f8, ((0, 1), (1, 1))] = 16800, N[0x44f8, ((0, 1), (1, 1))] = 1

--- Simulation 53 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.782882981446, 16802.782882981446, 21771.23500789295, 16802.782882981446, 19602.782882981446]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46b7, Score: 11200
Depth 2: State = 0x46b7, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x46b7: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x45a5, Score: 14000
Depth 3: State = 0x45a5, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a5: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4a76, Score: 16800
Depth 4: State = 0x4a76, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a76: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x47d1, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1064600, N[0x3c25, ((2, 3), (2, 4))] = 49
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46b7, ((1, 3), (2, 3))] = 19600, N[0x46b7, ((1, 3), (2, 3))] = 1
Updated Q[0x45a5, ((0, 1), (0, 2))] = 19600, N[0x45a5, ((0, 1), (0, 2))] = 1
Updated Q[0x4a76, ((1, 1), (2, 1))] = 19600, N[0x4a76, ((1, 1), (2, 1))] = 1

--- Simulation 54 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.789582791487, 16802.789582791487, 21726.929124072252, 16802.789582791487, 19602.789582791487]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x443a, Score: 8400
Depth 2: State = 0x443a, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443a: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1161, Score: 11200
Depth 3: State = 0x1161, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (1, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1161: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x29dd, Score: 14000
Depth 4: State = 0x29dd, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x29dd: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x3719, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1081400, N[0x3c25, ((2, 3), (2, 4))] = 50
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x443a, ((0, 0), (0, 1))] = 16800, N[0x443a, ((0, 0), (0, 1))] = 1
Updated Q[0x1161, ((0, 0), (1, 0))] = 16800, N[0x1161, ((0, 0), (1, 0))] = 1
Updated Q[0x29dd, ((1, 0), (1, 1))] = 16800, N[0x29dd, ((1, 0), (1, 1))] = 1

--- Simulation 55 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.796141758077, 16802.796141758077, 21628.395434159658, 16802.796141758077, 19602.796141758077]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4aac, Score: 8400
Depth 2: State = 0x4aac, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aac: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x455e, Score: 11200
Depth 3: State = 0x455e, Legal Moves = [((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x455e: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x47f2, Score: 16800
Depth 4: State = 0x47f2, Legal Moves = [((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47f2: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4a98, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1101000, N[0x3c25, ((2, 3), (2, 4))] = 51
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4aac, ((1, 3), (2, 3))] = 19600, N[0x4aac, ((1, 3), (2, 3))] = 1
Updated Q[0x455e, ((1, 2), (1, 3))] = 19600, N[0x455e, ((1, 2), (1, 3))] = 1
Updated Q[0x47f2, ((2, 0), (2, 1))] = 19600, N[0x47f2, ((2, 0), (2, 1))] = 1

--- Simulation 56 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.802565439568, 16802.802565439568, 21588.627731774566, 16802.802565439568, 19602.802565439568]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x452b, Score: 8400
Depth 2: State = 0x452b, Legal Moves = [((0, 3), (0, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x452b: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x48f5, Score: 11200
Depth 3: State = 0x48f5, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f5: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x49a1, Score: 14000
Depth 4: State = 0x49a1, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x49a1: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4af7, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1117800, N[0x3c25, ((2, 3), (2, 4))] = 52
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x452b, ((0, 3), (0, 4))] = 16800, N[0x452b, ((0, 3), (0, 4))] = 1
Updated Q[0x48f5, ((1, 2), (2, 2))] = 16800, N[0x48f5, ((1, 2), (2, 2))] = 1
Updated Q[0x49a1, ((1, 3), (2, 3))] = 16800, N[0x49a1, ((1, 3), (2, 3))] = 1

--- Simulation 57 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.808859076893, 16802.808859076893, 21496.543364824127, 16802.808859076893, 19602.808859076893]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x368c, Score: 11200
Depth 2: State = 0x368c, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x368c: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4450, Score: 16800
Depth 3: State = 0x4450, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((3, 3), (4, 3)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x4450: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x4848, Score: 19600
Depth 4: State = 0x4848, Legal Moves = [((2, 0), (2, 1)), ((3, 2), (4, 2)), ((3, 3), (4, 3)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x4848: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4450, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1140200, N[0x3c25, ((2, 3), (2, 4))] = 53
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x368c, ((2, 0), (2, 1))] = 22400, N[0x368c, ((2, 0), (2, 1))] = 1
Updated Q[0x4450, ((0, 1), (1, 1))] = 22400, N[0x4450, ((0, 1), (1, 1))] = 1
Updated Q[0x4848, ((2, 0), (2, 1))] = 22400, N[0x4848, ((2, 0), (2, 1))] = 1

--- Simulation 58 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.815027617085, 16802.815027617085, 21513.594220950825, 16802.815027617085, 19602.815027617085]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43f9, Score: 8400
Depth 2: State = 0x43f9, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43f9: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4705, Score: 11200
Depth 3: State = 0x4705, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4705: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4705, Score: 14000
Depth 4: State = 0x4705, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4705: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4946, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1159800, N[0x3c25, ((2, 3), (2, 4))] = 54
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43f9, ((1, 3), (2, 3))] = 19600, N[0x43f9, ((1, 3), (2, 3))] = 1
Updated Q[0x4705, ((2, 0), (2, 1))] = 19600, N[0x4705, ((2, 0), (2, 1))] = 1
Updated Q[0x4705, ((1, 3), (1, 4))] = 19600, N[0x4705, ((1, 3), (1, 4))] = 1

--- Simulation 59 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.821075734657, 16802.821075734657, 21478.161677559758, 16802.821075734657, 19602.821075734657]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d2e, Score: 13300
Depth 2: State = 0x3d2e, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d2e: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3d50, Score: 16100
Depth 3: State = 0x3d50, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d50: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3957, Score: 18900
Depth 4: State = 0x3957, Legal Moves = [((1, 1), (2, 1))]
UCB1 values for moves at state 0x3957: [inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3af1, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1181500, N[0x3c25, ((2, 3), (2, 4))] = 55
Updated Q[0x3c25, ((1, 3), (2, 3))] = 21700, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3d2e, ((1, 2), (1, 3))] = 21700, N[0x3d2e, ((1, 2), (1, 3))] = 1
Updated Q[0x3d50, ((2, 0), (2, 1))] = 21700, N[0x3d50, ((2, 0), (2, 1))] = 1
Updated Q[0x3957, ((1, 1), (2, 1))] = 21700, N[0x3957, ((1, 1), (2, 1))] = 1

--- Simulation 60 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.82700785108, 16802.82700785108, 21482.199375479056, 16802.82700785108, 19602.82700785108]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46d5, Score: 8400
Depth 2: State = 0x46d5, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46d5: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4825, Score: 11200
Depth 3: State = 0x4825, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4825: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4825, Score: 14000
Depth 4: State = 0x4825, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1195500, N[0x3c25, ((2, 3), (2, 4))] = 56
Updated Q[0x3c24, ((0, 0), (0, 1))] = 14000, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46d5, ((1, 3), (2, 3))] = 14000, N[0x46d5, ((1, 3), (2, 3))] = 1
Updated Q[0x4825, ((1, 1), (2, 1))] = 14000, N[0x4825, ((1, 1), (2, 1))] = 1

--- Simulation 61 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.832828152565, 16802.832828152565, 21348.592838299377, 16802.832828152565, 19602.832828152565]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46c1, Score: 8400
Depth 2: State = 0x46c1, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46c1: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x455d, Score: 11200
Depth 3: State = 0x455d, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x455d: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x440a, Score: 14000
Depth 4: State = 0x440a, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 1), (2, 2)), ((2, 2), (2, 3))]
UCB1 values for moves at state 0x440a: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x47a6, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1212300, N[0x3c25, ((2, 3), (2, 4))] = 57
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46c1, ((1, 3), (2, 3))] = 16800, N[0x46c1, ((1, 3), (2, 3))] = 1
Updated Q[0x455d, ((1, 1), (2, 1))] = 16800, N[0x455d, ((1, 1), (2, 1))] = 1
Updated Q[0x440a, ((0, 1), (0, 2))] = 16800, N[0x440a, ((0, 1), (0, 2))] = 1

--- Simulation 62 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.838540606328, 16802.838540606328, 21268.797026519573, 16802.838540606328, 19602.838540606328]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3be4, Score: 8400
Depth 2: State = 0x3be4, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be4: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c06, Score: 11200
Depth 3: State = 0x3c06, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c06: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3c02, Score: 14000
Depth 4: State = 0x3c02, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c02: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3d3a, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1231900, N[0x3c25, ((2, 3), (2, 4))] = 58
Updated Q[0x3c25, ((0, 2), (1, 2))] = 19600, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3be4, ((1, 2), (2, 2))] = 19600, N[0x3be4, ((1, 2), (2, 2))] = 1
Updated Q[0x3c06, ((1, 3), (1, 4))] = 19600, N[0x3c06, ((1, 3), (1, 4))] = 1
Updated Q[0x3c02, ((1, 1), (2, 1))] = 19600, N[0x3c02, ((1, 1), (2, 1))] = 1

--- Simulation 63 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.844148975473, 16802.844148975473, 21240.028627470285, 16802.844148975473, 19602.844148975473]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c06, Score: 8400
Depth 2: State = 0x3c06, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c06: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c5e, Score: 14000
Depth 3: State = 0x3c5e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3865, Score: 16800
Depth 4: State = 0x3865, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x3865: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x3832, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1251500, N[0x3c25, ((2, 3), (2, 4))] = 59
Updated Q[0x3c24, ((0, 2), (1, 2))] = 19600, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c06, ((1, 2), (2, 2))] = 19600, N[0x3c06, ((1, 2), (2, 2))] = 1
Updated Q[0x3c5e, ((2, 0), (2, 1))] = 19600, N[0x3c5e, ((2, 0), (2, 1))] = 1
Updated Q[0x3865, ((4, 1), (4, 2))] = 19600, N[0x3865, ((4, 1), (4, 2))] = 1

--- Simulation 64 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.849656832626, 16802.849656832626, 21212.23540049937, 16802.849656832626, 19602.849656832626]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 21701.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x382d, Score: 8400
Depth 2: State = 0x382d, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (1, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x382d: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x21ee, Score: 11200
Depth 3: State = 0x21ee, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x21ee: [inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x1f48, Score: 14000
Depth 4: State = 0x1f48, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x1f48: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x1f47, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1268300, N[0x3c25, ((2, 3), (2, 4))] = 60
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x382d, ((0, 0), (0, 1))] = 16800, N[0x382d, ((0, 0), (0, 1))] = 1
Updated Q[0x21ee, ((0, 1), (1, 1))] = 16800, N[0x21ee, ((0, 1), (1, 1))] = 1
Updated Q[0x1f48, ((4, 1), (4, 2))] = 16800, N[0x1f48, ((4, 1), (4, 2))] = 1

--- Simulation 65 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.855067572473, 16802.855067572473, 21138.701920972017, 16802.855067572473, 19602.855067572473]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4852, Score: 8400
Depth 2: State = 0x4852, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4852: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a6a, Score: 16100
Depth 3: State = 0x4a6a, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a6a: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x47e3, Score: 29800
Depth 4: State = 0x47e3, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47e3: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x46de, Score: 32600
End of simulation with depth 5. Reward (Score): 32600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1300900, N[0x3c25, ((2, 3), (2, 4))] = 61
Updated Q[0x3c25, ((0, 0), (0, 1))] = 32600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4852, ((1, 3), (2, 3))] = 32600, N[0x4852, ((1, 3), (2, 3))] = 1
Updated Q[0x4a6a, ((2, 0), (2, 1))] = 32600, N[0x4a6a, ((2, 0), (2, 1))] = 1
Updated Q[0x47e3, ((0, 3), (1, 3))] = 32600, N[0x47e3, ((0, 3), (1, 3))] = 1

--- Simulation 66 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.86038442329, 16802.86038442329, 21326.595742893685, 16802.86038442329, 19602.86038442329]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4aed, Score: 8400
Depth 2: State = 0x4aed, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aed: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4aba, Score: 11200
Depth 3: State = 0x4aba, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aba: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x36d9, Score: 16800
Depth 4: State = 0x36d9, Legal Moves = [((0, 0), (0, 1)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d9: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0xf3c9, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1320500, N[0x3c25, ((2, 3), (2, 4))] = 62
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4aed, ((0, 3), (1, 3))] = 19600, N[0x4aed, ((0, 3), (1, 3))] = 1
Updated Q[0x4aba, ((0, 2), (1, 2))] = 19600, N[0x4aba, ((0, 2), (1, 2))] = 1
Updated Q[0x36d9, ((0, 0), (0, 1))] = 19600, N[0x36d9, ((0, 0), (0, 1))] = 1

--- Simulation 67 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.865610457542, 16802.865610457542, 21298.751029666233, 16802.865610457542, 19602.865610457542]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4965, Score: 8400
Depth 2: State = 0x4965, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4965: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x480b, Score: 11200
Depth 3: State = 0x480b, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x480b: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x482c, Score: 14000
Depth 4: State = 0x482c, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x482c: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a4e, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1337300, N[0x3c25, ((2, 3), (2, 4))] = 63
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4965, ((0, 1), (0, 2))] = 16800, N[0x4965, ((0, 1), (0, 2))] = 1
Updated Q[0x480b, ((0, 2), (1, 2))] = 16800, N[0x480b, ((0, 2), (1, 2))] = 1
Updated Q[0x482c, ((1, 3), (2, 3))] = 16800, N[0x482c, ((1, 3), (2, 3))] = 1

--- Simulation 68 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.870748601672, 16802.870748601672, 21227.345807311583, 16802.870748601672, 19602.870748601672]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47a4, Score: 8400
Depth 2: State = 0x47a4, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47a4: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x47c0, Score: 14000
Depth 3: State = 0x47c0, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c0: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x46b8, Score: 16800
Depth 4: State = 0x46b8, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46b8: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x46b8, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1356900, N[0x3c25, ((2, 3), (2, 4))] = 64
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47a4, ((1, 2), (2, 2))] = 19600, N[0x47a4, ((1, 2), (2, 2))] = 1
Updated Q[0x47c0, ((0, 3), (1, 3))] = 19600, N[0x47c0, ((0, 3), (1, 3))] = 1
Updated Q[0x46b8, ((2, 0), (2, 1))] = 19600, N[0x46b8, ((2, 0), (2, 1))] = 1

--- Simulation 69 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.875801645132, 16802.875801645132, 21201.92197520564, 16802.875801645132, 19602.875801645132]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46e3, Score: 8400
Depth 2: State = 0x46e3, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46e3: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4ad5, Score: 11200
Depth 3: State = 0x4ad5, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ad5: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4aca, Score: 14000
Depth 4: State = 0x4aca, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aca: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4aaf, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1376500, N[0x3c25, ((2, 3), (2, 4))] = 65
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46e3, ((1, 3), (2, 3))] = 19600, N[0x46e3, ((1, 3), (2, 3))] = 1
Updated Q[0x4ad5, ((0, 3), (1, 3))] = 19600, N[0x4ad5, ((0, 3), (1, 3))] = 1
Updated Q[0x4aca, ((1, 1), (2, 1))] = 19600, N[0x4aca, ((1, 1), (2, 1))] = 1

--- Simulation 70 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.88077224872, 16802.88077224872, 21177.28039274436, 16802.88077224872, 19602.88077224872]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4957, Score: 14000
Depth 2: State = 0x4957, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4957: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4a66, Score: 16800
Depth 3: State = 0x4a66, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a66: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x43c8, Score: 19600
Depth 4: State = 0x43c8, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1396100, N[0x3c25, ((2, 3), (2, 4))] = 66
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4957, ((0, 3), (1, 3))] = 19600, N[0x4957, ((0, 3), (1, 3))] = 1
Updated Q[0x4a66, ((2, 0), (2, 1))] = 19600, N[0x4a66, ((2, 0), (2, 1))] = 1

--- Simulation 71 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.885662952325, 16802.885662952325, 21153.38550358557, 16802.885662952325, 19602.885662952325]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43d4, Score: 8400
Depth 2: State = 0x43d4, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43d4: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x43fb, Score: 11200
Depth 3: State = 0x43fb, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43fb: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1412, Score: 16800
Depth 4: State = 0x1412, Legal Moves = [((0, 0), (0, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1412: [inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x50f4, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1415700, N[0x3c25, ((2, 3), (2, 4))] = 67
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43d4, ((1, 2), (2, 2))] = 19600, N[0x43d4, ((1, 2), (2, 2))] = 1
Updated Q[0x43fb, ((2, 0), (2, 1))] = 19600, N[0x43fb, ((2, 0), (2, 1))] = 1
Updated Q[0x1412, ((0, 0), (0, 1))] = 19600, N[0x1412, ((0, 0), (0, 1))] = 1

--- Simulation 72 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.890476182052, 16802.890476182052, 21130.203874137744, 16802.890476182052, 19602.890476182052]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x48f7, Score: 8400
Depth 2: State = 0x48f7, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f7: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a91, Score: 11200
Depth 3: State = 0x4a91, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a91: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4a6c, Score: 22100
Depth 4: State = 0x4a6c, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a6c: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4919, Score: 24900
End of simulation with depth 5. Reward (Score): 24900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1440600, N[0x3c25, ((2, 3), (2, 4))] = 68
Updated Q[0x3c24, ((0, 0), (0, 1))] = 24900, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x48f7, ((1, 3), (2, 3))] = 24900, N[0x48f7, ((1, 3), (2, 3))] = 1
Updated Q[0x4a91, ((0, 3), (1, 3))] = 24900, N[0x4a91, ((0, 3), (1, 3))] = 1
Updated Q[0x4a6c, ((2, 0), (2, 1))] = 24900, N[0x4a6c, ((2, 0), (2, 1))] = 1

--- Simulation 73 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.895214256885, 16802.895214256885, 21185.645213946762, 16802.895214256885, 19602.895214256885]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47ec, Score: 8400
Depth 2: State = 0x47ec, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47ec: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x47f3, Score: 11200
Depth 3: State = 0x47f3, Legal Moves = [((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x47f3: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x4834, Score: 14000
Depth 4: State = 0x4834, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4834: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x3961, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1457400, N[0x3c25, ((2, 3), (2, 4))] = 69
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47ec, ((1, 3), (1, 4))] = 16800, N[0x47ec, ((1, 3), (1, 4))] = 1
Updated Q[0x47f3, ((1, 1), (1, 2))] = 16800, N[0x47f3, ((1, 1), (1, 2))] = 1
Updated Q[0x4834, ((0, 0), (0, 1))] = 16800, N[0x4834, ((0, 0), (0, 1))] = 1

--- Simulation 74 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.899879394845, 16802.899879394845, 21122.08823488958, 16802.899879394845, 19602.899879394845]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x465a, Score: 8400
Depth 2: State = 0x465a, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x465a: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a92, Score: 11200
Depth 3: State = 0x4a92, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a92: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4a8c, Score: 14000
Depth 4: State = 0x4a8c, Legal Moves = [((0, 3), (0, 4)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x4a8c: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x4a87, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1474200, N[0x3c25, ((2, 3), (2, 4))] = 70
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x465a, ((1, 3), (2, 3))] = 16800, N[0x465a, ((1, 3), (2, 3))] = 1
Updated Q[0x4a92, ((0, 3), (1, 3))] = 16800, N[0x4a92, ((0, 3), (1, 3))] = 1
Updated Q[0x4a8c, ((0, 3), (0, 4))] = 16800, N[0x4a8c, ((0, 3), (0, 4))] = 1

--- Simulation 75 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.90447371871, 16802.90447371871, 21060.347151008365, 16802.90447371871, 19602.90447371871]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [24900.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x395d, Score: 16100
Depth 2: State = 0x395d, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x395d: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x39bc, Score: 18900
Depth 3: State = 0x39bc, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39bc: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3b0f, Score: 21700
Depth 4: State = 0x3b0f, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3b0f: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x1c7c, Score: 32100
End of simulation with depth 5. Reward (Score): 32100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1506300, N[0x3c25, ((2, 3), (2, 4))] = 71
Updated Q[0x3c24, ((1, 3), (2, 3))] = 32100, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x395d, ((0, 2), (1, 2))] = 32100, N[0x395d, ((0, 2), (1, 2))] = 1
Updated Q[0x39bc, ((1, 3), (2, 3))] = 32100, N[0x39bc, ((1, 3), (2, 3))] = 1
Updated Q[0x3b0f, ((1, 1), (2, 1))] = 32100, N[0x3b0f, ((1, 1), (2, 1))] = 1

--- Simulation 76 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.908999261348, 16802.908999261348, 21215.838192443185, 16802.908999261348, 19602.908999261348]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 25201.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c24, Score: 8400
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((1, 0), (1, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46e3, Score: 11200
Depth 3: State = 0x46e3, Legal Moves = [((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x46e3: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x4705, Score: 16800
Depth 4: State = 0x4705, Legal Moves = [((0, 1), (0, 2)), ((0, 1), (1, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4705: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x469f, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1525900, N[0x3c25, ((2, 3), (2, 4))] = 72
Updated Q[0x3c24, ((2, 0), (2, 1))] = 19600, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46e3, ((1, 0), (1, 1))] = 19600, N[0x46e3, ((1, 0), (1, 1))] = 1
Updated Q[0x4705, ((0, 1), (0, 2))] = 19600, N[0x4705, ((0, 1), (0, 2))] = 1

--- Simulation 77 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.913457970688, 16802.913457970688, 21193.398909870182, 16802.913457970688, 19602.913457970688]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x452c, Score: 8400
Depth 2: State = 0x452c, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x452c: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4580, Score: 14000
Depth 3: State = 0x4580, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4580: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4935, Score: 16800
Depth 4: State = 0x4935, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4935: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x48f1, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1545500, N[0x3c25, ((2, 3), (2, 4))] = 73
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x452c, ((1, 3), (1, 4))] = 19600, N[0x452c, ((1, 3), (1, 4))] = 1
Updated Q[0x4580, ((0, 1), (0, 2))] = 19600, N[0x4580, ((0, 1), (0, 2))] = 1
Updated Q[0x4935, ((1, 2), (1, 3))] = 19600, N[0x4935, ((1, 2), (1, 3))] = 1

--- Simulation 78 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.917851714334, 16802.917851714334, 21171.574385424323, 16802.917851714334, 19602.917851714334]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43f3, Score: 8400
Depth 2: State = 0x43f3, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43f3: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4456, Score: 16800
Depth 3: State = 0x4456, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4456: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x43a8, Score: 19600
Depth 4: State = 0x43a8, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43a8: [inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x4a43, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1570700, N[0x3c25, ((2, 3), (2, 4))] = 74
Updated Q[0x3c24, ((0, 0), (0, 1))] = 25200, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43f3, ((1, 2), (2, 2))] = 25200, N[0x43f3, ((1, 2), (2, 2))] = 1
Updated Q[0x4456, ((0, 2), (1, 2))] = 25200, N[0x4456, ((0, 2), (1, 2))] = 1
Updated Q[0x43a8, ((0, 3), (0, 4))] = 25200, N[0x43a8, ((0, 3), (0, 4))] = 1

--- Simulation 79 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.922182283895, 16802.922182283895, 21226.015372466158, 16802.922182283895, 19602.922182283895]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4832, Score: 8400
Depth 2: State = 0x4832, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4832: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x3d51, Score: 11200
Depth 3: State = 0x3d51, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d51: [inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3d5d, Score: 14000
Depth 4: State = 0x3d5d, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d5d: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3a62, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1587500, N[0x3c25, ((2, 3), (2, 4))] = 75
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4832, ((0, 0), (0, 1))] = 16800, N[0x4832, ((0, 0), (0, 1))] = 1
Updated Q[0x3d51, ((0, 4), (1, 4))] = 16800, N[0x3d51, ((0, 4), (1, 4))] = 1
Updated Q[0x3d5d, ((1, 3), (1, 4))] = 16800, N[0x3d5d, ((1, 3), (1, 4))] = 1

--- Simulation 80 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.92645139902, 16802.92645139902, 21167.004584167265, 16802.92645139902, 19602.92645139902]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x464e, Score: 8400
Depth 2: State = 0x464e, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x464e: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4ad5, Score: 11200
Depth 3: State = 0x4ad5, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ad5: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x482f, Score: 14000
Depth 4: State = 0x482f, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3))]
UCB1 values for moves at state 0x482f: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4a73, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1607100, N[0x3c25, ((2, 3), (2, 4))] = 76
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x464e, ((1, 3), (1, 4))] = 19600, N[0x464e, ((1, 3), (1, 4))] = 1
Updated Q[0x4ad5, ((1, 1), (2, 1))] = 19600, N[0x4ad5, ((1, 1), (2, 1))] = 1
Updated Q[0x482f, ((1, 2), (2, 2))] = 19600, N[0x482f, ((1, 2), (2, 2))] = 1

--- Simulation 81 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.930660711165, 16802.930660711165, 21146.388801417834, 16802.930660711165, 19602.930660711165]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4419, Score: 8400
Depth 2: State = 0x4419, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x4419: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x43b3, Score: 11200
Depth 3: State = 0x43b3, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43b3: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x499a, Score: 14000
Depth 4: State = 0x499a, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x499a: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x46d6, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1623900, N[0x3c25, ((2, 3), (2, 4))] = 77
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4419, ((0, 2), (1, 2))] = 16800, N[0x4419, ((0, 2), (1, 2))] = 1
Updated Q[0x43b3, ((1, 3), (2, 3))] = 16800, N[0x43b3, ((1, 3), (2, 3))] = 1
Updated Q[0x499a, ((0, 3), (1, 3))] = 16800, N[0x499a, ((0, 3), (1, 3))] = 1

--- Simulation 82 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.93481180711, 16802.93481180711, 21089.944842455727, 16802.93481180711, 19602.93481180711]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bbc, Score: 13300
Depth 2: State = 0x3bbc, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbc: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3917, Score: 16100
Depth 3: State = 0x3917, Legal Moves = [((0, 0), (0, 1)), ((0, 0), (1, 0)), ((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3917: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2bdb, Score: 18900
Depth 4: State = 0x2bdb, Legal Moves = [((0, 2), (0, 3)), ((1, 0), (1, 1)), ((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2bdb: [inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x5104, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1645600, N[0x3c25, ((2, 3), (2, 4))] = 78
Updated Q[0x3c24, ((1, 2), (2, 2))] = 21700, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3bbc, ((2, 0), (2, 1))] = 21700, N[0x3bbc, ((2, 0), (2, 1))] = 1
Updated Q[0x3917, ((0, 0), (0, 1))] = 21700, N[0x3917, ((0, 0), (0, 1))] = 1
Updated Q[0x2bdb, ((0, 2), (0, 3))] = 21700, N[0x2bdb, ((0, 2), (0, 3))] = 1

--- Simulation 83 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.93890621229, 16802.93890621229, 21097.768663036866, 16802.93890621229, 19602.93890621229]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3a69, Score: 14000
Depth 2: State = 0x3a69, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3a69: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x371e, Score: 19600
Depth 3: State = 0x371e, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((3, 2), (4, 2))]
UCB1 values for moves at state 0x371e: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x2017, Score: 22400
Depth 4: State = 0x2017, Legal Moves = [((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2017: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x1dcb, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1672900, N[0x3c25, ((2, 3), (2, 4))] = 79
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27300, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3a69, ((0, 1), (0, 2))] = 27300, N[0x3a69, ((0, 1), (0, 2))] = 1
Updated Q[0x371e, ((1, 0), (2, 0))] = 27300, N[0x371e, ((1, 0), (2, 0))] = 1
Updated Q[0x2017, ((1, 2), (2, 2))] = 27300, N[0x2017, ((1, 2), (2, 2))] = 1

--- Simulation 84 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.94294539387, 16802.94294539387, 21176.28047431418, 16802.94294539387, 19602.94294539387]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46b1, Score: 8400
Depth 2: State = 0x46b1, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46b1: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4413, Score: 13300
Depth 3: State = 0x4413, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4413: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4ab1, Score: 16100
Depth 4: State = 0x4ab1, Legal Moves = [((2, 0), (2, 1))]
UCB1 values for moves at state 0x4ab1: [inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x22fc, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1694600, N[0x3c25, ((2, 3), (2, 4))] = 80
Updated Q[0x3c25, ((0, 0), (0, 1))] = 21700, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x46b1, ((0, 3), (1, 3))] = 21700, N[0x46b1, ((0, 3), (1, 3))] = 1
Updated Q[0x4413, ((1, 1), (2, 1))] = 21700, N[0x4413, ((1, 1), (2, 1))] = 1
Updated Q[0x4ab1, ((2, 0), (2, 1))] = 21700, N[0x4ab1, ((2, 0), (2, 1))] = 1

--- Simulation 85 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.946930763646, 16802.946930763646, 21182.829476875624, 16802.946930763646, 19602.946930763646]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4520, Score: 8400
Depth 2: State = 0x4520, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4520: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4ab3, Score: 11200
Depth 3: State = 0x4ab3, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab3: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4ab3, Score: 14000
Depth 4: State = 0x4ab3, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab3: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4415, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1714200, N[0x3c25, ((2, 3), (2, 4))] = 81
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4520, ((1, 3), (2, 3))] = 19600, N[0x4520, ((1, 3), (2, 3))] = 1
Updated Q[0x4ab3, ((0, 3), (1, 3))] = 19600, N[0x4ab3, ((0, 3), (1, 3))] = 1
Updated Q[0x4ab3, ((1, 3), (1, 4))] = 19600, N[0x4ab3, ((1, 3), (1, 4))] = 1

--- Simulation 86 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.95086368081, 16802.95086368081, 21163.290836705277, 16802.95086368081, 19602.95086368081]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.467405903557, 21701.467405903557, 16801.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c2c, Score: 8400
Depth 2: State = 0x3c2c, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c2c: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x46c3, Score: 14000
Depth 3: State = 0x46c3, Legal Moves = [((2, 1), (2, 2)), ((2, 2), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x46c3: [inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x46d9, Score: 16800
Depth 4: State = 0x46d9, Legal Moves = [((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x46d9: [inf, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x37c3, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1736600, N[0x3c25, ((2, 3), (2, 4))] = 82
Updated Q[0x3c25, ((2, 3), (3, 3))] = 22400, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3c2c, ((2, 0), (2, 1))] = 22400, N[0x3c2c, ((2, 0), (2, 1))] = 1
Updated Q[0x46c3, ((2, 1), (2, 2))] = 22400, N[0x46c3, ((2, 1), (2, 2))] = 1
Updated Q[0x46d9, ((3, 0), (3, 1))] = 22400, N[0x46d9, ((3, 0), (3, 1))] = 1

--- Simulation 87 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.95474545446, 16802.95474545446, 21178.375077537505, 16802.95474545446, 19602.95474545446]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47af, Score: 8400
Depth 2: State = 0x47af, Legal Moves = [((0, 3), (0, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47af: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x47ac, Score: 11200
Depth 3: State = 0x47ac, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47ac: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4412, Score: 14000
Depth 4: State = 0x4412, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4412: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x148f, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1756200, N[0x3c25, ((2, 3), (2, 4))] = 83
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x47af, ((0, 3), (0, 4))] = 19600, N[0x47af, ((0, 3), (0, 4))] = 1
Updated Q[0x47ac, ((1, 3), (2, 3))] = 19600, N[0x47ac, ((1, 3), (2, 3))] = 1
Updated Q[0x4412, ((2, 0), (2, 1))] = 19600, N[0x4412, ((2, 0), (2, 1))] = 1

--- Simulation 88 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.95857734605, 16802.95857734605, 21159.360890631324, 16802.95857734605, 19602.95857734605]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43d4, Score: 8400
Depth 2: State = 0x43d4, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43d4: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x46d2, Score: 11200
Depth 3: State = 0x46d2, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46d2: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1443, Score: 16800
Depth 4: State = 0x1443, Legal Moves = [((4, 0), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1443: [inf, inf]
Selected move: ((4, 0), (4, 1))
New board state after move: 0x119e, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1775800, N[0x3c25, ((2, 3), (2, 4))] = 84
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43d4, ((1, 3), (2, 3))] = 19600, N[0x43d4, ((1, 3), (2, 3))] = 1
Updated Q[0x46d2, ((2, 0), (2, 1))] = 19600, N[0x46d2, ((2, 0), (2, 1))] = 1
Updated Q[0x1443, ((4, 0), (4, 1))] = 19600, N[0x1443, ((4, 0), (4, 1))] = 1

--- Simulation 89 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.962360571633, 16802.962360571633, 21140.79941051322, 16802.962360571633, 19602.962360571633]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c4d, Score: 8400
Depth 1: State = 0x3c4d, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4d: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x5289, Score: 11200
Depth 2: State = 0x5289, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5289: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x53d5, Score: 16800
Depth 3: State = 0x53d5, Legal Moves = [((0, 3), (0, 4)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x53d5: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x5573, Score: 19600
Depth 4: State = 0x5573, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5573: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x56c6, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1798200, N[0x3c25, ((2, 3), (2, 4))] = 85
Updated Q[0x3c4d, ((0, 0), (1, 0))] = 22400, N[0x3c4d, ((0, 0), (1, 0))] = 1
Updated Q[0x5289, ((1, 3), (2, 3))] = 22400, N[0x5289, ((1, 3), (2, 3))] = 1
Updated Q[0x53d5, ((0, 3), (0, 4))] = 22400, N[0x53d5, ((0, 3), (0, 4))] = 1
Updated Q[0x5573, ((2, 0), (2, 1))] = 22400, N[0x5573, ((2, 0), (2, 1))] = 1

--- Simulation 90 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.96609630401, 16802.96609630401, 21155.615835961642, 16802.96609630401, 19602.96609630401]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a4b, Score: 8400
Depth 2: State = 0x4a4b, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a4b: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4837, Score: 11200
Depth 3: State = 0x4837, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4837: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4592, Score: 14000
Depth 4: State = 0x4592, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x4592: [inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3043, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1815000, N[0x3c25, ((2, 3), (2, 4))] = 86
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4a4b, ((1, 3), (2, 3))] = 16800, N[0x4a4b, ((1, 3), (2, 3))] = 1
Updated Q[0x4837, ((2, 0), (2, 1))] = 16800, N[0x4837, ((2, 0), (2, 1))] = 1
Updated Q[0x4592, ((0, 1), (1, 1))] = 16800, N[0x4592, ((0, 1), (1, 1))] = 1

--- Simulation 91 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.969785674733, 16802.969785674733, 21104.971403015825, 16802.969785674733, 19602.969785674733]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4438, Score: 8400
Depth 2: State = 0x4438, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4438: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4677, Score: 22100
Depth 3: State = 0x4677, Legal Moves = [((1, 0), (1, 1)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4677: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x479e, Score: 27700
Depth 4: State = 0x479e, Legal Moves = [((0, 3), (0, 4)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x479e: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x47ae, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1845500, N[0x3c25, ((2, 3), (2, 4))] = 87
Updated Q[0x3c25, ((0, 0), (0, 1))] = 30500, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4438, ((1, 3), (2, 3))] = 30500, N[0x4438, ((1, 3), (2, 3))] = 1
Updated Q[0x4677, ((1, 0), (1, 1))] = 30500, N[0x4677, ((1, 0), (1, 1))] = 1
Updated Q[0x479e, ((0, 3), (0, 4))] = 30500, N[0x479e, ((0, 3), (0, 4))] = 1

--- Simulation 92 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.973429775993, 16802.973429775993, 21212.96246329435, 16802.973429775993, 19602.973429775993]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c6d, Score: 8400
Depth 1: State = 0x3c6d, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6d: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x399e, Score: 11200
Depth 2: State = 0x399e, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x399e: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3845, Score: 16100
Depth 3: State = 0x3845, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3845: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3845, Score: 18900
Depth 4: State = 0x3845, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1))]
UCB1 values for moves at state 0x3845: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x36f2, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1867200, N[0x3c25, ((2, 3), (2, 4))] = 88
Updated Q[0x3c6d, ((1, 3), (2, 3))] = 21700, N[0x3c6d, ((1, 3), (2, 3))] = 1
Updated Q[0x399e, ((0, 2), (1, 2))] = 21700, N[0x399e, ((0, 2), (1, 2))] = 1
Updated Q[0x3845, ((1, 1), (2, 1))] = 21700, N[0x3845, ((1, 1), (2, 1))] = 1
Updated Q[0x3845, ((1, 1), (2, 1))] = 21700, N[0x3845, ((1, 1), (2, 1))] = 1

--- Simulation 93 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.977029662434, 16802.977029662434, 21218.499170610143, 16802.977029662434, 19602.977029662434]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x456b, Score: 8400
Depth 2: State = 0x456b, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x456b: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x43d5, Score: 18900
Depth 3: State = 0x43d5, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x43d5: [inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x43b3, Score: 21700
Depth 4: State = 0x43b3, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1888900, N[0x3c25, ((2, 3), (2, 4))] = 89
Updated Q[0x3c24, ((0, 0), (0, 1))] = 21700, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x456b, ((1, 3), (2, 3))] = 21700, N[0x456b, ((1, 3), (2, 3))] = 1
Updated Q[0x43d5, ((1, 1), (1, 2))] = 21700, N[0x43d5, ((1, 1), (1, 2))] = 1

--- Simulation 94 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.980586352813, 16802.980586352813, 21223.911447139493, 16802.980586352813, 19602.980586352813]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x469f, Score: 11200
Depth 2: State = 0x469f, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x469f: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a52, Score: 16800
Depth 3: State = 0x4a52, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a52: [inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x1f0b, Score: 19600
Depth 4: State = 0x1f0b, Legal Moves = [((1, 1), (1, 2))]
UCB1 values for moves at state 0x1f0b: [inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x1eba, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1911300, N[0x3c25, ((2, 3), (2, 4))] = 90
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x469f, ((1, 3), (2, 3))] = 22400, N[0x469f, ((1, 3), (2, 3))] = 1
Updated Q[0x4a52, ((1, 0), (2, 0))] = 22400, N[0x4a52, ((1, 0), (2, 0))] = 1
Updated Q[0x1f0b, ((1, 1), (1, 2))] = 22400, N[0x1f0b, ((1, 1), (1, 2))] = 1

--- Simulation 95 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.984100831614, 16802.984100831614, 21236.981218513185, 16802.984100831614, 19602.984100831614]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37c9, Score: 11200
Depth 2: State = 0x37c9, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37c9: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3bc2, Score: 14000
Depth 3: State = 0x3bc2, Legal Moves = [((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 4), (3, 4))]
UCB1 values for moves at state 0x3bc2: [inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x11cd, Score: 16800
Depth 4: State = 0x11cd, Legal Moves = [((2, 2), (3, 2)), ((2, 4), (3, 4)), ((3, 1), (4, 1))]
UCB1 values for moves at state 0x11cd: [inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x11e6, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1930900, N[0x3c25, ((2, 3), (2, 4))] = 91
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x37c9, ((2, 0), (2, 1))] = 19600, N[0x37c9, ((2, 0), (2, 1))] = 1
Updated Q[0x3bc2, ((2, 1), (3, 1))] = 19600, N[0x3bc2, ((2, 1), (3, 1))] = 1
Updated Q[0x11cd, ((2, 2), (3, 2))] = 19600, N[0x11cd, ((2, 2), (3, 2))] = 1

--- Simulation 96 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.987574050552, 16802.987574050552, 21218.9945015389, 16802.987574050552, 19602.987574050552]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4459, Score: 11200
Depth 2: State = 0x4459, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4459: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4677, Score: 19600
Depth 3: State = 0x4677, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4677: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4524, Score: 22400
Depth 4: State = 0x4524, Legal Moves = [((4, 0), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4524: [inf, inf]
Selected move: ((4, 0), (4, 1))
New board state after move: 0x5260, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1956100, N[0x3c25, ((2, 3), (2, 4))] = 92
Updated Q[0x3c24, ((0, 0), (0, 1))] = 25200, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4459, ((1, 3), (2, 3))] = 25200, N[0x4459, ((1, 3), (2, 3))] = 1
Updated Q[0x4677, ((2, 0), (2, 1))] = 25200, N[0x4677, ((2, 0), (2, 1))] = 1
Updated Q[0x4524, ((4, 0), (4, 1))] = 25200, N[0x4524, ((4, 0), (4, 1))] = 1

--- Simulation 97 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.991006929995, 16802.991006929995, 21262.268355767857, 16802.991006929995, 19602.991006929995]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4561, Score: 8400
Depth 2: State = 0x4561, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4561: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x482c, Score: 11200
Depth 3: State = 0x482c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x482c: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4858, Score: 14000
Depth 4: State = 0x4858, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4858: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x5288, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1975700, N[0x3c25, ((2, 3), (2, 4))] = 93
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4561, ((0, 1), (0, 2))] = 19600, N[0x4561, ((0, 1), (0, 2))] = 1
Updated Q[0x482c, ((1, 2), (2, 2))] = 19600, N[0x482c, ((1, 2), (2, 2))] = 1
Updated Q[0x4858, ((2, 0), (2, 1))] = 19600, N[0x4858, ((2, 0), (2, 1))] = 1

--- Simulation 98 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.994400360316, 16802.994400360316, 21244.39652635821, 16802.994400360316, 19602.994400360316]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c61, Score: 8400
Depth 1: State = 0x3c61, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c61: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x1d51, Score: 14000
Depth 2: State = 0x1d51, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1d51: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x231d, Score: 16800
Depth 3: State = 0x231d, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x231d: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x21ca, Score: 19600
Depth 4: State = 0x21ca, Legal Moves = [((0, 0), (0, 1)), ((0, 0), (1, 0)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((2, 0), (2, 1))]
UCB1 values for moves at state 0x21ca: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1dd2, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2000900, N[0x3c25, ((2, 3), (2, 4))] = 94
Updated Q[0x3c61, ((1, 3), (2, 3))] = 25200, N[0x3c61, ((1, 3), (2, 3))] = 1
Updated Q[0x1d51, ((1, 3), (2, 3))] = 25200, N[0x1d51, ((1, 3), (2, 3))] = 1
Updated Q[0x231d, ((2, 0), (2, 1))] = 25200, N[0x231d, ((2, 0), (2, 1))] = 1
Updated Q[0x21ca, ((0, 0), (0, 1))] = 25200, N[0x21ca, ((0, 0), (0, 1))] = 1

--- Simulation 99 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.99775520318, 16802.99775520318, 21286.479407606723, 16802.99775520318, 19602.99775520318]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4956, Score: 8400
Depth 2: State = 0x4956, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4956: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4412, Score: 11200
Depth 3: State = 0x4412, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4412: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x480a, Score: 14000
Depth 4: State = 0x480a, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x480a: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x45af, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2017700, N[0x3c25, ((2, 3), (2, 4))] = 95
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4956, ((0, 3), (1, 3))] = 16800, N[0x4956, ((0, 3), (1, 3))] = 1
Updated Q[0x4412, ((2, 0), (2, 1))] = 16800, N[0x4412, ((2, 0), (2, 1))] = 1
Updated Q[0x480a, ((0, 1), (1, 1))] = 16800, N[0x480a, ((0, 1), (1, 1))] = 1

--- Simulation 100 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.001072292744, 16803.001072292744, 21239.255271941594, 16803.001072292744, 19603.001072292744]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x44f9, Score: 8400
Depth 2: State = 0x44f9, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x44f9: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x4678, Score: 11200
Depth 3: State = 0x4678, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4678: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x469a, Score: 14000
Depth 4: State = 0x469a, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x469a: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x43f4, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2034500, N[0x3c25, ((2, 3), (2, 4))] = 96
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x44f9, ((0, 1), (1, 1))] = 16800, N[0x44f9, ((0, 1), (1, 1))] = 1
Updated Q[0x4678, ((0, 1), (0, 2))] = 16800, N[0x4678, ((0, 1), (0, 2))] = 1
Updated Q[0x469a, ((1, 1), (2, 1))] = 16800, N[0x469a, ((1, 1), (2, 1))] = 1

--- Simulation 101 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.004352436805, 16803.004352436805, 21193.0149637699, 16803.004352436805, 19603.004352436805]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4aed, Score: 8400
Depth 2: State = 0x4aed, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aed: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x466d, Score: 11200
Depth 3: State = 0x466d, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x466d: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x43c7, Score: 14000
Depth 4: State = 0x43c7, Legal Moves = [((2, 1), (2, 2)), ((2, 3), (2, 4)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x43c7: [inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x5818, Score: 38100
End of simulation with depth 5. Reward (Score): 38100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2072600, N[0x3c25, ((2, 3), (2, 4))] = 97
Updated Q[0x3c24, ((0, 0), (0, 1))] = 38100, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4aed, ((0, 3), (1, 3))] = 38100, N[0x4aed, ((0, 3), (1, 3))] = 1
Updated Q[0x466d, ((2, 0), (2, 1))] = 38100, N[0x466d, ((2, 0), (2, 1))] = 1
Updated Q[0x43c7, ((2, 1), (2, 2))] = 38100, N[0x43c7, ((2, 1), (2, 2))] = 1

--- Simulation 102 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.00759641791, 16803.00759641791, 21367.31568442727, 16803.00759641791, 19603.00759641791]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43b4, Score: 8400
Depth 2: State = 0x43b4, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43b4: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x443d, Score: 11200
Depth 3: State = 0x443d, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443d: [inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x442e, Score: 14000
Depth 4: State = 0x442e, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x442e: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4a6d, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2089400, N[0x3c25, ((2, 3), (2, 4))] = 98
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x43b4, ((1, 2), (2, 2))] = 16800, N[0x43b4, ((1, 2), (2, 2))] = 1
Updated Q[0x443d, ((0, 3), (0, 4))] = 16800, N[0x443d, ((0, 3), (0, 4))] = 1
Updated Q[0x442e, ((0, 2), (1, 2))] = 16800, N[0x442e, ((0, 2), (1, 2))] = 1

--- Simulation 103 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.010804994356, 16803.010804994356, 21320.712300497926, 16803.010804994356, 19603.010804994356]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d36, Score: 11200
Depth 2: State = 0x3d36, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d36: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3db5, Score: 19600
Depth 3: State = 0x3db5, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2109000, N[0x3c25, ((2, 3), (2, 4))] = 99
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3d36, ((2, 0), (2, 1))] = 19600, N[0x3d36, ((2, 0), (2, 1))] = 1

--- Simulation 104 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.01397890121, 16803.01397890121, 21303.333219307315, 16803.01397890121, 19603.01397890121]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c07, Score: 8400
Depth 1: State = 0x3c07, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c07: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x391c, Score: 11200
Depth 2: State = 0x391c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x391c: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3975, Score: 14000
Depth 3: State = 0x3975, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3975: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3670, Score: 16800
Depth 4: State = 0x3670, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3670: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3d0e, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2128600, N[0x3c25, ((2, 3), (2, 4))] = 100
Updated Q[0x3c07, ((0, 1), (0, 2))] = 19600, N[0x3c07, ((0, 1), (0, 2))] = 1
Updated Q[0x391c, ((1, 2), (2, 2))] = 19600, N[0x391c, ((1, 2), (2, 2))] = 1
Updated Q[0x3975, ((0, 3), (1, 3))] = 19600, N[0x3975, ((0, 3), (1, 3))] = 1
Updated Q[0x3670, ((1, 1), (2, 1))] = 19600, N[0x3670, ((1, 1), (2, 1))] = 1

--- Simulation 105 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.017118851207, 16803.017118851207, 21286.30171188512, 16803.017118851207, 19603.017118851207]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x482b, Score: 8400
Depth 2: State = 0x482b, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x482b: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x47eb, Score: 11200
Depth 3: State = 0x47eb, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47eb: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x47e4, Score: 14000
Depth 4: State = 0x47e4, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47e4: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x53f0, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2151000, N[0x3c25, ((2, 3), (2, 4))] = 101
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x482b, ((1, 3), (2, 3))] = 22400, N[0x482b, ((1, 3), (2, 3))] = 1
Updated Q[0x47eb, ((0, 3), (1, 3))] = 22400, N[0x47eb, ((0, 3), (1, 3))] = 1
Updated Q[0x47e4, ((2, 0), (2, 1))] = 22400, N[0x47e4, ((2, 0), (2, 1))] = 1

--- Simulation 106 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.02022553567, 16803.02022553567, 21297.33022664338, 16803.02022553567, 19603.02022553567]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4ad6, Score: 8400
Depth 2: State = 0x4ad6, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ad6: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x47cb, Score: 19600
Depth 3: State = 0x47cb, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47cb: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4671, Score: 25200
Depth 4: State = 0x4671, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4671: [inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x47e2, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2179000, N[0x3c25, ((2, 3), (2, 4))] = 102
Updated Q[0x3c25, ((0, 0), (0, 1))] = 28000, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4ad6, ((1, 3), (2, 3))] = 28000, N[0x4ad6, ((1, 3), (2, 3))] = 1
Updated Q[0x47cb, ((0, 1), (0, 2))] = 28000, N[0x47cb, ((0, 1), (0, 2))] = 1
Updated Q[0x4671, ((0, 1), (1, 1))] = 28000, N[0x4671, ((0, 1), (1, 1))] = 1

--- Simulation 107 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.02329962532, 16803.02329962532, 21363.044449308785, 16803.02329962532, 19603.02329962532]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x466e, Score: 8400
Depth 2: State = 0x466e, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x466e: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4546, Score: 13300
Depth 3: State = 0x4546, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4546: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4698, Score: 16100
Depth 4: State = 0x4698, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4698: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x47eb, Score: 18900
End of simulation with depth 5. Reward (Score): 18900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2197900, N[0x3c25, ((2, 3), (2, 4))] = 103
Updated Q[0x3c25, ((0, 0), (0, 1))] = 18900, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x466e, ((0, 3), (1, 3))] = 18900, N[0x466e, ((0, 3), (1, 3))] = 1
Updated Q[0x4546, ((0, 1), (0, 2))] = 18900, N[0x4546, ((0, 1), (0, 2))] = 1
Updated Q[0x4698, ((1, 1), (2, 1))] = 18900, N[0x4698, ((1, 1), (2, 1))] = 1

--- Simulation 108 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.026341771107, 16803.026341771107, 21339.133145771593, 16803.026341771107, 19603.026341771107]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4923, Score: 8400
Depth 2: State = 0x4923, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4923: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4935, Score: 11200
Depth 3: State = 0x4935, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4935: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x453d, Score: 14000
Depth 4: State = 0x453d, Legal Moves = [((0, 1), (0, 2)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x453d: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4690, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2214700, N[0x3c25, ((2, 3), (2, 4))] = 104
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4923, ((1, 2), (2, 2))] = 16800, N[0x4923, ((1, 2), (2, 2))] = 1
Updated Q[0x4935, ((2, 0), (2, 1))] = 16800, N[0x4935, ((2, 0), (2, 1))] = 1
Updated Q[0x453d, ((0, 1), (0, 2))] = 16800, N[0x453d, ((0, 1), (0, 2))] = 1

--- Simulation 109 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.029352604957, 16803.029352604957, 21295.489360154737, 16803.029352604957, 19603.029352604957]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c4c, Score: 8400
Depth 1: State = 0x3c4c, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4c: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3ab6, Score: 11200
Depth 2: State = 0x3ab6, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3ab6: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3974, Score: 14000
Depth 3: State = 0x3974, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3974: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x46d2, Score: 19600
Depth 4: State = 0x46d2, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46d2: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x5430, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2237100, N[0x3c25, ((2, 3), (2, 4))] = 105
Updated Q[0x3c4c, ((0, 0), (1, 0))] = 22400, N[0x3c4c, ((0, 0), (1, 0))] = 1
Updated Q[0x3ab6, ((1, 3), (2, 3))] = 22400, N[0x3ab6, ((1, 3), (2, 3))] = 1
Updated Q[0x3974, ((0, 1), (1, 1))] = 22400, N[0x3974, ((0, 1), (1, 1))] = 1
Updated Q[0x46d2, ((1, 0), (2, 0))] = 22400, N[0x46d2, ((1, 0), (2, 0))] = 1

--- Simulation 110 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.03233274051, 16803.03233274051, 21306.010211088553, 16803.03233274051, 19603.03233274051]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4ab3, Score: 8400
Depth 2: State = 0x4ab3, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab3: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x43f6, Score: 14000
Depth 3: State = 0x43f6, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x43f6: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4942, Score: 16800
Depth 4: State = 0x4942, Legal Moves = [((0, 2), (0, 3)), ((3, 1), (3, 2)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x4942: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x1ebf, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2256700, N[0x3c25, ((2, 3), (2, 4))] = 106
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4ab3, ((1, 3), (1, 4))] = 19600, N[0x4ab3, ((1, 3), (1, 4))] = 1
Updated Q[0x43f6, ((2, 0), (2, 1))] = 19600, N[0x43f6, ((2, 0), (2, 1))] = 1
Updated Q[0x4942, ((0, 2), (0, 3))] = 19600, N[0x4942, ((0, 2), (0, 3))] = 1

--- Simulation 111 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.035282773806, 16803.035282773806, 21289.91745423408, 16803.035282773806, 19603.035282773806]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4903, Score: 19600
Depth 2: State = 0x4903, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (0, 2)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((3, 0), (3, 1)), ((3, 2), (4, 2))]
UCB1 values for moves at state 0x4903: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x57f7, Score: 22400
Depth 3: State = 0x57f7, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x57f7: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x550e, Score: 25200
Depth 4: State = 0x550e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x550e: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x54fc, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2284700, N[0x3c25, ((2, 3), (2, 4))] = 107
Updated Q[0x3c24, ((1, 3), (1, 4))] = 28000, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x4903, ((0, 0), (1, 0))] = 28000, N[0x4903, ((0, 0), (1, 0))] = 1
Updated Q[0x57f7, ((0, 1), (0, 2))] = 28000, N[0x57f7, ((0, 1), (0, 2))] = 1
Updated Q[0x550e, ((1, 3), (2, 3))] = 28000, N[0x550e, ((1, 3), (2, 3))] = 1

--- Simulation 112 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.038203283944, 16803.038203283944, 21352.630162795704, 16803.038203283944, 19603.038203283944]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22400.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c5f, Score: 13300
Depth 2: State = 0x3c5f, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5f: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4580, Score: 16100
Depth 3: State = 0x4580, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4580: [inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x39b9, Score: 18900
Depth 4: State = 0x39b9, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39b9: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c5f, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2306400, N[0x3c25, ((2, 3), (2, 4))] = 108
Updated Q[0x3c25, ((1, 3), (2, 3))] = 21700, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3c5f, ((1, 2), (1, 3))] = 21700, N[0x3c5f, ((1, 2), (1, 3))] = 1
Updated Q[0x4580, ((0, 1), (1, 1))] = 21700, N[0x4580, ((0, 1), (1, 1))] = 1
Updated Q[0x39b9, ((2, 0), (2, 1))] = 21700, N[0x39b9, ((2, 0), (2, 1))] = 1

--- Simulation 113 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.04109483373, 16803.04109483373, 21355.84818504237, 16803.04109483373, 19603.04109483373]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4584, Score: 8400
Depth 2: State = 0x4584, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4584: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x482a, Score: 11200
Depth 3: State = 0x482a, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x482a: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4570, Score: 14000
Depth 4: State = 0x4570, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (4, 2))]
UCB1 values for moves at state 0x4570: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4569, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2323200, N[0x3c25, ((2, 3), (2, 4))] = 109
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4584, ((1, 3), (2, 3))] = 16800, N[0x4584, ((1, 3), (2, 3))] = 1
Updated Q[0x482a, ((1, 2), (2, 2))] = 16800, N[0x482a, ((1, 2), (2, 2))] = 1
Updated Q[0x4570, ((1, 3), (1, 4))] = 16800, N[0x4570, ((1, 3), (1, 4))] = 1

--- Simulation 114 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.043957970254, 16803.043957970254, 21314.05302618541, 16803.043957970254, 19603.043957970254]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4afb, Score: 8400
Depth 2: State = 0x4afb, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4afb: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x495a, Score: 11200
Depth 3: State = 0x495a, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x495a: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2184, Score: 16800
Depth 4: State = 0x2184, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (0, 2)), ((1, 2), (1, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2184: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x104f, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2342800, N[0x3c25, ((2, 3), (2, 4))] = 110
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4afb, ((1, 3), (2, 3))] = 19600, N[0x4afb, ((1, 3), (2, 3))] = 1
Updated Q[0x495a, ((2, 0), (2, 1))] = 19600, N[0x495a, ((2, 0), (2, 1))] = 1
Updated Q[0x2184, ((0, 0), (0, 1))] = 19600, N[0x2184, ((0, 0), (0, 1))] = 1

--- Simulation 115 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.046793225483, 16803.046793225483, 21298.472318517586, 16803.046793225483, 19603.046793225483]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 21701.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d99, Score: 19600
Depth 2: State = 0x3d99, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d99: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x390f, Score: 25200
Depth 3: State = 0x390f, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2368000, N[0x3c25, ((2, 3), (2, 4))] = 111
Updated Q[0x3c24, ((1, 3), (2, 3))] = 25200, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3d99, ((2, 0), (2, 1))] = 25200, N[0x3d99, ((2, 0), (2, 1))] = 1

--- Simulation 116 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.0496011168, 16803.0496011168, 21333.62278866172, 16803.0496011168, 19603.0496011168]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43f3, Score: 8400
Depth 2: State = 0x43f3, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43f3: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x45a1, Score: 16100
Depth 3: State = 0x45a1, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a1: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4847, Score: 18900
Depth 4: State = 0x4847, Legal Moves = [((2, 1), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4847: [inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x53cb, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2389700, N[0x3c25, ((2, 3), (2, 4))] = 112
Updated Q[0x3c24, ((0, 0), (0, 1))] = 21700, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43f3, ((1, 3), (2, 3))] = 21700, N[0x43f3, ((1, 3), (2, 3))] = 1
Updated Q[0x45a1, ((2, 0), (2, 1))] = 21700, N[0x45a1, ((2, 0), (2, 1))] = 1
Updated Q[0x4847, ((2, 1), (3, 1))] = 21700, N[0x4847, ((2, 1), (3, 1))] = 1

--- Simulation 117 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.052382147533, 16803.052382147533, 21336.895565859595, 16803.052382147533, 19603.052382147533]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4aee, Score: 8400
Depth 2: State = 0x4aee, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aee: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x45a9, Score: 11200
Depth 3: State = 0x45a9, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a9: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x484f, Score: 14000
Depth 4: State = 0x484f, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2))]
UCB1 values for moves at state 0x484f: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x2c5e, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2412100, N[0x3c25, ((2, 3), (2, 4))] = 113
Updated Q[0x3c25, ((0, 0), (0, 1))] = 22400, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4aee, ((0, 3), (1, 3))] = 22400, N[0x4aee, ((0, 3), (1, 3))] = 1
Updated Q[0x45a9, ((2, 0), (2, 1))] = 22400, N[0x45a9, ((2, 0), (2, 1))] = 1
Updated Q[0x484f, ((1, 1), (2, 1))] = 22400, N[0x484f, ((1, 1), (2, 1))] = 1

--- Simulation 118 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.055136807445, 16803.055136807445, 21346.305102210095, 16803.055136807445, 19603.055136807445]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c6b, Score: 14000
Depth 2: State = 0x3c6b, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 0), (1, 1)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3c6b: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x20a0, Score: 16800
Depth 3: State = 0x20a0, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x20a0: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x2096, Score: 22400
Depth 4: State = 0x2096, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2096: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2096, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2437300, N[0x3c25, ((2, 3), (2, 4))] = 114
Updated Q[0x3c24, ((1, 3), (2, 3))] = 25200, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3c6b, ((0, 1), (1, 1))] = 25200, N[0x3c6b, ((0, 1), (1, 1))] = 1
Updated Q[0x20a0, ((0, 3), (1, 3))] = 25200, N[0x20a0, ((0, 3), (1, 3))] = 1
Updated Q[0x2096, ((2, 0), (2, 1))] = 25200, N[0x2096, ((2, 0), (2, 1))] = 1

--- Simulation 119 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.05786557323, 16803.05786557323, 21380.11095675447, 16803.05786557323, 19603.05786557323]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c4d, Score: 8400
Depth 1: State = 0x3c4d, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4d: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x541f, Score: 11200
Depth 2: State = 0x541f, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x541f: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x5136, Score: 14000
Depth 3: State = 0x5136, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5136: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x5136, Score: 16800
Depth 4: State = 0x5136, Legal Moves = [((2, 3), (2, 4))]
UCB1 values for moves at state 0x5136: [inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x512c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2456900, N[0x3c25, ((2, 3), (2, 4))] = 115
Updated Q[0x3c4d, ((0, 0), (1, 0))] = 19600, N[0x3c4d, ((0, 0), (1, 0))] = 1
Updated Q[0x541f, ((1, 3), (1, 4))] = 19600, N[0x541f, ((1, 3), (1, 4))] = 1
Updated Q[0x5136, ((1, 1), (2, 1))] = 19600, N[0x5136, ((1, 1), (2, 1))] = 1
Updated Q[0x5136, ((2, 3), (2, 4))] = 19600, N[0x5136, ((2, 3), (2, 4))] = 1

--- Simulation 120 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.06056890896, 16803.06056890896, 21364.633225609312, 16803.06056890896, 19603.06056890896]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c40, Score: 8400
Depth 1: State = 0x3c40, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c40: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x29b9, Score: 11200
Depth 2: State = 0x29b9, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x29b9: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x2977, Score: 14000
Depth 3: State = 0x2977, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2977: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x10b1, Score: 16800
Depth 4: State = 0x10b1, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x10b1: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x10b2, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2476500, N[0x3c25, ((2, 3), (2, 4))] = 116
Updated Q[0x3c40, ((0, 0), (1, 0))] = 19600, N[0x3c40, ((0, 0), (1, 0))] = 1
Updated Q[0x29b9, ((1, 2), (2, 2))] = 19600, N[0x29b9, ((1, 2), (2, 2))] = 1
Updated Q[0x2977, ((0, 0), (0, 1))] = 19600, N[0x2977, ((0, 0), (0, 1))] = 1
Updated Q[0x10b1, ((0, 4), (1, 4))] = 19600, N[0x10b1, ((0, 4), (1, 4))] = 1

--- Simulation 121 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.06324726652, 16803.06324726652, 21349.422346403022, 16803.06324726652, 19603.06324726652]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4430, Score: 8400
Depth 2: State = 0x4430, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4430: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x46be, Score: 11200
Depth 3: State = 0x46be, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46be: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x46b7, Score: 14000
Depth 4: State = 0x46b7, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46b7: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x44ff, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2498200, N[0x3c25, ((2, 3), (2, 4))] = 117
Updated Q[0x3c24, ((0, 0), (0, 1))] = 21700, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4430, ((1, 3), (2, 3))] = 21700, N[0x4430, ((1, 3), (2, 3))] = 1
Updated Q[0x46be, ((0, 3), (1, 3))] = 21700, N[0x46be, ((0, 3), (1, 3))] = 1
Updated Q[0x46b7, ((1, 2), (1, 3))] = 21700, N[0x46b7, ((1, 2), (1, 3))] = 1

--- Simulation 122 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.065901086036, 16803.065901086036, 21352.420194792427, 16803.065901086036, 19603.065901086036]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4815, Score: 8400
Depth 2: State = 0x4815, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4815: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4add, Score: 11200
Depth 3: State = 0x4add, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4add: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4ab1, Score: 14000
Depth 4: State = 0x4ab1, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x4ab1: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2f07, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2517800, N[0x3c25, ((2, 3), (2, 4))] = 118
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4815, ((0, 3), (1, 3))] = 19600, N[0x4815, ((0, 3), (1, 3))] = 1
Updated Q[0x4add, ((1, 2), (2, 2))] = 19600, N[0x4add, ((1, 2), (2, 2))] = 1
Updated Q[0x4ab1, ((2, 0), (2, 1))] = 19600, N[0x4ab1, ((2, 0), (2, 1))] = 1

--- Simulation 123 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.068530796274, 16803.068530796274, 21337.57061674975, 16803.068530796274, 19603.068530796274]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 19601.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4524, Score: 11200
Depth 2: State = 0x4524, Legal Moves = [((0, 3), (0, 4)), ((1, 0), (1, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4524: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x47c0, Score: 14000
Depth 3: State = 0x47c0, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x47c0: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x39a1, Score: 21700
Depth 4: State = 0x39a1, Legal Moves = [((2, 1), (2, 2)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x39a1: [inf, inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x3953, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2542300, N[0x3c25, ((2, 3), (2, 4))] = 119
Updated Q[0x3c24, ((2, 0), (2, 1))] = 24500, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x4524, ((0, 3), (0, 4))] = 24500, N[0x4524, ((0, 3), (0, 4))] = 1
Updated Q[0x47c0, ((0, 1), (1, 1))] = 24500, N[0x47c0, ((0, 1), (1, 1))] = 1
Updated Q[0x39a1, ((2, 1), (2, 2))] = 24500, N[0x39a1, ((2, 1), (2, 2))] = 1

--- Simulation 124 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.071136815015, 16803.071136815015, 21364.147076868736, 16803.071136815015, 19603.071136815015]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c1a, Score: 8400
Depth 1: State = 0x3c1a, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1a: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x397b, Score: 11200
Depth 2: State = 0x397b, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x397b: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4433, Score: 24900
Depth 3: State = 0x4433, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 24900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2567200, N[0x3c25, ((2, 3), (2, 4))] = 120
Updated Q[0x3c1a, ((0, 3), (1, 3))] = 24900, N[0x3c1a, ((0, 3), (1, 3))] = 1
Updated Q[0x397b, ((2, 0), (2, 1))] = 24900, N[0x397b, ((2, 0), (2, 1))] = 1

--- Simulation 125 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.073719549437, 16803.073719549437, 21393.613924255445, 16803.073719549437, 19603.073719549437]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x39bf, Score: 11200
Depth 2: State = 0x39bf, Legal Moves = [((0, 1), (0, 2)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39bf: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3da1, Score: 14000
Depth 3: State = 0x3da1, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3da1: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x118e, Score: 16800
Depth 4: State = 0x118e, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x118e: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0xee8d, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2586800, N[0x3c25, ((2, 3), (2, 4))] = 121
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x39bf, ((0, 1), (0, 2))] = 19600, N[0x39bf, ((0, 1), (0, 2))] = 1
Updated Q[0x3da1, ((0, 2), (1, 2))] = 19600, N[0x3da1, ((0, 2), (1, 2))] = 1
Updated Q[0x118e, ((2, 0), (2, 1))] = 19600, N[0x118e, ((2, 0), (2, 1))] = 1

--- Simulation 126 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.076279396464, 16803.076279396464, 21378.79205845753, 16803.076279396464, 19603.076279396464]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x453c, Score: 8400
Depth 2: State = 0x453c, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x453c: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x454a, Score: 14000
Depth 3: State = 0x454a, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x454a: [inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x454b, Score: 19600
Depth 4: State = 0x454b, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x454b: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x454b, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2617300, N[0x3c25, ((2, 3), (2, 4))] = 122
Updated Q[0x3c24, ((0, 0), (0, 1))] = 30500, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x453c, ((0, 3), (1, 3))] = 30500, N[0x453c, ((0, 3), (1, 3))] = 1
Updated Q[0x454a, ((0, 3), (0, 4))] = 30500, N[0x454a, ((0, 3), (0, 4))] = 1
Updated Q[0x454b, ((2, 0), (2, 1))] = 30500, N[0x454b, ((2, 0), (2, 1))] = 1

--- Simulation 127 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.078816743106, 16803.078816743106, 21453.557431495356, 16803.078816743106, 19603.078816743106]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4540, Score: 8400
Depth 2: State = 0x4540, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4540: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x47a1, Score: 14000
Depth 3: State = 0x47a1, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47a1: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x467e, Score: 16800
Depth 4: State = 0x467e, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x467e: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4655, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2636900, N[0x3c25, ((2, 3), (2, 4))] = 123
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4540, ((1, 3), (2, 3))] = 19600, N[0x4540, ((1, 3), (2, 3))] = 1
Updated Q[0x47a1, ((1, 2), (2, 2))] = 19600, N[0x47a1, ((1, 2), (2, 2))] = 1
Updated Q[0x467e, ((0, 3), (1, 3))] = 19600, N[0x467e, ((0, 3), (1, 3))] = 1

--- Simulation 128 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.081331966772, 16803.081331966772, 21438.4892164607, 16803.081331966772, 19603.081331966772]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1c1d, Score: 11200
Depth 2: State = 0x1c1d, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 4), (2, 4)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1c1d: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x1c61, Score: 14000
Depth 3: State = 0x1c61, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 4), (2, 4)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1c61: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x1fe9, Score: 16800
Depth 4: State = 0x1fe9, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 2), (2, 2)), ((1, 4), (2, 4)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1fe9: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x2074, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2664600, N[0x3c25, ((2, 3), (2, 4))] = 124
Updated Q[0x3c24, ((2, 0), (2, 1))] = 27700, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x1c1d, ((0, 1), (1, 1))] = 27700, N[0x1c1d, ((0, 1), (1, 1))] = 1
Updated Q[0x1c61, ((1, 0), (1, 1))] = 27700, N[0x1c61, ((1, 0), (1, 1))] = 1
Updated Q[0x1fe9, ((0, 1), (1, 1))] = 27700, N[0x1fe9, ((0, 1), (1, 1))] = 1

--- Simulation 129 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.083825435606, 16803.083825435606, 21488.986613118737, 16803.083825435606, 19603.083825435606]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c6c, Score: 14000
Depth 1: State = 0x3c6c, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6c: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3975, Score: 16800
Depth 2: State = 0x3975, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3975: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4957, Score: 19600
Depth 3: State = 0x4957, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4957: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4804, Score: 22400
Depth 4: State = 0x4804, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (1, 1)), ((0, 3), (0, 4)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 2), (2, 3)), ((2, 3), (2, 4))]
UCB1 values for moves at state 0x4804: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x228f, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2689800, N[0x3c25, ((2, 3), (2, 4))] = 125
Updated Q[0x3c6c, ((1, 3), (2, 3))] = 25200, N[0x3c6c, ((1, 3), (2, 3))] = 1
Updated Q[0x3975, ((1, 2), (1, 3))] = 25200, N[0x3975, ((1, 2), (1, 3))] = 1
Updated Q[0x4957, ((1, 1), (2, 1))] = 25200, N[0x4957, ((1, 1), (2, 1))] = 1
Updated Q[0x4804, ((0, 0), (1, 0))] = 25200, N[0x4804, ((0, 0), (1, 0))] = 1

--- Simulation 130 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.086297508755, 16803.086297508755, 21518.676046841138, 16803.086297508755, 19603.086297508755]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47ca, Score: 8400
Depth 2: State = 0x47ca, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47ca: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x482f, Score: 14000
Depth 3: State = 0x482f, Legal Moves = [((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x482f: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x4830, Score: 16800
Depth 4: State = 0x4830, Legal Moves = [((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x4830: [inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x4830, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2709400, N[0x3c25, ((2, 3), (2, 4))] = 126
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47ca, ((1, 2), (2, 2))] = 19600, N[0x47ca, ((1, 2), (2, 2))] = 1
Updated Q[0x482f, ((0, 4), (1, 4))] = 19600, N[0x482f, ((0, 4), (1, 4))] = 1
Updated Q[0x4830, ((0, 4), (1, 4))] = 19600, N[0x4830, ((0, 4), (1, 4))] = 1

--- Simulation 131 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.088748536687, 16803.088748536687, 21503.44977076456, 16803.088748536687, 19603.088748536687]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c0a, Score: 8400
Depth 1: State = 0x3c0a, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c0a: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3be0, Score: 11200
Depth 2: State = 0x3be0, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be0: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3bdd, Score: 14000
Depth 3: State = 0x3bdd, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bdd: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3bde, Score: 16800
Depth 4: State = 0x3bde, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bde: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3be7, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2729000, N[0x3c25, ((2, 3), (2, 4))] = 127
Updated Q[0x3c0a, ((1, 2), (2, 2))] = 19600, N[0x3c0a, ((1, 2), (2, 2))] = 1
Updated Q[0x3be0, ((0, 3), (1, 3))] = 19600, N[0x3be0, ((0, 3), (1, 3))] = 1
Updated Q[0x3bdd, ((1, 3), (1, 4))] = 19600, N[0x3bdd, ((1, 3), (1, 4))] = 1
Updated Q[0x3bde, ((0, 3), (0, 4))] = 19600, N[0x3bde, ((0, 3), (0, 4))] = 1

--- Simulation 132 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.09117886145, 16803.09117886145, 21488.4632741464, 16803.09117886145, 19603.09117886145]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3af6, Score: 16800
Depth 2: State = 0x3af6, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3af6: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3d4b, Score: 19600
Depth 3: State = 0x3d4b, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d4b: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x36cf, Score: 22400
Depth 4: State = 0x36cf, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36cf: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36cf, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2754200, N[0x3c25, ((2, 3), (2, 4))] = 128
Updated Q[0x3c24, ((1, 3), (2, 3))] = 25200, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3af6, ((0, 1), (1, 1))] = 25200, N[0x3af6, ((0, 1), (1, 1))] = 1
Updated Q[0x3d4b, ((0, 0), (1, 0))] = 25200, N[0x3d4b, ((0, 0), (1, 0))] = 1
Updated Q[0x36cf, ((2, 0), (2, 1))] = 25200, N[0x36cf, ((2, 0), (2, 1))] = 1

--- Simulation 133 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.093588816937, 16803.093588816937, 21517.460937203832, 16803.093588816937, 19603.093588816937]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x53ce, Score: 13300
Depth 2: State = 0x53ce, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x53ce: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x5524, Score: 16100
Depth 3: State = 0x5524, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5524: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x5103, Score: 18900
Depth 4: State = 0x5103, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5103: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x50e4, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2778700, N[0x3c25, ((2, 3), (2, 4))] = 129
Updated Q[0x3c24, ((0, 0), (0, 1))] = 24500, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x53ce, ((1, 3), (2, 3))] = 24500, N[0x53ce, ((1, 3), (2, 3))] = 1
Updated Q[0x5524, ((0, 1), (1, 1))] = 24500, N[0x5524, ((0, 1), (1, 1))] = 1
Updated Q[0x5103, ((0, 3), (1, 3))] = 24500, N[0x5103, ((0, 3), (1, 3))] = 1

--- Simulation 134 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.095978729143, 16803.095978729143, 21540.582663247187, 16803.095978729143, 19603.095978729143]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46f4, Score: 8400
Depth 2: State = 0x46f4, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46f4: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x464e, Score: 11200
Depth 3: State = 0x464e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x464e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x464e, Score: 14000
Depth 4: State = 0x464e, Legal Moves = [((2, 1), (2, 2)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x464e: [inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x46f5, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2795500, N[0x3c25, ((2, 3), (2, 4))] = 130
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46f4, ((0, 2), (1, 2))] = 16800, N[0x46f4, ((0, 2), (1, 2))] = 1
Updated Q[0x464e, ((2, 0), (2, 1))] = 16800, N[0x464e, ((2, 0), (2, 1))] = 1
Updated Q[0x464e, ((2, 1), (2, 2))] = 16800, N[0x464e, ((2, 1), (2, 2))] = 1

--- Simulation 135 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.098348916425, 16803.098348916425, 21504.11789702253, 16803.098348916425, 19603.098348916425]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c65, Score: 8400
Depth 2: State = 0x3c65, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c65: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3917, Score: 19300
Depth 3: State = 0x3917, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3917: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3917, Score: 22100
Depth 4: State = 0x3917, Legal Moves = [((1, 1), (2, 1))]
UCB1 values for moves at state 0x3917: [inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x1dfc, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2823200, N[0x3c25, ((2, 3), (2, 4))] = 131
Updated Q[0x3c24, ((0, 2), (1, 2))] = 27700, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c65, ((1, 3), (1, 4))] = 27700, N[0x3c65, ((1, 3), (1, 4))] = 1
Updated Q[0x3917, ((2, 0), (2, 1))] = 27700, N[0x3917, ((2, 0), (2, 1))] = 1
Updated Q[0x3917, ((1, 1), (2, 1))] = 27700, N[0x3917, ((1, 1), (2, 1))] = 1

--- Simulation 136 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.100699689705, 16803.100699689705, 21551.415947557678, 16803.100699689705, 19603.100699689705]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43d9, Score: 8400
Depth 2: State = 0x43d9, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43d9: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x45a2, Score: 11200
Depth 3: State = 0x45a2, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a2: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4aaa, Score: 14000
Depth 4: State = 0x4aaa, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aaa: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x451b, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2842800, N[0x3c25, ((2, 3), (2, 4))] = 132
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x43d9, ((1, 3), (2, 3))] = 19600, N[0x43d9, ((1, 3), (2, 3))] = 1
Updated Q[0x45a2, ((0, 1), (0, 2))] = 19600, N[0x45a2, ((0, 1), (0, 2))] = 1
Updated Q[0x4aaa, ((0, 3), (1, 3))] = 19600, N[0x4aaa, ((0, 3), (1, 3))] = 1

--- Simulation 137 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.103031352734, 16803.103031352734, 21536.633720575755, 16803.103031352734, 19603.103031352734]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bdb, Score: 8400
Depth 1: State = 0x3bdb, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bdb: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3871, Score: 11200
Depth 2: State = 0x3871, Legal Moves = [((0, 1), (0, 2)), ((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3871: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3d78, Score: 14000
Depth 3: State = 0x3d78, Legal Moves = [((0, 0), (0, 1)), ((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d78: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x5812, Score: 16800
Depth 4: State = 0x5812, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5812: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3080, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2862400, N[0x3c25, ((2, 3), (2, 4))] = 133
Updated Q[0x3bdb, ((1, 3), (2, 3))] = 19600, N[0x3bdb, ((1, 3), (2, 3))] = 1
Updated Q[0x3871, ((0, 1), (0, 2))] = 19600, N[0x3871, ((0, 1), (0, 2))] = 1
Updated Q[0x3d78, ((0, 0), (0, 1))] = 19600, N[0x3d78, ((0, 0), (0, 1))] = 1
Updated Q[0x5812, ((0, 2), (1, 2))] = 19600, N[0x5812, ((0, 2), (1, 2))] = 1

--- Simulation 138 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.10534420228, 16803.10534420228, 21522.073778769856, 16803.10534420228, 19603.10534420228]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47a1, Score: 8400
Depth 2: State = 0x47a1, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x47a1: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4811, Score: 11200
Depth 3: State = 0x4811, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4811: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x47a1, Score: 14000
Depth 4: State = 0x47a1, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47a1: [inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x4807, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2879200, N[0x3c25, ((2, 3), (2, 4))] = 134
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47a1, ((1, 2), (2, 2))] = 16800, N[0x47a1, ((1, 2), (2, 2))] = 1
Updated Q[0x4811, ((1, 2), (2, 2))] = 16800, N[0x4811, ((1, 2), (2, 2))] = 1
Updated Q[0x47a1, ((1, 1), (1, 2))] = 16800, N[0x47a1, ((1, 1), (1, 2))] = 1

--- Simulation 139 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.107638528352, 16803.107638528352, 21486.835623259383, 16803.107638528352, 19603.107638528352]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4653, Score: 8400
Depth 2: State = 0x4653, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4653: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4588, Score: 11200
Depth 3: State = 0x4588, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4588: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4588, Score: 14000
Depth 4: State = 0x4588, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (0, 2)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x4588: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2079, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2901600, N[0x3c25, ((2, 3), (2, 4))] = 135
Updated Q[0x3c25, ((0, 0), (0, 1))] = 22400, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4653, ((1, 3), (2, 3))] = 22400, N[0x4653, ((1, 3), (2, 3))] = 1
Updated Q[0x4588, ((1, 1), (2, 1))] = 22400, N[0x4588, ((1, 1), (2, 1))] = 1
Updated Q[0x4588, ((0, 0), (0, 1))] = 22400, N[0x4588, ((0, 0), (0, 1))] = 1

--- Simulation 140 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.10991461441, 16803.10991461441, 21493.60099216688, 16803.10991461441, 19603.10991461441]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4935, Score: 8400
Depth 2: State = 0x4935, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4935: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4939, Score: 11200
Depth 3: State = 0x4939, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4939: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4540, Score: 14000
Depth 4: State = 0x4540, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2915600, N[0x3c25, ((2, 3), (2, 4))] = 136
Updated Q[0x3c25, ((0, 0), (0, 1))] = 14000, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4935, ((0, 3), (1, 3))] = 14000, N[0x4935, ((0, 3), (1, 3))] = 1
Updated Q[0x4939, ((2, 0), (2, 1))] = 14000, N[0x4939, ((2, 0), (2, 1))] = 1

--- Simulation 141 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.112172737543, 16803.112172737543, 21438.50216072825, 16803.112172737543, 19603.112172737543]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4693, Score: 8400
Depth 2: State = 0x4693, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4693: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4656, Score: 11200
Depth 3: State = 0x4656, Legal Moves = [((0, 3), (1, 3)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4656: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4656, Score: 14000
Depth 4: State = 0x4656, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4656: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x2d75, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2932400, N[0x3c25, ((2, 3), (2, 4))] = 137
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4693, ((1, 3), (2, 3))] = 16800, N[0x4693, ((1, 3), (2, 3))] = 1
Updated Q[0x4656, ((0, 3), (1, 3))] = 16800, N[0x4656, ((0, 3), (1, 3))] = 1
Updated Q[0x4656, ((1, 0), (2, 0))] = 16800, N[0x4656, ((1, 0), (2, 0))] = 1

--- Simulation 142 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.114413168663, 16803.114413168663, 21404.64564431779, 16803.114413168663, 19603.114413168663]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bfe, Score: 8400
Depth 1: State = 0x3bfe, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bfe: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3701, Score: 11200
Depth 2: State = 0x3701, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3701: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x54ea, Score: 14000
Depth 3: State = 0x54ea, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x54ea: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x563d, Score: 16800
Depth 4: State = 0x563d, Legal Moves = [((3, 3), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x563d: [inf, inf]
Selected move: ((3, 3), (3, 4))
New board state after move: 0x56a0, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2954800, N[0x3c25, ((2, 3), (2, 4))] = 138
Updated Q[0x3bfe, ((1, 3), (1, 4))] = 22400, N[0x3bfe, ((1, 3), (1, 4))] = 1
Updated Q[0x3701, ((0, 2), (1, 2))] = 22400, N[0x3701, ((0, 2), (1, 2))] = 1
Updated Q[0x54ea, ((2, 0), (2, 1))] = 22400, N[0x54ea, ((2, 0), (2, 1))] = 1
Updated Q[0x563d, ((3, 3), (3, 4))] = 22400, N[0x563d, ((3, 3), (3, 4))] = 1

--- Simulation 143 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.116636172686, 16803.116636172686, 21411.859508588153, 16803.116636172686, 19603.116636172686]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x469c, Score: 8400
Depth 2: State = 0x469c, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x469c: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x1c34, Score: 14000
Depth 3: State = 0x1c34, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1c34: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x1d43, Score: 16800
Depth 4: State = 0x1d43, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 0), (2, 0)), ((2, 0), (2, 1)), ((2, 4), (3, 4))]
UCB1 values for moves at state 0x1d43: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x1f03, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2974400, N[0x3c25, ((2, 3), (2, 4))] = 139
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x469c, ((1, 3), (2, 3))] = 19600, N[0x469c, ((1, 3), (2, 3))] = 1
Updated Q[0x1c34, ((1, 0), (2, 0))] = 19600, N[0x1c34, ((1, 0), (2, 0))] = 1
Updated Q[0x1d43, ((0, 1), (1, 1))] = 19600, N[0x1d43, ((0, 1), (1, 1))] = 1

--- Simulation 144 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.118842008713, 16803.118842008713, 21398.825687805656, 16803.118842008713, 19603.118842008713]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c1e, Score: 8400
Depth 1: State = 0x3c1e, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1e: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3c40, Score: 11200
Depth 2: State = 0x3c40, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c40: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x53ad, Score: 14000
Depth 3: State = 0x53ad, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x53ad: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5413, Score: 16800
Depth 4: State = 0x5413, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x5413: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x580c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2994000, N[0x3c25, ((2, 3), (2, 4))] = 140
Updated Q[0x3c1e, ((0, 3), (1, 3))] = 19600, N[0x3c1e, ((0, 3), (1, 3))] = 1
Updated Q[0x3c40, ((0, 0), (1, 0))] = 19600, N[0x3c40, ((0, 0), (1, 0))] = 1
Updated Q[0x53ad, ((1, 2), (1, 3))] = 19600, N[0x53ad, ((1, 2), (1, 3))] = 1
Updated Q[0x5413, ((2, 0), (2, 1))] = 19600, N[0x5413, ((2, 0), (2, 1))] = 1

--- Simulation 145 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.121030930186, 16803.121030930186, 21385.978060971265, 16803.121030930186, 19603.121030930186]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.467405903557, 25201.467405903557, 19601.467405903557, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c27, Score: 10500
Depth 2: State = 0x3c27, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c27: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c27, Score: 13300
Depth 3: State = 0x3c27, Legal Moves = [((2, 1), (3, 1)), ((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c27: [inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x3d7a, Score: 16100
Depth 4: State = 0x3d7a, Legal Moves = [((0, 1), (1, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d7a: [inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x1189, Score: 18900
End of simulation with depth 5. Reward (Score): 18900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3012900, N[0x3c25, ((2, 3), (2, 4))] = 141
Updated Q[0x3c24, ((2, 3), (2, 4))] = 18900, N[0x3c24, ((2, 3), (2, 4))] = 1
Updated Q[0x3c27, ((2, 0), (2, 1))] = 18900, N[0x3c27, ((2, 0), (2, 1))] = 1
Updated Q[0x3c27, ((2, 1), (3, 1))] = 18900, N[0x3c27, ((2, 1), (3, 1))] = 1
Updated Q[0x3d7a, ((0, 1), (1, 1))] = 18900, N[0x3d7a, ((0, 1), (1, 1))] = 1

--- Simulation 146 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.123203185056, 16803.123203185056, 21368.348127539197, 16803.123203185056, 19603.123203185056]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x484c, Score: 8400
Depth 2: State = 0x484c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x484c: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x47a9, Score: 11200
Depth 3: State = 0x47a9, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47a9: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x47ac, Score: 14000
Depth 4: State = 0x47ac, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47ac: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x45ac, Score: 24900
End of simulation with depth 5. Reward (Score): 24900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3037800, N[0x3c25, ((2, 3), (2, 4))] = 142
Updated Q[0x3c25, ((0, 0), (0, 1))] = 24900, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x484c, ((1, 2), (2, 2))] = 24900, N[0x484c, ((1, 2), (2, 2))] = 1
Updated Q[0x47a9, ((0, 3), (1, 3))] = 24900, N[0x47a9, ((0, 3), (1, 3))] = 1
Updated Q[0x47ac, ((1, 3), (2, 3))] = 24900, N[0x47ac, ((1, 3), (2, 3))] = 1

--- Simulation 147 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.125359015947, 16803.125359015947, 21393.22002078129, 16803.125359015947, 19603.125359015947]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 27701.16557645562, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3c1a, Score: 8400
Depth 2: State = 0x3c1a, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1a: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3d8f, Score: 11200
Depth 3: State = 0x3d8f, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d8f: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x368b, Score: 14000
Depth 4: State = 0x368b, Legal Moves = [((1, 0), (1, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x368b: [inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x3869, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3060200, N[0x3c25, ((2, 3), (2, 4))] = 143
Updated Q[0x3c24, ((0, 3), (0, 4))] = 22400, N[0x3c24, ((0, 3), (0, 4))] = 1
Updated Q[0x3c1a, ((0, 3), (1, 3))] = 22400, N[0x3c1a, ((0, 3), (1, 3))] = 1
Updated Q[0x3d8f, ((0, 2), (1, 2))] = 22400, N[0x3d8f, ((0, 2), (1, 2))] = 1
Updated Q[0x368b, ((1, 0), (1, 1))] = 22400, N[0x368b, ((1, 0), (1, 1))] = 1

--- Simulation 148 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.127498660284, 16803.127498660284, 21400.2615345766, 16803.127498660284, 19603.127498660284]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x366c, Score: 18200
Depth 2: State = 0x366c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x366c: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x368e, Score: 21000
Depth 3: State = 0x368e, Legal Moves = [((0, 2), (1, 2)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x368e: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x371a, Score: 23800
Depth 4: State = 0x371a, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x371a: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x386d, Score: 26600
End of simulation with depth 5. Reward (Score): 26600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3086800, N[0x3c25, ((2, 3), (2, 4))] = 144
Updated Q[0x3c24, ((1, 3), (2, 3))] = 26600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x366c, ((1, 2), (2, 2))] = 26600, N[0x366c, ((1, 2), (2, 2))] = 1
Updated Q[0x368e, ((0, 2), (1, 2))] = 26600, N[0x368e, ((0, 2), (1, 2))] = 1
Updated Q[0x371a, ((2, 0), (2, 1))] = 26600, N[0x371a, ((2, 0), (2, 1))] = 1

--- Simulation 149 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.129622350472, 16803.129622350472, 21436.37191297365, 16803.129622350472, 19603.129622350472]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc1, Score: 8400
Depth 1: State = 0x3bc1, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc1: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d7a, Score: 11200
Depth 2: State = 0x3d7a, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d7a: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2c67, Score: 14000
Depth 3: State = 0x2c67, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2c67: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2c5e, Score: 22400
Depth 4: State = 0x2c5e, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2c5e: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x46d6, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3112000, N[0x3c25, ((2, 3), (2, 4))] = 145
Updated Q[0x3bc1, ((1, 3), (2, 3))] = 25200, N[0x3bc1, ((1, 3), (2, 3))] = 1
Updated Q[0x3d7a, ((1, 2), (1, 3))] = 25200, N[0x3d7a, ((1, 2), (1, 3))] = 1
Updated Q[0x2c67, ((1, 2), (1, 3))] = 25200, N[0x2c67, ((1, 2), (1, 3))] = 1
Updated Q[0x2c5e, ((1, 0), (1, 1))] = 25200, N[0x2c5e, ((1, 0), (1, 1))] = 1

--- Simulation 150 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.131730314006, 16803.131730314006, 21462.329041563942, 16803.131730314006, 19603.131730314006]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x39bd, Score: 11200
Depth 2: State = 0x39bd, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39bd: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4584, Score: 14000
Depth 3: State = 0x4584, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4584: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x46d7, Score: 16800
Depth 4: State = 0x46d7, Legal Moves = [((1, 1), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x46d7: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4431, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3134400, N[0x3c25, ((2, 3), (2, 4))] = 146
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x39bd, ((1, 2), (1, 3))] = 22400, N[0x39bd, ((1, 2), (1, 3))] = 1
Updated Q[0x4584, ((1, 1), (2, 1))] = 22400, N[0x4584, ((1, 1), (2, 1))] = 1
Updated Q[0x46d7, ((1, 1), (2, 1))] = 22400, N[0x46d7, ((1, 1), (2, 1))] = 1

--- Simulation 151 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.133822773616, 16803.133822773616, 21468.75250770306, 16803.133822773616, 19603.133822773616]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47c4, Score: 8400
Depth 2: State = 0x47c4, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c4: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4852, Score: 11200
Depth 3: State = 0x4852, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4852: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4852, Score: 14000
Depth 4: State = 0x4852, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x4852: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x49a5, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3151200, N[0x3c25, ((2, 3), (2, 4))] = 147
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x47c4, ((1, 3), (2, 3))] = 16800, N[0x47c4, ((1, 3), (2, 3))] = 1
Updated Q[0x4852, ((0, 3), (1, 3))] = 16800, N[0x4852, ((0, 3), (1, 3))] = 1
Updated Q[0x4852, ((2, 0), (2, 1))] = 16800, N[0x4852, ((2, 0), (2, 1))] = 1

--- Simulation 152 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.135899947407, 16803.135899947407, 21436.99333854595, 16803.135899947407, 19603.135899947407]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47cb, Score: 8400
Depth 2: State = 0x47cb, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47cb: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4658, Score: 24900
Depth 3: State = 0x4658, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4658: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3720, Score: 30500
Depth 4: State = 0x3720, Legal Moves = [((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3720: [inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x368b, Score: 33300
End of simulation with depth 5. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3184500, N[0x3c25, ((2, 3), (2, 4))] = 148
Updated Q[0x3c25, ((0, 0), (0, 1))] = 33300, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x47cb, ((1, 3), (2, 3))] = 33300, N[0x47cb, ((1, 3), (2, 3))] = 1
Updated Q[0x4658, ((1, 1), (2, 1))] = 33300, N[0x4658, ((1, 1), (2, 1))] = 1
Updated Q[0x3720, ((2, 2), (3, 2))] = 33300, N[0x3720, ((2, 2), (3, 2))] = 1

--- Simulation 153 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.137962048982, 16803.137962048982, 21517.149830783423, 16803.137962048982, 19603.137962048982]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d55, Score: 13300
Depth 2: State = 0x3d55, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d55: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2c8c, Score: 29800
Depth 3: State = 0x2c8c, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 29800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3214300, N[0x3c25, ((2, 3), (2, 4))] = 149
Updated Q[0x3c24, ((1, 3), (2, 3))] = 29800, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3d55, ((2, 0), (2, 1))] = 29800, N[0x3d55, ((2, 0), (2, 1))] = 1

--- Simulation 154 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.140009287556, 16803.140009287556, 21572.740461060417, 16803.140009287556, 19603.140009287556]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22400.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3af4, Score: 11200
Depth 2: State = 0x3af4, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3af4: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x5287, Score: 14000
Depth 3: State = 0x5287, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5287: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x567f, Score: 16800
Depth 4: State = 0x567f, Legal Moves = [((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x567f: [inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x5816, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3233900, N[0x3c25, ((2, 3), (2, 4))] = 150
Updated Q[0x3c25, ((1, 3), (2, 3))] = 19600, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3af4, ((0, 2), (0, 3))] = 19600, N[0x3af4, ((0, 2), (0, 3))] = 1
Updated Q[0x5287, ((2, 0), (2, 1))] = 19600, N[0x5287, ((2, 0), (2, 1))] = 1
Updated Q[0x567f, ((2, 1), (3, 1))] = 19600, N[0x567f, ((2, 1), (3, 1))] = 1

--- Simulation 155 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.142041868075, 16803.142041868075, 21559.589879977575, 16803.142041868075, 19603.142041868075]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x442d, Score: 8400
Depth 2: State = 0x442d, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x442d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4509, Score: 11200
Depth 3: State = 0x4509, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x4509: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x47af, Score: 14000
Depth 4: State = 0x47af, Legal Moves = [((2, 1), (3, 1)), ((3, 4), (4, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x47af: [inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x3855, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3250700, N[0x3c25, ((2, 3), (2, 4))] = 151
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x442d, ((0, 2), (1, 2))] = 16800, N[0x442d, ((0, 2), (1, 2))] = 1
Updated Q[0x4509, ((2, 0), (2, 1))] = 16800, N[0x4509, ((2, 0), (2, 1))] = 1
Updated Q[0x47af, ((2, 1), (3, 1))] = 16800, N[0x47af, ((2, 1), (3, 1))] = 1

--- Simulation 156 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.144059991344, 16803.144059991344, 21528.070429509888, 16803.144059991344, 19603.144059991344]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4837, Score: 8400
Depth 2: State = 0x4837, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4837: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x45a9, Score: 11200
Depth 3: State = 0x45a9, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a9: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x456b, Score: 14000
Depth 4: State = 0x456b, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x456b: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1f4d, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3270300, N[0x3c25, ((2, 3), (2, 4))] = 152
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4837, ((1, 3), (1, 4))] = 19600, N[0x4837, ((1, 3), (1, 4))] = 1
Updated Q[0x45a9, ((0, 3), (1, 3))] = 19600, N[0x45a9, ((0, 3), (1, 3))] = 1
Updated Q[0x456b, ((2, 0), (2, 1))] = 19600, N[0x456b, ((2, 0), (2, 1))] = 1

--- Simulation 157 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.14606385412, 16803.14606385412, 21515.38675842206, 16803.14606385412, 19603.14606385412]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47f2, Score: 8400
Depth 2: State = 0x47f2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47f2: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x45a5, Score: 11200
Depth 3: State = 0x45a5, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a5: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4ad6, Score: 14000
Depth 4: State = 0x4ad6, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ad6: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4ada, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3287100, N[0x3c25, ((2, 3), (2, 4))] = 153
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47f2, ((1, 3), (2, 3))] = 16800, N[0x47f2, ((1, 3), (2, 3))] = 1
Updated Q[0x45a5, ((0, 1), (0, 2))] = 16800, N[0x45a5, ((0, 1), (0, 2))] = 1
Updated Q[0x4ad6, ((0, 3), (1, 3))] = 16800, N[0x4ad6, ((0, 3), (1, 3))] = 1

--- Simulation 158 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.148053649238, 16803.148053649238, 21484.56823054335, 16803.148053649238, 19603.148053649238]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 27301.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x57ce, Score: 11200
Depth 2: State = 0x57ce, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x57ce: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x5245, Score: 14000
Depth 3: State = 0x5245, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x5245: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x56d6, Score: 24900
Depth 4: State = 0x56d6, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x56d6: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3953, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3314800, N[0x3c25, ((2, 3), (2, 4))] = 154
Updated Q[0x3c24, ((2, 0), (2, 1))] = 27700, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x57ce, ((1, 0), (1, 1))] = 27700, N[0x57ce, ((1, 0), (1, 1))] = 1
Updated Q[0x5245, ((4, 1), (4, 2))] = 27700, N[0x5245, ((4, 1), (4, 2))] = 1
Updated Q[0x56d6, ((0, 1), (1, 1))] = 27700, N[0x56d6, ((0, 1), (1, 1))] = 1

--- Simulation 159 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.15002956569, 16803.15002956569, 21524.929161291464, 16803.15002956569, 19603.15002956569]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22401.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c25, Score: 11200
Depth 2: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47c4, Score: 14000
Depth 3: State = 0x47c4, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x47c4: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x47e5, Score: 16800
Depth 4: State = 0x47e5, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3331600, N[0x3c25, ((2, 3), (2, 4))] = 155
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x47c4, ((4, 1), (4, 2))] = 16800, N[0x47c4, ((4, 1), (4, 2))] = 1

--- Simulation 160 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.15199178875, 16803.15199178875, 21494.446722460027, 16803.15199178875, 19603.15199178875]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a91, Score: 8400
Depth 2: State = 0x4a91, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a91: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4589, Score: 14000
Depth 3: State = 0x4589, Legal Moves = [((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4589: [inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x457f, Score: 16800
Depth 4: State = 0x457f, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x457f: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x46d2, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3351200, N[0x3c25, ((2, 3), (2, 4))] = 156
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a91, ((1, 3), (2, 3))] = 19600, N[0x4a91, ((1, 3), (2, 3))] = 1
Updated Q[0x4589, ((1, 4), (2, 4))] = 19600, N[0x4589, ((1, 4), (2, 4))] = 1
Updated Q[0x457f, ((2, 0), (2, 1))] = 19600, N[0x457f, ((2, 0), (2, 1))] = 1

--- Simulation 161 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.15394050005, 16803.15394050005, 21482.303799386023, 16803.15394050005, 19603.15394050005]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c02, Score: 8400
Depth 1: State = 0x3c02, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c02: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3b18, Score: 14000
Depth 2: State = 0x3b18, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3b18: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c6b, Score: 16800
Depth 3: State = 0x3c6b, Legal Moves = [((1, 1), (2, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3c6b: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x563a, Score: 19600
Depth 4: State = 0x563a, Legal Moves = [((2, 0), (2, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x563a: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x5394, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3373600, N[0x3c25, ((2, 3), (2, 4))] = 157
Updated Q[0x3c02, ((1, 3), (2, 3))] = 22400, N[0x3c02, ((1, 3), (2, 3))] = 1
Updated Q[0x3b18, ((2, 0), (2, 1))] = 22400, N[0x3b18, ((2, 0), (2, 1))] = 1
Updated Q[0x3c6b, ((1, 1), (2, 1))] = 22400, N[0x3c6b, ((1, 1), (2, 1))] = 1
Updated Q[0x563a, ((2, 0), (2, 1))] = 22400, N[0x563a, ((2, 0), (2, 1))] = 1

--- Simulation 162 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.15587587769, 16803.15587587769, 21488.14995548667, 16803.15587587769, 19603.15587587769]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3915, Score: 11200
Depth 2: State = 0x3915, Legal Moves = [((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3915: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3a68, Score: 14000
Depth 3: State = 0x3a68, Legal Moves = [((0, 2), (1, 2)), ((2, 4), (3, 4)), ((3, 3), (4, 3)), ((4, 0), (4, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3a68: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x36f7, Score: 16800
Depth 4: State = 0x36f7, Legal Moves = [((2, 4), (3, 4)), ((3, 3), (4, 3)), ((4, 0), (4, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x36f7: [inf, inf, inf, inf]
Selected move: ((2, 4), (3, 4))
New board state after move: 0x36f8, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3393200, N[0x3c25, ((2, 3), (2, 4))] = 158
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3915, ((2, 0), (2, 1))] = 19600, N[0x3915, ((2, 0), (2, 1))] = 1
Updated Q[0x3a68, ((0, 2), (1, 2))] = 19600, N[0x3a68, ((0, 2), (1, 2))] = 1
Updated Q[0x36f7, ((2, 4), (3, 4))] = 19600, N[0x36f7, ((2, 4), (3, 4))] = 1

--- Simulation 163 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.15779809631, 16803.15779809631, 21476.200588016356, 16803.15779809631, 19603.15779809631]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bb6, Score: 8400
Depth 1: State = 0x3bb6, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb6: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x371b, Score: 11200
Depth 2: State = 0x371b, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x371b: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1f48, Score: 16800
Depth 3: State = 0x1f48, Legal Moves = [((2, 1), (3, 1)), ((2, 2), (3, 2))]
UCB1 values for moves at state 0x1f48: [inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x1c40, Score: 22400
Depth 4: State = 0x1c40, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((2, 1), (2, 2)), ((3, 2), (4, 2))]
UCB1 values for moves at state 0x1c40: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x2169, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3421200, N[0x3c25, ((2, 3), (2, 4))] = 159
Updated Q[0x3bb6, ((0, 1), (1, 1))] = 28000, N[0x3bb6, ((0, 1), (1, 1))] = 1
Updated Q[0x371b, ((2, 0), (2, 1))] = 28000, N[0x371b, ((2, 0), (2, 1))] = 1
Updated Q[0x1f48, ((2, 1), (3, 1))] = 28000, N[0x1f48, ((2, 1), (3, 1))] = 1
Updated Q[0x1c40, ((0, 2), (1, 2))] = 28000, N[0x1c40, ((0, 2), (1, 2))] = 1

--- Simulation 164 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.159707327202, 16803.159707327202, 21517.231713166097, 16803.159707327202, 19603.159707327202]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bbf, Score: 8400
Depth 2: State = 0x3bbf, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbf: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3bbf, Score: 14000
Depth 3: State = 0x3bbf, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbf: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3bbf, Score: 16800
Depth 4: State = 0x3bbf, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbf: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c46, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3440800, N[0x3c25, ((2, 3), (2, 4))] = 160
Updated Q[0x3c25, ((0, 2), (1, 2))] = 19600, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3bbf, ((1, 3), (1, 4))] = 19600, N[0x3bbf, ((1, 3), (1, 4))] = 1
Updated Q[0x3bbf, ((1, 3), (1, 4))] = 19600, N[0x3bbf, ((1, 3), (1, 4))] = 1
Updated Q[0x3bbf, ((1, 3), (2, 3))] = 19600, N[0x3bbf, ((1, 3), (2, 3))] = 1

--- Simulation 165 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.16160373838, 16803.16160373838, 21505.249946721804, 16803.16160373838, 19603.16160373838]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [27200.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c4e, Score: 8400
Depth 2: State = 0x3c4e, Legal Moves = [((0, 0), (1, 0)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c4e: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x29a5, Score: 11200
Depth 3: State = 0x29a5, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x29a5: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x29a4, Score: 14000
Depth 4: State = 0x29a4, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x29a4: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x29a4, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3457600, N[0x3c25, ((2, 3), (2, 4))] = 161
Updated Q[0x3c24, ((0, 2), (1, 2))] = 16800, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c4e, ((0, 0), (1, 0))] = 16800, N[0x3c4e, ((0, 0), (1, 0))] = 1
Updated Q[0x29a5, ((1, 2), (2, 2))] = 16800, N[0x29a5, ((1, 2), (2, 2))] = 1
Updated Q[0x29a4, ((1, 2), (1, 3))] = 16800, N[0x29a4, ((1, 2), (1, 3))] = 1

--- Simulation 166 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.163487494658, 16803.163487494658, 21476.025715256983, 16803.163487494658, 19603.163487494658]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x469f, Score: 8400
Depth 2: State = 0x469f, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x469f: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4aed, Score: 11200
Depth 3: State = 0x4aed, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aed: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4ab9, Score: 14000
Depth 4: State = 0x4ab9, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab9: [inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x36fa, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3477200, N[0x3c25, ((2, 3), (2, 4))] = 162
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x469f, ((1, 3), (2, 3))] = 19600, N[0x469f, ((1, 3), (2, 3))] = 1
Updated Q[0x4aed, ((0, 2), (1, 2))] = 19600, N[0x4aed, ((0, 2), (1, 2))] = 1
Updated Q[0x4ab9, ((1, 0), (2, 0))] = 19600, N[0x4ab9, ((1, 0), (2, 0))] = 1

--- Simulation 167 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.165358757735, 16803.165358757735, 21464.446224935582, 16803.165358757735, 19603.165358757735]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46da, Score: 8400
Depth 2: State = 0x46da, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46da: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4808, Score: 11200
Depth 3: State = 0x4808, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4808: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x495b, Score: 14000
Depth 4: State = 0x495b, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2))]
UCB1 values for moves at state 0x495b: [inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x4a48, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3494000, N[0x3c25, ((2, 3), (2, 4))] = 163
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x46da, ((1, 3), (2, 3))] = 16800, N[0x46da, ((1, 3), (2, 3))] = 1
Updated Q[0x4808, ((1, 1), (2, 1))] = 16800, N[0x4808, ((1, 1), (2, 1))] = 1
Updated Q[0x495b, ((0, 1), (1, 1))] = 16800, N[0x495b, ((0, 1), (1, 1))] = 1

--- Simulation 168 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.16721768629, 16803.16721768629, 21435.830897720905, 16803.16721768629, 19603.16721768629]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x454e, Score: 8400
Depth 2: State = 0x454e, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x454e: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x2d69, Score: 18800
Depth 3: State = 0x2d69, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2d69: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x300f, Score: 21600
Depth 4: State = 0x300f, Legal Moves = [((3, 0), (3, 1))]
UCB1 values for moves at state 0x300f: [inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x2ac3, Score: 24400
End of simulation with depth 5. Reward (Score): 24400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3518400, N[0x3c25, ((2, 3), (2, 4))] = 164
Updated Q[0x3c25, ((0, 0), (0, 1))] = 24400, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x454e, ((1, 3), (1, 4))] = 24400, N[0x454e, ((1, 3), (1, 4))] = 1
Updated Q[0x2d69, ((2, 0), (2, 1))] = 24400, N[0x2d69, ((2, 0), (2, 1))] = 1
Updated Q[0x300f, ((3, 0), (3, 1))] = 24400, N[0x300f, ((3, 0), (3, 1))] = 1

--- Simulation 169 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.169064436017, 16803.169064436017, 21453.905998942686, 16803.169064436017, 19603.169064436017]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c02, Score: 8400
Depth 1: State = 0x3c02, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c02: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x36fb, Score: 11200
Depth 2: State = 0x36fb, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (0, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x36fb: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4568, Score: 14000
Depth 3: State = 0x4568, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x4568: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4567, Score: 16800
Depth 4: State = 0x4567, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4567: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4676, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3540800, N[0x3c25, ((2, 3), (2, 4))] = 165
Updated Q[0x3c02, ((1, 3), (1, 4))] = 22400, N[0x3c02, ((1, 3), (1, 4))] = 1
Updated Q[0x36fb, ((0, 2), (1, 2))] = 22400, N[0x36fb, ((0, 2), (1, 2))] = 1
Updated Q[0x4568, ((0, 2), (1, 2))] = 22400, N[0x4568, ((0, 2), (1, 2))] = 1
Updated Q[0x4567, ((2, 0), (2, 1))] = 22400, N[0x4567, ((2, 0), (2, 1))] = 1

--- Simulation 170 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.17089915974, 16803.17089915974, 21459.64079355873, 16803.17089915974, 19603.17089915974]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22400.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d70, Score: 26000
Depth 2: State = 0x3d70, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3d70: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x22b4, Score: 31600
Depth 3: State = 0x22b4, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 2), (3, 3)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x22b4: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x5260, Score: 40000
Depth 4: State = 0x5260, Legal Moves = [((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 1), (4, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x5260: [inf, inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x52a0, Score: 42800
End of simulation with depth 5. Reward (Score): 42800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3583600, N[0x3c25, ((2, 3), (2, 4))] = 166
Updated Q[0x3c24, ((1, 3), (2, 3))] = 42800, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3d70, ((2, 0), (2, 1))] = 42800, N[0x3d70, ((2, 0), (2, 1))] = 1
Updated Q[0x22b4, ((0, 0), (0, 1))] = 42800, N[0x22b4, ((0, 0), (0, 1))] = 1
Updated Q[0x5260, ((2, 2), (3, 2))] = 42800, N[0x5260, ((2, 2), (3, 2))] = 1

--- Simulation 171 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.17272200746, 16803.17272200746, 21588.19805821432, 16803.17272200746, 19603.17272200746]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3aa7, Score: 11200
Depth 2: State = 0x3aa7, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3aa7: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x15fd, Score: 14000
Depth 3: State = 0x15fd, Legal Moves = [((0, 3), (0, 4)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x15fd: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x11ab, Score: 16800
Depth 4: State = 0x11ab, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x11ab: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x15a4, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3603200, N[0x3c25, ((2, 3), (2, 4))] = 167
Updated Q[0x3c25, ((1, 3), (2, 3))] = 19600, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3aa7, ((0, 2), (1, 2))] = 19600, N[0x3aa7, ((0, 2), (1, 2))] = 1
Updated Q[0x15fd, ((0, 3), (0, 4))] = 19600, N[0x15fd, ((0, 3), (0, 4))] = 1
Updated Q[0x11ab, ((2, 0), (2, 1))] = 19600, N[0x11ab, ((2, 0), (2, 1))] = 1

--- Simulation 172 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.17453312642, 16803.17453312642, 21576.29355694018, 16803.17453312642, 19603.17453312642]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x45a5, Score: 8400
Depth 2: State = 0x45a5, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a5: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4702, Score: 11200
Depth 3: State = 0x4702, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4702: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4a98, Score: 16800
Depth 4: State = 0x4a98, Legal Moves = [((0, 2), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((3, 0), (3, 1)), ((3, 0), (4, 0)), ((3, 2), (4, 2))]
UCB1 values for moves at state 0x4a98: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x46f8, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3622800, N[0x3c25, ((2, 3), (2, 4))] = 168
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x45a5, ((1, 3), (1, 4))] = 19600, N[0x45a5, ((1, 3), (1, 4))] = 1
Updated Q[0x4702, ((1, 2), (2, 2))] = 19600, N[0x4702, ((1, 2), (2, 2))] = 1
Updated Q[0x4a98, ((0, 2), (1, 2))] = 19600, N[0x4a98, ((0, 2), (1, 2))] = 1

--- Simulation 173 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.17633266119, 16803.17633266119, 21564.53077367082, 16803.17633266119, 19603.17633266119]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22400.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x36ac, Score: 11200
Depth 2: State = 0x36ac, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x36ac: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3986, Score: 14000
Depth 3: State = 0x3986, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3986: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x393a, Score: 16800
Depth 4: State = 0x393a, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x393a: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x5260, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3645200, N[0x3c25, ((2, 3), (2, 4))] = 169
Updated Q[0x3c24, ((1, 3), (2, 3))] = 22400, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x36ac, ((0, 1), (0, 2))] = 22400, N[0x36ac, ((0, 1), (0, 2))] = 1
Updated Q[0x3986, ((1, 1), (1, 2))] = 22400, N[0x3986, ((1, 1), (1, 2))] = 1
Updated Q[0x393a, ((0, 0), (1, 0))] = 22400, N[0x393a, ((0, 0), (1, 0))] = 1

--- Simulation 174 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.178120753717, 16803.178120753717, 21569.47524005798, 16803.178120753717, 19603.178120753717]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c47, Score: 13200
Depth 1: State = 0x3c47, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c47: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x56d7, Score: 21600
Depth 2: State = 0x56d7, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x56d7: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x5242, Score: 24400
Depth 3: State = 0x5242, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5242: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x107b, Score: 30000
Depth 4: State = 0x107b, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 2), (2, 2))]
UCB1 values for moves at state 0x107b: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x104e, Score: 32800
End of simulation with depth 5. Reward (Score): 32800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3678000, N[0x3c25, ((2, 3), (2, 4))] = 170
Updated Q[0x3c47, ((0, 0), (1, 0))] = 32800, N[0x3c47, ((0, 0), (1, 0))] = 1
Updated Q[0x56d7, ((0, 3), (1, 3))] = 32800, N[0x56d7, ((0, 3), (1, 3))] = 1
Updated Q[0x5242, ((2, 0), (2, 1))] = 32800, N[0x5242, ((2, 0), (2, 1))] = 1
Updated Q[0x107b, ((0, 3), (1, 3))] = 32800, N[0x107b, ((0, 3), (1, 3))] = 1

--- Simulation 175 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.179897543392, 16803.179897543392, 21635.53800465545, 16803.179897543392, 19603.179897543392]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4854, Score: 8400
Depth 2: State = 0x4854, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4854: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x46e3, Score: 11200
Depth 3: State = 0x46e3, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46e3: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x46e3, Score: 14000
Depth 4: State = 0x46e3, Legal Moves = [((2, 1), (3, 1))]
UCB1 values for moves at state 0x46e3: [inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x46e3, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3694800, N[0x3c25, ((2, 3), (2, 4))] = 171
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4854, ((1, 3), (1, 4))] = 16800, N[0x4854, ((1, 3), (1, 4))] = 1
Updated Q[0x46e3, ((2, 0), (2, 1))] = 16800, N[0x46e3, ((2, 0), (2, 1))] = 1
Updated Q[0x46e3, ((2, 1), (3, 1))] = 16800, N[0x46e3, ((2, 1), (3, 1))] = 1

--- Simulation 176 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.181663167103, 16803.181663167103, 21607.26085172312, 16803.181663167103, 19603.181663167103]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bb6, Score: 23800
Depth 2: State = 0x3bb6, Legal Moves = [((1, 0), (1, 1)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((3, 0), (3, 1)), ((3, 3), (3, 4)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3bb6: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x3d08, Score: 26600
Depth 3: State = 0x3d08, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 0), (4, 0)), ((3, 3), (3, 4)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3d08: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3d56, Score: 32200
Depth 4: State = 0x3d56, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1)), ((3, 0), (4, 0)), ((3, 3), (3, 4)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3d56: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d5d, Score: 35000
End of simulation with depth 5. Reward (Score): 35000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3729800, N[0x3c25, ((2, 3), (2, 4))] = 172
Updated Q[0x3c25, ((1, 3), (2, 3))] = 35000, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3bb6, ((1, 0), (1, 1))] = 35000, N[0x3bb6, ((1, 0), (1, 1))] = 1
Updated Q[0x3d08, ((1, 2), (2, 2))] = 35000, N[0x3d08, ((1, 2), (2, 2))] = 1
Updated Q[0x3d56, ((1, 3), (1, 4))] = 35000, N[0x3d56, ((1, 3), (1, 4))] = 1

--- Simulation 177 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.18341775931, 16803.18341775931, 21685.126454258767, 16803.18341775931, 19603.18341775931]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 19601.467405903557, 24501.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3982, Score: 11200
Depth 2: State = 0x3982, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3982: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3978, Score: 14000
Depth 3: State = 0x3978, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3978: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3982, Score: 16800
Depth 4: State = 0x3982, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3982: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2e86, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3752200, N[0x3c25, ((2, 3), (2, 4))] = 173
Updated Q[0x3c24, ((2, 3), (3, 3))] = 22400, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x3982, ((1, 3), (1, 4))] = 22400, N[0x3982, ((1, 3), (1, 4))] = 1
Updated Q[0x3978, ((1, 3), (2, 3))] = 22400, N[0x3978, ((1, 3), (2, 3))] = 1
Updated Q[0x3982, ((2, 0), (2, 1))] = 22400, N[0x3982, ((2, 0), (2, 1))] = 1

--- Simulation 178 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.185161452086, 16803.185161452086, 21689.259504381364, 16803.185161452086, 19603.185161452086]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46d3, Score: 11200
Depth 2: State = 0x46d3, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46d3: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x44f9, Score: 14000
Depth 3: State = 0x44f9, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x44f9: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4a44, Score: 16800
Depth 4: State = 0x4a44, Legal Moves = [((2, 1), (2, 2))]
UCB1 values for moves at state 0x4a44: [inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x4815, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3779500, N[0x3c25, ((2, 3), (2, 4))] = 174
Updated Q[0x3c25, ((0, 0), (0, 1))] = 27300, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x46d3, ((0, 3), (1, 3))] = 27300, N[0x46d3, ((0, 3), (1, 3))] = 1
Updated Q[0x44f9, ((1, 1), (2, 1))] = 27300, N[0x44f9, ((1, 1), (2, 1))] = 1
Updated Q[0x4a44, ((2, 1), (2, 2))] = 27300, N[0x4a44, ((2, 1), (2, 2))] = 1

--- Simulation 179 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.186894375183, 16803.186894375183, 21721.505965655186, 16803.186894375183, 19603.186894375183]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bf9, Score: 8400
Depth 1: State = 0x3bf9, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bf9: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3aed, Score: 11200
Depth 2: State = 0x3aed, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3aed: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0xedaf, Score: 14000
Depth 3: State = 0xedaf, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0xedaf: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3bb8, Score: 16800
Depth 4: State = 0x3bb8, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb8: [inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x3bf9, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3799100, N[0x3c25, ((2, 3), (2, 4))] = 175
Updated Q[0x3bf9, ((0, 3), (1, 3))] = 19600, N[0x3bf9, ((0, 3), (1, 3))] = 1
Updated Q[0x3aed, ((0, 2), (1, 2))] = 19600, N[0x3aed, ((0, 2), (1, 2))] = 1
Updated Q[0xedaf, ((1, 2), (1, 3))] = 19600, N[0xedaf, ((1, 2), (1, 3))] = 1
Updated Q[0x3bb8, ((0, 2), (0, 3))] = 19600, N[0x3bb8, ((0, 2), (0, 3))] = 1

--- Simulation 180 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.188616656083, 16803.188616656083, 21709.383893905666, 16803.188616656083, 19603.188616656083]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.648374031523, 19601.648374031523, 24501.648374031523, 22401.648374031523, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x1470, Score: 8400
Depth 2: State = 0x1470, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x1470: [inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x22bb, Score: 11200
Depth 3: State = 0x22bb, Legal Moves = [((2, 3), (3, 3))]
UCB1 values for moves at state 0x22bb: [inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x2346, Score: 16800
Depth 4: State = 0x2346, Legal Moves = [((2, 2), (3, 2))]
UCB1 values for moves at state 0x2346: [inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x233c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3818700, N[0x3c25, ((2, 3), (2, 4))] = 176
Updated Q[0x3c24, ((3, 0), (3, 1))] = 19600, N[0x3c24, ((3, 0), (3, 1))] = 1
Updated Q[0x1470, ((0, 0), (1, 0))] = 19600, N[0x1470, ((0, 0), (1, 0))] = 1
Updated Q[0x22bb, ((2, 3), (3, 3))] = 19600, N[0x22bb, ((2, 3), (3, 3))] = 1
Updated Q[0x2346, ((2, 2), (3, 2))] = 19600, N[0x2346, ((2, 2), (3, 2))] = 1

--- Simulation 181 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.190328420045, 16803.190328420045, 21697.399570961985, 16803.190328420045, 19603.190328420045]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [18900.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3bbe, Score: 14000
Depth 2: State = 0x3bbe, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbe: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5789, Score: 16800
Depth 3: State = 0x5789, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5789: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x5637, Score: 19600
Depth 4: State = 0x5637, Legal Moves = [((2, 2), (2, 3))]
UCB1 values for moves at state 0x5637: [inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x567a, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3841100, N[0x3c25, ((2, 3), (2, 4))] = 177
Updated Q[0x3c25, ((1, 3), (1, 4))] = 22400, N[0x3c25, ((1, 3), (1, 4))] = 1
Updated Q[0x3bbe, ((1, 2), (1, 3))] = 22400, N[0x3bbe, ((1, 2), (1, 3))] = 1
Updated Q[0x5789, ((2, 0), (2, 1))] = 22400, N[0x5789, ((2, 0), (2, 1))] = 1
Updated Q[0x5637, ((2, 2), (2, 3))] = 22400, N[0x5637, ((2, 2), (2, 3))] = 1

--- Simulation 182 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.192029790163, 16803.192029790163, 21701.369871154126, 16803.192029790163, 19603.192029790163]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x391d, Score: 16800
Depth 2: State = 0x391d, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x391d: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x1f2c, Score: 19600
Depth 3: State = 0x1f2c, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1f2c: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x2d99, Score: 27200
Depth 4: State = 0x2d99, Legal Moves = [((0, 3), (0, 4)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((4, 0), (4, 1))]
UCB1 values for moves at state 0x2d99: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x29bf, Score: 30000
End of simulation with depth 5. Reward (Score): 30000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3871100, N[0x3c25, ((2, 3), (2, 4))] = 178
Updated Q[0x3c24, ((1, 3), (2, 3))] = 30000, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x391d, ((1, 1), (2, 1))] = 30000, N[0x391d, ((1, 1), (2, 1))] = 1
Updated Q[0x1f2c, ((1, 1), (2, 1))] = 30000, N[0x1f2c, ((1, 1), (2, 1))] = 1
Updated Q[0x2d99, ((0, 3), (0, 4))] = 30000, N[0x2d99, ((0, 3), (0, 4))] = 1

--- Simulation 183 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.193720887408, 16803.193720887408, 21747.992188489854, 16803.193720887408, 19603.193720887408]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47a2, Score: 8400
Depth 2: State = 0x47a2, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47a2: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4a88, Score: 11200
Depth 3: State = 0x4a88, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a88: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4a8c, Score: 14000
Depth 4: State = 0x4a8c, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a8c: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x4a6d, Score: 24900
End of simulation with depth 5. Reward (Score): 24900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3896000, N[0x3c25, ((2, 3), (2, 4))] = 179
Updated Q[0x3c25, ((0, 0), (0, 1))] = 24900, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x47a2, ((1, 3), (1, 4))] = 24900, N[0x47a2, ((1, 3), (1, 4))] = 1
Updated Q[0x4a88, ((1, 2), (1, 3))] = 24900, N[0x4a88, ((1, 2), (1, 3))] = 1
Updated Q[0x4a8c, ((0, 2), (0, 3))] = 24900, N[0x4a8c, ((0, 2), (0, 3))] = 1

--- Simulation 184 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.19540183069, 16803.19540183069, 21765.60196403799, 16803.19540183069, 19603.19540183069]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c3f, Score: 11200
Depth 1: State = 0x3c3f, Legal Moves = [((0, 0), (1, 0)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c3f: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x440e, Score: 14000
Depth 2: State = 0x440e, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x440e: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4415, Score: 16800
Depth 3: State = 0x4415, Legal Moves = [((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4415: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4a88, Score: 24500
Depth 4: State = 0x4a88, Legal Moves = [((1, 0), (1, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a88: [inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x491e, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3923300, N[0x3c25, ((2, 3), (2, 4))] = 180
Updated Q[0x3c3f, ((0, 0), (1, 0))] = 27300, N[0x3c3f, ((0, 0), (1, 0))] = 1
Updated Q[0x440e, ((1, 2), (2, 2))] = 27300, N[0x440e, ((1, 2), (2, 2))] = 1
Updated Q[0x4415, ((0, 3), (1, 3))] = 27300, N[0x4415, ((0, 3), (1, 3))] = 1
Updated Q[0x4a88, ((1, 0), (1, 1))] = 27300, N[0x4a88, ((1, 0), (1, 1))] = 1

--- Simulation 185 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.197072736883, 16803.197072736883, 21796.349406843397, 16803.197072736883, 19603.197072736883]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d96, Score: 14000
Depth 2: State = 0x3d96, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3d96: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3db8, Score: 16800
Depth 3: State = 0x3db8, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3db8: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3dbf, Score: 19600
Depth 4: State = 0x3dbf, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3dbf: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x36da, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3945700, N[0x3c25, ((2, 3), (2, 4))] = 181
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3d96, ((0, 1), (0, 2))] = 22400, N[0x3d96, ((0, 1), (0, 2))] = 1
Updated Q[0x3db8, ((0, 3), (0, 4))] = 22400, N[0x3db8, ((0, 3), (0, 4))] = 1
Updated Q[0x3dbf, ((0, 3), (0, 4))] = 22400, N[0x3dbf, ((0, 3), (0, 4))] = 1

--- Simulation 186 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.19873372089, 16803.19873372089, 21799.68527381717, 16803.19873372089, 19603.19873372089]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [21700.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0xee0b, Score: 26000
Depth 2: State = 0xee0b, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0xee0b: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0xedaf, Score: 28800
Depth 3: State = 0xedaf, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0xedaf: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0xf1eb, Score: 31600
Depth 4: State = 0xf1eb, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0xf1eb: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0xf009, Score: 34400
End of simulation with depth 5. Reward (Score): 34400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3980100, N[0x3c25, ((2, 3), (2, 4))] = 182
Updated Q[0x3c25, ((1, 3), (1, 4))] = 34400, N[0x3c25, ((1, 3), (1, 4))] = 1
Updated Q[0xee0b, ((0, 3), (0, 4))] = 34400, N[0xee0b, ((0, 3), (0, 4))] = 1
Updated Q[0xedaf, ((1, 2), (1, 3))] = 34400, N[0xedaf, ((1, 2), (1, 3))] = 1
Updated Q[0xf1eb, ((0, 3), (1, 3))] = 34400, N[0xf1eb, ((0, 3), (1, 3))] = 1

--- Simulation 187 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.200384895677, 16803.200384895677, 21868.918546993016, 16803.200384895677, 19603.200384895677]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x440b, Score: 8400
Depth 2: State = 0x440b, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x440b: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4a8b, Score: 19300
Depth 3: State = 0x4a8b, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a8b: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4ab7, Score: 22100
Depth 4: State = 0x4ab7, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x4ab7: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x456c, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4007800, N[0x3c25, ((2, 3), (2, 4))] = 183
Updated Q[0x3c24, ((0, 0), (0, 1))] = 27700, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x440b, ((0, 2), (1, 2))] = 27700, N[0x440b, ((0, 2), (1, 2))] = 1
Updated Q[0x4a8b, ((1, 2), (2, 2))] = 27700, N[0x4a8b, ((1, 2), (2, 2))] = 1
Updated Q[0x4ab7, ((2, 0), (2, 1))] = 27700, N[0x4ab7, ((2, 0), (2, 1))] = 1

--- Simulation 188 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.20202637232, 16803.20202637232, 21900.78314868789, 16803.20202637232, 19603.20202637232]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x39bc, Score: 11200
Depth 2: State = 0x39bc, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39bc: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x39a1, Score: 24900
Depth 3: State = 0x39a1, Legal Moves = [((0, 2), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39a1: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x391d, Score: 27700
Depth 4: State = 0x391d, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x391d: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3bc3, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4038300, N[0x3c25, ((2, 3), (2, 4))] = 184
Updated Q[0x3c25, ((1, 3), (2, 3))] = 30500, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x39bc, ((1, 2), (2, 2))] = 30500, N[0x39bc, ((1, 2), (2, 2))] = 1
Updated Q[0x39a1, ((0, 2), (1, 2))] = 30500, N[0x39a1, ((0, 2), (1, 2))] = 1
Updated Q[0x391d, ((1, 1), (2, 1))] = 30500, N[0x391d, ((1, 1), (2, 1))] = 1

--- Simulation 189 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.203658260045, 16803.203658260045, 21947.518785516007, 16803.203658260045, 19603.203658260045]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3be2, Score: 8400
Depth 1: State = 0x3be2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be2: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bb9, Score: 16100
Depth 2: State = 0x3bb9, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb9: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x3c1b, Score: 18900
Depth 3: State = 0x3c1b, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3c1b: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x1c62, Score: 24500
Depth 4: State = 0x1c62, Legal Moves = [((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1c62: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1c85, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4065600, N[0x3c25, ((2, 3), (2, 4))] = 185
Updated Q[0x3be2, ((1, 3), (2, 3))] = 27300, N[0x3be2, ((1, 3), (2, 3))] = 1
Updated Q[0x3bb9, ((0, 2), (0, 3))] = 27300, N[0x3bb9, ((0, 2), (0, 3))] = 1
Updated Q[0x3c1b, ((0, 2), (0, 3))] = 27300, N[0x3c1b, ((0, 2), (0, 3))] = 1
Updated Q[0x1c62, ((0, 2), (1, 2))] = 27300, N[0x1c62, ((0, 2), (1, 2))] = 1

--- Simulation 190 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.20528066626, 16803.20528066626, 21976.45187313759, 16803.20528066626, 19603.20528066626]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [18901.16557645562, 22401.16557645562, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bb8, Score: 13300
Depth 2: State = 0x3bb8, Legal Moves = [((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb8: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bbb, Score: 16100
Depth 3: State = 0x3bbb, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbb: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x393b, Score: 21700
Depth 4: State = 0x393b, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x393b: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3a8e, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4090100, N[0x3c25, ((2, 3), (2, 4))] = 186
Updated Q[0x3c25, ((1, 3), (2, 3))] = 24500, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3bb8, ((1, 2), (2, 2))] = 24500, N[0x3bb8, ((1, 2), (2, 2))] = 1
Updated Q[0x3bbb, ((0, 3), (1, 3))] = 24500, N[0x3bbb, ((0, 3), (1, 3))] = 1
Updated Q[0x393b, ((2, 0), (2, 1))] = 24500, N[0x393b, ((2, 0), (2, 1))] = 1

--- Simulation 191 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.20689369662, 16803.20689369662, 21990.020087090954, 16803.20689369662, 19603.20689369662]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 27301.467405903557, 27701.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3673, Score: 14000
Depth 2: State = 0x3673, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3673: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0xf227, Score: 30500
Depth 3: State = 0xf227, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0xf227: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x131a, Score: 33300
Depth 4: State = 0x131a, Legal Moves = [((0, 0), (1, 0)), ((0, 2), (1, 2)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x131a: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x14b1, Score: 36100
End of simulation with depth 5. Reward (Score): 36100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4126200, N[0x3c25, ((2, 3), (2, 4))] = 187
Updated Q[0x3c24, ((2, 3), (3, 3))] = 36100, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x3673, ((1, 2), (1, 3))] = 36100, N[0x3673, ((1, 2), (1, 3))] = 1
Updated Q[0xf227, ((1, 1), (2, 1))] = 36100, N[0xf227, ((1, 1), (2, 1))] = 1
Updated Q[0x131a, ((0, 0), (1, 0))] = 36100, N[0x131a, ((0, 0), (1, 0))] = 1

--- Simulation 192 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.208497455034, 16803.208497455034, 22065.475270282404, 16803.208497455034, 19603.208497455034]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x467c, Score: 11200
Depth 2: State = 0x467c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x467c: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4655, Score: 14000
Depth 3: State = 0x4655, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4655: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4655, Score: 16800
Depth 4: State = 0x4655, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4655: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x43af, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4145800, N[0x3c25, ((2, 3), (2, 4))] = 188
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x467c, ((1, 2), (2, 2))] = 19600, N[0x467c, ((1, 2), (2, 2))] = 1
Updated Q[0x4655, ((0, 3), (1, 3))] = 19600, N[0x4655, ((0, 3), (1, 3))] = 1
Updated Q[0x4655, ((2, 0), (2, 1))] = 19600, N[0x4655, ((2, 0), (2, 1))] = 1

--- Simulation 193 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.210092043722, 16803.210092043722, 22052.3617795988, 16803.210092043722, 19603.210092043722]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3975, Score: 11200
Depth 2: State = 0x3975, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3975: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x391d, Score: 14000
Depth 3: State = 0x391d, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x391d: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3a70, Score: 16800
Depth 4: State = 0x3a70, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3a70: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x36dd, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4168200, N[0x3c25, ((2, 3), (2, 4))] = 189
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3975, ((1, 3), (2, 3))] = 22400, N[0x3975, ((1, 3), (2, 3))] = 1
Updated Q[0x391d, ((1, 1), (2, 1))] = 22400, N[0x391d, ((1, 1), (2, 1))] = 1
Updated Q[0x3a70, ((0, 1), (0, 2))] = 22400, N[0x3a70, ((0, 1), (0, 2))] = 1

--- Simulation 194 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.211677563246, 16803.211677563246, 22054.201869135577, 16803.211677563246, 19603.211677563246]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a91, Score: 8400
Depth 2: State = 0x4a91, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a91: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x21c4, Score: 22100
Depth 3: State = 0x21c4, Legal Moves = [((0, 0), (1, 0)), ((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x21c4: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x47c0, Score: 27700
Depth 4: State = 0x47c0, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c0: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x2d26, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4198700, N[0x3c25, ((2, 3), (2, 4))] = 190
Updated Q[0x3c24, ((0, 0), (0, 1))] = 30500, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a91, ((1, 3), (2, 3))] = 30500, N[0x4a91, ((1, 3), (2, 3))] = 1
Updated Q[0x21c4, ((0, 0), (1, 0))] = 30500, N[0x21c4, ((0, 0), (1, 0))] = 1
Updated Q[0x47c0, ((1, 0), (2, 0))] = 30500, N[0x47c0, ((1, 0), (2, 0))] = 1

--- Simulation 195 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.213254112543, 16803.213254112543, 22098.654166586002, 16803.213254112543, 19603.213254112543]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bd9, Score: 8400
Depth 1: State = 0x3bd9, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bd9: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d0d, Score: 11200
Depth 2: State = 0x3d0d, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3d0d: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3806, Score: 14000
Depth 3: State = 0x3806, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3806: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3806, Score: 16800
Depth 4: State = 0x3806, Legal Moves = [((3, 3), (3, 4))]
UCB1 values for moves at state 0x3806: [inf]
Selected move: ((3, 3), (3, 4))
New board state after move: 0x3806, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4218300, N[0x3c25, ((2, 3), (2, 4))] = 191
Updated Q[0x3bd9, ((1, 3), (1, 4))] = 19600, N[0x3bd9, ((1, 3), (1, 4))] = 1
Updated Q[0x3d0d, ((1, 1), (2, 1))] = 19600, N[0x3d0d, ((1, 1), (2, 1))] = 1
Updated Q[0x3806, ((2, 0), (2, 1))] = 19600, N[0x3806, ((2, 0), (2, 1))] = 1
Updated Q[0x3806, ((3, 3), (3, 4))] = 19600, N[0x3806, ((3, 3), (3, 4))] = 1

--- Simulation 196 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.214821788963, 16803.214821788963, 22085.572930476832, 16803.214821788963, 19603.214821788963]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bfc, Score: 11200
Depth 2: State = 0x3bfc, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bfc: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3807, Score: 14000
Depth 3: State = 0x3807, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3807: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3aad, Score: 16800
Depth 4: State = 0x3aad, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3))]
UCB1 values for moves at state 0x3aad: [inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3986, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4237900, N[0x3c25, ((2, 3), (2, 4))] = 192
Updated Q[0x3c24, ((1, 2), (2, 2))] = 19600, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3bfc, ((1, 3), (2, 3))] = 19600, N[0x3bfc, ((1, 3), (2, 3))] = 1
Updated Q[0x3807, ((2, 0), (2, 1))] = 19600, N[0x3807, ((2, 0), (2, 1))] = 1
Updated Q[0x3aad, ((0, 1), (1, 1))] = 19600, N[0x3aad, ((0, 1), (1, 1))] = 1

--- Simulation 197 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.216380688304, 16803.216380688304, 22072.627955615357, 16803.216380688304, 19603.216380688304]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4549, Score: 8400
Depth 2: State = 0x4549, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4549: [inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x454a, Score: 11200
Depth 3: State = 0x454a, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x454a: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x49a8, Score: 14000
Depth 4: State = 0x49a8, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x49a8: [inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x54eb, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4254700, N[0x3c25, ((2, 3), (2, 4))] = 193
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4549, ((0, 4), (1, 4))] = 16800, N[0x4549, ((0, 4), (1, 4))] = 1
Updated Q[0x454a, ((1, 3), (2, 3))] = 16800, N[0x454a, ((1, 3), (2, 3))] = 1
Updated Q[0x49a8, ((0, 2), (0, 3))] = 16800, N[0x49a8, ((0, 2), (0, 3))] = 1

--- Simulation 198 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.21793090484, 16803.21793090484, 22045.309351942265, 16803.21793090484, 19603.21793090484]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x148e, Score: 11200
Depth 2: State = 0x148e, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x148e: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x57c9, Score: 22100
Depth 3: State = 0x57c9, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x57c9: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x22fb, Score: 27700
Depth 4: State = 0x22fb, Legal Moves = [((0, 2), (0, 3)), ((2, 1), (3, 1)), ((2, 3), (2, 4)), ((4, 0), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x22fb: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x2299, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4285200, N[0x3c25, ((2, 3), (2, 4))] = 194
Updated Q[0x3c24, ((0, 0), (0, 1))] = 30500, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x148e, ((0, 0), (1, 0))] = 30500, N[0x148e, ((0, 0), (1, 0))] = 1
Updated Q[0x57c9, ((2, 0), (2, 1))] = 30500, N[0x57c9, ((2, 0), (2, 1))] = 1
Updated Q[0x22fb, ((0, 2), (0, 3))] = 30500, N[0x22fb, ((0, 2), (0, 3))] = 1

--- Simulation 199 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.219472531357, 16803.219472531357, 22088.890938471468, 16803.219472531357, 19603.219472531357]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3da1, Score: 14000
Depth 2: State = 0x3da1, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3da1: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3be7, Score: 16800
Depth 3: State = 0x3be7, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be7: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3be7, Score: 19600
Depth 4: State = 0x3be7, Legal Moves = [((1, 1), (1, 2)), ((1, 1), (2, 1))]
UCB1 values for moves at state 0x3be7: [inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x3c2b, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4307600, N[0x3c25, ((2, 3), (2, 4))] = 195
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3da1, ((0, 1), (0, 2))] = 22400, N[0x3da1, ((0, 1), (0, 2))] = 1
Updated Q[0x3be7, ((2, 0), (2, 1))] = 22400, N[0x3be7, ((2, 0), (2, 1))] = 1
Updated Q[0x3be7, ((1, 1), (1, 2))] = 22400, N[0x3be7, ((1, 1), (1, 2))] = 1

--- Simulation 200 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.22100565918, 16803.22100565918, 22090.4870712626, 16803.22100565918, 19603.22100565918]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14000.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3af6, Score: 11200
Depth 2: State = 0x3af6, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3af6: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3d6d, Score: 14000
Depth 3: State = 0x3d6d, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d6d: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x213c, Score: 16800
Depth 4: State = 0x213c, Legal Moves = [((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x213c: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1d44, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4327200, N[0x3c25, ((2, 3), (2, 4))] = 196
Updated Q[0x3c24, ((1, 3), (1, 4))] = 19600, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x3af6, ((0, 1), (1, 1))] = 19600, N[0x3af6, ((0, 1), (1, 1))] = 1
Updated Q[0x3d6d, ((0, 1), (1, 1))] = 19600, N[0x3d6d, ((0, 1), (1, 1))] = 1
Updated Q[0x213c, ((2, 0), (2, 1))] = 19600, N[0x213c, ((2, 0), (2, 1))] = 1

--- Simulation 201 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.222530378203, 16803.222530378203, 22077.78120114946, 16803.222530378203, 19603.222530378203]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c69, Score: 8400
Depth 1: State = 0x3c69, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c69: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bb9, Score: 14000
Depth 2: State = 0x3bb9, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb9: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x11cb, Score: 22400
Depth 3: State = 0x11cb, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x11cb: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4678, Score: 25200
Depth 4: State = 0x4678, Legal Moves = [((2, 2), (2, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4678: [inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x4503, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4355200, N[0x3c25, ((2, 3), (2, 4))] = 197
Updated Q[0x3c69, ((1, 2), (2, 2))] = 28000, N[0x3c69, ((1, 2), (2, 2))] = 1
Updated Q[0x3bb9, ((2, 0), (2, 1))] = 28000, N[0x3bb9, ((2, 0), (2, 1))] = 1
Updated Q[0x11cb, ((1, 1), (2, 1))] = 28000, N[0x11cb, ((1, 1), (2, 1))] = 1
Updated Q[0x4678, ((2, 2), (2, 3))] = 28000, N[0x4678, ((2, 2), (2, 3))] = 1

--- Simulation 202 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.224046776922, 16803.224046776922, 22107.843917019847, 16803.224046776922, 19603.224046776922]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4afa, Score: 8400
Depth 2: State = 0x4afa, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4afa: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4ad9, Score: 11200
Depth 3: State = 0x4ad9, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ad9: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x53dc, Score: 14000
Depth 4: State = 0x53dc, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x53dc: [inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x56a1, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4372000, N[0x3c25, ((2, 3), (2, 4))] = 198
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4afa, ((1, 2), (2, 2))] = 16800, N[0x4afa, ((1, 2), (2, 2))] = 1
Updated Q[0x4ad9, ((0, 0), (0, 1))] = 16800, N[0x4ad9, ((0, 0), (0, 1))] = 1
Updated Q[0x53dc, ((0, 3), (0, 4))] = 16800, N[0x53dc, ((0, 3), (0, 4))] = 1

--- Simulation 203 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.225554942474, 16803.225554942474, 22081.037311016207, 16803.225554942474, 19603.225554942474]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x48fc, Score: 8400
Depth 2: State = 0x48fc, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48fc: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4566, Score: 14000
Depth 3: State = 0x4566, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4566: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4ab1, Score: 16800
Depth 4: State = 0x4ab1, Legal Moves = [((2, 1), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x4ab1: [inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x3aad, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4391600, N[0x3c25, ((2, 3), (2, 4))] = 199
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x48fc, ((1, 3), (2, 3))] = 19600, N[0x48fc, ((1, 3), (2, 3))] = 1
Updated Q[0x4566, ((2, 0), (2, 1))] = 19600, N[0x4566, ((2, 0), (2, 1))] = 1
Updated Q[0x4ab1, ((2, 1), (3, 1))] = 19600, N[0x4ab1, ((2, 1), (3, 1))] = 1

--- Simulation 204 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.22705496063, 16803.22705496063, 22068.570468403625, 16803.22705496063, 19603.22705496063]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46fe, Score: 8400
Depth 2: State = 0x46fe, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46fe: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x47f2, Score: 11200
Depth 3: State = 0x47f2, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47f2: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x454c, Score: 14000
Depth 4: State = 0x454c, Legal Moves = [((0, 1), (0, 2))]
UCB1 values for moves at state 0x454c: [inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x43d8, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4408400, N[0x3c25, ((2, 3), (2, 4))] = 200
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46fe, ((1, 3), (1, 4))] = 16800, N[0x46fe, ((1, 3), (1, 4))] = 1
Updated Q[0x47f2, ((1, 1), (2, 1))] = 16800, N[0x47f2, ((1, 1), (2, 1))] = 1
Updated Q[0x454c, ((0, 1), (0, 2))] = 16800, N[0x454c, ((0, 1), (0, 2))] = 1

--- Simulation 205 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.228546915863, 16803.228546915863, 22042.22829274176, 16803.228546915863, 19603.228546915863]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bd7, Score: 8400
Depth 1: State = 0x3bd7, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bd7: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x36f4, Score: 13300
Depth 2: State = 0x36f4, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36f4: [inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x3677, Score: 16100
Depth 3: State = 0x3677, Legal Moves = [((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3677: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x37eb, Score: 18900
Depth 4: State = 0x37eb, Legal Moves = [((0, 3), (0, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37eb: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x380e, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4430100, N[0x3c25, ((2, 3), (2, 4))] = 201
Updated Q[0x3bd7, ((0, 3), (1, 3))] = 21700, N[0x3bd7, ((0, 3), (1, 3))] = 1
Updated Q[0x36f4, ((0, 2), (0, 3))] = 21700, N[0x36f4, ((0, 2), (0, 3))] = 1
Updated Q[0x3677, ((1, 2), (2, 2))] = 21700, N[0x3677, ((1, 2), (2, 2))] = 1
Updated Q[0x37eb, ((0, 3), (0, 4))] = 21700, N[0x37eb, ((0, 3), (0, 4))] = 1

--- Simulation 206 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.230030891355, 16803.230030891355, 22040.526336275514, 16803.230030891355, 19603.230030891355]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x45ab, Score: 8400
Depth 2: State = 0x45ab, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45ab: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4ad1, Score: 16800
Depth 3: State = 0x4ad1, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ad1: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1df4, Score: 22400
Depth 4: State = 0x1df4, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x1df4: [inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x1df4, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4455300, N[0x3c25, ((2, 3), (2, 4))] = 202
Updated Q[0x3c24, ((0, 0), (0, 1))] = 25200, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x45ab, ((1, 3), (2, 3))] = 25200, N[0x45ab, ((1, 3), (2, 3))] = 1
Updated Q[0x4ad1, ((2, 0), (2, 1))] = 25200, N[0x4ad1, ((2, 0), (2, 1))] = 1
Updated Q[0x1df4, ((1, 1), (1, 2))] = 25200, N[0x1df4, ((1, 1), (1, 2))] = 1

--- Simulation 207 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.23150696902, 16803.23150696902, 22056.167962096322, 16803.23150696902, 19603.23150696902]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3be8, Score: 14000
Depth 2: State = 0x3be8, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be8: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bd7, Score: 16800
Depth 3: State = 0x3bd7, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bd7: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d2a, Score: 19600
Depth 4: State = 0x3d2a, Legal Moves = [((2, 1), (2, 2))]
UCB1 values for moves at state 0x3d2a: [inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x3d73, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4480500, N[0x3c25, ((2, 3), (2, 4))] = 203
Updated Q[0x3c24, ((1, 2), (2, 2))] = 25200, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3be8, ((1, 3), (2, 3))] = 25200, N[0x3be8, ((1, 3), (2, 3))] = 1
Updated Q[0x3bd7, ((2, 0), (2, 1))] = 25200, N[0x3bd7, ((2, 0), (2, 1))] = 1
Updated Q[0x3d2a, ((2, 1), (2, 2))] = 25200, N[0x3d2a, ((2, 1), (2, 2))] = 1

--- Simulation 208 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.232975229537, 16803.232975229537, 22071.655481806, 16803.232975229537, 19603.232975229537]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 10500
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x49a2, Score: 13300
Depth 2: State = 0x49a2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x49a2: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x443c, Score: 16100
Depth 3: State = 0x443c, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443c: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1300, Score: 18900
Depth 4: State = 0x1300, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1300: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x12bf, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4502200, N[0x3c25, ((2, 3), (2, 4))] = 204
Updated Q[0x3c25, ((0, 0), (0, 1))] = 21700, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x49a2, ((1, 3), (2, 3))] = 21700, N[0x49a2, ((1, 3), (2, 3))] = 1
Updated Q[0x443c, ((0, 0), (0, 1))] = 21700, N[0x443c, ((0, 0), (0, 1))] = 1
Updated Q[0x1300, ((0, 2), (1, 2))] = 21700, N[0x1300, ((0, 2), (1, 2))] = 1

--- Simulation 209 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.234435752373, 16803.234435752373, 22069.83429893561, 16803.234435752373, 19603.234435752373]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3b16, Score: 11200
Depth 2: State = 0x3b16, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3b16: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x1d56, Score: 14000
Depth 3: State = 0x1d56, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1d56: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x1d55, Score: 16800
Depth 4: State = 0x1d55, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1d55: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3020, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4521800, N[0x3c25, ((2, 3), (2, 4))] = 205
Updated Q[0x3c25, ((1, 3), (2, 3))] = 19600, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3b16, ((0, 2), (0, 3))] = 19600, N[0x3b16, ((0, 2), (0, 3))] = 1
Updated Q[0x1d56, ((1, 3), (1, 4))] = 19600, N[0x1d56, ((1, 3), (1, 4))] = 1
Updated Q[0x1d55, ((1, 2), (1, 3))] = 19600, N[0x1d55, ((1, 2), (1, 3))] = 1

--- Simulation 210 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.235888615796, 16803.235888615796, 22057.786979874054, 16803.235888615796, 19603.235888615796]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4960, Score: 8400
Depth 2: State = 0x4960, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4960: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x465c, Score: 14000
Depth 3: State = 0x465c, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x465c: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x465c, Score: 16800
Depth 4: State = 0x465c, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x465c: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x465d, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4541400, N[0x3c25, ((2, 3), (2, 4))] = 206
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4960, ((1, 3), (2, 3))] = 19600, N[0x4960, ((1, 3), (2, 3))] = 1
Updated Q[0x465c, ((1, 3), (1, 4))] = 19600, N[0x465c, ((1, 3), (1, 4))] = 1
Updated Q[0x465c, ((0, 4), (1, 4))] = 19600, N[0x465c, ((0, 4), (1, 4))] = 1

--- Simulation 211 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.23733389693, 16803.23733389693, 22045.85662370159, 16803.23733389693, 19603.23733389693]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d37, Score: 11200
Depth 2: State = 0x3d37, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d37: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x29c3, Score: 14000
Depth 3: State = 0x29c3, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x29c3: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2c68, Score: 16800
Depth 4: State = 0x2c68, Legal Moves = [((1, 1), (1, 2)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x2c68: [inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x2bd4, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4561000, N[0x3c25, ((2, 3), (2, 4))] = 207
Updated Q[0x3c24, ((1, 3), (1, 4))] = 19600, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x3d37, ((1, 2), (1, 3))] = 19600, N[0x3d37, ((1, 2), (1, 3))] = 1
Updated Q[0x29c3, ((2, 0), (2, 1))] = 19600, N[0x29c3, ((2, 0), (2, 1))] = 1
Updated Q[0x2c68, ((1, 1), (1, 2))] = 19600, N[0x2c68, ((1, 1), (1, 2))] = 1

--- Simulation 212 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.23877167173, 16803.23877167173, 22034.04153531324, 16803.23877167173, 19603.23877167173]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.648374031523, 21701.648374031523, 16801.648374031523, 22401.648374031523, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x1f4b, Score: 11200
Depth 2: State = 0x1f4b, Legal Moves = [((1, 0), (2, 0)), ((2, 0), (2, 1)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x1f4b: [inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x458b, Score: 14000
Depth 3: State = 0x458b, Legal Moves = [((2, 2), (2, 3)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x458b: [inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x4581, Score: 18900
Depth 4: State = 0x4581, Legal Moves = [((2, 3), (2, 4))]
UCB1 values for moves at state 0x4581: [inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x4584, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4585500, N[0x3c25, ((2, 3), (2, 4))] = 208
Updated Q[0x3c25, ((3, 0), (3, 1))] = 24500, N[0x3c25, ((3, 0), (3, 1))] = 1
Updated Q[0x1f4b, ((1, 0), (2, 0))] = 24500, N[0x1f4b, ((1, 0), (2, 0))] = 1
Updated Q[0x458b, ((2, 2), (2, 3))] = 24500, N[0x458b, ((2, 2), (2, 3))] = 1
Updated Q[0x4581, ((2, 3), (2, 4))] = 24500, N[0x4581, ((2, 3), (2, 4))] = 1

--- Simulation 213 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.240202015055, 16803.240202015055, 22045.897744509773, 16803.240202015055, 19603.240202015055]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [21700.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d90, Score: 11200
Depth 2: State = 0x3d90, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d90: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1dee, Score: 14000
Depth 3: State = 0x1dee, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1dee: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2094, Score: 16800
Depth 4: State = 0x2094, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 1), (4, 1))]
UCB1 values for moves at state 0x2094: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0xf3dd, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4607900, N[0x3c25, ((2, 3), (2, 4))] = 209
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3d90, ((0, 2), (1, 2))] = 22400, N[0x3d90, ((0, 2), (1, 2))] = 1
Updated Q[0x1dee, ((2, 0), (2, 1))] = 22400, N[0x1dee, ((2, 0), (2, 1))] = 1
Updated Q[0x2094, ((0, 1), (1, 1))] = 22400, N[0x2094, ((0, 1), (1, 1))] = 1

--- Simulation 214 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.241625000643, 16803.241625000643, 22047.592648942566, 16803.241625000643, 19603.241625000643]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46e0, Score: 8400
Depth 2: State = 0x46e0, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46e0: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2ee1, Score: 11200
Depth 3: State = 0x2ee1, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2ee1: [inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x2ee1, Score: 14000
Depth 4: State = 0x2ee1, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2ee1: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x2ddc, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4624700, N[0x3c25, ((2, 3), (2, 4))] = 210
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46e0, ((0, 0), (0, 1))] = 16800, N[0x46e0, ((0, 0), (0, 1))] = 1
Updated Q[0x2ee1, ((0, 4), (1, 4))] = 16800, N[0x2ee1, ((0, 4), (1, 4))] = 1
Updated Q[0x2ee1, ((1, 3), (2, 3))] = 16800, N[0x2ee1, ((1, 3), (2, 3))] = 1

--- Simulation 215 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.24304070117, 16803.24304070117, 22022.604743450498, 16803.24304070117, 19603.24304070117]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [30500.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d4b, Score: 11200
Depth 2: State = 0x3d4b, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d4b: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2b29, Score: 14000
Depth 3: State = 0x2b29, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2b29: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x2b34, Score: 16800
Depth 4: State = 0x2b34, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2b34: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x2ab0, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4644300, N[0x3c25, ((2, 3), (2, 4))] = 211
Updated Q[0x3c24, ((1, 3), (1, 4))] = 19600, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x3d4b, ((1, 2), (1, 3))] = 19600, N[0x3d4b, ((1, 2), (1, 3))] = 1
Updated Q[0x2b29, ((1, 3), (1, 4))] = 19600, N[0x2b29, ((1, 3), (1, 4))] = 1
Updated Q[0x2b34, ((1, 2), (2, 2))] = 19600, N[0x2b34, ((1, 2), (2, 2))] = 1

--- Simulation 216 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.24444918825, 16803.24444918825, 22011.123831027027, 16803.24444918825, 19603.24444918825]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47ab, Score: 8400
Depth 2: State = 0x47ab, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47ab: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x47af, Score: 11200
Depth 3: State = 0x47af, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47af: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4902, Score: 14000
Depth 4: State = 0x4902, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x4902: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x4921, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4663900, N[0x3c25, ((2, 3), (2, 4))] = 212
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47ab, ((1, 2), (2, 2))] = 19600, N[0x47ab, ((1, 2), (2, 2))] = 1
Updated Q[0x47af, ((2, 0), (2, 1))] = 19600, N[0x47af, ((2, 0), (2, 1))] = 1
Updated Q[0x4902, ((4, 1), (4, 2))] = 19600, N[0x4902, ((4, 1), (4, 2))] = 1

--- Simulation 217 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.245850532458, 16803.245850532458, 21999.751227816607, 16803.245850532458, 19603.245850532458]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c46, Score: 8400
Depth 1: State = 0x3c46, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c46: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3be0, Score: 11200
Depth 2: State = 0x3be0, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be0: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3825, Score: 19600
Depth 3: State = 0x3825, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((0, 2), (1, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3825: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3c68, Score: 32100
Depth 4: State = 0x3c68, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c68: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c46, Score: 34900
End of simulation with depth 5. Reward (Score): 34900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4698800, N[0x3c25, ((2, 3), (2, 4))] = 213
Updated Q[0x3c46, ((0, 0), (1, 0))] = 34900, N[0x3c46, ((0, 0), (1, 0))] = 1
Updated Q[0x3be0, ((1, 3), (2, 3))] = 34900, N[0x3be0, ((1, 3), (2, 3))] = 1
Updated Q[0x3825, ((0, 1), (0, 2))] = 34900, N[0x3825, ((0, 1), (0, 2))] = 1
Updated Q[0x3c68, ((0, 2), (1, 2))] = 34900, N[0x3c68, ((0, 2), (1, 2))] = 1

--- Simulation 218 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.24724480336, 16803.24724480336, 22060.316394261343, 16803.24724480336, 19603.24724480336]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bda, Score: 8400
Depth 1: State = 0x3bda, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bda: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x386d, Score: 11200
Depth 2: State = 0x386d, Legal Moves = [((0, 1), (0, 2)), ((0, 1), (1, 1)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x386d: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x2c62, Score: 16800
Depth 3: State = 0x2c62, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2c62: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x1212, Score: 19600
Depth 4: State = 0x1212, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1212: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x11c0, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4721200, N[0x3c25, ((2, 3), (2, 4))] = 214
Updated Q[0x3bda, ((1, 3), (2, 3))] = 22400, N[0x3bda, ((1, 3), (2, 3))] = 1
Updated Q[0x386d, ((0, 1), (0, 2))] = 22400, N[0x386d, ((0, 1), (0, 2))] = 1
Updated Q[0x2c62, ((0, 2), (0, 3))] = 22400, N[0x2c62, ((0, 2), (0, 3))] = 1
Updated Q[0x1212, ((0, 2), (1, 2))] = 22400, N[0x1212, ((0, 2), (1, 2))] = 1

--- Simulation 219 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.248632069513, 16803.248632069513, 22061.904314907133, 16803.248632069513, 19603.248632069513]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [30500.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3719, Score: 11200
Depth 2: State = 0x3719, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3719: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3db8, Score: 14000
Depth 3: State = 0x3db8, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (2, 2)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3db8: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3ab0, Score: 16800
Depth 4: State = 0x3ab0, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (1, 3)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3ab0: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x2d4e, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4740800, N[0x3c25, ((2, 3), (2, 4))] = 215
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3719, ((2, 0), (2, 1))] = 19600, N[0x3719, ((2, 0), (2, 1))] = 1
Updated Q[0x3db8, ((1, 1), (2, 1))] = 19600, N[0x3db8, ((1, 1), (2, 1))] = 1
Updated Q[0x3ab0, ((0, 2), (0, 3))] = 19600, N[0x3ab0, ((0, 2), (0, 3))] = 1

--- Simulation 220 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.250012398505, 16803.250012398505, 22050.454207145434, 16803.250012398505, 19603.250012398505]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [24400.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d7f, Score: 11200
Depth 2: State = 0x3d7f, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d7f: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3913, Score: 14000
Depth 3: State = 0x3913, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3913: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x5129, Score: 19600
Depth 4: State = 0x5129, Legal Moves = [((1, 3), (2, 3))]
UCB1 values for moves at state 0x5129: [inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x53fe, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4763200, N[0x3c25, ((2, 3), (2, 4))] = 216
Updated Q[0x3c25, ((1, 3), (1, 4))] = 22400, N[0x3c25, ((1, 3), (1, 4))] = 1
Updated Q[0x3d7f, ((0, 2), (1, 2))] = 22400, N[0x3d7f, ((0, 2), (1, 2))] = 1
Updated Q[0x3913, ((2, 0), (2, 1))] = 22400, N[0x3913, ((2, 0), (2, 1))] = 1
Updated Q[0x5129, ((1, 3), (2, 3))] = 22400, N[0x5129, ((1, 3), (2, 3))] = 1

--- Simulation 221 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.251385856962, 16803.251385856962, 22052.07308063814, 16803.251385856962, 19603.251385856962]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c0a, Score: 8400
Depth 1: State = 0x3c0a, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c0a: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c27, Score: 11200
Depth 2: State = 0x3c27, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c27: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x382f, Score: 14000
Depth 3: State = 0x382f, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x382f: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x3874, Score: 16800
Depth 4: State = 0x3874, Legal Moves = [((2, 3), (2, 4))]
UCB1 values for moves at state 0x3874: [inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3867, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4782800, N[0x3c25, ((2, 3), (2, 4))] = 217
Updated Q[0x3c0a, ((1, 2), (2, 2))] = 19600, N[0x3c0a, ((1, 2), (2, 2))] = 1
Updated Q[0x3c27, ((2, 0), (2, 1))] = 19600, N[0x3c27, ((2, 0), (2, 1))] = 1
Updated Q[0x382f, ((4, 1), (4, 2))] = 19600, N[0x382f, ((4, 1), (4, 2))] = 1
Updated Q[0x3874, ((2, 3), (2, 4))] = 19600, N[0x3874, ((2, 3), (2, 4))] = 1

--- Simulation 222 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.25275251056, 16803.25275251056, 22040.773806620124, 16803.25275251056, 19603.25275251056]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c21, Score: 11200
Depth 2: State = 0x3c21, Legal Moves = [((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3c21: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397b, Score: 14000
Depth 3: State = 0x397b, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (1, 1)), ((2, 1), (3, 1)), ((2, 4), (3, 4)), ((3, 3), (3, 4)), ((3, 3), (4, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397b: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x120a, Score: 16800
Depth 4: State = 0x120a, Legal Moves = [((2, 1), (3, 1)), ((2, 4), (3, 4)), ((3, 3), (3, 4)), ((3, 3), (4, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x120a: [inf, inf, inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x144a, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4813300, N[0x3c25, ((2, 3), (2, 4))] = 218
Updated Q[0x3c25, ((1, 2), (2, 2))] = 30500, N[0x3c25, ((1, 2), (2, 2))] = 1
Updated Q[0x3c21, ((2, 0), (2, 1))] = 30500, N[0x3c21, ((2, 0), (2, 1))] = 1
Updated Q[0x397b, ((0, 0), (1, 0))] = 30500, N[0x397b, ((0, 0), (1, 0))] = 1
Updated Q[0x120a, ((2, 1), (3, 1))] = 30500, N[0x120a, ((2, 1), (3, 1))] = 1

--- Simulation 223 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.254112424067, 16803.254112424067, 22079.57819446862, 16803.254112424067, 19603.254112424067]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c6f, Score: 8400
Depth 1: State = 0x3c6f, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c6f: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c67, Score: 11200
Depth 2: State = 0x3c67, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c67: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3be0, Score: 25200
Depth 3: State = 0x3be0, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be0: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c25, Score: 28000
Depth 4: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x445a, Score: 30800
End of simulation with depth 5. Reward (Score): 30800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4844100, N[0x3c25, ((2, 3), (2, 4))] = 219
Updated Q[0x3c6f, ((1, 2), (2, 2))] = 30800, N[0x3c6f, ((1, 2), (2, 2))] = 1
Updated Q[0x3c67, ((0, 3), (1, 3))] = 30800, N[0x3c67, ((0, 3), (1, 3))] = 1
Updated Q[0x3be0, ((0, 2), (1, 2))] = 30800, N[0x3be0, ((0, 2), (1, 2))] = 1
Updated Q[0x3c25, ((0, 0), (0, 1))] = 30800, N[0x3c25, ((0, 0), (0, 1))] = 1

--- Simulation 224 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.255465661325, 16803.255465661325, 22119.398066174926, 16803.255465661325, 19603.255465661325]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4506, Score: 11200
Depth 2: State = 0x4506, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4506: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a76, Score: 16800
Depth 3: State = 0x4a76, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a76: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x47d1, Score: 19600
Depth 4: State = 0x47d1, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 1), (4, 1))]
UCB1 values for moves at state 0x47d1: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x37ef, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4866500, N[0x3c25, ((2, 3), (2, 4))] = 220
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4506, ((1, 3), (2, 3))] = 22400, N[0x4506, ((1, 3), (2, 3))] = 1
Updated Q[0x4a76, ((1, 1), (2, 1))] = 22400, N[0x4a76, ((1, 1), (2, 1))] = 1
Updated Q[0x47d1, ((0, 0), (0, 1))] = 22400, N[0x47d1, ((0, 0), (0, 1))] = 1

--- Simulation 225 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.256812285294, 16803.256812285294, 22120.674119694024, 16803.256812285294, 19603.256812285294]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x48f8, Score: 8400
Depth 2: State = 0x48f8, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x48f8: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x499a, Score: 11200
Depth 3: State = 0x499a, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x499a: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x46bb, Score: 14000
Depth 4: State = 0x46bb, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46bb: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x469c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4886100, N[0x3c25, ((2, 3), (2, 4))] = 221
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x48f8, ((1, 2), (2, 2))] = 19600, N[0x48f8, ((1, 2), (2, 2))] = 1
Updated Q[0x499a, ((0, 3), (1, 3))] = 19600, N[0x499a, ((0, 3), (1, 3))] = 1
Updated Q[0x46bb, ((0, 3), (1, 3))] = 19600, N[0x46bb, ((0, 3), (1, 3))] = 1

--- Simulation 226 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.25815235806, 16803.25815235806, 22109.26894080065, 16803.25815235806, 19603.25815235806]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4705, Score: 8400
Depth 2: State = 0x4705, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4705: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4527, Score: 11200
Depth 3: State = 0x4527, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4527: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4527, Score: 14000
Depth 4: State = 0x4527, Legal Moves = [((1, 3), (1, 4)), ((1, 4), (2, 4)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x4527: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x452a, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4902900, N[0x3c25, ((2, 3), (2, 4))] = 222
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4705, ((1, 3), (2, 3))] = 16800, N[0x4705, ((1, 3), (2, 3))] = 1
Updated Q[0x4527, ((1, 1), (2, 1))] = 16800, N[0x4527, ((1, 1), (2, 1))] = 1
Updated Q[0x4527, ((1, 3), (1, 4))] = 16800, N[0x4527, ((1, 3), (1, 4))] = 1

--- Simulation 227 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.259485940845, 16803.259485940845, 22085.353897507746, 16803.259485940845, 19603.259485940845]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [24900.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c3b, Score: 11200
Depth 2: State = 0x3c3b, Legal Moves = [((0, 0), (1, 0)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3c3b: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x46d2, Score: 16800
Depth 3: State = 0x46d2, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x46d2: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x46d2, Score: 19600
Depth 4: State = 0x46d2, Legal Moves = [((3, 2), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x46d2: [inf, inf]
Selected move: ((3, 2), (3, 3))
New board state after move: 0x46e3, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4928100, N[0x3c25, ((2, 3), (2, 4))] = 223
Updated Q[0x3c25, ((1, 2), (2, 2))] = 25200, N[0x3c25, ((1, 2), (2, 2))] = 1
Updated Q[0x3c3b, ((0, 0), (1, 0))] = 25200, N[0x3c3b, ((0, 0), (1, 0))] = 1
Updated Q[0x46d2, ((2, 0), (2, 1))] = 25200, N[0x46d2, ((2, 0), (2, 1))] = 1
Updated Q[0x46d2, ((3, 2), (3, 3))] = 25200, N[0x46d2, ((3, 2), (3, 3))] = 1

--- Simulation 228 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.26081309404, 16803.26081309404, 22099.321499209094, 16803.26081309404, 19603.26081309404]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c1b, Score: 13300
Depth 2: State = 0x3c1b, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1b: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x1d45, Score: 16100
Depth 3: State = 0x1d45, Legal Moves = [((1, 0), (1, 1)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1d45: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x2038, Score: 18900
Depth 4: State = 0x2038, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x2038: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x36b8, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4949800, N[0x3c25, ((2, 3), (2, 4))] = 224
Updated Q[0x3c25, ((1, 3), (2, 3))] = 21700, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3c1b, ((1, 2), (1, 3))] = 21700, N[0x3c1b, ((1, 2), (1, 3))] = 1
Updated Q[0x1d45, ((1, 0), (1, 1))] = 21700, N[0x1d45, ((1, 0), (1, 1))] = 1
Updated Q[0x2038, ((0, 0), (0, 1))] = 21700, N[0x2038, ((0, 0), (0, 1))] = 1

--- Simulation 229 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.262133877197, 16803.262133877197, 22097.539389059253, 16803.262133877197, 19603.262133877197]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c24, Score: 8400
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 1), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a72, Score: 11200
Depth 3: State = 0x4a72, Legal Moves = [((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4a72: [inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x4a94, Score: 14000
Depth 4: State = 0x4a94, Legal Moves = [((1, 4), (2, 4)), ((2, 3), (2, 4)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4a94: [inf, inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x4a91, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4966600, N[0x3c25, ((2, 3), (2, 4))] = 225
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a72, ((1, 1), (1, 2))] = 16800, N[0x4a72, ((1, 1), (1, 2))] = 1
Updated Q[0x4a94, ((1, 4), (2, 4))] = 16800, N[0x4a94, ((1, 4), (2, 4))] = 1

--- Simulation 230 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.26344834906, 16803.26344834906, 22073.99534100105, 16803.26344834906, 19603.26344834906]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14000.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x37ca, Score: 11200
Depth 2: State = 0x37ca, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37ca: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3a70, Score: 14000
Depth 3: State = 0x3a70, Legal Moves = [((2, 1), (3, 1)), ((2, 2), (2, 3)), ((3, 1), (4, 1))]
UCB1 values for moves at state 0x3a70: [inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x2c8a, Score: 19600
Depth 4: State = 0x2c8a, Legal Moves = [((1, 1), (2, 1))]
UCB1 values for moves at state 0x2c8a: [inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3083, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4989000, N[0x3c25, ((2, 3), (2, 4))] = 226
Updated Q[0x3c24, ((1, 3), (1, 4))] = 22400, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x37ca, ((2, 0), (2, 1))] = 22400, N[0x37ca, ((2, 0), (2, 1))] = 1
Updated Q[0x3a70, ((2, 1), (3, 1))] = 22400, N[0x3a70, ((2, 1), (3, 1))] = 1
Updated Q[0x2c8a, ((1, 1), (2, 1))] = 22400, N[0x2c8a, ((1, 1), (2, 1))] = 1

--- Simulation 231 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.26475656757, 16803.26475656757, 22075.43840731453, 16803.26475656757, 19603.26475656757]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c4d, Score: 11200
Depth 1: State = 0x3c4d, Legal Moves = [((0, 0), (1, 0)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4d: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x1f51, Score: 14000
Depth 2: State = 0x1f51, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1f51: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x1f07, Score: 16800
Depth 3: State = 0x1f07, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1f07: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x1efd, Score: 19600
Depth 4: State = 0x1efd, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1efd: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1efd, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5011400, N[0x3c25, ((2, 3), (2, 4))] = 227
Updated Q[0x3c4d, ((0, 0), (1, 0))] = 22400, N[0x3c4d, ((0, 0), (1, 0))] = 1
Updated Q[0x1f51, ((1, 2), (2, 2))] = 22400, N[0x1f51, ((1, 2), (2, 2))] = 1
Updated Q[0x1f07, ((0, 3), (1, 3))] = 22400, N[0x1f07, ((0, 3), (1, 3))] = 1
Updated Q[0x1efd, ((2, 0), (2, 1))] = 22400, N[0x1efd, ((2, 0), (2, 1))] = 1

--- Simulation 232 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.266058589896, 16803.266058589896, 22076.86875830117, 16803.266058589896, 19603.266058589896]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 22401.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d78, Score: 8400
Depth 2: State = 0x3d78, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d78: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x578a, Score: 11200
Depth 3: State = 0x578a, Legal Moves = [((2, 2), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x578a: [inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x57ce, Score: 14000
Depth 4: State = 0x57ce, Legal Moves = [((0, 2), (1, 2)), ((2, 3), (3, 3)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x57ce: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x541a, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5028200, N[0x3c25, ((2, 3), (2, 4))] = 228
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3d78, ((0, 0), (0, 1))] = 16800, N[0x3d78, ((0, 0), (0, 1))] = 1
Updated Q[0x578a, ((2, 2), (2, 3))] = 16800, N[0x578a, ((2, 2), (2, 3))] = 1
Updated Q[0x57ce, ((0, 2), (1, 2))] = 16800, N[0x57ce, ((0, 2), (1, 2))] = 1

--- Simulation 233 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.267354472424, 16803.267354472424, 22053.72515776586, 16803.267354472424, 19603.267354472424]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 8400
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x464f, Score: 11200
Depth 2: State = 0x464f, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x464f: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x48f5, Score: 14000
Depth 3: State = 0x48f5, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f5: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x44fd, Score: 16800
Depth 4: State = 0x44fd, Legal Moves = [((1, 3), (2, 3)), ((2, 2), (2, 3)), ((2, 3), (2, 4))]
UCB1 values for moves at state 0x44fd: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4506, Score: 27200
End of simulation with depth 5. Reward (Score): 27200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5055400, N[0x3c25, ((2, 3), (2, 4))] = 229
Updated Q[0x3c25, ((0, 0), (0, 1))] = 27200, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x464f, ((1, 3), (2, 3))] = 27200, N[0x464f, ((1, 3), (2, 3))] = 1
Updated Q[0x48f5, ((1, 1), (2, 1))] = 27200, N[0x48f5, ((1, 1), (2, 1))] = 1
Updated Q[0x44fd, ((1, 3), (2, 3))] = 27200, N[0x44fd, ((1, 3), (2, 3))] = 1

--- Simulation 234 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.268644270793, 16803.268644270793, 22076.198530844333, 16803.268644270793, 19603.268644270793]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 29801.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36d8, Score: 8400
Depth 2: State = 0x36d8, Legal Moves = [((0, 0), (0, 1)), ((1, 1), (2, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x36d8: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x15eb, Score: 11200
Depth 3: State = 0x15eb, Legal Moves = [((1, 1), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x15eb: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x56c4, Score: 14000
Depth 4: State = 0x56c4, Legal Moves = [((0, 0), (0, 1)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x56c4: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4adb, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5072200, N[0x3c25, ((2, 3), (2, 4))] = 230
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x36d8, ((0, 0), (0, 1))] = 16800, N[0x36d8, ((0, 0), (0, 1))] = 1
Updated Q[0x15eb, ((1, 1), (2, 1))] = 16800, N[0x15eb, ((1, 1), (2, 1))] = 1
Updated Q[0x56c4, ((0, 0), (0, 1))] = 16800, N[0x56c4, ((0, 0), (0, 1))] = 1

--- Simulation 235 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.269928039896, 16803.269928039896, 22053.25909093076, 16803.269928039896, 19603.269928039896]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bc6, Score: 11200
Depth 2: State = 0x3bc6, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc6: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3bc6, Score: 14000
Depth 3: State = 0x3bc6, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x3bc6: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x3c06, Score: 16800
Depth 4: State = 0x3c06, Legal Moves = [((0, 1), (0, 2))]
UCB1 values for moves at state 0x3c06: [inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3986, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5094600, N[0x3c25, ((2, 3), (2, 4))] = 231
Updated Q[0x3c24, ((1, 2), (2, 2))] = 22400, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3bc6, ((2, 0), (2, 1))] = 22400, N[0x3bc6, ((2, 0), (2, 1))] = 1
Updated Q[0x3bc6, ((4, 1), (4, 2))] = 22400, N[0x3bc6, ((4, 1), (4, 2))] = 1
Updated Q[0x3c06, ((0, 1), (0, 2))] = 22400, N[0x3c06, ((0, 1), (0, 2))] = 1

--- Simulation 236 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.2712058339, 16803.2712058339, 22054.760684087752, 16803.2712058339, 19603.2712058339]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 29801.467405903557, 16801.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3673, Score: 11200
Depth 2: State = 0x3673, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3673: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3d4f, Score: 14000
Depth 3: State = 0x3d4f, Legal Moves = [((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d4f: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3d15, Score: 16800
Depth 4: State = 0x3d15, Legal Moves = [((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d15: [inf, inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x37c9, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5114200, N[0x3c25, ((2, 3), (2, 4))] = 232
Updated Q[0x3c24, ((2, 3), (3, 3))] = 19600, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x3673, ((0, 3), (0, 4))] = 19600, N[0x3673, ((0, 3), (0, 4))] = 1
Updated Q[0x3d4f, ((0, 4), (1, 4))] = 19600, N[0x3d4f, ((0, 4), (1, 4))] = 1
Updated Q[0x3d15, ((2, 0), (2, 1))] = 19600, N[0x3d15, ((2, 0), (2, 1))] = 1

--- Simulation 237 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.272477706243, 16803.272477706243, 22044.18036592849, 16803.272477706243, 19603.272477706243]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3821, Score: 16800
Depth 2: State = 0x3821, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3821: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4912, Score: 19600
Depth 3: State = 0x4912, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4912: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4915, Score: 22400
Depth 4: State = 0x4915, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4915: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x43d1, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5139400, N[0x3c25, ((2, 3), (2, 4))] = 233
Updated Q[0x3c24, ((1, 3), (2, 3))] = 25200, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3821, ((1, 1), (2, 1))] = 25200, N[0x3821, ((1, 1), (2, 1))] = 1
Updated Q[0x4912, ((1, 3), (2, 3))] = 25200, N[0x4912, ((1, 3), (2, 3))] = 1
Updated Q[0x4915, ((0, 1), (1, 1))] = 25200, N[0x4915, ((0, 1), (1, 1))] = 1

--- Simulation 238 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.273743709673, 16803.273743709673, 22057.725199695047, 16803.273743709673, 19603.273743709673]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4506, Score: 11200
Depth 2: State = 0x4506, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4506: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x45af, Score: 14000
Depth 3: State = 0x45af, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45af: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4afa, Score: 16800
Depth 4: State = 0x4afa, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4afa: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3081, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5159000, N[0x3c25, ((2, 3), (2, 4))] = 234
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4506, ((1, 2), (2, 2))] = 19600, N[0x4506, ((1, 2), (2, 2))] = 1
Updated Q[0x45af, ((2, 0), (2, 1))] = 19600, N[0x45af, ((2, 0), (2, 1))] = 1
Updated Q[0x4afa, ((2, 0), (2, 1))] = 19600, N[0x4afa, ((2, 0), (2, 1))] = 1

--- Simulation 239 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.27500389624, 16803.27500389624, 22047.222640710777, 16803.27500389624, 19603.27500389624]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4431, Score: 8400
Depth 2: State = 0x4431, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x4431: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a4b, Score: 11200
Depth 3: State = 0x4a4b, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x4a4b: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4a4f, Score: 14000
Depth 4: State = 0x4a4f, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x4a4f: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x4aaa, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5175800, N[0x3c25, ((2, 3), (2, 4))] = 235
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4431, ((1, 3), (2, 3))] = 16800, N[0x4431, ((1, 3), (2, 3))] = 1
Updated Q[0x4a4b, ((1, 3), (1, 4))] = 16800, N[0x4a4b, ((1, 3), (1, 4))] = 1
Updated Q[0x4a4f, ((0, 2), (0, 3))] = 16800, N[0x4a4f, ((0, 2), (0, 3))] = 1

--- Simulation 240 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.276258317317, 16803.276258317317, 22024.894570591325, 16803.276258317317, 19603.276258317317]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 22401.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36da, Score: 8400
Depth 2: State = 0x36da, Legal Moves = [((0, 0), (0, 1)), ((1, 1), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x36da: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x11c1, Score: 11200
Depth 3: State = 0x11c1, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x11c1: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x2dae, Score: 14000
Depth 4: State = 0x2dae, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((1, 4), (2, 4)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2dae: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x3845, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5192600, N[0x3c25, ((2, 3), (2, 4))] = 236
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x36da, ((0, 0), (0, 1))] = 16800, N[0x36da, ((0, 0), (0, 1))] = 1
Updated Q[0x11c1, ((1, 1), (2, 1))] = 16800, N[0x11c1, ((1, 1), (2, 1))] = 1
Updated Q[0x2dae, ((0, 0), (0, 1))] = 16800, N[0x2dae, ((0, 0), (0, 1))] = 1

--- Simulation 241 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.277507023602, 16803.277507023602, 22002.755720416422, 16803.277507023602, 19603.277507023602]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3829, Score: 19300
Depth 2: State = 0x3829, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3829: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d74, Score: 22100
Depth 3: State = 0x3d74, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x3d74: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x2d2c, Score: 24900
Depth 4: State = 0x2d2c, Legal Moves = [((0, 1), (0, 2)), ((0, 1), (1, 1)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x2d2c: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x2934, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5220300, N[0x3c25, ((2, 3), (2, 4))] = 237
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27700, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3829, ((2, 0), (2, 1))] = 27700, N[0x3829, ((2, 0), (2, 1))] = 1
Updated Q[0x3d74, ((1, 1), (2, 1))] = 27700, N[0x3d74, ((1, 1), (2, 1))] = 1
Updated Q[0x2d2c, ((0, 1), (0, 2))] = 27700, N[0x2d2c, ((0, 1), (0, 2))] = 1

--- Simulation 242 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.27875006514, 16803.27875006514, 22026.795256184225, 16803.27875006514, 19603.27875006514]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc0, Score: 8400
Depth 1: State = 0x3bc0, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc0: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x39a5, Score: 11200
Depth 2: State = 0x39a5, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x39a5: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x37bd, Score: 14000
Depth 3: State = 0x37bd, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x37bd: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3910, Score: 19600
Depth 4: State = 0x3910, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 0), (1, 1)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 3), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3910: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x37c1, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5242700, N[0x3c25, ((2, 3), (2, 4))] = 238
Updated Q[0x3bc0, ((1, 3), (1, 4))] = 22400, N[0x3bc0, ((1, 3), (1, 4))] = 1
Updated Q[0x39a5, ((0, 1), (1, 1))] = 22400, N[0x39a5, ((0, 1), (1, 1))] = 1
Updated Q[0x37bd, ((1, 1), (2, 1))] = 22400, N[0x37bd, ((1, 1), (2, 1))] = 1
Updated Q[0x3910, ((0, 1), (1, 1))] = 22400, N[0x3910, ((0, 1), (1, 1))] = 1

--- Simulation 243 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.27998749133, 16803.27998749133, 22028.36387051471, 16803.27998749133, 19603.27998749133]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46f4, Score: 8400
Depth 2: State = 0x46f4, Legal Moves = [((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46f4: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4ab3, Score: 11200
Depth 3: State = 0x4ab3, Legal Moves = [((0, 4), (1, 4)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab3: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x4ab4, Score: 14000
Depth 4: State = 0x4ab4, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab4: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4416, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5259500, N[0x3c25, ((2, 3), (2, 4))] = 239
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46f4, ((0, 3), (1, 3))] = 16800, N[0x46f4, ((0, 3), (1, 3))] = 1
Updated Q[0x4ab3, ((0, 4), (1, 4))] = 16800, N[0x4ab3, ((0, 4), (1, 4))] = 1
Updated Q[0x4ab4, ((1, 1), (2, 1))] = 16800, N[0x4ab4, ((1, 1), (2, 1))] = 1

--- Simulation 244 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.281219350934, 16803.281219350934, 22006.488395063443, 16803.281219350934, 19603.281219350934]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4967, Score: 8400
Depth 2: State = 0x4967, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4967: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x469f, Score: 11200
Depth 3: State = 0x469f, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x469f: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x469f, Score: 14000
Depth 4: State = 0x469f, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x469f: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4945, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5279100, N[0x3c25, ((2, 3), (2, 4))] = 240
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4967, ((1, 3), (2, 3))] = 19600, N[0x4967, ((1, 3), (2, 3))] = 1
Updated Q[0x469f, ((1, 2), (1, 3))] = 19600, N[0x469f, ((1, 2), (1, 3))] = 1
Updated Q[0x469f, ((0, 3), (1, 3))] = 19600, N[0x469f, ((0, 3), (1, 3))] = 1

--- Simulation 245 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.282445692097, 16803.282445692097, 21996.461880958337, 16803.282445692097, 19603.282445692097]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 30501.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x382d, Score: 11200
Depth 2: State = 0x382d, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 1), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x382d: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2293, Score: 14000
Depth 3: State = 0x2293, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 1), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2293: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x2bf9, Score: 19600
Depth 4: State = 0x2bf9, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((1, 1), (1, 2)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2bf9: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3038, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5301500, N[0x3c25, ((2, 3), (2, 4))] = 241
Updated Q[0x3c25, ((2, 0), (2, 1))] = 22400, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x382d, ((0, 0), (0, 1))] = 22400, N[0x382d, ((0, 0), (0, 1))] = 1
Updated Q[0x2293, ((0, 1), (0, 2))] = 22400, N[0x2293, ((0, 1), (0, 2))] = 1
Updated Q[0x2bf9, ((0, 1), (1, 1))] = 22400, N[0x2bf9, ((0, 1), (1, 1))] = 1

--- Simulation 246 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.283666562347, 16803.283666562347, 21998.13683076082, 16803.283666562347, 19603.283666562347]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22400.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c1a, Score: 8400
Depth 2: State = 0x3c1a, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1a: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bb9, Score: 11200
Depth 3: State = 0x3bb9, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb9: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2d6e, Score: 16800
Depth 4: State = 0x2d6e, Legal Moves = [((0, 1), (1, 1)), ((2, 2), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2d6e: [inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x2932, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5321100, N[0x3c25, ((2, 3), (2, 4))] = 242
Updated Q[0x3c25, ((0, 2), (1, 2))] = 19600, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3c1a, ((0, 2), (1, 2))] = 19600, N[0x3c1a, ((0, 2), (1, 2))] = 1
Updated Q[0x3bb9, ((2, 0), (2, 1))] = 19600, N[0x3bb9, ((2, 0), (2, 1))] = 1
Updated Q[0x2d6e, ((0, 1), (1, 1))] = 19600, N[0x2d6e, ((0, 1), (1, 1))] = 1

--- Simulation 247 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.2848820086, 16803.2848820086, 21988.22768913868, 16803.2848820086, 19603.2848820086]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bb8, Score: 8400
Depth 1: State = 0x3bb8, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb8: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x37de, Score: 11200
Depth 2: State = 0x37de, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37de: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3bbf, Score: 14000
Depth 3: State = 0x3bbf, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3bbf: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x3c1e, Score: 16800
Depth 4: State = 0x3c1e, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1e: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bd7, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5340700, N[0x3c25, ((2, 3), (2, 4))] = 243
Updated Q[0x3bb8, ((1, 3), (1, 4))] = 19600, N[0x3bb8, ((1, 3), (1, 4))] = 1
Updated Q[0x37de, ((0, 3), (1, 3))] = 19600, N[0x37de, ((0, 3), (1, 3))] = 1
Updated Q[0x3bbf, ((0, 2), (0, 3))] = 19600, N[0x3bbf, ((0, 2), (0, 3))] = 1
Updated Q[0x3c1e, ((0, 2), (1, 2))] = 19600, N[0x3c1e, ((0, 2), (1, 2))] = 1

--- Simulation 248 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.286092077193, 16803.286092077193, 21978.400103316562, 16803.286092077193, 19603.286092077193]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3825, Score: 14000
Depth 2: State = 0x3825, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3825: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x440f, Score: 19600
Depth 3: State = 0x440f, Legal Moves = [((1, 1), (1, 2)), ((2, 1), (3, 1))]
UCB1 values for moves at state 0x440f: [inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x43c7, Score: 22400
Depth 4: State = 0x43c7, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 1), (3, 1))]
UCB1 values for moves at state 0x43c7: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x458e, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5365900, N[0x3c25, ((2, 3), (2, 4))] = 244
Updated Q[0x3c24, ((1, 3), (1, 4))] = 25200, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x3825, ((2, 0), (2, 1))] = 25200, N[0x3825, ((2, 0), (2, 1))] = 1
Updated Q[0x440f, ((1, 1), (1, 2))] = 25200, N[0x440f, ((1, 1), (1, 2))] = 1
Updated Q[0x43c7, ((0, 1), (0, 2))] = 25200, N[0x43c7, ((0, 1), (0, 2))] = 1

--- Simulation 249 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.28729681387, 16803.28729681387, 21991.60389023668, 16803.28729681387, 19603.28729681387]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [27201.16557645562, 16801.16557645562, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3bbc, Score: 8400
Depth 2: State = 0x3bbc, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3bbc: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c61, Score: 11200
Depth 3: State = 0x3c61, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c61: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x39bc, Score: 14000
Depth 4: State = 0x39bc, Legal Moves = [((1, 0), (1, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x39bc: [inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x3c61, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5382700, N[0x3c25, ((2, 3), (2, 4))] = 245
Updated Q[0x3c24, ((0, 4), (1, 4))] = 16800, N[0x3c24, ((0, 4), (1, 4))] = 1
Updated Q[0x3bbc, ((1, 2), (2, 2))] = 16800, N[0x3bbc, ((1, 2), (2, 2))] = 1
Updated Q[0x3c61, ((2, 0), (2, 1))] = 16800, N[0x3c61, ((2, 0), (2, 1))] = 1
Updated Q[0x39bc, ((1, 0), (1, 1))] = 16800, N[0x39bc, ((1, 0), (1, 1))] = 1

--- Simulation 250 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.288496263805, 16803.288496263805, 21970.414175952355, 16803.288496263805, 19603.288496263805]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x495e, Score: 8400
Depth 2: State = 0x495e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x495e: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4852, Score: 11200
Depth 3: State = 0x4852, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4852: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x57a6, Score: 21700
Depth 4: State = 0x57a6, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x57a6: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4693, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5407200, N[0x3c25, ((2, 3), (2, 4))] = 246
Updated Q[0x3c25, ((0, 0), (0, 1))] = 24500, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x495e, ((1, 3), (2, 3))] = 24500, N[0x495e, ((1, 3), (2, 3))] = 1
Updated Q[0x4852, ((0, 2), (1, 2))] = 24500, N[0x4852, ((0, 2), (1, 2))] = 1
Updated Q[0x57a6, ((0, 2), (1, 2))] = 24500, N[0x57a6, ((0, 2), (1, 2))] = 1

--- Simulation 251 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.28969047161, 16803.28969047161, 21980.69754788184, 16803.28969047161, 19603.28969047161]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c4d, Score: 14000
Depth 1: State = 0x3c4d, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4d: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x1f51, Score: 16800
Depth 2: State = 0x1f51, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1f51: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x22d3, Score: 19600
Depth 3: State = 0x22d3, Legal Moves = [((0, 1), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x22d3: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x2346, Score: 22400
Depth 4: State = 0x2346, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2346: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x29c3, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5432400, N[0x3c25, ((2, 3), (2, 4))] = 247
Updated Q[0x3c4d, ((0, 0), (1, 0))] = 25200, N[0x3c4d, ((0, 0), (1, 0))] = 1
Updated Q[0x1f51, ((1, 3), (2, 3))] = 25200, N[0x1f51, ((1, 3), (2, 3))] = 1
Updated Q[0x22d3, ((0, 1), (1, 1))] = 25200, N[0x22d3, ((0, 1), (1, 1))] = 1
Updated Q[0x2346, ((1, 0), (2, 0))] = 25200, N[0x2346, ((1, 0), (2, 0))] = 1

--- Simulation 252 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.290879481337, 16803.290879481337, 21993.731660853555, 16803.290879481337, 19603.290879481337]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.648374031523, 27301.648374031523, 27701.648374031523, 36101.64837403152, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x5434, Score: 16800
Depth 2: State = 0x5434, Legal Moves = [((1, 3), (1, 4)), ((2, 3), (2, 4))]
UCB1 values for moves at state 0x5434: [inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x5431, Score: 22400
Depth 3: State = 0x5431, Legal Moves = [((1, 4), (2, 4))]
UCB1 values for moves at state 0x5431: [inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x53b4, Score: 25200
Depth 4: State = 0x53b4, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5457600, N[0x3c25, ((2, 3), (2, 4))] = 248
Updated Q[0x3c24, ((3, 0), (3, 1))] = 25200, N[0x3c24, ((3, 0), (3, 1))] = 1
Updated Q[0x5434, ((1, 3), (1, 4))] = 25200, N[0x5434, ((1, 3), (1, 4))] = 1
Updated Q[0x5431, ((1, 4), (2, 4))] = 25200, N[0x5431, ((1, 4), (2, 4))] = 1

--- Simulation 253 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.2920633365, 16803.2920633365, 22006.66065913414, 16803.2920633365, 19603.2920633365]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14000.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c5d, Score: 11200
Depth 2: State = 0x3c5d, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5d: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3865, Score: 14000
Depth 3: State = 0x3865, Legal Moves = [((2, 2), (3, 2))]
UCB1 values for moves at state 0x3865: [inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x380e, Score: 16800
Depth 4: State = 0x380e, Legal Moves = [((0, 1), (0, 2)), ((1, 3), (2, 3))]
UCB1 values for moves at state 0x380e: [inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3a92, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5477200, N[0x3c25, ((2, 3), (2, 4))] = 249
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3c5d, ((2, 0), (2, 1))] = 19600, N[0x3c5d, ((2, 0), (2, 1))] = 1
Updated Q[0x3865, ((2, 2), (3, 2))] = 19600, N[0x3865, ((2, 2), (3, 2))] = 1
Updated Q[0x380e, ((0, 1), (0, 2))] = 19600, N[0x380e, ((0, 1), (0, 2))] = 1

--- Simulation 254 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.293242080064, 16803.293242080064, 21996.995849331273, 16803.293242080064, 19603.293242080064]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 44201.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37ed, Score: 11200
Depth 2: State = 0x37ed, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37ed: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5570, Score: 14000
Depth 3: State = 0x5570, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5570: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x52df, Score: 16800
Depth 4: State = 0x52df, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x52df: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x56d7, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5496800, N[0x3c25, ((2, 3), (2, 4))] = 250
Updated Q[0x3c25, ((1, 3), (2, 3))] = 19600, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x37ed, ((1, 2), (1, 3))] = 19600, N[0x37ed, ((1, 2), (1, 3))] = 1
Updated Q[0x5570, ((1, 3), (1, 4))] = 19600, N[0x5570, ((1, 3), (1, 4))] = 1
Updated Q[0x52df, ((2, 0), (2, 1))] = 19600, N[0x52df, ((2, 0), (2, 1))] = 1

--- Simulation 255 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.294415754477, 16803.294415754477, 21987.408357146876, 16803.294415754477, 19603.294415754477]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [21701.16557645562, 22401.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x5675, Score: 16800
Depth 2: State = 0x5675, Legal Moves = [((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x5675: [inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x567c, Score: 19600
Depth 3: State = 0x567c, Legal Moves = [((0, 2), (0, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x567c: [inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x56de, Score: 22400
Depth 4: State = 0x56de, Legal Moves = [((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x56de: [inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x5635, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5522000, N[0x3c25, ((2, 3), (2, 4))] = 251
Updated Q[0x3c25, ((2, 0), (2, 1))] = 25200, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x5675, ((2, 3), (2, 4))] = 25200, N[0x5675, ((2, 3), (2, 4))] = 1
Updated Q[0x567c, ((0, 2), (0, 3))] = 25200, N[0x567c, ((0, 2), (0, 3))] = 1
Updated Q[0x56de, ((2, 2), (3, 2))] = 25200, N[0x56de, ((2, 2), (3, 2))] = 1

--- Simulation 256 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.29558440167, 16803.29558440167, 22000.208015442928, 16803.29558440167, 19603.29558440167]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14001.16557645562, 19601.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36d8, Score: 8400
Depth 2: State = 0x36d8, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x36d8: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x15eb, Score: 11200
Depth 3: State = 0x15eb, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x15eb: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x1587, Score: 14000
Depth 4: State = 0x1587, Legal Moves = [((0, 1), (0, 2)), ((1, 3), (1, 4)), ((2, 3), (2, 4))]
UCB1 values for moves at state 0x1587: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x56a3, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5544400, N[0x3c25, ((2, 3), (2, 4))] = 252
Updated Q[0x3c24, ((2, 0), (2, 1))] = 22400, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x36d8, ((0, 0), (0, 1))] = 22400, N[0x36d8, ((0, 0), (0, 1))] = 1
Updated Q[0x15eb, ((4, 1), (4, 2))] = 22400, N[0x15eb, ((4, 1), (4, 2))] = 1
Updated Q[0x1587, ((0, 1), (0, 2))] = 22400, N[0x1587, ((0, 1), (0, 2))] = 1

--- Simulation 257 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.296748063043, 16803.296748063043, 22001.794977194684, 16803.296748063043, 19603.296748063043]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3d5d, Score: 19300
Depth 1: State = 0x3d5d, Legal Moves = [((0, 1), (0, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d5d: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x39a5, Score: 22100
Depth 2: State = 0x39a5, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39a5: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3932, Score: 24900
Depth 3: State = 0x3932, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3932: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x36b8, Score: 30500
Depth 4: State = 0x36b8, Legal Moves = [((0, 2), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 0), (4, 0)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x36b8: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x384f, Score: 33300
End of simulation with depth 5. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5577700, N[0x3c25, ((2, 3), (2, 4))] = 253
Updated Q[0x3d5d, ((0, 1), (0, 2))] = 33300, N[0x3d5d, ((0, 1), (0, 2))] = 1
Updated Q[0x39a5, ((1, 3), (1, 4))] = 33300, N[0x39a5, ((1, 3), (1, 4))] = 1
Updated Q[0x3932, ((1, 0), (1, 1))] = 33300, N[0x3932, ((1, 0), (1, 1))] = 1
Updated Q[0x36b8, ((0, 2), (1, 2))] = 33300, N[0x36b8, ((0, 2), (1, 2))] = 1

--- Simulation 258 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.297906779517, 16803.297906779517, 22046.452396911336, 16803.297906779517, 19603.297906779517]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x49ab, Score: 8400
Depth 2: State = 0x49ab, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x49ab: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x43d5, Score: 11200
Depth 3: State = 0x43d5, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43d5: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4528, Score: 14000
Depth 4: State = 0x4528, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5591700, N[0x3c25, ((2, 3), (2, 4))] = 254
Updated Q[0x3c24, ((0, 0), (0, 1))] = 14000, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x49ab, ((1, 3), (1, 4))] = 14000, N[0x49ab, ((1, 3), (1, 4))] = 1
Updated Q[0x43d5, ((2, 0), (2, 1))] = 14000, N[0x43d5, ((2, 0), (2, 1))] = 1

--- Simulation 259 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.299060591507, 16803.299060591507, 22014.773930605825, 16803.299060591507, 19603.299060591507]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [33300.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x39b9, Score: 11200
Depth 2: State = 0x39b9, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39b9: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3b0c, Score: 14000
Depth 3: State = 0x3b0c, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 1), (2, 2)), ((2, 2), (3, 2))]
UCB1 values for moves at state 0x3b0c: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3823, Score: 19600
Depth 4: State = 0x3823, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x3823: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3d93, Score: 29400
End of simulation with depth 5. Reward (Score): 29400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5621100, N[0x3c25, ((2, 3), (2, 4))] = 255
Updated Q[0x3c25, ((1, 3), (2, 3))] = 29400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x39b9, ((2, 0), (2, 1))] = 29400, N[0x39b9, ((2, 0), (2, 1))] = 1
Updated Q[0x3b0c, ((0, 1), (1, 1))] = 29400, N[0x3b0c, ((0, 1), (1, 1))] = 1
Updated Q[0x3823, ((1, 2), (2, 2))] = 29400, N[0x3823, ((1, 2), (2, 2))] = 1

--- Simulation 260 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.300209538942, 16803.300209538942, 22043.736078902602, 16803.300209538942, 19603.300209538942]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x399a, Score: 14000
Depth 2: State = 0x399a, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x399a: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1d47, Score: 16800
Depth 3: State = 0x1d47, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1d47: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x1c57, Score: 19600
Depth 4: State = 0x1c57, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1c57: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x2d47, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5643500, N[0x3c25, ((2, 3), (2, 4))] = 256
Updated Q[0x3c25, ((1, 2), (2, 2))] = 22400, N[0x3c25, ((1, 2), (2, 2))] = 1
Updated Q[0x399a, ((0, 2), (1, 2))] = 22400, N[0x399a, ((0, 2), (1, 2))] = 1
Updated Q[0x1d47, ((0, 1), (0, 2))] = 22400, N[0x1d47, ((0, 1), (0, 2))] = 1
Updated Q[0x1c57, ((1, 0), (2, 0))] = 22400, N[0x1c57, ((1, 0), (2, 0))] = 1

--- Simulation 261 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.30135366127, 16803.30135366127, 22045.12820960383, 16803.30135366127, 19603.30135366127]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c03, Score: 8400
Depth 1: State = 0x3c03, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c03: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c40, Score: 16800
Depth 2: State = 0x3c40, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (1, 3)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c40: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x484c, Score: 19600
Depth 3: State = 0x484c, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x484c: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x4aae, Score: 22400
Depth 4: State = 0x4aae, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aae: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x47c4, Score: 36100
End of simulation with depth 5. Reward (Score): 36100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5679600, N[0x3c25, ((2, 3), (2, 4))] = 257
Updated Q[0x3c03, ((1, 3), (2, 3))] = 36100, N[0x3c03, ((1, 3), (2, 3))] = 1
Updated Q[0x3c40, ((0, 0), (1, 0))] = 36100, N[0x3c40, ((0, 0), (1, 0))] = 1
Updated Q[0x484c, ((0, 1), (1, 1))] = 36100, N[0x484c, ((0, 1), (1, 1))] = 1
Updated Q[0x4aae, ((2, 0), (2, 1))] = 36100, N[0x4aae, ((2, 0), (2, 1))] = 1

--- Simulation 262 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.30249299747, 16803.30249299747, 22099.816898794856, 16803.30249299747, 19603.30249299747]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc7, Score: 8400
Depth 1: State = 0x3bc7, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc7: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3871, Score: 11200
Depth 2: State = 0x3871, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3871: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3844, Score: 24900
Depth 3: State = 0x3844, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3844: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3942, Score: 29800
Depth 4: State = 0x3942, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3942: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x36be, Score: 35400
End of simulation with depth 5. Reward (Score): 35400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5715000, N[0x3c25, ((2, 3), (2, 4))] = 258
Updated Q[0x3bc7, ((1, 3), (2, 3))] = 35400, N[0x3bc7, ((1, 3), (2, 3))] = 1
Updated Q[0x3871, ((0, 3), (1, 3))] = 35400, N[0x3871, ((0, 3), (1, 3))] = 1
Updated Q[0x3844, ((0, 2), (1, 2))] = 35400, N[0x3844, ((0, 2), (1, 2))] = 1
Updated Q[0x3942, ((0, 1), (0, 2))] = 35400, N[0x3942, ((0, 1), (0, 2))] = 1

--- Simulation 263 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.303627586058, 16803.303627586058, 22151.36846556742, 16803.303627586058, 19603.303627586058]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c1b, Score: 8400
Depth 1: State = 0x3c1b, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1b: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3873, Score: 19300
Depth 2: State = 0x3873, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3873: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x39c6, Score: 22100
Depth 3: State = 0x39c6, Legal Moves = [((0, 2), (1, 2)), ((2, 1), (3, 1))]
UCB1 values for moves at state 0x39c6: [inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x37c7, Score: 24900
Depth 4: State = 0x37c7, Legal Moves = [((2, 1), (3, 1)), ((2, 2), (2, 3))]
UCB1 values for moves at state 0x37c7: [inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x3696, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5742700, N[0x3c25, ((2, 3), (2, 4))] = 259
Updated Q[0x3c1b, ((0, 3), (1, 3))] = 27700, N[0x3c1b, ((0, 3), (1, 3))] = 1
Updated Q[0x3873, ((2, 0), (2, 1))] = 27700, N[0x3873, ((2, 0), (2, 1))] = 1
Updated Q[0x39c6, ((0, 2), (1, 2))] = 27700, N[0x39c6, ((0, 2), (1, 2))] = 1
Updated Q[0x37c7, ((2, 1), (3, 1))] = 27700, N[0x37c7, ((2, 1), (3, 1))] = 1

--- Simulation 264 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.304757465092, 16803.304757465092, 22172.79222022415, 16803.304757465092, 19603.304757465092]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4afa, Score: 8400
Depth 2: State = 0x4afa, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4afa: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x43c7, Score: 11200
Depth 3: State = 0x43c7, Legal Moves = [((0, 1), (0, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43c7: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4565, Score: 14000
Depth 4: State = 0x4565, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4565: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4412, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5759500, N[0x3c25, ((2, 3), (2, 4))] = 260
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4afa, ((1, 3), (2, 3))] = 16800, N[0x4afa, ((1, 3), (2, 3))] = 1
Updated Q[0x43c7, ((0, 1), (0, 2))] = 16800, N[0x43c7, ((0, 1), (0, 2))] = 1
Updated Q[0x4565, ((2, 0), (2, 1))] = 16800, N[0x4565, ((2, 0), (2, 1))] = 1

--- Simulation 265 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.30588267217, 16803.30588267217, 22152.12809906299, 16803.30588267217, 19603.30588267217]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d4f, Score: 16100
Depth 2: State = 0x3d4f, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d4f: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3d59, Score: 18900
Depth 3: State = 0x3d59, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d59: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36bb, Score: 21700
Depth 4: State = 0x36bb, Legal Moves = [((2, 3), (3, 3))]
UCB1 values for moves at state 0x36bb: [inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3702, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5786800, N[0x3c25, ((2, 3), (2, 4))] = 261
Updated Q[0x3c25, ((1, 3), (2, 3))] = 27300, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3d4f, ((1, 2), (2, 2))] = 27300, N[0x3d4f, ((1, 2), (2, 2))] = 1
Updated Q[0x3d59, ((2, 0), (2, 1))] = 27300, N[0x3d59, ((2, 0), (2, 1))] = 1
Updated Q[0x36bb, ((2, 3), (3, 3))] = 27300, N[0x36bb, ((2, 3), (3, 3))] = 1

--- Simulation 266 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.30700324447, 16803.30700324447, 22171.852207940487, 16803.30700324447, 19603.30700324447]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc3, Score: 11200
Depth 1: State = 0x3bc3, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc3: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d7c, Score: 14000
Depth 2: State = 0x3d7c, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d7c: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x565d, Score: 16800
Depth 3: State = 0x565d, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x565d: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5661, Score: 19600
Depth 4: State = 0x5661, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5661: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5630, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5812000, N[0x3c25, ((2, 3), (2, 4))] = 262
Updated Q[0x3bc3, ((1, 3), (2, 3))] = 25200, N[0x3bc3, ((1, 3), (2, 3))] = 1
Updated Q[0x3d7c, ((1, 2), (1, 3))] = 25200, N[0x3d7c, ((1, 2), (1, 3))] = 1
Updated Q[0x565d, ((1, 2), (1, 3))] = 25200, N[0x565d, ((1, 2), (1, 3))] = 1
Updated Q[0x5661, ((1, 2), (1, 3))] = 25200, N[0x5661, ((1, 2), (1, 3))] = 1

--- Simulation 267 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.308119218713, 16803.308119218713, 22183.410483158095, 16803.308119218713, 19603.308119218713]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c24, Score: 8400
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4804, Score: 11200
Depth 3: State = 0x4804, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4804: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x5693, Score: 21700
Depth 4: State = 0x5693, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5693: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x5129, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5836500, N[0x3c25, ((2, 3), (2, 4))] = 263
Updated Q[0x3c24, ((0, 4), (1, 4))] = 24500, N[0x3c24, ((0, 4), (1, 4))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 24500, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4804, ((0, 2), (1, 2))] = 24500, N[0x4804, ((0, 2), (1, 2))] = 1
Updated Q[0x5693, ((1, 3), (2, 3))] = 24500, N[0x5693, ((1, 3), (2, 3))] = 1

--- Simulation 268 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.3092306312, 16803.3092306312, 22192.219265027852, 16803.3092306312, 19603.3092306312]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3871, Score: 13300
Depth 2: State = 0x3871, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3871: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3874, Score: 16100
Depth 3: State = 0x3874, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3874: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3874, Score: 18900
Depth 4: State = 0x3874, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1))]
UCB1 values for moves at state 0x3874: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4ada, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5858200, N[0x3c25, ((2, 3), (2, 4))] = 264
Updated Q[0x3c25, ((1, 3), (2, 3))] = 21700, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3871, ((1, 3), (1, 4))] = 21700, N[0x3871, ((1, 3), (1, 4))] = 1
Updated Q[0x3874, ((2, 0), (2, 1))] = 21700, N[0x3874, ((2, 0), (2, 1))] = 1
Updated Q[0x3874, ((1, 1), (2, 1))] = 21700, N[0x3874, ((1, 1), (2, 1))] = 1

--- Simulation 269 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.310337517807, 16803.310337517807, 22190.355252341873, 16803.310337517807, 19603.310337517807]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47cd, Score: 8400
Depth 2: State = 0x47cd, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47cd: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x479e, Score: 11200
Depth 3: State = 0x479e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x479e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x300f, Score: 19600
Depth 4: State = 0x300f, Legal Moves = [((0, 1), (1, 1))]
UCB1 values for moves at state 0x300f: [inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x22b1, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5883400, N[0x3c25, ((2, 3), (2, 4))] = 265
Updated Q[0x3c24, ((0, 0), (0, 1))] = 25200, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47cd, ((1, 3), (2, 3))] = 25200, N[0x47cd, ((1, 3), (2, 3))] = 1
Updated Q[0x479e, ((2, 0), (2, 1))] = 25200, N[0x479e, ((2, 0), (2, 1))] = 1
Updated Q[0x300f, ((0, 1), (1, 1))] = 25200, N[0x300f, ((0, 1), (1, 1))] = 1

--- Simulation 270 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.311439914, 16803.311439914, 22201.712854099147, 16803.311439914, 19603.311439914]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [18901.467405903557, 22401.467405903557, 24501.467405903557, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d78, Score: 8400
Depth 2: State = 0x3d78, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 1), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d78: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x10c0, Score: 16800
Depth 3: State = 0x10c0, Legal Moves = [((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x10c0: [inf, inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x109a, Score: 30500
Depth 4: State = 0x109a, Legal Moves = [((1, 0), (2, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x109a: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x11cb, Score: 41400
End of simulation with depth 5. Reward (Score): 41400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5924800, N[0x3c25, ((2, 3), (2, 4))] = 266
Updated Q[0x3c25, ((2, 0), (2, 1))] = 41400, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3d78, ((0, 0), (0, 1))] = 41400, N[0x3d78, ((0, 0), (0, 1))] = 1
Updated Q[0x10c0, ((1, 4), (2, 4))] = 41400, N[0x10c0, ((1, 4), (2, 4))] = 1
Updated Q[0x109a, ((1, 0), (2, 0))] = 41400, N[0x109a, ((1, 0), (2, 0))] = 1

--- Simulation 271 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.312537854825, 16803.312537854825, 22273.88731525355, 16803.312537854825, 19603.312537854825]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 25201.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d29, Score: 11200
Depth 2: State = 0x3d29, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d29: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3930, Score: 14000
Depth 3: State = 0x3930, Legal Moves = [((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3930: [inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x3974, Score: 16800
Depth 4: State = 0x3974, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3974: [inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x39a8, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5944400, N[0x3c25, ((2, 3), (2, 4))] = 267
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3d29, ((2, 0), (2, 1))] = 19600, N[0x3d29, ((2, 0), (2, 1))] = 1
Updated Q[0x3930, ((2, 2), (3, 2))] = 19600, N[0x3930, ((2, 2), (3, 2))] = 1
Updated Q[0x3974, ((1, 1), (1, 2))] = 19600, N[0x3974, ((1, 1), (1, 2))] = 1

--- Simulation 272 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.31363137493, 16803.31363137493, 22263.873202931867, 16803.31363137493, 19603.31363137493]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3980, Score: 8400
Depth 2: State = 0x3980, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3980: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2932, Score: 11200
Depth 3: State = 0x2932, Legal Moves = [((2, 2), (2, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2932: [inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x29db, Score: 14000
Depth 4: State = 0x29db, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x29db: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x29c3, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5961200, N[0x3c25, ((2, 3), (2, 4))] = 268
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3980, ((0, 0), (0, 1))] = 16800, N[0x3980, ((0, 0), (0, 1))] = 1
Updated Q[0x2932, ((2, 2), (2, 3))] = 16800, N[0x2932, ((2, 2), (2, 3))] = 1
Updated Q[0x29db, ((2, 0), (2, 1))] = 16800, N[0x29db, ((2, 0), (2, 1))] = 1

--- Simulation 273 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.31472050857, 16803.31472050857, 22243.486060870917, 16803.31472050857, 19603.31472050857]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47c4, Score: 8400
Depth 2: State = 0x47c4, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c4: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4943, Score: 11200
Depth 3: State = 0x4943, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4943: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4859, Score: 16800
Depth 4: State = 0x4859, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4859: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x47ac, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5986400, N[0x3c25, ((2, 3), (2, 4))] = 269
Updated Q[0x3c25, ((0, 0), (0, 1))] = 25200, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x47c4, ((1, 3), (2, 3))] = 25200, N[0x47c4, ((1, 3), (2, 3))] = 1
Updated Q[0x4943, ((0, 1), (0, 2))] = 25200, N[0x4943, ((0, 1), (0, 2))] = 1
Updated Q[0x4859, ((1, 1), (2, 1))] = 25200, N[0x4859, ((1, 1), (2, 1))] = 1

--- Simulation 274 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.315805289603, 16803.315805289603, 22254.477261153395, 16803.315805289603, 19603.315805289603]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46b2, Score: 8400
Depth 2: State = 0x46b2, Legal Moves = [((0, 3), (0, 4)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x46b2: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x46c2, Score: 14000
Depth 3: State = 0x46c2, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46c2: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x46f8, Score: 16800
Depth 4: State = 0x46f8, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46f8: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x47c3, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6006000, N[0x3c25, ((2, 3), (2, 4))] = 270
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x46b2, ((0, 3), (0, 4))] = 19600, N[0x46b2, ((0, 3), (0, 4))] = 1
Updated Q[0x46c2, ((0, 2), (1, 2))] = 19600, N[0x46c2, ((0, 2), (1, 2))] = 1
Updated Q[0x46f8, ((1, 3), (2, 3))] = 19600, N[0x46f8, ((1, 3), (2, 3))] = 1

--- Simulation 275 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.3168857515, 16803.3168857515, 22244.646303682974, 16803.3168857515, 19603.3168857515]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bc7, Score: 11200
Depth 2: State = 0x3bc7, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc7: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d19, Score: 14000
Depth 3: State = 0x3d19, Legal Moves = [((0, 1), (0, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 1), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d19: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3ab7, Score: 24900
Depth 4: State = 0x3ab7, Legal Moves = [((0, 2), (1, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3ab7: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x454e, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6033700, N[0x3c25, ((2, 3), (2, 4))] = 271
Updated Q[0x3c24, ((1, 2), (2, 2))] = 27700, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3bc7, ((2, 0), (2, 1))] = 27700, N[0x3bc7, ((2, 0), (2, 1))] = 1
Updated Q[0x3d19, ((0, 1), (0, 2))] = 27700, N[0x3d19, ((0, 1), (0, 2))] = 1
Updated Q[0x3ab7, ((0, 2), (1, 2))] = 27700, N[0x3ab7, ((0, 2), (1, 2))] = 1

--- Simulation 276 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.31796192736, 16803.31796192736, 22264.777197589785, 16803.31796192736, 19603.31796192736]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14001.16557645562, 22401.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3964, Score: 13300
Depth 2: State = 0x3964, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3964: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3957, Score: 16100
Depth 3: State = 0x3957, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3957: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3957, Score: 18900
Depth 4: State = 0x3957, Legal Moves = [((2, 1), (3, 1))]
UCB1 values for moves at state 0x3957: [inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x368c, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6055400, N[0x3c25, ((2, 3), (2, 4))] = 272
Updated Q[0x3c24, ((1, 3), (2, 3))] = 21700, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3964, ((1, 3), (2, 3))] = 21700, N[0x3964, ((1, 3), (2, 3))] = 1
Updated Q[0x3957, ((2, 0), (2, 1))] = 21700, N[0x3957, ((2, 0), (2, 1))] = 1
Updated Q[0x3957, ((2, 1), (3, 1))] = 21700, N[0x3957, ((2, 1), (3, 1))] = 1

--- Simulation 277 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.319033849904, 16803.319033849904, 22262.701245987326, 16803.319033849904, 19603.319033849904]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c44, Score: 8400
Depth 1: State = 0x3c44, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c44: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x15e2, Score: 11200
Depth 2: State = 0x15e2, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x15e2: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x1f48, Score: 16800
Depth 3: State = 0x1f48, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1f48: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1df5, Score: 19600
Depth 4: State = 0x1df5, Legal Moves = [((4, 0), (4, 1))]
UCB1 values for moves at state 0x1df5: [inf]
Selected move: ((4, 0), (4, 1))
New board state after move: 0x209a, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6077800, N[0x3c25, ((2, 3), (2, 4))] = 273
Updated Q[0x3c44, ((0, 0), (1, 0))] = 22400, N[0x3c44, ((0, 0), (1, 0))] = 1
Updated Q[0x15e2, ((0, 0), (1, 0))] = 22400, N[0x15e2, ((0, 0), (1, 0))] = 1
Updated Q[0x1f48, ((2, 0), (2, 1))] = 22400, N[0x1f48, ((2, 0), (2, 1))] = 1
Updated Q[0x1df5, ((4, 0), (4, 1))] = 22400, N[0x1df5, ((4, 0), (4, 1))] = 1

--- Simulation 278 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.32010155148, 16803.32010155148, 22263.204604690683, 16803.32010155148, 19603.32010155148]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 19601.467405903557, 27701.467405903557, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c21, Score: 10500
Depth 2: State = 0x3c21, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c21: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36d6, Score: 13300
Depth 3: State = 0x36d6, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x36d6: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x3721, Score: 16100
Depth 4: State = 0x3721, Legal Moves = [((2, 1), (2, 2))]
UCB1 values for moves at state 0x3721: [inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x3873, Score: 18900
End of simulation with depth 5. Reward (Score): 18900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6096700, N[0x3c25, ((2, 3), (2, 4))] = 274
Updated Q[0x3c24, ((2, 3), (2, 4))] = 18900, N[0x3c24, ((2, 3), (2, 4))] = 1
Updated Q[0x3c21, ((2, 0), (2, 1))] = 18900, N[0x3c21, ((2, 0), (2, 1))] = 1
Updated Q[0x36d6, ((4, 1), (4, 2))] = 18900, N[0x36d6, ((4, 1), (4, 2))] = 1
Updated Q[0x3721, ((2, 1), (2, 2))] = 18900, N[0x3721, ((2, 1), (2, 2))] = 1

--- Simulation 279 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.321165064077, 16803.321165064077, 22250.930565926377, 16803.321165064077, 19603.321165064077]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c43, Score: 8400
Depth 2: State = 0x3c43, Legal Moves = [((0, 0), (1, 0)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c43: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3806, Score: 11200
Depth 3: State = 0x3806, Legal Moves = [((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3806: [inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x37bc, Score: 14000
Depth 4: State = 0x37bc, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37bc: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3673, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6113500, N[0x3c25, ((2, 3), (2, 4))] = 275
Updated Q[0x3c24, ((0, 2), (1, 2))] = 16800, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c43, ((0, 0), (1, 0))] = 16800, N[0x3c43, ((0, 0), (1, 0))] = 1
Updated Q[0x3806, ((0, 4), (1, 4))] = 16800, N[0x3806, ((0, 4), (1, 4))] = 1
Updated Q[0x37bc, ((0, 1), (1, 1))] = 16800, N[0x37bc, ((0, 1), (1, 1))] = 1

--- Simulation 280 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.322224419328, 16803.322224419328, 22231.109428579424, 16803.322224419328, 19603.322224419328]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 19601.16557645562, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3812, Score: 21400
Depth 2: State = 0x3812, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3812: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3852, Score: 24200
Depth 3: State = 0x3852, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3852: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3826, Score: 29800
Depth 4: State = 0x3826, Legal Moves = [((1, 3), (1, 4))]
UCB1 values for moves at state 0x3826: [inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3bde, Score: 32600
End of simulation with depth 5. Reward (Score): 32600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6146100, N[0x3c25, ((2, 3), (2, 4))] = 276
Updated Q[0x3c24, ((1, 3), (2, 3))] = 32600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3812, ((1, 3), (2, 3))] = 32600, N[0x3812, ((1, 3), (2, 3))] = 1
Updated Q[0x3852, ((2, 0), (2, 1))] = 32600, N[0x3852, ((2, 0), (2, 1))] = 1
Updated Q[0x3826, ((1, 3), (1, 4))] = 32600, N[0x3826, ((1, 3), (1, 4))] = 1

--- Simulation 281 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.32327964851, 16803.32327964851, 22268.678298797327, 16803.32327964851, 19603.32327964851]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bff, Score: 8400
Depth 1: State = 0x3bff, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bff: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3870, Score: 11200
Depth 2: State = 0x3870, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3870: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3c62, Score: 16800
Depth 3: State = 0x3c62, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c62: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x3c62, Score: 19600
Depth 4: State = 0x3c62, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c62: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x3c4c, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6168500, N[0x3c25, ((2, 3), (2, 4))] = 277
Updated Q[0x3bff, ((1, 3), (2, 3))] = 22400, N[0x3bff, ((1, 3), (2, 3))] = 1
Updated Q[0x3870, ((0, 3), (1, 3))] = 22400, N[0x3870, ((0, 3), (1, 3))] = 1
Updated Q[0x3c62, ((1, 0), (1, 1))] = 22400, N[0x3c62, ((1, 0), (1, 1))] = 1
Updated Q[0x3c62, ((1, 1), (1, 2))] = 22400, N[0x3c62, ((1, 1), (1, 2))] = 1

--- Simulation 282 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.32433078256, 16803.32433078256, 22269.15280827058, 16803.32433078256, 19603.32433078256]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 27701.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d77, Score: 8400
Depth 2: State = 0x3d77, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d77: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x529d, Score: 11200
Depth 3: State = 0x529d, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x529d: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x5543, Score: 14000
Depth 4: State = 0x5543, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (2, 3)), ((2, 1), (3, 1)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x5543: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x5286, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6185300, N[0x3c25, ((2, 3), (2, 4))] = 278
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3d77, ((0, 0), (0, 1))] = 16800, N[0x3d77, ((0, 0), (0, 1))] = 1
Updated Q[0x529d, ((1, 0), (1, 1))] = 16800, N[0x529d, ((1, 0), (1, 1))] = 1
Updated Q[0x5543, ((0, 3), (1, 3))] = 16800, N[0x5543, ((0, 3), (1, 3))] = 1

--- Simulation 283 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.32537785207, 16803.32537785207, 22249.480018449478, 16803.32537785207, 19603.32537785207]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 22401.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d0e, Score: 11200
Depth 2: State = 0x3d0e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d0e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3996, Score: 16800
Depth 3: State = 0x3996, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2))]
UCB1 values for moves at state 0x3996: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x453c, Score: 19600
Depth 4: State = 0x453c, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2))]
UCB1 values for moves at state 0x453c: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x43c7, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6207700, N[0x3c25, ((2, 3), (2, 4))] = 279
Updated Q[0x3c24, ((1, 3), (2, 3))] = 22400, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3d0e, ((2, 0), (2, 1))] = 22400, N[0x3d0e, ((2, 0), (2, 1))] = 1
Updated Q[0x3996, ((0, 2), (1, 2))] = 22400, N[0x3996, ((0, 2), (1, 2))] = 1
Updated Q[0x453c, ((0, 1), (0, 2))] = 22400, N[0x453c, ((0, 1), (0, 2))] = 1

--- Simulation 284 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.326420887286, 16803.326420887286, 22250.01993613984, 16803.326420887286, 19603.326420887286]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 30001.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397f, Score: 8400
Depth 2: State = 0x397f, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397f: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2aaf, Score: 11200
Depth 3: State = 0x2aaf, Legal Moves = [((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2aaf: [inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x2aa2, Score: 14000
Depth 4: State = 0x2aa2, Legal Moves = [((1, 2), (1, 3)), ((1, 2), (2, 2)), ((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2aa2: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2aac, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6224500, N[0x3c25, ((2, 3), (2, 4))] = 280
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x397f, ((0, 0), (0, 1))] = 16800, N[0x397f, ((0, 0), (0, 1))] = 1
Updated Q[0x2aaf, ((2, 3), (2, 4))] = 16800, N[0x2aaf, ((2, 3), (2, 4))] = 1
Updated Q[0x2aa2, ((1, 2), (1, 3))] = 16800, N[0x2aa2, ((1, 2), (1, 3))] = 1

--- Simulation 285 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.327459918135, 16803.327459918135, 22230.55599662167, 16803.327459918135, 19603.327459918135]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 30501.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bc3, Score: 11200
Depth 2: State = 0x3bc3, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc3: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x1d96, Score: 14000
Depth 3: State = 0x1d96, Legal Moves = [((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1d96: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x14b0, Score: 19600
Depth 4: State = 0x14b0, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x14b0: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1477, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6246900, N[0x3c25, ((2, 3), (2, 4))] = 281
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3bc3, ((1, 2), (1, 3))] = 22400, N[0x3bc3, ((1, 2), (1, 3))] = 1
Updated Q[0x1d96, ((1, 2), (2, 2))] = 22400, N[0x1d96, ((1, 2), (2, 2))] = 1
Updated Q[0x14b0, ((0, 2), (1, 2))] = 22400, N[0x14b0, ((0, 2), (1, 2))] = 1

--- Simulation 286 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.32849497421, 16803.32849497421, 22231.159415455644, 16803.32849497421, 19603.32849497421]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14001.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37c0, Score: 16100
Depth 2: State = 0x37c0, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x37c0: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2293, Score: 21700
Depth 3: State = 0x2293, Legal Moves = [((1, 0), (2, 0)), ((1, 2), (2, 2)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x2293: [inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x484b, Score: 24500
Depth 4: State = 0x484b, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x484b: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x47ca, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6274200, N[0x3c25, ((2, 3), (2, 4))] = 282
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27300, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x37c0, ((2, 0), (2, 1))] = 27300, N[0x37c0, ((2, 0), (2, 1))] = 1
Updated Q[0x2293, ((1, 0), (2, 0))] = 27300, N[0x2293, ((1, 0), (2, 0))] = 1
Updated Q[0x484b, ((0, 2), (0, 3))] = 27300, N[0x484b, ((0, 2), (0, 3))] = 1

--- Simulation 287 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.329526084777, 16803.329526084777, 22249.134440605805, 16803.329526084777, 19603.329526084777]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3c69, Score: 11200
Depth 2: State = 0x3c69, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c69: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c06, Score: 14000
Depth 3: State = 0x3c06, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c06: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3961, Score: 16800
Depth 4: State = 0x3961, Legal Moves = [((1, 1), (2, 1))]
UCB1 values for moves at state 0x3961: [inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x5111, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6293800, N[0x3c25, ((2, 3), (2, 4))] = 283
Updated Q[0x3c24, ((1, 3), (1, 4))] = 19600, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x3c69, ((1, 3), (2, 3))] = 19600, N[0x3c69, ((1, 3), (2, 3))] = 1
Updated Q[0x3c06, ((2, 0), (2, 1))] = 19600, N[0x3c06, ((2, 0), (2, 1))] = 1
Updated Q[0x3961, ((1, 1), (2, 1))] = 19600, N[0x3961, ((1, 1), (2, 1))] = 1

--- Simulation 288 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.330553278796, 16803.330553278796, 22239.77395257379, 16803.330553278796, 19603.330553278796]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c3c, Score: 11200
Depth 2: State = 0x3c3c, Legal Moves = [((0, 0), (1, 0)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c3c: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x15da, Score: 14000
Depth 3: State = 0x15da, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x15da: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x15e1, Score: 16800
Depth 4: State = 0x15e1, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x15e1: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x12bb, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6324300, N[0x3c25, ((2, 3), (2, 4))] = 284
Updated Q[0x3c24, ((1, 3), (2, 3))] = 30500, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3c3c, ((0, 0), (1, 0))] = 30500, N[0x3c3c, ((0, 0), (1, 0))] = 1
Updated Q[0x15da, ((0, 2), (1, 2))] = 30500, N[0x15da, ((0, 2), (1, 2))] = 1
Updated Q[0x15e1, ((2, 0), (2, 1))] = 30500, N[0x15e1, ((2, 0), (2, 1))] = 1

--- Simulation 289 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.3315765849, 16803.3315765849, 22268.859664530177, 16803.3315765849, 19603.3315765849]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c6b, Score: 8400
Depth 2: State = 0x3c6b, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6b: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3db4, Score: 11200
Depth 3: State = 0x3db4, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3db4: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x564e, Score: 16800
Depth 4: State = 0x564e, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x564e: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x56da, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6346700, N[0x3c25, ((2, 3), (2, 4))] = 285
Updated Q[0x3c24, ((0, 2), (1, 2))] = 22400, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c6b, ((1, 3), (1, 4))] = 22400, N[0x3c6b, ((1, 3), (1, 4))] = 1
Updated Q[0x3db4, ((1, 2), (1, 3))] = 22400, N[0x3db4, ((1, 2), (1, 3))] = 1
Updated Q[0x564e, ((0, 3), (1, 3))] = 22400, N[0x564e, ((0, 3), (1, 3))] = 1

--- Simulation 290 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.33259603143, 16803.33259603143, 22269.320212969466, 16803.33259603143, 19603.33259603143]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x491f, Score: 8400
Depth 2: State = 0x491f, Legal Moves = [((0, 2), (0, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x491f: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x1447, Score: 11200
Depth 3: State = 0x1447, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1447: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x4a68, Score: 14000
Depth 4: State = 0x4a68, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a68: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4a68, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6363500, N[0x3c25, ((2, 3), (2, 4))] = 286
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x491f, ((0, 2), (0, 3))] = 16800, N[0x491f, ((0, 2), (0, 3))] = 1
Updated Q[0x1447, ((0, 0), (1, 0))] = 16800, N[0x1447, ((0, 0), (1, 0))] = 1
Updated Q[0x4a68, ((2, 0), (2, 1))] = 16800, N[0x4a68, ((2, 0), (2, 1))] = 1

--- Simulation 291 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.333611646405, 16803.333611646405, 22250.197120588993, 16803.333611646405, 19603.333611646405]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.467405903557, 19601.467405903557, 32601.467405903557, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x47cd, Score: 13300
Depth 2: State = 0x47cd, Legal Moves = [((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x47cd: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x4811, Score: 16100
Depth 3: State = 0x4811, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (2, 1)), ((1, 4), (2, 4)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4811: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x43d5, Score: 18900
Depth 4: State = 0x43d5, Legal Moves = [((1, 1), (2, 1)), ((1, 4), (2, 4)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x43d5: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x43cb, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6385200, N[0x3c25, ((2, 3), (2, 4))] = 287
Updated Q[0x3c24, ((2, 0), (2, 1))] = 21700, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x47cd, ((1, 1), (1, 2))] = 21700, N[0x47cd, ((1, 1), (1, 2))] = 1
Updated Q[0x4811, ((0, 3), (1, 3))] = 21700, N[0x4811, ((0, 3), (1, 3))] = 1
Updated Q[0x43d5, ((1, 1), (2, 1))] = 21700, N[0x43d5, ((1, 1), (2, 1))] = 1

--- Simulation 292 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.33462345755, 16803.33462345755, 22248.28046029237, 16803.33462345755, 19603.33462345755]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 19601.467405903557, 16801.467405903557, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c1d, Score: 13300
Depth 2: State = 0x3c1d, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1d: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3977, Score: 16100
Depth 3: State = 0x3977, Legal Moves = [((1, 1), (2, 1)), ((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3977: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x15bb, Score: 18900
Depth 4: State = 0x15bb, Legal Moves = [((1, 1), (2, 1)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x15bb: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x499d, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6409700, N[0x3c25, ((2, 3), (2, 4))] = 288
Updated Q[0x3c24, ((2, 3), (2, 4))] = 24500, N[0x3c24, ((2, 3), (2, 4))] = 1
Updated Q[0x3c1d, ((2, 0), (2, 1))] = 24500, N[0x3c1d, ((2, 0), (2, 1))] = 1
Updated Q[0x3977, ((1, 1), (2, 1))] = 24500, N[0x3977, ((1, 1), (2, 1))] = 1
Updated Q[0x15bb, ((1, 1), (2, 1))] = 24500, N[0x15bb, ((1, 1), (2, 1))] = 1

--- Simulation 293 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.335631492304, 16803.335631492304, 22256.099331748424, 16803.335631492304, 19603.335631492304]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.77609073765, 21701.77609073765, 16801.77609073765, 22401.77609073765, 24501.77609073765]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x1471, Score: 8400
Depth 2: State = 0x1471, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x1471: [inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3dbc, Score: 11200
Depth 3: State = 0x3dbc, Legal Moves = [((0, 3), (0, 4)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x3dbc: [inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3d59, Score: 14000
Depth 4: State = 0x3d59, Legal Moves = [((0, 4), (1, 4))]
UCB1 values for moves at state 0x3d59: [inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3db5, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6426500, N[0x3c25, ((2, 3), (2, 4))] = 289
Updated Q[0x3c25, ((3, 0), (3, 1))] = 41300, N[0x3c25, ((3, 0), (3, 1))] = 2
Updated Q[0x1471, ((0, 0), (1, 0))] = 16800, N[0x1471, ((0, 0), (1, 0))] = 1
Updated Q[0x3dbc, ((0, 3), (0, 4))] = 16800, N[0x3dbc, ((0, 3), (0, 4))] = 1
Updated Q[0x3d59, ((0, 4), (1, 4))] = 16800, N[0x3d59, ((0, 4), (1, 4))] = 1

--- Simulation 294 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.336635777796, 16803.336635777796, 22237.2204941461, 16803.336635777796, 19603.336635777796]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c27, Score: 8400
Depth 1: State = 0x3c27, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c27: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x393e, Score: 11200
Depth 2: State = 0x393e, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x393e: [inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x397e, Score: 14000
Depth 3: State = 0x397e, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x397e: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2981, Score: 16800
Depth 4: State = 0x2981, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2981: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x47ae, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6451700, N[0x3c25, ((2, 3), (2, 4))] = 290
Updated Q[0x3c27, ((1, 3), (2, 3))] = 25200, N[0x3c27, ((1, 3), (2, 3))] = 1
Updated Q[0x393e, ((1, 1), (1, 2))] = 25200, N[0x393e, ((1, 1), (1, 2))] = 1
Updated Q[0x397e, ((0, 0), (0, 1))] = 25200, N[0x397e, ((0, 0), (0, 1))] = 1
Updated Q[0x2981, ((2, 0), (2, 1))] = 25200, N[0x2981, ((2, 0), (2, 1))] = 1

--- Simulation 295 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.337636340882, 16803.337636340882, 22247.43737206482, 16803.337636340882, 19603.337636340882]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.77609073765, 27301.77609073765, 27701.77609073765, 36101.77609073765, 25201.77609073765]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x393f, Score: 22100
Depth 2: State = 0x393f, Legal Moves = [((0, 3), (0, 4)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x393f: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x393c, Score: 24900
Depth 3: State = 0x393c, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x393c: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x36d3, Score: 27700
Depth 4: State = 0x36d3, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d3: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3826, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6482200, N[0x3c25, ((2, 3), (2, 4))] = 291
Updated Q[0x3c24, ((2, 3), (3, 3))] = 66600, N[0x3c24, ((2, 3), (3, 3))] = 2
Updated Q[0x393f, ((0, 3), (0, 4))] = 30500, N[0x393f, ((0, 3), (0, 4))] = 1
Updated Q[0x393c, ((0, 2), (1, 2))] = 30500, N[0x393c, ((0, 2), (1, 2))] = 1
Updated Q[0x36d3, ((1, 1), (2, 1))] = 30500, N[0x36d3, ((1, 1), (2, 1))] = 1

--- Simulation 296 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.338633208128, 16803.338633208128, 22275.797088715197, 16803.338633208128, 19603.338633208128]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3975, Score: 14000
Depth 2: State = 0x3975, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3975: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4a44, Score: 16800
Depth 3: State = 0x4a44, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a44: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x479f, Score: 19600
Depth 4: State = 0x479f, Legal Moves = [((0, 1), (0, 2)), ((0, 1), (1, 1)), ((1, 3), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x479f: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x440c, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6504600, N[0x3c25, ((2, 3), (2, 4))] = 292
Updated Q[0x3c24, ((1, 2), (2, 2))] = 22400, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3975, ((1, 2), (1, 3))] = 22400, N[0x3975, ((1, 2), (1, 3))] = 1
Updated Q[0x4a44, ((1, 1), (2, 1))] = 22400, N[0x4a44, ((1, 1), (2, 1))] = 1
Updated Q[0x479f, ((0, 1), (0, 2))] = 22400, N[0x479f, ((0, 1), (0, 2))] = 1

--- Simulation 297 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.339626405825, 16803.339626405825, 22276.222834113145, 16803.339626405825, 19603.339626405825]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc5, Score: 8400
Depth 1: State = 0x3bc5, Legal Moves = [((0, 3), (0, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc5: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3bbc, Score: 11200
Depth 2: State = 0x3bbc, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbc: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c6b, Score: 14000
Depth 3: State = 0x3c6b, Legal Moves = [((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6b: [inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c6c, Score: 16800
Depth 4: State = 0x3c6c, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6c: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d74, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6524200, N[0x3c25, ((2, 3), (2, 4))] = 293
Updated Q[0x3bc5, ((0, 3), (0, 4))] = 19600, N[0x3bc5, ((0, 3), (0, 4))] = 1
Updated Q[0x3bbc, ((1, 2), (2, 2))] = 19600, N[0x3bbc, ((1, 2), (2, 2))] = 1
Updated Q[0x3c6b, ((0, 4), (1, 4))] = 19600, N[0x3c6b, ((0, 4), (1, 4))] = 1
Updated Q[0x3c6c, ((1, 3), (1, 4))] = 19600, N[0x3c6c, ((1, 3), (1, 4))] = 1

--- Simulation 298 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.340615959976, 16803.340615959976, 22267.08935882042, 16803.340615959976, 19603.340615959976]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 22401.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2a8b, Score: 16800
Depth 2: State = 0x2a8b, Legal Moves = [((0, 4), (1, 4)), ((3, 1), (3, 2)), ((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2a8b: [inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x2a84, Score: 22400
Depth 3: State = 0x2a84, Legal Moves = [((3, 1), (3, 2)), ((3, 2), (4, 2)), ((3, 3), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2a84: [inf, inf, inf, inf]
Selected move: ((3, 1), (3, 2))
New board state after move: 0x2d2a, Score: 25200
Depth 4: State = 0x2d2a, Legal Moves = [((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 4), (3, 4)), ((3, 3), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2d2a: [inf, inf, inf, inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x5263, Score: 35700
End of simulation with depth 5. Reward (Score): 35700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6559900, N[0x3c25, ((2, 3), (2, 4))] = 294
Updated Q[0x3c25, ((2, 0), (2, 1))] = 35700, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x2a8b, ((0, 4), (1, 4))] = 35700, N[0x2a8b, ((0, 4), (1, 4))] = 1
Updated Q[0x2a84, ((3, 1), (3, 2))] = 35700, N[0x2a84, ((3, 1), (3, 2))] = 1
Updated Q[0x2d2a, ((2, 1), (2, 2))] = 35700, N[0x2d2a, ((2, 1), (2, 2))] = 1

--- Simulation 299 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.34160189633, 16803.34160189633, 22312.779920193832, 16803.34160189633, 19603.34160189633]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14001.467405903555, 19601.467405903557, 27301.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c24, Score: 8400
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x484e, Score: 11200
Depth 3: State = 0x484e, Legal Moves = [((1, 0), (1, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x484e: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x1c19, Score: 16800
Depth 4: State = 0x1c19, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x1c19: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x1c65, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6579500, N[0x3c25, ((2, 3), (2, 4))] = 295
Updated Q[0x3c24, ((2, 0), (2, 1))] = 19600, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x484e, ((1, 0), (1, 1))] = 19600, N[0x484e, ((1, 0), (1, 1))] = 1
Updated Q[0x1c19, ((4, 1), (4, 2))] = 19600, N[0x1c19, ((4, 1), (4, 2))] = 1

--- Simulation 300 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.342584240352, 16803.342584240352, 22303.584443287018, 16803.342584240352, 19603.342584240352]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [24901.16557645562, 25201.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d90, Score: 11200
Depth 2: State = 0x3d90, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d90: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x466e, Score: 14000
Depth 3: State = 0x466e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x466e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1554, Score: 19600
Depth 4: State = 0x1554, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1))]
UCB1 values for moves at state 0x1554: [inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1ca9, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6604700, N[0x3c25, ((2, 3), (2, 4))] = 296
Updated Q[0x3c25, ((1, 3), (2, 3))] = 25200, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3d90, ((0, 2), (1, 2))] = 25200, N[0x3d90, ((0, 2), (1, 2))] = 1
Updated Q[0x466e, ((2, 0), (2, 1))] = 25200, N[0x466e, ((2, 0), (2, 1))] = 1
Updated Q[0x1554, ((0, 0), (0, 1))] = 25200, N[0x1554, ((0, 0), (0, 1))] = 1

--- Simulation 301 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.34356301725, 16803.34356301725, 22313.37001632855, 16803.34356301725, 19603.34356301725]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43af, Score: 8400
Depth 2: State = 0x43af, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43af: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x43b0, Score: 11200
Depth 3: State = 0x43b0, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43b0: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4434, Score: 16800
Depth 4: State = 0x4434, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4434: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4587, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6632400, N[0x3c25, ((2, 3), (2, 4))] = 297
Updated Q[0x3c24, ((0, 0), (0, 1))] = 27700, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43af, ((0, 4), (1, 4))] = 27700, N[0x43af, ((0, 4), (1, 4))] = 1
Updated Q[0x43b0, ((1, 2), (2, 2))] = 27700, N[0x43b0, ((1, 2), (2, 2))] = 1
Updated Q[0x4434, ((1, 3), (2, 3))] = 27700, N[0x4434, ((1, 3), (2, 3))] = 1

--- Simulation 302 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.34453825197, 16803.34453825197, 22331.507201106182, 16803.34453825197, 19603.34453825197]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c25, Score: 8400
Depth 2: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (0, 2)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4416, Score: 16000
Depth 3: State = 0x4416, Legal Moves = [((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4416: [inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x441a, Score: 18800
Depth 4: State = 0x441a, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x441a: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4418, Score: 21600
End of simulation with depth 5. Reward (Score): 21600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6654000, N[0x3c25, ((2, 3), (2, 4))] = 298
Updated Q[0x3c25, ((2, 0), (2, 1))] = 21600, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3c25, ((0, 0), (0, 1))] = 21600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4416, ((2, 3), (3, 3))] = 21600, N[0x4416, ((2, 3), (3, 3))] = 1
Updated Q[0x441a, ((1, 3), (1, 4))] = 21600, N[0x441a, ((1, 3), (1, 4))] = 1

--- Simulation 303 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.345509969207, 16803.345509969207, 22329.052860591713, 16803.345509969207, 19603.345509969207]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 10500
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x48f2, Score: 13300
Depth 2: State = 0x48f2, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f2: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x45a6, Score: 16100
Depth 3: State = 0x45a6, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a6: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4565, Score: 18900
Depth 4: State = 0x4565, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4565: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4565, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6675700, N[0x3c25, ((2, 3), (2, 4))] = 299
Updated Q[0x3c25, ((0, 0), (0, 1))] = 21700, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x48f2, ((0, 1), (1, 1))] = 21700, N[0x48f2, ((0, 1), (1, 1))] = 1
Updated Q[0x45a6, ((1, 3), (2, 3))] = 21700, N[0x45a6, ((1, 3), (2, 3))] = 1
Updated Q[0x4565, ((1, 3), (1, 4))] = 21700, N[0x4565, ((1, 3), (1, 4))] = 1

--- Simulation 304 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.346478193384, 16803.346478193384, 22326.949384673684, 16803.346478193384, 19603.346478193384]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 19601.16557645562, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3bff, Score: 8400
Depth 2: State = 0x3bff, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bff: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c28, Score: 11200
Depth 3: State = 0x3c28, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c28: [inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3be4, Score: 14000
Depth 4: State = 0x3be4, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be4: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3be4, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6692500, N[0x3c25, ((2, 3), (2, 4))] = 300
Updated Q[0x3c24, ((0, 4), (1, 4))] = 16800, N[0x3c24, ((0, 4), (1, 4))] = 1
Updated Q[0x3bff, ((1, 2), (2, 2))] = 16800, N[0x3bff, ((1, 2), (2, 2))] = 1
Updated Q[0x3c28, ((0, 4), (1, 4))] = 16800, N[0x3c28, ((0, 4), (1, 4))] = 1
Updated Q[0x3be4, ((1, 2), (1, 3))] = 16800, N[0x3be4, ((1, 2), (1, 3))] = 1

--- Simulation 305 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.347442948692, 16803.347442948692, 22308.526598042085, 16803.347442948692, 19603.347442948692]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x36e1, Score: 14000
Depth 2: State = 0x36e1, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36e1: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x36da, Score: 16800
Depth 3: State = 0x36da, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36da: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1321, Score: 19600
Depth 4: State = 0x1321, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1321: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x1314, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6714900, N[0x3c25, ((2, 3), (2, 4))] = 301
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x36e1, ((1, 2), (1, 3))] = 22400, N[0x36e1, ((1, 2), (1, 3))] = 1
Updated Q[0x36da, ((0, 0), (0, 1))] = 22400, N[0x36da, ((0, 0), (0, 1))] = 1
Updated Q[0x1321, ((1, 3), (1, 4))] = 22400, N[0x1321, ((1, 3), (1, 4))] = 1

--- Simulation 306 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.348404259068, 16803.348404259068, 22308.830872567105, 16803.348404259068, 19603.348404259068]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 27301.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c25, Score: 8400
Depth 2: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 1), (2, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x5573, Score: 14000
Depth 3: State = 0x5573, Legal Moves = [((1, 1), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x5573: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x57d5, Score: 16800
Depth 4: State = 0x57d5, Legal Moves = [((0, 2), (0, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x57d5: [inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x495e, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6734500, N[0x3c25, ((2, 3), (2, 4))] = 302
Updated Q[0x3c25, ((2, 0), (2, 1))] = 19600, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x5573, ((1, 1), (2, 1))] = 19600, N[0x5573, ((1, 1), (2, 1))] = 1
Updated Q[0x57d5, ((0, 2), (0, 3))] = 19600, N[0x57d5, ((0, 2), (0, 3))] = 1

--- Simulation 307 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.349362148205, 16803.349362148205, 22299.86160830605, 16803.349362148205, 19603.349362148205]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [27300.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c4d, Score: 11200
Depth 2: State = 0x3c4d, Legal Moves = [((0, 0), (1, 0)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4d: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x5572, Score: 14000
Depth 3: State = 0x5572, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5572: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x36fb, Score: 18900
Depth 4: State = 0x36fb, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36fb: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3920, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6761800, N[0x3c25, ((2, 3), (2, 4))] = 303
Updated Q[0x3c25, ((1, 2), (2, 2))] = 27300, N[0x3c25, ((1, 2), (2, 2))] = 1
Updated Q[0x3c4d, ((0, 0), (1, 0))] = 27300, N[0x3c4d, ((0, 0), (1, 0))] = 1
Updated Q[0x5572, ((0, 1), (1, 1))] = 27300, N[0x5572, ((0, 1), (1, 1))] = 1
Updated Q[0x36fb, ((2, 0), (2, 1))] = 27300, N[0x36fb, ((2, 0), (2, 1))] = 1

--- Simulation 308 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.350316639553, 16803.350316639553, 22316.364087823706, 16803.350316639553, 19603.350316639553]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [21700.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3832, Score: 11200
Depth 2: State = 0x3832, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3832: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3985, Score: 14000
Depth 3: State = 0x3985, Legal Moves = [((2, 1), (3, 1))]
UCB1 values for moves at state 0x3985: [inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x519c, Score: 35800
Depth 4: State = 0x519c, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (2, 3))]
UCB1 values for moves at state 0x519c: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x11e2, Score: 38600
End of simulation with depth 5. Reward (Score): 38600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6800400, N[0x3c25, ((2, 3), (2, 4))] = 304
Updated Q[0x3c24, ((1, 3), (2, 3))] = 38600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3832, ((2, 0), (2, 1))] = 38600, N[0x3832, ((2, 0), (2, 1))] = 1
Updated Q[0x3985, ((2, 1), (3, 1))] = 38600, N[0x3985, ((2, 1), (3, 1))] = 1
Updated Q[0x519c, ((0, 0), (0, 1))] = 38600, N[0x519c, ((0, 0), (0, 1))] = 1

--- Simulation 309 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.35126775633, 16803.35126775633, 22369.929050493192, 16803.35126775633, 19603.35126775633]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c5d, Score: 11200
Depth 2: State = 0x3c5d, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5d: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3865, Score: 14000
Depth 3: State = 0x3865, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x3865: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x37c3, Score: 24400
Depth 4: State = 0x37c3, Legal Moves = [((0, 2), (1, 2)), ((1, 1), (2, 1)), ((2, 3), (2, 4))]
UCB1 values for moves at state 0x37c3: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x37cb, Score: 27200
End of simulation with depth 5. Reward (Score): 27200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6827600, N[0x3c25, ((2, 3), (2, 4))] = 305
Updated Q[0x3c24, ((1, 2), (2, 2))] = 27200, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3c5d, ((2, 0), (2, 1))] = 27200, N[0x3c5d, ((2, 0), (2, 1))] = 1
Updated Q[0x3865, ((4, 1), (4, 2))] = 27200, N[0x3865, ((4, 1), (4, 2))] = 1
Updated Q[0x37c3, ((0, 2), (1, 2))] = 27200, N[0x37c3, ((0, 2), (1, 2))] = 1

--- Simulation 310 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.35221552152, 16803.35221552152, 22385.76571779419, 16803.35221552152, 19603.35221552152]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22400.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x386c, Score: 11200
Depth 2: State = 0x386c, Legal Moves = [((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x386c: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3af0, Score: 14000
Depth 3: State = 0x3af0, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3af0: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x399d, Score: 16800
Depth 4: State = 0x399d, Legal Moves = [((1, 1), (2, 1))]
UCB1 values for moves at state 0x399d: [inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4836, Score: 33300
End of simulation with depth 5. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6860900, N[0x3c25, ((2, 3), (2, 4))] = 306
Updated Q[0x3c24, ((1, 3), (2, 3))] = 33300, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x386c, ((1, 2), (1, 3))] = 33300, N[0x386c, ((1, 2), (1, 3))] = 1
Updated Q[0x3af0, ((2, 0), (2, 1))] = 33300, N[0x3af0, ((2, 0), (2, 1))] = 1
Updated Q[0x399d, ((1, 1), (2, 1))] = 33300, N[0x399d, ((1, 1), (2, 1))] = 1

--- Simulation 311 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.35315995787, 16803.35315995787, 22421.433517461537, 16803.35315995787, 19603.35315995787]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [21701.467405903557, 22401.467405903557, 25201.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c22, Score: 8400
Depth 2: State = 0x3c22, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c22: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3be0, Score: 11200
Depth 3: State = 0x3be0, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be0: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3bdd, Score: 14000
Depth 4: State = 0x3bdd, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bdd: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x37e4, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6877700, N[0x3c25, ((2, 3), (2, 4))] = 307
Updated Q[0x3c25, ((2, 3), (3, 3))] = 16800, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3c22, ((1, 2), (2, 2))] = 16800, N[0x3c22, ((1, 2), (2, 2))] = 1
Updated Q[0x3be0, ((1, 2), (1, 3))] = 16800, N[0x3be0, ((1, 2), (1, 3))] = 1
Updated Q[0x3bdd, ((2, 0), (2, 1))] = 16800, N[0x3bdd, ((2, 0), (2, 1))] = 1

--- Simulation 312 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.3541010879, 16803.3541010879, 22403.12302475141, 16803.3541010879, 19603.3541010879]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x382c, Score: 13300
Depth 2: State = 0x382c, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x382c: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2180, Score: 16100
Depth 3: State = 0x2180, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x2180: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x22d3, Score: 18900
Depth 4: State = 0x22d3, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 1), (3, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x22d3: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x300f, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6899400, N[0x3c25, ((2, 3), (2, 4))] = 308
Updated Q[0x3c24, ((1, 3), (2, 3))] = 21700, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x382c, ((0, 0), (0, 1))] = 21700, N[0x382c, ((0, 0), (0, 1))] = 1
Updated Q[0x2180, ((2, 0), (2, 1))] = 21700, N[0x2180, ((2, 0), (2, 1))] = 1
Updated Q[0x22d3, ((1, 0), (1, 1))] = 21700, N[0x22d3, ((1, 0), (1, 1))] = 1

--- Simulation 313 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.355038933918, 16803.355038933918, 22400.840521734826, 16803.355038933918, 19603.355038933918]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x453c, Score: 8400
Depth 2: State = 0x453c, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x453c: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x43ce, Score: 11200
Depth 3: State = 0x43ce, Legal Moves = [((0, 1), (0, 2)), ((0, 3), (1, 3)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43ce: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x48f7, Score: 14000
Depth 4: State = 0x48f7, Legal Moves = [((0, 3), (1, 3)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f7: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4a8f, Score: 18900
End of simulation with depth 5. Reward (Score): 18900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6918300, N[0x3c25, ((2, 3), (2, 4))] = 309
Updated Q[0x3c24, ((0, 0), (0, 1))] = 18900, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x453c, ((0, 3), (1, 3))] = 18900, N[0x453c, ((0, 3), (1, 3))] = 1
Updated Q[0x43ce, ((0, 1), (0, 2))] = 18900, N[0x43ce, ((0, 1), (0, 2))] = 1
Updated Q[0x48f7, ((0, 3), (1, 3))] = 18900, N[0x48f7, ((0, 3), (1, 3))] = 1

--- Simulation 314 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.35597351799, 16803.35597351799, 22389.511303012616, 16803.35597351799, 19603.35597351799]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.873992678666, 27301.873992678666, 27701.873992678666, 33301.32511293098, 25201.873992678666]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3833, Score: 11200
Depth 2: State = 0x3833, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3833: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x519c, Score: 14000
Depth 3: State = 0x519c, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x519c: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x14ad, Score: 16800
Depth 4: State = 0x14ad, Legal Moves = [((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x14ad: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x115e, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6937900, N[0x3c25, ((2, 3), (2, 4))] = 310
Updated Q[0x3c24, ((2, 3), (3, 3))] = 86200, N[0x3c24, ((2, 3), (3, 3))] = 3
Updated Q[0x3833, ((1, 2), (1, 3))] = 19600, N[0x3833, ((1, 2), (1, 3))] = 1
Updated Q[0x519c, ((0, 0), (0, 1))] = 19600, N[0x519c, ((0, 0), (0, 1))] = 1
Updated Q[0x14ad, ((1, 0), (1, 1))] = 19600, N[0x14ad, ((1, 0), (1, 1))] = 1

--- Simulation 315 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.35690486198, 16803.35690486198, 22380.513240029442, 16803.35690486198, 19603.35690486198]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c5f, Score: 8400
Depth 2: State = 0x3c5f, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5f: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3953, Score: 11200
Depth 3: State = 0x3953, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3953: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3bf9, Score: 14000
Depth 4: State = 0x3bf9, Legal Moves = [((4, 0), (4, 1))]
UCB1 values for moves at state 0x3bf9: [inf]
Selected move: ((4, 0), (4, 1))
New board state after move: 0x200c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6957500, N[0x3c25, ((2, 3), (2, 4))] = 311
Updated Q[0x3c25, ((0, 2), (1, 2))] = 19600, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3c5f, ((0, 3), (1, 3))] = 19600, N[0x3c5f, ((0, 3), (1, 3))] = 1
Updated Q[0x3953, ((2, 0), (2, 1))] = 19600, N[0x3953, ((2, 0), (2, 1))] = 1
Updated Q[0x3bf9, ((4, 0), (4, 1))] = 19600, N[0x3bf9, ((4, 0), (4, 1))] = 1

--- Simulation 316 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.357832987524, 16803.357832987524, 22371.573041896256, 16803.357832987524, 19603.357832987524]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x444e, Score: 8400
Depth 2: State = 0x444e, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x444e: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x45b2, Score: 11200
Depth 3: State = 0x45b2, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45b2: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4705, Score: 14000
Depth 4: State = 0x4705, Legal Moves = [((0, 1), (0, 2)), ((0, 1), (1, 1)), ((0, 3), (1, 3)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4705: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x43fa, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6974300, N[0x3c25, ((2, 3), (2, 4))] = 312
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x444e, ((0, 2), (1, 2))] = 16800, N[0x444e, ((0, 2), (1, 2))] = 1
Updated Q[0x45b2, ((2, 0), (2, 1))] = 16800, N[0x45b2, ((2, 0), (2, 1))] = 1
Updated Q[0x4705, ((0, 1), (0, 2))] = 16800, N[0x4705, ((0, 1), (0, 2))] = 1

--- Simulation 317 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.35875791605, 16803.35875791605, 22353.71579324822, 16803.35875791605, 19603.35875791605]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bd6, Score: 11200
Depth 2: State = 0x3bd6, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bd6: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5277, Score: 14000
Depth 3: State = 0x5277, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5277: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x540e, Score: 16800
Depth 4: State = 0x540e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x540e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x52bb, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6993900, N[0x3c25, ((2, 3), (2, 4))] = 313
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3bd6, ((1, 2), (1, 3))] = 19600, N[0x3bd6, ((1, 2), (1, 3))] = 1
Updated Q[0x5277, ((0, 1), (0, 2))] = 19600, N[0x5277, ((0, 1), (0, 2))] = 1
Updated Q[0x540e, ((2, 0), (2, 1))] = 19600, N[0x540e, ((2, 0), (2, 1))] = 1

--- Simulation 318 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.359679668778, 16803.359679668778, 22344.918334827365, 16803.359679668778, 19603.359679668778]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc2, Score: 8400
Depth 1: State = 0x3bc2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc2: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3964, Score: 11200
Depth 2: State = 0x3964, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3964: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x1dff, Score: 14000
Depth 3: State = 0x1dff, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1dff: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x201d, Score: 16800
Depth 4: State = 0x201d, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (0, 2)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((1, 0), (2, 0)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4))]
UCB1 values for moves at state 0x201d: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x3a95, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7013500, N[0x3c25, ((2, 3), (2, 4))] = 314
Updated Q[0x3bc2, ((1, 3), (2, 3))] = 19600, N[0x3bc2, ((1, 3), (2, 3))] = 1
Updated Q[0x3964, ((1, 2), (1, 3))] = 19600, N[0x3964, ((1, 2), (1, 3))] = 1
Updated Q[0x1dff, ((1, 0), (2, 0))] = 19600, N[0x1dff, ((1, 0), (2, 0))] = 1
Updated Q[0x201d, ((0, 0), (0, 1))] = 19600, N[0x201d, ((0, 0), (0, 1))] = 1

--- Simulation 319 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.360598266714, 16803.360598266714, 22336.17691067836, 16803.360598266714, 19603.360598266714]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4957, Score: 8400
Depth 2: State = 0x4957, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4957: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x2b09, Score: 16800
Depth 3: State = 0x2b09, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2b09: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0xf3de, Score: 19600
Depth 4: State = 0xf3de, Legal Moves = [((0, 2), (0, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 0), (4, 0))]
UCB1 values for moves at state 0xf3de: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x2347, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7038700, N[0x3c25, ((2, 3), (2, 4))] = 315
Updated Q[0x3c25, ((0, 0), (0, 1))] = 25200, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4957, ((0, 2), (1, 2))] = 25200, N[0x4957, ((0, 2), (1, 2))] = 1
Updated Q[0x2b09, ((0, 2), (1, 2))] = 25200, N[0x2b09, ((0, 2), (1, 2))] = 1
Updated Q[0xf3de, ((0, 2), (0, 3))] = 25200, N[0xf3de, ((0, 2), (0, 3))] = 1

--- Simulation 320 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.361513730666, 16803.361513730666, 22345.268764921482, 16803.361513730666, 19603.361513730666]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c40, Score: 8400
Depth 1: State = 0x3c40, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c40: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3c61, Score: 11200
Depth 2: State = 0x3c61, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c61: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bb8, Score: 16800
Depth 3: State = 0x3bb8, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb8: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c29, Score: 19600
Depth 4: State = 0x3c29, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c29: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3c22, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7061100, N[0x3c25, ((2, 3), (2, 4))] = 316
Updated Q[0x3c40, ((0, 3), (0, 4))] = 22400, N[0x3c40, ((0, 3), (0, 4))] = 1
Updated Q[0x3c61, ((1, 2), (2, 2))] = 22400, N[0x3c61, ((1, 2), (2, 2))] = 1
Updated Q[0x3bb8, ((1, 2), (2, 2))] = 22400, N[0x3bb8, ((1, 2), (2, 2))] = 1
Updated Q[0x3c29, ((1, 3), (1, 4))] = 22400, N[0x3c29, ((1, 3), (1, 4))] = 1

--- Simulation 321 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.362426081232, 16803.362426081232, 22345.44231580205, 16803.362426081232, 19603.362426081232]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bd6, Score: 14000
Depth 2: State = 0x3bd6, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bd6: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d29, Score: 16800
Depth 3: State = 0x3d29, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d29: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x3d3a, Score: 19600
Depth 4: State = 0x3d3a, Legal Moves = [((2, 2), (3, 2))]
UCB1 values for moves at state 0x3d3a: [inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x3d5c, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7083500, N[0x3c25, ((2, 3), (2, 4))] = 317
Updated Q[0x3c24, ((1, 2), (2, 2))] = 22400, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3bd6, ((2, 0), (2, 1))] = 22400, N[0x3bd6, ((2, 0), (2, 1))] = 1
Updated Q[0x3d29, ((4, 1), (4, 2))] = 22400, N[0x3d29, ((4, 1), (4, 2))] = 1
Updated Q[0x3d3a, ((2, 2), (3, 2))] = 22400, N[0x3d3a, ((2, 2), (3, 2))] = 1

--- Simulation 322 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.363335338818, 16803.363335338818, 22345.614771240493, 16803.363335338818, 19603.363335338818]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3910, Score: 11200
Depth 2: State = 0x3910, Legal Moves = [((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3910: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3979, Score: 14000
Depth 3: State = 0x3979, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3979: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3979, Score: 16800
Depth 4: State = 0x3979, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3979: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x3997, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7103100, N[0x3c25, ((2, 3), (2, 4))] = 318
Updated Q[0x3c25, ((1, 3), (2, 3))] = 19600, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3910, ((1, 2), (2, 2))] = 19600, N[0x3910, ((1, 2), (2, 2))] = 1
Updated Q[0x3979, ((1, 3), (2, 3))] = 19600, N[0x3979, ((1, 3), (2, 3))] = 1
Updated Q[0x3979, ((1, 1), (1, 2))] = 19600, N[0x3979, ((1, 1), (1, 2))] = 1

--- Simulation 323 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.36424152362, 16803.36424152362, 22336.9811101268, 16803.36424152362, 19603.36424152362]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c22, Score: 8400
Depth 1: State = 0x3c22, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c22: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c20, Score: 11200
Depth 2: State = 0x3c20, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c20: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37ee, Score: 14000
Depth 3: State = 0x37ee, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37ee: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3be7, Score: 16800
Depth 4: State = 0x3be7, Legal Moves = [((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1))]
UCB1 values for moves at state 0x3be7: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x3be7, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7127600, N[0x3c25, ((2, 3), (2, 4))] = 319
Updated Q[0x3c22, ((0, 2), (1, 2))] = 24500, N[0x3c22, ((0, 2), (1, 2))] = 1
Updated Q[0x3c20, ((1, 3), (2, 3))] = 24500, N[0x3c20, ((1, 3), (2, 3))] = 1
Updated Q[0x37ee, ((2, 0), (2, 1))] = 24500, N[0x37ee, ((2, 0), (2, 1))] = 1
Updated Q[0x3be7, ((1, 1), (1, 2))] = 24500, N[0x3be7, ((1, 1), (1, 2))] = 1

--- Simulation 324 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.36514465566, 16803.36514465566, 22343.7620796407, 16803.36514465566, 19603.36514465566]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 25201.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3854, Score: 16100
Depth 2: State = 0x3854, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3854: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x43d8, Score: 18900
Depth 3: State = 0x43d8, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((1, 1), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43d8: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x47ae, Score: 24500
Depth 4: State = 0x47ae, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47ae: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3d18, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7154900, N[0x3c25, ((2, 3), (2, 4))] = 320
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27300, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3854, ((0, 2), (1, 2))] = 27300, N[0x3854, ((0, 2), (1, 2))] = 1
Updated Q[0x43d8, ((0, 1), (0, 2))] = 27300, N[0x43d8, ((0, 1), (0, 2))] = 1
Updated Q[0x47ae, ((0, 1), (1, 1))] = 27300, N[0x47ae, ((0, 1), (1, 1))] = 1

--- Simulation 325 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.366044754745, 16803.366044754745, 22359.250667622175, 16803.366044754745, 19603.366044754745]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c65, Score: 8400
Depth 1: State = 0x3c65, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c65: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c24, Score: 11200
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 3), (0, 4)), ((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x48fb, Score: 14000
Depth 3: State = 0x48fb, Legal Moves = [((0, 3), (0, 4)), ((0, 3), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x48fb: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x48f4, Score: 16800
Depth 4: State = 0x48f4, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f4: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x464f, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7174500, N[0x3c25, ((2, 3), (2, 4))] = 321
Updated Q[0x3c65, ((1, 2), (2, 2))] = 19600, N[0x3c65, ((1, 2), (2, 2))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x48fb, ((0, 3), (0, 4))] = 19600, N[0x48fb, ((0, 3), (0, 4))] = 1
Updated Q[0x48f4, ((2, 0), (2, 1))] = 19600, N[0x48f4, ((2, 0), (2, 1))] = 1

--- Simulation 326 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.366941840508, 16803.366941840508, 22350.655214087634, 16803.366941840508, 19603.366941840508]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a46, Score: 8400
Depth 2: State = 0x4a46, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a46: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x48f7, Score: 14000
Depth 3: State = 0x48f7, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f7: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x48f7, Score: 16800
Depth 4: State = 0x48f7, Legal Moves = [((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f7: [inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x48f7, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7194100, N[0x3c25, ((2, 3), (2, 4))] = 322
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a46, ((1, 3), (2, 3))] = 19600, N[0x4a46, ((1, 3), (2, 3))] = 1
Updated Q[0x48f7, ((1, 3), (1, 4))] = 19600, N[0x48f7, ((1, 3), (1, 4))] = 1
Updated Q[0x48f7, ((1, 4), (2, 4))] = 19600, N[0x48f7, ((1, 4), (2, 4))] = 1

--- Simulation 327 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.367835932386, 16803.367835932386, 22342.113147997374, 16803.367835932386, 19603.367835932386]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3be0, Score: 8400
Depth 1: State = 0x3be0, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be0: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3a72, Score: 14000
Depth 2: State = 0x3a72, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3a72: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x37bf, Score: 19600
Depth 3: State = 0x37bf, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37bf: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3677, Score: 22400
Depth 4: State = 0x3677, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3677: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3719, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7219300, N[0x3c25, ((2, 3), (2, 4))] = 323
Updated Q[0x3be0, ((1, 3), (2, 3))] = 25200, N[0x3be0, ((1, 3), (2, 3))] = 1
Updated Q[0x3a72, ((0, 2), (0, 3))] = 25200, N[0x3a72, ((0, 2), (0, 3))] = 1
Updated Q[0x37bf, ((0, 1), (0, 2))] = 25200, N[0x37bf, ((0, 1), (0, 2))] = 1
Updated Q[0x3677, ((1, 2), (2, 2))] = 25200, N[0x3677, ((1, 2), (2, 2))] = 1

--- Simulation 328 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.368727049638, 16803.368727049638, 22350.96143479513, 16803.368727049638, 19603.368727049638]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14000.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x37ca, Score: 11200
Depth 2: State = 0x37ca, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x37ca: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x36dd, Score: 14000
Depth 3: State = 0x36dd, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x36dd: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x523c, Score: 24400
Depth 4: State = 0x523c, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x523c: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3c65, Score: 30000
End of simulation with depth 5. Reward (Score): 30000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7249300, N[0x3c25, ((2, 3), (2, 4))] = 324
Updated Q[0x3c24, ((1, 3), (1, 4))] = 30000, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x37ca, ((0, 1), (0, 2))] = 30000, N[0x37ca, ((0, 1), (0, 2))] = 1
Updated Q[0x36dd, ((0, 1), (1, 1))] = 30000, N[0x36dd, ((0, 1), (1, 1))] = 1
Updated Q[0x523c, ((1, 2), (1, 3))] = 30000, N[0x523c, ((1, 2), (1, 3))] = 1

--- Simulation 329 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.36961521133, 16803.36961521133, 22374.569916894456, 16803.36961521133, 19603.36961521133]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22401.16557645562, 42801.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d77, Score: 8400
Depth 2: State = 0x3d77, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (0, 2)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d77: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x3c1a, Score: 18800
Depth 3: State = 0x3c1a, Legal Moves = [((1, 0), (2, 0)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c1a: [inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x1c9a, Score: 21600
Depth 4: State = 0x1c9a, Legal Moves = [((1, 0), (1, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1c9a: [inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x1c8a, Score: 24400
End of simulation with depth 5. Reward (Score): 24400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7273700, N[0x3c25, ((2, 3), (2, 4))] = 325
Updated Q[0x3c24, ((2, 0), (2, 1))] = 24400, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3d77, ((0, 0), (0, 1))] = 24400, N[0x3d77, ((0, 0), (0, 1))] = 1
Updated Q[0x3c1a, ((1, 0), (2, 0))] = 24400, N[0x3c1a, ((1, 0), (2, 0))] = 1
Updated Q[0x1c9a, ((1, 0), (1, 1))] = 24400, N[0x1c9a, ((1, 0), (1, 1))] = 1

--- Simulation 330 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.37050043636, 16803.37050043636, 22380.802346340726, 16803.37050043636, 19603.37050043636]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x45a2, Score: 8400
Depth 2: State = 0x45a2, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a2: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x45a9, Score: 14000
Depth 3: State = 0x45a9, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a9: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x49a2, Score: 16800
Depth 4: State = 0x49a2, Legal Moves = [((1, 2), (2, 2)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x49a2: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x12f9, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7293300, N[0x3c25, ((2, 3), (2, 4))] = 326
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x45a2, ((0, 3), (1, 3))] = 19600, N[0x45a2, ((0, 3), (1, 3))] = 1
Updated Q[0x45a9, ((2, 0), (2, 1))] = 19600, N[0x45a9, ((2, 0), (2, 1))] = 1
Updated Q[0x49a2, ((1, 2), (2, 2))] = 19600, N[0x49a2, ((1, 2), (2, 2))] = 1

--- Simulation 331 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.371382743437, 16803.371382743437, 22372.272613191013, 16803.371382743437, 19603.371382743437]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47a5, Score: 8400
Depth 2: State = 0x47a5, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47a5: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x443b, Score: 11200
Depth 3: State = 0x443b, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443b: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0xf43b, Score: 14000
Depth 4: State = 0xf43b, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0xf43b: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x29e5, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7312900, N[0x3c25, ((2, 3), (2, 4))] = 327
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47a5, ((1, 3), (2, 3))] = 19600, N[0x47a5, ((1, 3), (2, 3))] = 1
Updated Q[0x443b, ((0, 0), (0, 1))] = 19600, N[0x443b, ((0, 0), (0, 1))] = 1
Updated Q[0xf43b, ((0, 2), (1, 2))] = 19600, N[0xf43b, ((0, 2), (1, 2))] = 1

--- Simulation 332 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.3722621511, 16803.3722621511, 22363.795049214208, 16803.3722621511, 19603.3722621511]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x48f4, Score: 8400
Depth 2: State = 0x48f4, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f4: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x2f00, Score: 14000
Depth 3: State = 0x2f00, Legal Moves = [((0, 0), (1, 0)), ((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2f00: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x4aa9, Score: 19600
Depth 4: State = 0x4aa9, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aa9: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x48f7, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7335300, N[0x3c25, ((2, 3), (2, 4))] = 328
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x48f4, ((1, 3), (2, 3))] = 22400, N[0x48f4, ((1, 3), (2, 3))] = 1
Updated Q[0x2f00, ((0, 0), (1, 0))] = 22400, N[0x2f00, ((0, 0), (1, 0))] = 1
Updated Q[0x4aa9, ((1, 3), (2, 3))] = 22400, N[0x4aa9, ((1, 3), (2, 3))] = 1

--- Simulation 333 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.37313867771, 16803.37313867771, 22363.905762621045, 16803.37313867771, 19603.37313867771]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [25200.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bbc, Score: 8400
Depth 2: State = 0x3bbc, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbc: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3845, Score: 11200
Depth 3: State = 0x3845, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3845: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x2950, Score: 14000
Depth 4: State = 0x2950, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2950: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x293f, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7354900, N[0x3c25, ((2, 3), (2, 4))] = 329
Updated Q[0x3c25, ((0, 2), (1, 2))] = 19600, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3bbc, ((1, 3), (2, 3))] = 19600, N[0x3bbc, ((1, 3), (2, 3))] = 1
Updated Q[0x3845, ((0, 2), (1, 2))] = 19600, N[0x3845, ((0, 2), (1, 2))] = 1
Updated Q[0x2950, ((0, 1), (0, 2))] = 19600, N[0x2950, ((0, 1), (0, 2))] = 1

--- Simulation 334 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.374012341465, 16803.374012341465, 22355.50516425796, 16803.374012341465, 19603.374012341465]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 19601.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d77, Score: 11200
Depth 2: State = 0x3d77, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d77: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x567d, Score: 14000
Depth 3: State = 0x567d, Legal Moves = [((1, 2), (2, 2)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x567d: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x5103, Score: 16800
Depth 4: State = 0x5103, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x5103: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x52ec, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7374500, N[0x3c25, ((2, 3), (2, 4))] = 330
Updated Q[0x3c24, ((2, 0), (2, 1))] = 19600, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3d77, ((0, 0), (0, 1))] = 19600, N[0x3d77, ((0, 0), (0, 1))] = 1
Updated Q[0x567d, ((1, 2), (2, 2))] = 19600, N[0x567d, ((1, 2), (2, 2))] = 1
Updated Q[0x5103, ((0, 1), (0, 2))] = 19600, N[0x5103, ((0, 1), (0, 2))] = 1

--- Simulation 335 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.374883160384, 16803.374883160384, 22347.155478173252, 16803.374883160384, 19603.374883160384]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c3c, Score: 8400
Depth 1: State = 0x3c3c, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c3c: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x2180, Score: 11200
Depth 2: State = 0x2180, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2180: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x1ec9, Score: 16100
Depth 3: State = 0x1ec9, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1ec9: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x216f, Score: 18900
Depth 4: State = 0x216f, Legal Moves = [((3, 0), (3, 1))]
UCB1 values for moves at state 0x216f: [inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x22c2, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7396200, N[0x3c25, ((2, 3), (2, 4))] = 331
Updated Q[0x3c3c, ((0, 0), (1, 0))] = 21700, N[0x3c3c, ((0, 0), (1, 0))] = 1
Updated Q[0x2180, ((0, 3), (1, 3))] = 21700, N[0x2180, ((0, 3), (1, 3))] = 1
Updated Q[0x1ec9, ((2, 0), (2, 1))] = 21700, N[0x1ec9, ((2, 0), (2, 1))] = 1
Updated Q[0x216f, ((3, 0), (3, 1))] = 21700, N[0x216f, ((3, 0), (3, 1))] = 1

--- Simulation 336 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.375751152318, 16803.375751152318, 22345.20065380435, 16803.375751152318, 19603.375751152318]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c0a, Score: 8400
Depth 1: State = 0x3c0a, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c0a: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37e9, Score: 11200
Depth 2: State = 0x37e9, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37e9: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x37df, Score: 14000
Depth 3: State = 0x37df, Legal Moves = [((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37df: [inf, inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x37dd, Score: 27700
Depth 4: State = 0x37dd, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37dd: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x369b, Score: 33300
End of simulation with depth 5. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7429500, N[0x3c25, ((2, 3), (2, 4))] = 332
Updated Q[0x3c0a, ((1, 3), (2, 3))] = 33300, N[0x3c0a, ((1, 3), (2, 3))] = 1
Updated Q[0x37e9, ((0, 3), (1, 3))] = 33300, N[0x37e9, ((0, 3), (1, 3))] = 1
Updated Q[0x37df, ((1, 4), (2, 4))] = 33300, N[0x37df, ((1, 4), (2, 4))] = 1
Updated Q[0x37dd, ((1, 1), (2, 1))] = 33300, N[0x37dd, ((1, 1), (2, 1))] = 1

--- Simulation 337 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.37661633496, 16803.37661633496, 22378.197364089407, 16803.37661633496, 19603.37661633496]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [18900.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x36f4, Score: 11200
Depth 2: State = 0x36f4, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x36f4: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0xefc2, Score: 16800
Depth 3: State = 0xefc2, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0xefc2: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0xefc3, Score: 19600
Depth 4: State = 0xefc3, Legal Moves = [((3, 2), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0xefc3: [inf, inf]
Selected move: ((3, 2), (3, 3))
New board state after move: 0xef8c, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7451900, N[0x3c25, ((2, 3), (2, 4))] = 333
Updated Q[0x3c24, ((1, 3), (2, 3))] = 22400, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x36f4, ((0, 2), (1, 2))] = 22400, N[0x36f4, ((0, 2), (1, 2))] = 1
Updated Q[0xefc2, ((2, 0), (2, 1))] = 22400, N[0xefc2, ((2, 0), (2, 1))] = 1
Updated Q[0xefc3, ((3, 2), (3, 3))] = 22400, N[0xefc3, ((3, 2), (3, 3))] = 1

--- Simulation 338 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.377478725837, 16803.377478725837, 22378.263162772135, 16803.377478725837, 19603.377478725837]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c2b, Score: 11200
Depth 2: State = 0x3c2b, Legal Moves = [((0, 3), (1, 3)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c2b: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3bd6, Score: 14000
Depth 3: State = 0x3bd6, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bd6: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x37de, Score: 16800
Depth 4: State = 0x37de, Legal Moves = [((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x37de: [inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x3870, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7471500, N[0x3c25, ((2, 3), (2, 4))] = 334
Updated Q[0x3c25, ((1, 2), (2, 2))] = 19600, N[0x3c25, ((1, 2), (2, 2))] = 1
Updated Q[0x3c2b, ((0, 3), (1, 3))] = 19600, N[0x3c2b, ((0, 3), (1, 3))] = 1
Updated Q[0x3bd6, ((2, 0), (2, 1))] = 19600, N[0x3bd6, ((2, 0), (2, 1))] = 1
Updated Q[0x37de, ((2, 1), (2, 2))] = 19600, N[0x37de, ((2, 1), (2, 2))] = 1

--- Simulation 339 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.378338342314, 16803.378338342314, 22369.945333491498, 16803.378338342314, 19603.378338342314]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 19601.16557645562, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3c27, Score: 8400
Depth 2: State = 0x3c27, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c27: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x390f, Score: 11200
Depth 3: State = 0x390f, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x390f: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5430, Score: 24900
Depth 4: State = 0x5430, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5430: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x468e, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7502000, N[0x3c25, ((2, 3), (2, 4))] = 335
Updated Q[0x3c25, ((0, 3), (0, 4))] = 30500, N[0x3c25, ((0, 3), (0, 4))] = 1
Updated Q[0x3c27, ((1, 3), (2, 3))] = 30500, N[0x3c27, ((1, 3), (2, 3))] = 1
Updated Q[0x390f, ((1, 2), (1, 3))] = 30500, N[0x390f, ((1, 2), (1, 3))] = 1
Updated Q[0x5430, ((1, 1), (2, 1))] = 30500, N[0x5430, ((1, 1), (2, 1))] = 1

--- Simulation 340 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.379195201593, 16803.379195201593, 22394.214475902707, 16803.379195201593, 19603.379195201593]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [25200.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bbc, Score: 11200
Depth 2: State = 0x3bbc, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbc: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3671, Score: 14000
Depth 3: State = 0x3671, Legal Moves = [((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3671: [inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3c66, Score: 16800
Depth 4: State = 0x3c66, Legal Moves = [((2, 0), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c66: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2f2a, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7521600, N[0x3c25, ((2, 3), (2, 4))] = 336
Updated Q[0x3c24, ((1, 2), (2, 2))] = 19600, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3bbc, ((2, 0), (2, 1))] = 19600, N[0x3bbc, ((2, 0), (2, 1))] = 1
Updated Q[0x3671, ((1, 2), (1, 3))] = 19600, N[0x3671, ((1, 2), (1, 3))] = 1
Updated Q[0x3c66, ((2, 0), (2, 1))] = 19600, N[0x3c66, ((2, 0), (2, 1))] = 1

--- Simulation 341 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.380049320724, 16803.380049320724, 22385.898682522202, 16803.380049320724, 19603.380049320724]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x397e, Score: 11200
Depth 2: State = 0x397e, Legal Moves = [((0, 0), (0, 1)), ((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x397e: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x301f, Score: 14000
Depth 3: State = 0x301f, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x301f: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3017, Score: 16800
Depth 4: State = 0x3017, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3017: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x53dd, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7541200, N[0x3c25, ((2, 3), (2, 4))] = 337
Updated Q[0x3c24, ((1, 3), (1, 4))] = 19600, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x397e, ((0, 0), (0, 1))] = 19600, N[0x397e, ((0, 0), (0, 1))] = 1
Updated Q[0x301f, ((0, 3), (0, 4))] = 19600, N[0x301f, ((0, 3), (0, 4))] = 1
Updated Q[0x3017, ((0, 0), (0, 1))] = 19600, N[0x3017, ((0, 0), (0, 1))] = 1

--- Simulation 342 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.380900716595, 16803.380900716595, 22377.632240613995, 16803.380900716595, 19603.380900716595]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.77609073765, 19601.77609073765, 24501.77609073765, 22401.77609073765, 19601.77609073765]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d77, Score: 8400
Depth 2: State = 0x3d77, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d77: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x567a, Score: 11200
Depth 3: State = 0x567a, Legal Moves = [((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x567a: [inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x567a, Score: 14000
Depth 4: State = 0x567a, Legal Moves = [((0, 2), (0, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x567a: [inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x5692, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7560800, N[0x3c25, ((2, 3), (2, 4))] = 338
Updated Q[0x3c24, ((2, 0), (2, 1))] = 44100, N[0x3c24, ((2, 0), (2, 1))] = 2
Updated Q[0x3d77, ((0, 0), (0, 1))] = 19600, N[0x3d77, ((0, 0), (0, 1))] = 1
Updated Q[0x567a, ((2, 3), (3, 3))] = 19600, N[0x567a, ((2, 3), (3, 3))] = 1
Updated Q[0x567a, ((0, 2), (0, 3))] = 19600, N[0x567a, ((0, 2), (0, 3))] = 1

--- Simulation 343 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.38174940595, 16803.38174940595, 22369.414712149017, 16803.38174940595, 19603.38174940595]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [25201.16557645562, 19601.16557645562, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c40, Score: 8400
Depth 2: State = 0x3c40, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c40: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x12d3, Score: 11200
Depth 3: State = 0x12d3, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x12d3: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x484b, Score: 14000
Depth 4: State = 0x484b, Legal Moves = [((0, 2), (0, 3)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x484b: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x47af, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7577600, N[0x3c25, ((2, 3), (2, 4))] = 339
Updated Q[0x3c25, ((0, 4), (1, 4))] = 16800, N[0x3c25, ((0, 4), (1, 4))] = 1
Updated Q[0x3c40, ((0, 0), (1, 0))] = 16800, N[0x3c40, ((0, 0), (1, 0))] = 1
Updated Q[0x12d3, ((0, 0), (1, 0))] = 16800, N[0x12d3, ((0, 0), (1, 0))] = 1
Updated Q[0x484b, ((0, 2), (0, 3))] = 16800, N[0x484b, ((0, 2), (0, 3))] = 1

--- Simulation 344 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.382595405372, 16803.382595405372, 22352.986077246027, 16803.382595405372, 19603.382595405372]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3be0, Score: 11200
Depth 2: State = 0x3be0, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be0: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3a8d, Score: 14000
Depth 3: State = 0x3a8d, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((1, 1), (1, 2)), ((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3a8d: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x3aec, Score: 16800
Depth 4: State = 0x3aec, Legal Moves = [((0, 2), (1, 2)), ((1, 1), (1, 2)), ((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3aec: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x46d5, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7597200, N[0x3c25, ((2, 3), (2, 4))] = 340
Updated Q[0x3c25, ((1, 2), (2, 2))] = 19600, N[0x3c25, ((1, 2), (2, 2))] = 1
Updated Q[0x3be0, ((2, 0), (2, 1))] = 19600, N[0x3be0, ((2, 0), (2, 1))] = 1
Updated Q[0x3a8d, ((0, 2), (0, 3))] = 19600, N[0x3a8d, ((0, 2), (0, 3))] = 1
Updated Q[0x3aec, ((0, 2), (1, 2))] = 19600, N[0x3aec, ((0, 2), (1, 2))] = 1

--- Simulation 345 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.3834387313, 16803.3834387313, 22344.889375081188, 16803.3834387313, 19603.3834387313]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [25200.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c69, Score: 8400
Depth 2: State = 0x3c69, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c69: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3702, Score: 14000
Depth 3: State = 0x3702, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3702: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3064, Score: 16800
Depth 4: State = 0x3064, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3064: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1426, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7619600, N[0x3c25, ((2, 3), (2, 4))] = 341
Updated Q[0x3c25, ((0, 2), (1, 2))] = 22400, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3c69, ((1, 3), (2, 3))] = 22400, N[0x3c69, ((1, 3), (2, 3))] = 1
Updated Q[0x3702, ((0, 2), (1, 2))] = 22400, N[0x3702, ((0, 2), (1, 2))] = 1
Updated Q[0x3064, ((0, 2), (1, 2))] = 22400, N[0x3064, ((0, 2), (1, 2))] = 1

--- Simulation 346 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.384279400016, 16803.384279400016, 22345.05130419516, 16803.384279400016, 19603.384279400016]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.648374031523, 19601.648374031523, 16801.648374031523, 24501.648374031523, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c1a, Score: 8400
Depth 2: State = 0x3c1a, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1a: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c5e, Score: 11200
Depth 3: State = 0x3c5e, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5e: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3c64, Score: 16800
Depth 4: State = 0x3c64, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3c64: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3dbf, Score: 32100
End of simulation with depth 5. Reward (Score): 32100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7651700, N[0x3c25, ((2, 3), (2, 4))] = 342
Updated Q[0x3c24, ((2, 3), (3, 3))] = 32100, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x3c1a, ((0, 2), (1, 2))] = 32100, N[0x3c1a, ((0, 2), (1, 2))] = 1
Updated Q[0x3c5e, ((0, 3), (0, 4))] = 32100, N[0x3c5e, ((0, 3), (0, 4))] = 1
Updated Q[0x3c64, ((1, 2), (2, 2))] = 32100, N[0x3c64, ((1, 2), (2, 2))] = 1

--- Simulation 347 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.38511742767, 16803.38511742767, 22373.574859052103, 16803.38511742767, 19603.38511742767]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3977, Score: 11200
Depth 2: State = 0x3977, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3977: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3999, Score: 16800
Depth 3: State = 0x3999, Legal Moves = [((1, 0), (1, 1)), ((2, 1), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3999: [inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x3d0a, Score: 19600
Depth 4: State = 0x3d0a, Legal Moves = [((1, 3), (1, 4)), ((2, 3), (2, 4)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3d0a: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d0c, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7674100, N[0x3c25, ((2, 3), (2, 4))] = 343
Updated Q[0x3c24, ((1, 3), (2, 3))] = 22400, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3977, ((2, 0), (2, 1))] = 22400, N[0x3977, ((2, 0), (2, 1))] = 1
Updated Q[0x3999, ((1, 0), (1, 1))] = 22400, N[0x3999, ((1, 0), (1, 1))] = 1
Updated Q[0x3d0a, ((1, 3), (1, 4))] = 22400, N[0x3d0a, ((1, 3), (1, 4))] = 1

--- Simulation 348 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.385952830253, 16803.385952830253, 22373.652212023262, 16803.385952830253, 19603.385952830253]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c06, Score: 8400
Depth 1: State = 0x3c06, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c06: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37c7, Score: 11200
Depth 2: State = 0x37c7, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37c7: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x37c7, Score: 14000
Depth 3: State = 0x37c7, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37c7: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3674, Score: 16800
Depth 4: State = 0x3674, Legal Moves = [((0, 3), (1, 3)), ((2, 1), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3674: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3873, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7693700, N[0x3c25, ((2, 3), (2, 4))] = 344
Updated Q[0x3c06, ((1, 3), (2, 3))] = 19600, N[0x3c06, ((1, 3), (2, 3))] = 1
Updated Q[0x37c7, ((0, 3), (1, 3))] = 19600, N[0x37c7, ((0, 3), (1, 3))] = 1
Updated Q[0x37c7, ((2, 0), (2, 1))] = 19600, N[0x37c7, ((2, 0), (2, 1))] = 1
Updated Q[0x3674, ((0, 3), (1, 3))] = 19600, N[0x3674, ((0, 3), (1, 3))] = 1

--- Simulation 349 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.38678562362, 16803.38678562362, 22365.58957998721, 16803.38678562362, 19603.38678562362]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47c6, Score: 8400
Depth 2: State = 0x47c6, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c6: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x47c6, Score: 14000
Depth 3: State = 0x47c6, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c6: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x49a4, Score: 16800
Depth 4: State = 0x49a4, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x49a4: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4960, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7716100, N[0x3c25, ((2, 3), (2, 4))] = 345
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47c6, ((0, 4), (1, 4))] = 22400, N[0x47c6, ((0, 4), (1, 4))] = 1
Updated Q[0x47c6, ((1, 3), (2, 3))] = 22400, N[0x47c6, ((1, 3), (2, 3))] = 1
Updated Q[0x49a4, ((0, 3), (1, 3))] = 22400, N[0x49a4, ((0, 3), (1, 3))] = 1

--- Simulation 350 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.387615823485, 16803.387615823485, 22365.68962948186, 16803.387615823485, 19603.387615823485]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c28, Score: 8400
Depth 2: State = 0x3c28, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c28: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3c4c, Score: 11200
Depth 3: State = 0x3c4c, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4c: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x57b2, Score: 14000
Depth 4: State = 0x57b2, Legal Moves = [((0, 2), (0, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x57b2: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x2b2c, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7732900, N[0x3c25, ((2, 3), (2, 4))] = 346
Updated Q[0x3c24, ((0, 2), (1, 2))] = 16800, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c28, ((0, 3), (1, 3))] = 16800, N[0x3c28, ((0, 3), (1, 3))] = 1
Updated Q[0x3c4c, ((0, 0), (1, 0))] = 16800, N[0x3c4c, ((0, 0), (1, 0))] = 1
Updated Q[0x57b2, ((0, 2), (0, 3))] = 16800, N[0x57b2, ((0, 2), (0, 3))] = 1

--- Simulation 351 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.388443445416, 16803.388443445416, 22349.60412916609, 16803.388443445416, 19603.388443445416]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c07, Score: 8400
Depth 1: State = 0x3c07, Legal Moves = [((0, 1), (0, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c07: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x391c, Score: 11200
Depth 2: State = 0x391c, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x391c: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x36d9, Score: 14000
Depth 3: State = 0x36d9, Legal Moves = [((0, 0), (0, 1)), ((0, 3), (1, 3)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d9: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x11a1, Score: 16800
Depth 4: State = 0x11a1, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x11a1: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0xefc3, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7752500, N[0x3c25, ((2, 3), (2, 4))] = 347
Updated Q[0x3c07, ((0, 1), (0, 2))] = 19600, N[0x3c07, ((0, 1), (0, 2))] = 1
Updated Q[0x391c, ((1, 3), (2, 3))] = 19600, N[0x391c, ((1, 3), (2, 3))] = 1
Updated Q[0x36d9, ((0, 0), (0, 1))] = 19600, N[0x36d9, ((0, 0), (0, 1))] = 1
Updated Q[0x11a1, ((1, 1), (2, 1))] = 19600, N[0x11a1, ((1, 1), (2, 1))] = 1

--- Simulation 352 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.389268504852, 16803.389268504852, 22341.680504544176, 16803.389268504852, 19603.389268504852]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [24901.467405903557, 25201.467405903557, 25201.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d78, Score: 8400
Depth 2: State = 0x3d78, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d78: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x563f, Score: 11200
Depth 3: State = 0x563f, Legal Moves = [((1, 2), (2, 2)), ((2, 2), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x563f: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x56a4, Score: 14000
Depth 4: State = 0x56a4, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x56a4: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x56d7, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7769300, N[0x3c25, ((2, 3), (2, 4))] = 348
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3d78, ((0, 0), (0, 1))] = 16800, N[0x3d78, ((0, 0), (0, 1))] = 1
Updated Q[0x563f, ((1, 2), (2, 2))] = 16800, N[0x563f, ((1, 2), (2, 2))] = 1
Updated Q[0x56a4, ((4, 1), (4, 2))] = 16800, N[0x56a4, ((4, 1), (4, 2))] = 1

--- Simulation 353 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.390091017092, 16803.390091017092, 22325.756440597364, 16803.390091017092, 19603.390091017092]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 16801.16557645562, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c47, Score: 8400
Depth 2: State = 0x3c47, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c47: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x48fb, Score: 14000
Depth 3: State = 0x48fb, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48fb: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x493e, Score: 19600
Depth 4: State = 0x493e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x493e: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x46c1, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7791700, N[0x3c25, ((2, 3), (2, 4))] = 349
Updated Q[0x3c24, ((0, 4), (1, 4))] = 22400, N[0x3c24, ((0, 4), (1, 4))] = 1
Updated Q[0x3c47, ((0, 0), (1, 0))] = 22400, N[0x3c47, ((0, 0), (1, 0))] = 1
Updated Q[0x48fb, ((1, 2), (2, 2))] = 22400, N[0x48fb, ((1, 2), (2, 2))] = 1
Updated Q[0x493e, ((1, 3), (2, 3))] = 22400, N[0x493e, ((1, 3), (2, 3))] = 1

--- Simulation 354 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.390910997296, 16803.390910997296, 22325.96947692026, 16803.390910997296, 19603.390910997296]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.467405903557, 44201.46740590355, 19601.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x12df, Score: 24900
Depth 2: State = 0x12df, Legal Moves = [((0, 3), (1, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x12df: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x1343, Score: 30500
Depth 3: State = 0x1343, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1343: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x133f, Score: 33300
Depth 4: State = 0x133f, Legal Moves = [((0, 2), (0, 3)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x133f: [inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x1316, Score: 38900
End of simulation with depth 5. Reward (Score): 38900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7830600, N[0x3c25, ((2, 3), (2, 4))] = 350
Updated Q[0x3c25, ((2, 0), (2, 1))] = 38900, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x12df, ((0, 3), (1, 3))] = 38900, N[0x12df, ((0, 3), (1, 3))] = 1
Updated Q[0x1343, ((1, 2), (2, 2))] = 38900, N[0x1343, ((1, 2), (2, 2))] = 1
Updated Q[0x133f, ((0, 2), (0, 3))] = 38900, N[0x133f, ((0, 2), (0, 3))] = 1

--- Simulation 355 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.391728460498, 16803.391728460498, 22373.324152654975, 16803.391728460498, 19603.391728460498]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [33301.16557645562, 29401.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4547, Score: 11200
Depth 2: State = 0x4547, Legal Moves = [((1, 0), (1, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4547: [inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x213d, Score: 25200
Depth 3: State = 0x213d, Legal Moves = [((3, 2), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x213d: [inf, inf]
Selected move: ((3, 2), (3, 3))
New board state after move: 0x2181, Score: 28000
Depth 4: State = 0x2181, Legal Moves = [((3, 1), (4, 1)), ((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2181: [inf, inf, inf]
Selected move: ((3, 1), (4, 1))
New board state after move: 0x36f2, Score: 30800
End of simulation with depth 5. Reward (Score): 30800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7861400, N[0x3c25, ((2, 3), (2, 4))] = 351
Updated Q[0x3c25, ((2, 0), (2, 1))] = 30800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x4547, ((1, 0), (1, 1))] = 30800, N[0x4547, ((1, 0), (1, 1))] = 1
Updated Q[0x213d, ((3, 2), (3, 3))] = 30800, N[0x213d, ((3, 2), (3, 3))] = 1
Updated Q[0x2181, ((3, 1), (4, 1))] = 30800, N[0x2181, ((3, 1), (4, 1))] = 1

--- Simulation 356 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.39254342159, 16803.39254342159, 22397.3320777226, 16803.39254342159, 19603.39254342159]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.95294236785, 27301.95294236785, 27701.95294236785, 28734.460865135123, 25201.95294236785]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c24, Score: 11200
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x452b, Score: 14000
Depth 3: State = 0x452b, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x452b: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x43cb, Score: 19600
Depth 4: State = 0x43cb, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43cb: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a47, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7883800, N[0x3c25, ((2, 3), (2, 4))] = 352
Updated Q[0x3c24, ((2, 3), (3, 3))] = 108600, N[0x3c24, ((2, 3), (3, 3))] = 4
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x452b, ((1, 3), (2, 3))] = 22400, N[0x452b, ((1, 3), (2, 3))] = 1
Updated Q[0x43cb, ((1, 3), (2, 3))] = 22400, N[0x43cb, ((1, 3), (2, 3))] = 1

--- Simulation 357 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.393355895343, 16803.393355895343, 22397.339957386026, 16803.393355895343, 19603.393355895343]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 25201.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0xee48, Score: 13300
Depth 2: State = 0xee48, Legal Moves = [((0, 2), (1, 2)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0xee48: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x43f6, Score: 18900
Depth 3: State = 0x43f6, Legal Moves = [((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x43f6: [inf, inf]
Selected move: ((2, 4), (3, 4))
New board state after move: 0x43f6, Score: 21700
Depth 4: State = 0x43f6, Legal Moves = [((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x43f6: [inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x43f3, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7908300, N[0x3c25, ((2, 3), (2, 4))] = 353
Updated Q[0x3c24, ((2, 0), (2, 1))] = 24500, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0xee48, ((0, 2), (1, 2))] = 24500, N[0xee48, ((0, 2), (1, 2))] = 1
Updated Q[0x43f6, ((2, 4), (3, 4))] = 24500, N[0x43f6, ((2, 4), (3, 4))] = 1
Updated Q[0x43f6, ((2, 3), (2, 4))] = 24500, N[0x43f6, ((2, 3), (2, 4))] = 1

--- Simulation 358 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.3941658964, 16803.3941658964, 22403.296800531218, 16803.3941658964, 19603.3941658964]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4af5, Score: 8400
Depth 2: State = 0x4af5, Legal Moves = [((0, 3), (0, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4af5: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x4412, Score: 11200
Depth 3: State = 0x4412, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4412: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x43b1, Score: 16800
Depth 4: State = 0x43b1, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43b1: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x43b1, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7927900, N[0x3c25, ((2, 3), (2, 4))] = 354
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4af5, ((0, 3), (0, 4))] = 19600, N[0x4af5, ((0, 3), (0, 4))] = 1
Updated Q[0x4412, ((1, 2), (2, 2))] = 19600, N[0x4412, ((1, 2), (2, 2))] = 1
Updated Q[0x43b1, ((0, 3), (1, 3))] = 19600, N[0x43b1, ((0, 3), (1, 3))] = 1

--- Simulation 359 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.39497343927, 16803.39497343927, 22395.37818091548, 16803.39497343927, 19603.39497343927]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [30000.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x1ff4, Score: 19300
Depth 2: State = 0x1ff4, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x1ff4: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x1ff4, Score: 27000
Depth 3: State = 0x1ff4, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1ff4: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1f0a, Score: 29800
Depth 4: State = 0x1f0a, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1f0a: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x21af, Score: 32600
End of simulation with depth 5. Reward (Score): 32600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7960500, N[0x3c25, ((2, 3), (2, 4))] = 355
Updated Q[0x3c25, ((1, 3), (1, 4))] = 32600, N[0x3c25, ((1, 3), (1, 4))] = 1
Updated Q[0x1ff4, ((0, 2), (0, 3))] = 32600, N[0x1ff4, ((0, 2), (0, 3))] = 1
Updated Q[0x1ff4, ((0, 2), (1, 2))] = 32600, N[0x1ff4, ((0, 2), (1, 2))] = 1
Updated Q[0x1f0a, ((2, 0), (2, 1))] = 32600, N[0x1f0a, ((2, 0), (2, 1))] = 1

--- Simulation 360 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.39577853834, 16803.39577853834, 22424.12389118334, 16803.39577853834, 19603.39577853834]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22401.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x231e, Score: 13300
Depth 2: State = 0x231e, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x231e: [inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x231e, Score: 16100
Depth 3: State = 0x231e, Legal Moves = [((2, 0), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x231e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2079, Score: 18900
Depth 4: State = 0x2079, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2079: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2b0f, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7982200, N[0x3c25, ((2, 3), (2, 4))] = 356
Updated Q[0x3c25, ((2, 0), (2, 1))] = 21700, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x231e, ((1, 0), (1, 1))] = 21700, N[0x231e, ((1, 0), (1, 1))] = 1
Updated Q[0x231e, ((2, 0), (2, 1))] = 21700, N[0x231e, ((2, 0), (2, 1))] = 1
Updated Q[0x2079, ((0, 0), (0, 1))] = 21700, N[0x2079, ((0, 0), (0, 1))] = 1

--- Simulation 361 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.396581207868, 16803.396581207868, 22422.09013080353, 16803.396581207868, 19603.396581207868]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x455e, Score: 8400
Depth 2: State = 0x455e, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x455e: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4901, Score: 14000
Depth 3: State = 0x4901, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4901: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x443e, Score: 16800
Depth 4: State = 0x443e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x443e, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8001800, N[0x3c25, ((2, 3), (2, 4))] = 357
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x455e, ((0, 2), (1, 2))] = 19600, N[0x455e, ((0, 2), (1, 2))] = 1
Updated Q[0x4901, ((0, 1), (1, 1))] = 19600, N[0x4901, ((0, 1), (1, 1))] = 1
Updated Q[0x443e, ((2, 0), (2, 1))] = 19600, N[0x443e, ((2, 0), (2, 1))] = 1

--- Simulation 362 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.397381462, 16803.397381462, 22414.18541073534, 16803.397381462, 19603.397381462]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c21, Score: 14000
Depth 2: State = 0x3c21, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c21: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d8f, Score: 16800
Depth 3: State = 0x3d8f, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d8f: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x551d, Score: 19600
Depth 4: State = 0x551d, Legal Moves = [((0, 1), (1, 1)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x551d: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x1422, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8024200, N[0x3c25, ((2, 3), (2, 4))] = 358
Updated Q[0x3c24, ((0, 2), (1, 2))] = 22400, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c21, ((1, 3), (2, 3))] = 22400, N[0x3c21, ((1, 3), (2, 3))] = 1
Updated Q[0x3d8f, ((0, 2), (1, 2))] = 22400, N[0x3d8f, ((0, 2), (1, 2))] = 1
Updated Q[0x551d, ((0, 1), (1, 1))] = 22400, N[0x551d, ((0, 1), (1, 1))] = 1

--- Simulation 363 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.398179314747, 16803.398179314747, 22414.1460798044, 16803.398179314747, 19603.398179314747]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x36d8, Score: 19300
Depth 2: State = 0x36d8, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d8: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x11cd, Score: 22100
Depth 3: State = 0x11cd, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x11cd: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2c89, Score: 30500
Depth 4: State = 0x2c89, Legal Moves = [((2, 3), (2, 4)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2c89: [inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x2c7b, Score: 33300
End of simulation with depth 5. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8057500, N[0x3c25, ((2, 3), (2, 4))] = 359
Updated Q[0x3c24, ((1, 2), (2, 2))] = 33300, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x36d8, ((0, 0), (0, 1))] = 33300, N[0x36d8, ((0, 0), (0, 1))] = 1
Updated Q[0x11cd, ((2, 0), (2, 1))] = 33300, N[0x11cd, ((2, 0), (2, 1))] = 1
Updated Q[0x2c89, ((2, 3), (2, 4))] = 33300, N[0x2c89, ((2, 3), (2, 4))] = 1

--- Simulation 364 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.39897478001, 16803.39897478001, 22444.46908462102, 16803.39897478001, 19603.39897478001]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.467405903557, 30501.467405903557, 22401.467405903557, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c2c, Score: 10500
Depth 2: State = 0x3c2c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c2c: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c5e, Score: 24200
Depth 3: State = 0x3c5e, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5e: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3c5f, Score: 27000
Depth 4: State = 0x3c5f, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3c5f: [inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x3bb5, Score: 29800
End of simulation with depth 5. Reward (Score): 29800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8087300, N[0x3c25, ((2, 3), (2, 4))] = 360
Updated Q[0x3c25, ((2, 3), (2, 4))] = 29800, N[0x3c25, ((2, 3), (2, 4))] = 1
Updated Q[0x3c2c, ((1, 2), (2, 2))] = 29800, N[0x3c2c, ((1, 2), (2, 2))] = 1
Updated Q[0x3c5e, ((1, 3), (1, 4))] = 29800, N[0x3c5e, ((1, 3), (1, 4))] = 1
Updated Q[0x3c5f, ((0, 2), (0, 3))] = 29800, N[0x3c5f, ((0, 2), (0, 3))] = 1

--- Simulation 365 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.39976787157, 16803.39976787157, 22464.901405722056, 16803.39976787157, 19603.39976787157]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4836, Score: 8400
Depth 2: State = 0x4836, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4836: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x493e, Score: 14000
Depth 3: State = 0x493e, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x493e: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x4a91, Score: 19600
Depth 4: State = 0x4a91, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a91: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4a8a, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8109700, N[0x3c25, ((2, 3), (2, 4))] = 361
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4836, ((1, 3), (2, 3))] = 22400, N[0x4836, ((1, 3), (2, 3))] = 1
Updated Q[0x493e, ((0, 1), (1, 1))] = 22400, N[0x493e, ((0, 1), (1, 1))] = 1
Updated Q[0x4a91, ((0, 3), (1, 3))] = 22400, N[0x4a91, ((0, 3), (1, 3))] = 1

--- Simulation 366 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.400558603087, 16803.400558603087, 22464.721913056674, 16803.400558603087, 19603.400558603087]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x455e, Score: 8400
Depth 2: State = 0x455e, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x455e: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x47f3, Score: 11200
Depth 3: State = 0x47f3, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47f3: [inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x4a73, Score: 14000
Depth 4: State = 0x4a73, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a73: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4855, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8126500, N[0x3c25, ((2, 3), (2, 4))] = 362
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x455e, ((0, 3), (1, 3))] = 16800, N[0x455e, ((0, 3), (1, 3))] = 1
Updated Q[0x47f3, ((0, 1), (1, 1))] = 16800, N[0x47f3, ((0, 1), (1, 1))] = 1
Updated Q[0x4a73, ((0, 1), (0, 2))] = 16800, N[0x4a73, ((0, 1), (0, 2))] = 1

--- Simulation 367 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.401346988103, 16803.401346988103, 22449.07379845305, 16803.401346988103, 19603.401346988103]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4673, Score: 19300
Depth 2: State = 0x4673, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4673: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3db7, Score: 24900
Depth 3: State = 0x3db7, Legal Moves = [((0, 2), (1, 2))]
UCB1 values for moves at state 0x3db7: [inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x56ba, Score: 30500
Depth 4: State = 0x56ba, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8157000, N[0x3c25, ((2, 3), (2, 4))] = 363
Updated Q[0x3c25, ((1, 3), (1, 4))] = 30500, N[0x3c25, ((1, 3), (1, 4))] = 1
Updated Q[0x4673, ((2, 0), (2, 1))] = 30500, N[0x4673, ((2, 0), (2, 1))] = 1
Updated Q[0x3db7, ((0, 2), (1, 2))] = 30500, N[0x3db7, ((0, 2), (1, 2))] = 1

--- Simulation 368 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.402133040046, 16803.402133040046, 22471.252945840424, 16803.402133040046, 19603.402133040046]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c1f, Score: 8400
Depth 1: State = 0x3c1f, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1f: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37f0, Score: 11200
Depth 2: State = 0x37f0, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37f0: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3a92, Score: 14000
Depth 3: State = 0x3a92, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3a92: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x2dde, Score: 16800
Depth 4: State = 0x2dde, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2dde: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x2dad, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8179400, N[0x3c25, ((2, 3), (2, 4))] = 364
Updated Q[0x3c1f, ((1, 3), (2, 3))] = 22400, N[0x3c1f, ((1, 3), (2, 3))] = 1
Updated Q[0x37f0, ((0, 3), (1, 3))] = 22400, N[0x37f0, ((0, 3), (1, 3))] = 1
Updated Q[0x3a92, ((0, 2), (1, 2))] = 22400, N[0x3a92, ((0, 2), (1, 2))] = 1
Updated Q[0x2dde, ((0, 3), (1, 3))] = 22400, N[0x2dde, ((0, 3), (1, 3))] = 1

--- Simulation 369 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.402916772244, 16803.402916772244, 22471.05748218177, 16803.402916772244, 19603.402916772244]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47b0, Score: 8400
Depth 2: State = 0x47b0, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47b0: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x491d, Score: 14000
Depth 3: State = 0x491d, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x491d: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4920, Score: 16800
Depth 4: State = 0x4920, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4920: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x5129, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8199000, N[0x3c25, ((2, 3), (2, 4))] = 365
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x47b0, ((1, 2), (2, 2))] = 19600, N[0x47b0, ((1, 2), (2, 2))] = 1
Updated Q[0x491d, ((0, 3), (1, 3))] = 19600, N[0x491d, ((0, 3), (1, 3))] = 1
Updated Q[0x4920, ((0, 2), (0, 3))] = 19600, N[0x4920, ((0, 2), (0, 3))] = 1

--- Simulation 370 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.40369819789, 16803.40369819789, 22463.191856336343, 16803.40369819789, 19603.40369819789]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [30500.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3956, Score: 11200
Depth 2: State = 0x3956, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3956: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x1335, Score: 21700
Depth 3: State = 0x1335, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1335: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x564e, Score: 24500
Depth 4: State = 0x564e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x564e: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x5658, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8226300, N[0x3c25, ((2, 3), (2, 4))] = 366
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27300, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3956, ((0, 3), (0, 4))] = 27300, N[0x3956, ((0, 3), (0, 4))] = 1
Updated Q[0x1335, ((0, 2), (1, 2))] = 27300, N[0x1335, ((0, 2), (1, 2))] = 1
Updated Q[0x564e, ((1, 3), (2, 3))] = 27300, N[0x564e, ((1, 3), (2, 3))] = 1

--- Simulation 371 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.404477330085, 16803.404477330085, 22476.4074630775, 16803.404477330085, 19603.404477330085]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc2, Score: 8400
Depth 1: State = 0x3bc2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc2: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3869, Score: 11200
Depth 2: State = 0x3869, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3869: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x1317, Score: 14000
Depth 3: State = 0x1317, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1317: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x43ed, Score: 16800
Depth 4: State = 0x43ed, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43ed: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x43f4, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8245900, N[0x3c25, ((2, 3), (2, 4))] = 367
Updated Q[0x3bc2, ((1, 3), (2, 3))] = 19600, N[0x3bc2, ((1, 3), (2, 3))] = 1
Updated Q[0x3869, ((1, 2), (1, 3))] = 19600, N[0x3869, ((1, 2), (1, 3))] = 1
Updated Q[0x1317, ((0, 0), (1, 0))] = 19600, N[0x1317, ((0, 0), (1, 0))] = 1
Updated Q[0x43ed, ((1, 3), (1, 4))] = 19600, N[0x43ed, ((1, 3), (1, 4))] = 1

--- Simulation 372 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.405254181806, 16803.405254181806, 22468.570123393598, 16803.405254181806, 19603.405254181806]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3ae9, Score: 11200
Depth 2: State = 0x3ae9, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3ae9: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x12cf, Score: 21700
Depth 3: State = 0x12cf, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x12cf: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x12d0, Score: 24500
Depth 4: State = 0x12d0, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x12d0: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x102b, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8273200, N[0x3c25, ((2, 3), (2, 4))] = 368
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27300, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3ae9, ((0, 1), (1, 1))] = 27300, N[0x3ae9, ((0, 1), (1, 1))] = 1
Updated Q[0x12cf, ((1, 3), (1, 4))] = 27300, N[0x12cf, ((1, 3), (1, 4))] = 1
Updated Q[0x12d0, ((2, 0), (2, 1))] = 27300, N[0x12d0, ((2, 0), (2, 1))] = 1

--- Simulation 373 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.406028765934, 16803.406028765934, 22481.699290653534, 16803.406028765934, 19603.406028765934]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.467405903557, 27301.467405903557, 19601.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c1e, Score: 8400
Depth 2: State = 0x3c1e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3979, Score: 11200
Depth 3: State = 0x3979, Legal Moves = [((0, 1), (1, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3979: [inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x100c, Score: 14000
Depth 4: State = 0x100c, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x100c: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x1099, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8290000, N[0x3c25, ((2, 3), (2, 4))] = 369
Updated Q[0x3c25, ((2, 3), (3, 3))] = 16800, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3c1e, ((2, 0), (2, 1))] = 16800, N[0x3c1e, ((2, 0), (2, 1))] = 1
Updated Q[0x3979, ((0, 1), (1, 1))] = 16800, N[0x3979, ((0, 1), (1, 1))] = 1
Updated Q[0x100c, ((4, 1), (4, 2))] = 16800, N[0x100c, ((4, 1), (4, 2))] = 1

--- Simulation 374 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.406801095236, 16803.406801095236, 22466.30201222763, 16803.406801095236, 19603.406801095236]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4ab4, Score: 8400
Depth 2: State = 0x4ab4, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab4: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4925, Score: 14000
Depth 3: State = 0x4925, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4925: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4a77, Score: 16800
Depth 4: State = 0x4a77, Legal Moves = [((0, 1), (0, 2)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((3, 1), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4a77: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4592, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8309600, N[0x3c25, ((2, 3), (2, 4))] = 370
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4ab4, ((1, 3), (2, 3))] = 19600, N[0x4ab4, ((1, 3), (2, 3))] = 1
Updated Q[0x4925, ((2, 0), (2, 1))] = 19600, N[0x4925, ((2, 0), (2, 1))] = 1
Updated Q[0x4a77, ((0, 1), (0, 2))] = 19600, N[0x4a77, ((0, 1), (0, 2))] = 1

--- Simulation 375 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.40757118237, 16803.40757118237, 22458.55552956868, 16803.40757118237, 19603.40757118237]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46c2, Score: 8400
Depth 2: State = 0x46c2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46c2: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4815, Score: 11200
Depth 3: State = 0x4815, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4815: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4968, Score: 14000
Depth 4: State = 0x4968, Legal Moves = [((1, 2), (1, 3)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4968: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4965, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8326400, N[0x3c25, ((2, 3), (2, 4))] = 371
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x46c2, ((1, 3), (2, 3))] = 16800, N[0x46c2, ((1, 3), (2, 3))] = 1
Updated Q[0x4815, ((1, 1), (2, 1))] = 16800, N[0x4815, ((1, 1), (2, 1))] = 1
Updated Q[0x4968, ((1, 2), (1, 3))] = 16800, N[0x4968, ((1, 2), (1, 3))] = 1

--- Simulation 376 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.4083390399, 16803.4083390399, 22443.30363678226, 16803.4083390399, 19603.4083390399]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 8400
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x493c, Score: 14000
Depth 2: State = 0x493c, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x493c: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x43ea, Score: 16800
Depth 3: State = 0x43ea, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x43ea: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x453d, Score: 19600
Depth 4: State = 0x453d, Legal Moves = [((3, 3), (3, 4))]
UCB1 values for moves at state 0x453d: [inf]
Selected move: ((3, 3), (3, 4))
New board state after move: 0x453d, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8348800, N[0x3c25, ((2, 3), (2, 4))] = 372
Updated Q[0x3c25, ((0, 0), (0, 1))] = 22400, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x493c, ((1, 3), (1, 4))] = 22400, N[0x493c, ((1, 3), (1, 4))] = 1
Updated Q[0x43ea, ((2, 0), (2, 1))] = 22400, N[0x43ea, ((2, 0), (2, 1))] = 1
Updated Q[0x453d, ((3, 3), (3, 4))] = 22400, N[0x453d, ((3, 3), (3, 4))] = 1

--- Simulation 377 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.40910468027, 16803.40910468027, 22443.18750653196, 16803.40910468027, 19603.40910468027]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [25201.467405903557, 19601.467405903557, 16801.467405903557, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x386f, Score: 27700
Depth 2: State = 0x386f, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x386f: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x386f, Score: 30500
Depth 3: State = 0x386f, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x386f: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x36bd, Score: 38200
Depth 4: State = 0x36bd, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36bd: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d11, Score: 43800
End of simulation with depth 5. Reward (Score): 43800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8392600, N[0x3c25, ((2, 3), (2, 4))] = 373
Updated Q[0x3c25, ((1, 3), (2, 3))] = 43800, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x386f, ((0, 4), (1, 4))] = 43800, N[0x386f, ((0, 4), (1, 4))] = 1
Updated Q[0x386f, ((1, 3), (2, 3))] = 43800, N[0x386f, ((1, 3), (2, 3))] = 1
Updated Q[0x36bd, ((2, 0), (2, 1))] = 43800, N[0x36bd, ((2, 0), (2, 1))] = 1

--- Simulation 378 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.409868115836, 16803.409868115836, 22500.44465279326, 16803.409868115836, 19603.409868115836]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x493e, Score: 8400
Depth 2: State = 0x493e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x493e: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x49aa, Score: 14000
Depth 3: State = 0x49aa, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x49aa: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x48f7, Score: 19600
Depth 4: State = 0x48f7, Legal Moves = [((0, 3), (0, 4)), ((0, 3), (1, 3)), ((3, 2), (4, 2)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x48f7: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x48f1, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8415000, N[0x3c25, ((2, 3), (2, 4))] = 374
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x493e, ((1, 3), (2, 3))] = 22400, N[0x493e, ((1, 3), (2, 3))] = 1
Updated Q[0x49aa, ((2, 0), (2, 1))] = 22400, N[0x49aa, ((2, 0), (2, 1))] = 1
Updated Q[0x48f7, ((0, 3), (0, 4))] = 22400, N[0x48f7, ((0, 3), (0, 4))] = 1

--- Simulation 379 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.410629358845, 16803.410629358845, 22500.17635944566, 16803.410629358845, 19603.410629358845]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bbc, Score: 8400
Depth 1: State = 0x3bbc, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbc: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d74, Score: 11200
Depth 2: State = 0x3d74, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d74: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397c, Score: 14000
Depth 3: State = 0x397c, Legal Moves = [((1, 3), (2, 3))]
UCB1 values for moves at state 0x397c: [inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3953, Score: 16800
Depth 4: State = 0x3953, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((0, 3), (1, 3))]
UCB1 values for moves at state 0x3953: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x390f, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8434600, N[0x3c25, ((2, 3), (2, 4))] = 375
Updated Q[0x3bbc, ((1, 3), (1, 4))] = 19600, N[0x3bbc, ((1, 3), (1, 4))] = 1
Updated Q[0x3d74, ((2, 0), (2, 1))] = 19600, N[0x3d74, ((2, 0), (2, 1))] = 1
Updated Q[0x397c, ((1, 3), (2, 3))] = 19600, N[0x397c, ((1, 3), (2, 3))] = 1
Updated Q[0x3953, ((0, 2), (0, 3))] = 19600, N[0x3953, ((0, 2), (0, 3))] = 1

--- Simulation 380 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.411388421442, 16803.411388421442, 22492.44283000725, 16803.411388421442, 19603.411388421442]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22401.467405903557, 19601.467405903557, 16801.467405903557, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3ab7, Score: 13300
Depth 2: State = 0x3ab7, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3ab7: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1216, Score: 16100
Depth 3: State = 0x1216, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1216: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x1074, Score: 21000
Depth 4: State = 0x1074, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x1074: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x2ef0, Score: 39500
End of simulation with depth 5. Reward (Score): 39500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8474100, N[0x3c25, ((2, 3), (2, 4))] = 376
Updated Q[0x3c25, ((2, 3), (2, 4))] = 39500, N[0x3c25, ((2, 3), (2, 4))] = 1
Updated Q[0x3ab7, ((0, 2), (1, 2))] = 39500, N[0x3ab7, ((0, 2), (1, 2))] = 1
Updated Q[0x1216, ((1, 3), (2, 3))] = 39500, N[0x1216, ((1, 3), (2, 3))] = 1
Updated Q[0x1074, ((1, 1), (2, 1))] = 39500, N[0x1074, ((1, 1), (2, 1))] = 1

--- Simulation 381 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.41214531568, 16803.41214531568, 22537.675967958698, 16803.41214531568, 19603.41214531568]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [21700.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37bc, Score: 11200
Depth 2: State = 0x37bc, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37bc: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3a65, Score: 14000
Depth 3: State = 0x3a65, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3a65: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x3a83, Score: 16800
Depth 4: State = 0x3a83, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3a83: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x37de, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8493700, N[0x3c25, ((2, 3), (2, 4))] = 377
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x37bc, ((1, 3), (2, 3))] = 19600, N[0x37bc, ((1, 3), (2, 3))] = 1
Updated Q[0x3a65, ((0, 2), (0, 3))] = 19600, N[0x3a65, ((0, 2), (0, 3))] = 1
Updated Q[0x3a83, ((2, 0), (2, 1))] = 19600, N[0x3a83, ((2, 0), (2, 1))] = 1

--- Simulation 382 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.41290005351, 16803.41290005351, 22529.88399610712, 16803.41290005351, 19603.41290005351]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 30501.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x367a, Score: 13300
Depth 2: State = 0x367a, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x367a: [inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x366d, Score: 16100
Depth 3: State = 0x366d, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x366d: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3692, Score: 18900
Depth 4: State = 0x3692, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3692: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x523b, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8518200, N[0x3c25, ((2, 3), (2, 4))] = 378
Updated Q[0x3c25, ((1, 3), (2, 3))] = 24500, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x367a, ((0, 3), (0, 4))] = 24500, N[0x367a, ((0, 3), (0, 4))] = 1
Updated Q[0x366d, ((1, 3), (2, 3))] = 24500, N[0x366d, ((1, 3), (2, 3))] = 1
Updated Q[0x3692, ((1, 2), (1, 3))] = 24500, N[0x3692, ((1, 2), (1, 3))] = 1

--- Simulation 383 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.41365264678, 16803.41365264678, 22535.09621426697, 16803.41365264678, 19603.41365264678]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [27201.467405903557, 16801.467405903557, 16801.467405903557, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c29, Score: 13300
Depth 2: State = 0x3c29, Legal Moves = [((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c29: [inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x3c62, Score: 16100
Depth 3: State = 0x3c62, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c62: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x386a, Score: 18900
Depth 4: State = 0x386a, Legal Moves = [((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x386a: [inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2162, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8545500, N[0x3c25, ((2, 3), (2, 4))] = 379
Updated Q[0x3c24, ((1, 2), (2, 2))] = 27300, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3c29, ((1, 4), (2, 4))] = 27300, N[0x3c29, ((1, 4), (2, 4))] = 1
Updated Q[0x3c62, ((2, 0), (2, 1))] = 27300, N[0x3c62, ((2, 0), (2, 1))] = 1
Updated Q[0x386a, ((1, 2), (1, 3))] = 27300, N[0x386a, ((1, 2), (1, 3))] = 1

--- Simulation 384 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.41440310725, 16803.41440310725, 22547.668789800813, 16803.41440310725, 19603.41440310725]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 35001.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d4c, Score: 16100
Depth 2: State = 0x3d4c, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d4c: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x48f2, Score: 21700
Depth 3: State = 0x48f2, Legal Moves = [((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x48f2: [inf, inf]
Selected move: ((3, 1), (3, 2))
New board state after move: 0x4a44, Score: 27300
Depth 4: State = 0x4a44, Legal Moves = [((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4a44: [inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2d27, Score: 35700
End of simulation with depth 5. Reward (Score): 35700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8581200, N[0x3c25, ((2, 3), (2, 4))] = 380
Updated Q[0x3c25, ((2, 0), (2, 1))] = 35700, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3d4c, ((1, 1), (2, 1))] = 35700, N[0x3d4c, ((1, 1), (2, 1))] = 1
Updated Q[0x48f2, ((3, 1), (3, 2))] = 35700, N[0x48f2, ((3, 1), (3, 2))] = 1
Updated Q[0x4a44, ((1, 2), (1, 3))] = 35700, N[0x4a44, ((1, 2), (1, 3))] = 1

--- Simulation 385 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.415151446578, 16803.415151446578, 22582.280456730557, 16803.415151446578, 19603.415151446578]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22400.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c24, Score: 8400
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4ad8, Score: 11200
Depth 3: State = 0x4ad8, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x4ad8: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x5267, Score: 14000
Depth 4: State = 0x5267, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x5267: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x516f, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8598000, N[0x3c25, ((2, 3), (2, 4))] = 381
Updated Q[0x3c24, ((0, 4), (1, 4))] = 16800, N[0x3c24, ((0, 4), (1, 4))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4ad8, ((0, 0), (0, 1))] = 16800, N[0x4ad8, ((0, 0), (0, 1))] = 1
Updated Q[0x5267, ((1, 3), (2, 3))] = 16800, N[0x5267, ((1, 3), (2, 3))] = 1

--- Simulation 386 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.415897676336, 16803.415897676336, 22567.104135597554, 16803.415897676336, 19603.415897676336]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c64, Score: 14000
Depth 2: State = 0x3c64, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c64: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x39bf, Score: 16800
Depth 3: State = 0x39bf, Legal Moves = [((0, 1), (0, 2)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x39bf: [inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3d33, Score: 30500
Depth 4: State = 0x3d33, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8628500, N[0x3c25, ((2, 3), (2, 4))] = 382
Updated Q[0x3c24, ((1, 3), (2, 3))] = 30500, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3c64, ((2, 0), (2, 1))] = 30500, N[0x3c64, ((2, 0), (2, 1))] = 1
Updated Q[0x39bf, ((0, 1), (0, 2))] = 30500, N[0x39bf, ((0, 1), (0, 2))] = 1

--- Simulation 387 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.416641808, 16803.416641808, 22587.871145680936, 16803.416641808, 19603.416641808]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [27201.648374031523, 16801.648374031523, 16801.648374031523, 27301.648374031523, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3aa7, Score: 16000
Depth 2: State = 0x3aa7, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3aa7: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3ab6, Score: 18800
Depth 3: State = 0x3ab6, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3ab6: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d5c, Score: 21600
Depth 4: State = 0x3d5c, Legal Moves = [((0, 2), (1, 2))]
UCB1 values for moves at state 0x3d5c: [inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x57ec, Score: 27200
End of simulation with depth 5. Reward (Score): 27200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8655700, N[0x3c25, ((2, 3), (2, 4))] = 383
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27200, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3aa7, ((0, 3), (0, 4))] = 27200, N[0x3aa7, ((0, 3), (0, 4))] = 1
Updated Q[0x3ab6, ((2, 0), (2, 1))] = 27200, N[0x3ab6, ((2, 0), (2, 1))] = 1
Updated Q[0x3d5c, ((0, 2), (1, 2))] = 27200, N[0x3d5c, ((0, 2), (1, 2))] = 1

--- Simulation 388 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.417383852942, 16803.417383852942, 22599.91352355195, 16803.417383852942, 19603.417383852942]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.648374031523, 30501.648374031523, 22401.648374031523, 29801.648374031523, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c1e, Score: 8400
Depth 2: State = 0x3c1e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3c1e: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d71, Score: 11200
Depth 3: State = 0x3d71, Legal Moves = [((1, 1), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d71: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4808, Score: 14000
Depth 4: State = 0x4808, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (1, 1)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4808: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x1c5b, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8672500, N[0x3c25, ((2, 3), (2, 4))] = 384
Updated Q[0x3c25, ((2, 3), (3, 3))] = 16800, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3c1e, ((2, 0), (2, 1))] = 16800, N[0x3c1e, ((2, 0), (2, 1))] = 1
Updated Q[0x3d71, ((1, 1), (2, 1))] = 16800, N[0x3d71, ((1, 1), (2, 1))] = 1
Updated Q[0x4808, ((0, 0), (1, 0))] = 16800, N[0x4808, ((0, 0), (1, 0))] = 1

--- Simulation 389 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.41812382246, 16803.41812382246, 22584.809847067558, 16803.41812382246, 19603.41812382246]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c02, Score: 8400
Depth 1: State = 0x3c02, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c02: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3c46, Score: 11200
Depth 2: State = 0x3c46, Legal Moves = [((0, 0), (1, 0)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c46: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x1dd5, Score: 14000
Depth 3: State = 0x1dd5, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1dd5: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1c82, Score: 16800
Depth 4: State = 0x1c82, Legal Moves = [((0, 1), (0, 2)), ((2, 1), (3, 1)), ((2, 3), (3, 3)), ((3, 1), (4, 1))]
UCB1 values for moves at state 0x1c82: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x1ea0, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8692100, N[0x3c25, ((2, 3), (2, 4))] = 385
Updated Q[0x3c02, ((1, 3), (1, 4))] = 19600, N[0x3c02, ((1, 3), (1, 4))] = 1
Updated Q[0x3c46, ((0, 0), (1, 0))] = 19600, N[0x3c46, ((0, 0), (1, 0))] = 1
Updated Q[0x1dd5, ((2, 0), (2, 1))] = 19600, N[0x1dd5, ((2, 0), (2, 1))] = 1
Updated Q[0x1c82, ((0, 1), (0, 2))] = 19600, N[0x1c82, ((0, 1), (0, 2))] = 1

--- Simulation 390 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.418861727754, 16803.418861727754, 22577.057358210863, 16803.418861727754, 19603.418861727754]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [21700.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x368f, Score: 11200
Depth 2: State = 0x368f, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x368f: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d2d, Score: 14000
Depth 3: State = 0x3d2d, Legal Moves = [((1, 1), (2, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3d2d: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x39bf, Score: 16800
Depth 4: State = 0x39bf, Legal Moves = [((0, 1), (0, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((3, 1), (3, 2)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x39bf: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3d50, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8719800, N[0x3c25, ((2, 3), (2, 4))] = 386
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27700, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x368f, ((2, 0), (2, 1))] = 27700, N[0x368f, ((2, 0), (2, 1))] = 1
Updated Q[0x3d2d, ((1, 1), (2, 1))] = 27700, N[0x3d2d, ((1, 1), (2, 1))] = 1
Updated Q[0x39bf, ((0, 1), (0, 2))] = 27700, N[0x39bf, ((0, 1), (0, 2))] = 1

--- Simulation 391 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.419597579934, 16803.419597579934, 22590.32949334857, 16803.419597579934, 19603.419597579934]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bfc, Score: 11200
Depth 1: State = 0x3bfc, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bfc: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3919, Score: 14000
Depth 2: State = 0x3919, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3919: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3919, Score: 16800
Depth 3: State = 0x3919, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3919: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3919, Score: 19600
Depth 4: State = 0x3919, Legal Moves = [((1, 1), (2, 1)), ((2, 2), (3, 2))]
UCB1 values for moves at state 0x3919: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x53f7, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8742200, N[0x3c25, ((2, 3), (2, 4))] = 387
Updated Q[0x3bfc, ((1, 3), (2, 3))] = 22400, N[0x3bfc, ((1, 3), (2, 3))] = 1
Updated Q[0x3919, ((0, 3), (1, 3))] = 22400, N[0x3919, ((0, 3), (1, 3))] = 1
Updated Q[0x3919, ((2, 0), (2, 1))] = 22400, N[0x3919, ((2, 0), (2, 1))] = 1
Updated Q[0x3919, ((1, 1), (2, 1))] = 22400, N[0x3919, ((1, 1), (2, 1))] = 1

--- Simulation 392 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.42033139002, 16803.42033139002, 22589.83794790302, 16803.42033139002, 19603.42033139002]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 19601.467405903557, 27301.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3670, Score: 16800
Depth 2: State = 0x3670, Legal Moves = [((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3670: [inf, inf]
Selected move: ((3, 2), (4, 2))
New board state after move: 0x390f, Score: 19600
Depth 3: State = 0x390f, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x390f: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x39a8, Score: 22400
Depth 4: State = 0x39a8, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x39a8: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d30, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8767400, N[0x3c25, ((2, 3), (2, 4))] = 388
Updated Q[0x3c24, ((2, 0), (2, 1))] = 25200, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3670, ((3, 2), (4, 2))] = 25200, N[0x3670, ((3, 2), (4, 2))] = 1
Updated Q[0x390f, ((0, 1), (1, 1))] = 25200, N[0x390f, ((0, 1), (1, 1))] = 1
Updated Q[0x39a8, ((2, 0), (2, 1))] = 25200, N[0x39a8, ((2, 0), (2, 1))] = 1

--- Simulation 393 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.421063168957, 16803.421063168957, 22596.565430745784, 16803.421063168957, 19603.421063168957]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 22401.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36da, Score: 8400
Depth 2: State = 0x36da, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (1, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x36da: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x14ab, Score: 11200
Depth 3: State = 0x14ab, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 2), (1, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x14ab: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x4aaa, Score: 16800
Depth 4: State = 0x4aaa, Legal Moves = [((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4aaa: [inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x4ab8, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8787000, N[0x3c25, ((2, 3), (2, 4))] = 389
Updated Q[0x3c25, ((2, 0), (2, 1))] = 19600, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x36da, ((0, 0), (0, 1))] = 19600, N[0x36da, ((0, 0), (0, 1))] = 1
Updated Q[0x14ab, ((0, 1), (1, 1))] = 19600, N[0x14ab, ((0, 1), (1, 1))] = 1
Updated Q[0x4aaa, ((2, 3), (2, 4))] = 19600, N[0x4aaa, ((2, 3), (2, 4))] = 1

--- Simulation 394 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.421792927584, 16803.421792927584, 22588.862437803746, 16803.421792927584, 19603.421792927584]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [27301.16557645562, 27301.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bde, Score: 11200
Depth 2: State = 0x3bde, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bde: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c5f, Score: 14000
Depth 3: State = 0x3c5f, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5f: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3b0c, Score: 16800
Depth 4: State = 0x3b0c, Legal Moves = [((0, 2), (1, 2)), ((1, 1), (2, 1))]
UCB1 values for moves at state 0x3b0c: [inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x21e7, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8806600, N[0x3c25, ((2, 3), (2, 4))] = 390
Updated Q[0x3c25, ((1, 3), (2, 3))] = 19600, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3bde, ((0, 2), (1, 2))] = 19600, N[0x3bde, ((0, 2), (1, 2))] = 1
Updated Q[0x3c5f, ((2, 0), (2, 1))] = 19600, N[0x3c5f, ((2, 0), (2, 1))] = 1
Updated Q[0x3b0c, ((0, 2), (1, 2))] = 19600, N[0x3b0c, ((0, 2), (1, 2))] = 1

--- Simulation 395 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.422520676668, 16803.422520676668, 22581.198947096836, 16803.422520676668, 19603.422520676668]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c68, Score: 16500
Depth 1: State = 0x3c68, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c68: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3847, Score: 22100
Depth 2: State = 0x3847, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3847: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3c09, Score: 24900
Depth 3: State = 0x3c09, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c09: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x50f2, Score: 27700
Depth 4: State = 0x50f2, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x50f2: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4542, Score: 47000
End of simulation with depth 5. Reward (Score): 47000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8853600, N[0x3c25, ((2, 3), (2, 4))] = 391
Updated Q[0x3c68, ((1, 3), (2, 3))] = 47000, N[0x3c68, ((1, 3), (2, 3))] = 1
Updated Q[0x3847, ((0, 1), (0, 2))] = 47000, N[0x3847, ((0, 1), (0, 2))] = 1
Updated Q[0x3c09, ((1, 2), (1, 3))] = 47000, N[0x3c09, ((1, 2), (1, 3))] = 1
Updated Q[0x50f2, ((2, 0), (2, 1))] = 47000, N[0x50f2, ((2, 0), (2, 1))] = 1

--- Simulation 396 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.42324642689, 16803.42324642689, 22643.651381882628, 16803.42324642689, 19603.42324642689]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 30501.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x458d, Score: 13300
Depth 2: State = 0x458d, Legal Moves = [((0, 0), (0, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x458d: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1dbb, Score: 18900
Depth 3: State = 0x1dbb, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1dbb: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x107f, Score: 21700
Depth 4: State = 0x107f, Legal Moves = [((2, 0), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x107f: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1325, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8878100, N[0x3c25, ((2, 3), (2, 4))] = 392
Updated Q[0x3c24, ((2, 0), (2, 1))] = 24500, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x458d, ((0, 0), (0, 1))] = 24500, N[0x458d, ((0, 0), (0, 1))] = 1
Updated Q[0x1dbb, ((1, 0), (1, 1))] = 24500, N[0x1dbb, ((1, 0), (1, 1))] = 1
Updated Q[0x107f, ((2, 0), (2, 1))] = 24500, N[0x107f, ((2, 0), (2, 1))] = 1

--- Simulation 397 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.42397018884, 16803.42397018884, 22648.38722232422, 16803.42397018884, 19603.42397018884]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bff, Score: 11200
Depth 1: State = 0x3bff, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bff: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c64, Score: 14000
Depth 2: State = 0x3c64, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c64: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x386c, Score: 16800
Depth 3: State = 0x386c, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x386c: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x1bfb, Score: 33300
Depth 4: State = 0x1bfb, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1))]
UCB1 values for moves at state 0x1bfb: [inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x2168, Score: 38900
End of simulation with depth 5. Reward (Score): 38900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8917000, N[0x3c25, ((2, 3), (2, 4))] = 393
Updated Q[0x3bff, ((1, 3), (2, 3))] = 38900, N[0x3bff, ((1, 3), (2, 3))] = 1
Updated Q[0x3c64, ((2, 0), (2, 1))] = 38900, N[0x3c64, ((2, 0), (2, 1))] = 1
Updated Q[0x386c, ((1, 1), (2, 1))] = 38900, N[0x386c, ((1, 1), (2, 1))] = 1
Updated Q[0x1bfb, ((0, 3), (1, 3))] = 38900, N[0x1bfb, ((0, 3), (1, 3))] = 1

--- Simulation 398 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.424691973032, 16803.424691973032, 22689.740182883306, 16803.424691973032, 19603.424691973032]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.873992678666, 19601.873992678666, 22051.325112930976, 22401.873992678666, 19601.873992678666]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3af6, Score: 11200
Depth 2: State = 0x3af6, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3af6: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x390f, Score: 14000
Depth 3: State = 0x390f, Legal Moves = [((0, 0), (1, 0)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x390f: [inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x1007, Score: 16800
Depth 4: State = 0x1007, Legal Moves = [((0, 0), (0, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1007: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1d87, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8936600, N[0x3c25, ((2, 3), (2, 4))] = 394
Updated Q[0x3c24, ((2, 3), (3, 3))] = 42000, N[0x3c24, ((2, 3), (3, 3))] = 2
Updated Q[0x3af6, ((0, 1), (1, 1))] = 19600, N[0x3af6, ((0, 1), (1, 1))] = 1
Updated Q[0x390f, ((0, 0), (1, 0))] = 19600, N[0x390f, ((0, 0), (1, 0))] = 1
Updated Q[0x1007, ((0, 0), (0, 1))] = 19600, N[0x1007, ((0, 0), (0, 1))] = 1

--- Simulation 399 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.425411789896, 16803.425411789896, 22681.898458077783, 16803.425411789896, 19603.425411789896]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 25201.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d76, Score: 8400
Depth 2: State = 0x3d76, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d76: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x567a, Score: 11200
Depth 3: State = 0x567a, Legal Moves = [((1, 3), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x567a: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x5176, Score: 18900
Depth 4: State = 0x5176, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x5176: [inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x514d, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8958300, N[0x3c25, ((2, 3), (2, 4))] = 395
Updated Q[0x3c24, ((2, 0), (2, 1))] = 21700, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3d76, ((0, 0), (0, 1))] = 21700, N[0x3d76, ((0, 0), (0, 1))] = 1
Updated Q[0x567a, ((1, 3), (2, 3))] = 21700, N[0x567a, ((1, 3), (2, 3))] = 1
Updated Q[0x5176, ((0, 1), (1, 1))] = 21700, N[0x5176, ((0, 1), (1, 1))] = 1

--- Simulation 400 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.42612964978, 16803.42612964978, 22679.412893620323, 16803.42612964978, 19603.42612964978]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 30501.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x10b1, Score: 13300
Depth 2: State = 0x10b1, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x10b1: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x1203, Score: 16100
Depth 3: State = 0x1203, Legal Moves = [((2, 0), (3, 0)), ((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1203: [inf, inf, inf]
Selected move: ((2, 0), (3, 0))
New board state after move: 0x1204, Score: 18900
Depth 4: State = 0x1204, Legal Moves = [((2, 2), (3, 2)), ((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1204: [inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x1204, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8980000, N[0x3c25, ((2, 3), (2, 4))] = 396
Updated Q[0x3c24, ((2, 0), (2, 1))] = 21700, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x10b1, ((1, 1), (2, 1))] = 21700, N[0x10b1, ((1, 1), (2, 1))] = 1
Updated Q[0x1203, ((2, 0), (3, 0))] = 21700, N[0x1203, ((2, 0), (3, 0))] = 1
Updated Q[0x1204, ((2, 2), (3, 2))] = 21700, N[0x1204, ((2, 2), (3, 2))] = 1

--- Simulation 401 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.426845562954, 16803.426845562954, 22676.93988223657, 16803.426845562954, 19603.426845562954]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 22401.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3afa, Score: 11200
Depth 2: State = 0x3afa, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3afa: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x2ffe, Score: 22100
Depth 3: State = 0x2ffe, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x2ffe: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x2fee, Score: 24900
Depth 4: State = 0x2fee, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 2), (3, 3)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x2fee: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5388, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9007700, N[0x3c25, ((2, 3), (2, 4))] = 397
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27700, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3afa, ((0, 2), (1, 2))] = 27700, N[0x3afa, ((0, 2), (1, 2))] = 1
Updated Q[0x2ffe, ((0, 3), (1, 3))] = 27700, N[0x2ffe, ((0, 3), (1, 3))] = 1
Updated Q[0x2fee, ((1, 2), (1, 3))] = 27700, N[0x2fee, ((1, 2), (1, 3))] = 1

--- Simulation 402 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.427559539603, 16803.427559539603, 22689.59267919398, 16803.427559539603, 19603.427559539603]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c5e, Score: 8400
Depth 1: State = 0x3c5e, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5e: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3c2b, Score: 11200
Depth 2: State = 0x3c2b, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c2b: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3986, Score: 14000
Depth 3: State = 0x3986, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9021700, N[0x3c25, ((2, 3), (2, 4))] = 398
Updated Q[0x3c5e, ((0, 3), (1, 3))] = 14000, N[0x3c5e, ((0, 3), (1, 3))] = 1
Updated Q[0x3c2b, ((2, 0), (2, 1))] = 14000, N[0x3c2b, ((2, 0), (2, 1))] = 1

--- Simulation 403 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.428271589837, 16803.428271589837, 22667.75978342566, 16803.428271589837, 19603.428271589837]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [30501.16557645562, 19601.16557645562, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3aa6, Score: 15400
Depth 2: State = 0x3aa6, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3aa6: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c5e, Score: 18200
Depth 3: State = 0x3c5e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5e: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x36d6, Score: 21000
Depth 4: State = 0x36d6, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d6: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c6c, Score: 28600
End of simulation with depth 5. Reward (Score): 28600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9050300, N[0x3c25, ((2, 3), (2, 4))] = 399
Updated Q[0x3c24, ((1, 3), (2, 3))] = 28600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3aa6, ((0, 2), (1, 2))] = 28600, N[0x3aa6, ((0, 2), (1, 2))] = 1
Updated Q[0x3c5e, ((1, 3), (2, 3))] = 28600, N[0x3c5e, ((1, 3), (2, 3))] = 1
Updated Q[0x36d6, ((2, 0), (2, 1))] = 28600, N[0x36d6, ((2, 0), (2, 1))] = 1

--- Simulation 404 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.428981723693, 16803.428981723693, 22682.627804151092, 16803.428981723693, 19603.428981723693]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bff, Score: 8400
Depth 2: State = 0x3bff, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bff: [inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3bde, Score: 11200
Depth 3: State = 0x3bde, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bde: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3dbb, Score: 14000
Depth 4: State = 0x3dbb, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3dbb: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3db1, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9067100, N[0x3c25, ((2, 3), (2, 4))] = 400
Updated Q[0x3c24, ((0, 2), (1, 2))] = 16800, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3bff, ((0, 4), (1, 4))] = 16800, N[0x3bff, ((0, 4), (1, 4))] = 1
Updated Q[0x3bde, ((1, 3), (2, 3))] = 16800, N[0x3bde, ((1, 3), (2, 3))] = 1
Updated Q[0x3dbb, ((0, 3), (1, 3))] = 16800, N[0x3dbb, ((0, 3), (1, 3))] = 1

--- Simulation 405 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.429689951117, 16803.429689951117, 22667.921484497558, 16803.429689951117, 19603.429689951117]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 30501.467405903557, 24501.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x380d, Score: 24400
Depth 2: State = 0x380d, Legal Moves = [((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x380d: [inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x37c7, Score: 27200
Depth 3: State = 0x37c7, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37c7: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x37cd, Score: 30000
Depth 4: State = 0x37cd, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x37cd: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3ab3, Score: 35600
End of simulation with depth 5. Reward (Score): 35600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9102700, N[0x3c25, ((2, 3), (2, 4))] = 401
Updated Q[0x3c24, ((2, 3), (3, 3))] = 35600, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x380d, ((1, 1), (1, 2))] = 35600, N[0x380d, ((1, 1), (1, 2))] = 1
Updated Q[0x37c7, ((0, 3), (1, 3))] = 35600, N[0x37c7, ((0, 3), (1, 3))] = 1
Updated Q[0x37cd, ((2, 0), (2, 1))] = 35600, N[0x37cd, ((2, 0), (2, 1))] = 1

--- Simulation 406 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.430396281994, 16803.430396281994, 22700.171305815496, 16803.430396281994, 19603.430396281994]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 33301.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bfb, Score: 16100
Depth 2: State = 0x3bfb, Legal Moves = [((1, 0), (1, 1)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bfb: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x3956, Score: 18900
Depth 3: State = 0x3956, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3956: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3bbb, Score: 21700
Depth 4: State = 0x3bbb, Legal Moves = [((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbb: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c47, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9127200, N[0x3c25, ((2, 3), (2, 4))] = 402
Updated Q[0x3c24, ((1, 3), (2, 3))] = 24500, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3bfb, ((1, 0), (1, 1))] = 24500, N[0x3bfb, ((1, 0), (1, 1))] = 1
Updated Q[0x3956, ((0, 3), (1, 3))] = 24500, N[0x3956, ((0, 3), (1, 3))] = 1
Updated Q[0x3bbb, ((1, 2), (2, 2))] = 24500, N[0x3bbb, ((1, 2), (2, 2))] = 1

--- Simulation 407 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.431100726124, 16803.431100726124, 22704.64873969067, 16803.431100726124, 19603.431100726124]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.467405903557, 30501.467405903557, 24501.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c25, Score: 8400
Depth 2: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x465a, Score: 11200
Depth 3: State = 0x465a, Legal Moves = [((1, 3), (2, 3)), ((2, 2), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x465a: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x46a0, Score: 14000
Depth 4: State = 0x46a0, Legal Moves = [((0, 3), (0, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x46a0: [inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x469a, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9144000, N[0x3c25, ((2, 3), (2, 4))] = 403
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x465a, ((1, 3), (2, 3))] = 16800, N[0x465a, ((1, 3), (2, 3))] = 1
Updated Q[0x46a0, ((0, 3), (0, 4))] = 16800, N[0x46a0, ((0, 3), (0, 4))] = 1

--- Simulation 408 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.431803293235, 16803.431803293235, 22689.99725302808, 16803.431803293235, 19603.431803293235]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [33301.46740590355, 29401.467405903557, 30801.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3a63, Score: 22100
Depth 2: State = 0x3a63, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (0, 2)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 2), (3, 3)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3a63: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x2e9b, Score: 24900
Depth 3: State = 0x2e9b, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x2e9b: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x2e80, Score: 27700
Depth 4: State = 0x2e80, Legal Moves = [((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x2e80: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x2fd3, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9174500, N[0x3c25, ((2, 3), (2, 4))] = 404
Updated Q[0x3c25, ((2, 3), (3, 3))] = 30500, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3a63, ((0, 0), (1, 0))] = 30500, N[0x3a63, ((0, 0), (1, 0))] = 1
Updated Q[0x2e9b, ((0, 2), (0, 3))] = 30500, N[0x2e9b, ((0, 2), (0, 3))] = 1
Updated Q[0x2e80, ((1, 0), (1, 1))] = 30500, N[0x2e80, ((1, 0), (1, 1))] = 1

--- Simulation 409 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.432503992983, 16803.432503992983, 22709.329189298012, 16803.432503992983, 19603.432503992983]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c1d, Score: 8400
Depth 1: State = 0x3c1d, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1d: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3876, Score: 11200
Depth 2: State = 0x3876, Legal Moves = [((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3876: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3872, Score: 14000
Depth 3: State = 0x3872, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3872: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3d2d, Score: 19600
Depth 4: State = 0x3d2d, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d2d: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x54ff, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9196900, N[0x3c25, ((2, 3), (2, 4))] = 405
Updated Q[0x3c1d, ((1, 3), (2, 3))] = 22400, N[0x3c1d, ((1, 3), (2, 3))] = 1
Updated Q[0x3876, ((1, 2), (1, 3))] = 22400, N[0x3876, ((1, 2), (1, 3))] = 1
Updated Q[0x3872, ((0, 1), (0, 2))] = 22400, N[0x3872, ((0, 1), (0, 2))] = 1
Updated Q[0x3d2d, ((1, 2), (1, 3))] = 22400, N[0x3d2d, ((1, 2), (1, 3))] = 1

--- Simulation 410 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.43320283494, 16803.43320283494, 22708.565658948828, 16803.43320283494, 19603.43320283494]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [21701.16557645562, 27701.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397f, Score: 8400
Depth 2: State = 0x397f, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397f: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2bff, Score: 14000
Depth 3: State = 0x2bff, Legal Moves = [((1, 3), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2bff: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x2fd9, Score: 22400
Depth 4: State = 0x2fd9, Legal Moves = [((1, 3), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2fd9: [inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x2fd5, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9222100, N[0x3c25, ((2, 3), (2, 4))] = 406
Updated Q[0x3c24, ((2, 0), (2, 1))] = 25200, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x397f, ((0, 0), (0, 1))] = 25200, N[0x397f, ((0, 0), (0, 1))] = 1
Updated Q[0x2bff, ((1, 3), (2, 3))] = 25200, N[0x2bff, ((1, 3), (2, 3))] = 1
Updated Q[0x2fd9, ((1, 3), (2, 3))] = 25200, N[0x2fd9, ((1, 3), (2, 3))] = 1

--- Simulation 411 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.433899828622, 16803.433899828622, 22714.702441291454, 16803.433899828622, 19603.433899828622]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bde, Score: 8400
Depth 1: State = 0x3bde, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bde: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c06, Score: 11200
Depth 2: State = 0x3c06, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c06: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bc2, Score: 14000
Depth 3: State = 0x3bc2, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc2: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x160a, Score: 16800
Depth 4: State = 0x160a, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x160a: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x160a, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9241700, N[0x3c25, ((2, 3), (2, 4))] = 407
Updated Q[0x3bde, ((1, 3), (2, 3))] = 19600, N[0x3bde, ((1, 3), (2, 3))] = 1
Updated Q[0x3c06, ((0, 2), (1, 2))] = 19600, N[0x3c06, ((0, 2), (1, 2))] = 1
Updated Q[0x3bc2, ((1, 2), (1, 3))] = 19600, N[0x3bc2, ((1, 2), (1, 3))] = 1
Updated Q[0x160a, ((1, 3), (1, 4))] = 19600, N[0x160a, ((1, 3), (1, 4))] = 1

--- Simulation 412 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.43459498346, 16803.43459498346, 22707.049853432287, 16803.43459498346, 19603.43459498346]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19602.01883764124, 27302.01883764124, 27702.01883764124, 27151.00941882062, 25202.01883764124]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36d9, Score: 8400
Depth 2: State = 0x36d9, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x36d9: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x12fb, Score: 11200
Depth 3: State = 0x12fb, Legal Moves = [((0, 1), (0, 2)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x12fb: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x1ee9, Score: 49700
Depth 4: State = 0x1ee9, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x1ee9: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x1f0b, Score: 55300
End of simulation with depth 5. Reward (Score): 55300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9297000, N[0x3c25, ((2, 3), (2, 4))] = 408
Updated Q[0x3c24, ((2, 0), (2, 1))] = 83000, N[0x3c24, ((2, 0), (2, 1))] = 2
Updated Q[0x36d9, ((0, 0), (0, 1))] = 55300, N[0x36d9, ((0, 0), (0, 1))] = 1
Updated Q[0x12fb, ((0, 1), (0, 2))] = 55300, N[0x12fb, ((0, 1), (0, 2))] = 1
Updated Q[0x1ee9, ((4, 1), (4, 2))] = 55300, N[0x1ee9, ((4, 1), (4, 2))] = 1

--- Simulation 413 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.43528830882, 16803.43528830882, 22786.934777996274, 16803.43528830882, 19603.43528830882]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x36d3, Score: 21600
Depth 2: State = 0x36d3, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d3: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x36d3, Score: 24400
Depth 3: State = 0x36d3, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d3: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c1e, Score: 27200
Depth 4: State = 0x3c1e, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (1, 1))]
UCB1 values for moves at state 0x3c1e: [inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x5544, Score: 32800
End of simulation with depth 5. Reward (Score): 32800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9329800, N[0x3c25, ((2, 3), (2, 4))] = 409
Updated Q[0x3c25, ((1, 3), (2, 3))] = 32800, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x36d3, ((1, 2), (1, 3))] = 32800, N[0x36d3, ((1, 2), (1, 3))] = 1
Updated Q[0x36d3, ((2, 0), (2, 1))] = 32800, N[0x36d3, ((2, 0), (2, 1))] = 1
Updated Q[0x3c1e, ((0, 0), (0, 1))] = 32800, N[0x3c1e, ((0, 0), (0, 1))] = 1

--- Simulation 414 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.435979814, 16803.435979814, 22811.41684203257, 16803.435979814, 19603.435979814]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c0a, Score: 8400
Depth 1: State = 0x3c0a, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c0a: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x366e, Score: 11200
Depth 2: State = 0x366e, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x366e: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3be1, Score: 24900
Depth 3: State = 0x3be1, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be1: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4830, Score: 27700
Depth 4: State = 0x4830, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x4830: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0xf009, Score: 33300
End of simulation with depth 5. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9363100, N[0x3c25, ((2, 3), (2, 4))] = 410
Updated Q[0x3c0a, ((1, 3), (2, 3))] = 33300, N[0x3c0a, ((1, 3), (2, 3))] = 1
Updated Q[0x366e, ((1, 3), (1, 4))] = 33300, N[0x366e, ((1, 3), (1, 4))] = 1
Updated Q[0x3be1, ((1, 2), (1, 3))] = 33300, N[0x3be1, ((1, 2), (1, 3))] = 1
Updated Q[0x4830, ((0, 1), (1, 1))] = 33300, N[0x4830, ((0, 1), (1, 1))] = 1

--- Simulation 415 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.436669508217, 16803.436669508217, 22836.99899330204, 16803.436669508217, 19603.436669508217]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 25201.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397e, Score: 8400
Depth 2: State = 0x397e, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (1, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397e: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2c3c, Score: 11200
Depth 3: State = 0x2c3c, Legal Moves = [((1, 0), (1, 1)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2c3c: [inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x2996, Score: 14000
Depth 4: State = 0x2996, Legal Moves = [((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2996: [inf, inf]
Selected move: ((2, 4), (3, 4))
New board state after move: 0x2997, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9379900, N[0x3c25, ((2, 3), (2, 4))] = 411
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x397e, ((0, 0), (0, 1))] = 16800, N[0x397e, ((0, 0), (0, 1))] = 1
Updated Q[0x2c3c, ((1, 0), (1, 1))] = 16800, N[0x2c3c, ((1, 0), (1, 1))] = 1
Updated Q[0x2996, ((2, 4), (3, 4))] = 16800, N[0x2996, ((2, 4), (3, 4))] = 1

--- Simulation 416 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.437357400628, 16803.437357400628, 22822.310671558138, 16803.437357400628, 19603.437357400628]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.648374031523, 30501.648374031523, 24501.648374031523, 35601.64837403152, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x569d, Score: 8400
Depth 2: State = 0x569d, Legal Moves = [((1, 3), (2, 3)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x569d: [inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x5634, Score: 14000
Depth 3: State = 0x5634, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3))]
UCB1 values for moves at state 0x5634: [inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x56e1, Score: 16800
Depth 4: State = 0x56e1, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9396700, N[0x3c25, ((2, 3), (2, 4))] = 412
Updated Q[0x3c24, ((3, 0), (3, 1))] = 16800, N[0x3c24, ((3, 0), (3, 1))] = 1
Updated Q[0x569d, ((1, 3), (2, 3))] = 16800, N[0x569d, ((1, 3), (2, 3))] = 1
Updated Q[0x5634, ((1, 2), (2, 2))] = 16800, N[0x5634, ((1, 2), (2, 2))] = 1

--- Simulation 417 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.438043500322, 16803.438043500322, 22807.693652090686, 16803.438043500322, 19603.438043500322]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3be7, Score: 8400
Depth 1: State = 0x3be7, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be7: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c28, Score: 11200
Depth 2: State = 0x3c28, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c28: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3982, Score: 14000
Depth 3: State = 0x3982, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x3982: [inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x20a0, Score: 16800
Depth 4: State = 0x20a0, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x20a0: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x2af3, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9416300, N[0x3c25, ((2, 3), (2, 4))] = 413
Updated Q[0x3be7, ((1, 3), (2, 3))] = 19600, N[0x3be7, ((1, 3), (2, 3))] = 1
Updated Q[0x3c28, ((2, 0), (2, 1))] = 19600, N[0x3c28, ((2, 0), (2, 1))] = 1
Updated Q[0x3982, ((1, 0), (2, 0))] = 19600, N[0x3982, ((1, 0), (2, 0))] = 1
Updated Q[0x20a0, ((0, 1), (1, 1))] = 19600, N[0x20a0, ((0, 1), (1, 1))] = 1

--- Simulation 418 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.43872781632, 16803.43872781632, 22799.9270779833, 16803.43872781632, 19603.43872781632]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bbf, Score: 8400
Depth 1: State = 0x3bbf, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbf: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c43, Score: 14000
Depth 2: State = 0x3c43, Legal Moves = [((0, 0), (1, 0)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c43: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x45a8, Score: 16800
Depth 3: State = 0x45a8, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a8: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x45a8, Score: 19600
Depth 4: State = 0x45a8, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1))]
UCB1 values for moves at state 0x45a8: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x1f25, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9438700, N[0x3c25, ((2, 3), (2, 4))] = 414
Updated Q[0x3bbf, ((1, 3), (2, 3))] = 22400, N[0x3bbf, ((1, 3), (2, 3))] = 1
Updated Q[0x3c43, ((0, 0), (1, 0))] = 22400, N[0x3c43, ((0, 0), (1, 0))] = 1
Updated Q[0x45a8, ((2, 0), (2, 1))] = 22400, N[0x45a8, ((2, 0), (2, 1))] = 1
Updated Q[0x45a8, ((1, 1), (2, 1))] = 22400, N[0x45a8, ((1, 1), (2, 1))] = 1

--- Simulation 419 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.43941035757, 16803.43941035757, 22798.96130832845, 16803.43941035757, 19603.43941035757]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c64, Score: 13200
Depth 1: State = 0x3c64, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c64: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bdd, Score: 16000
Depth 2: State = 0x3bdd, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bdd: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d2f, Score: 18800
Depth 3: State = 0x3d2f, Legal Moves = [((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d2f: [inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3d29, Score: 21600
Depth 4: State = 0x3d29, Legal Moves = [((2, 2), (2, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d29: [inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x3d6c, Score: 24400
End of simulation with depth 5. Reward (Score): 24400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9463100, N[0x3c25, ((2, 3), (2, 4))] = 415
Updated Q[0x3c64, ((1, 2), (2, 2))] = 24400, N[0x3c64, ((1, 2), (2, 2))] = 1
Updated Q[0x3bdd, ((2, 0), (2, 1))] = 24400, N[0x3bdd, ((2, 0), (2, 1))] = 1
Updated Q[0x3d2f, ((2, 3), (2, 4))] = 24400, N[0x3d2f, ((2, 3), (2, 4))] = 1
Updated Q[0x3d29, ((2, 2), (2, 3))] = 24400, N[0x3d29, ((2, 2), (2, 3))] = 1

--- Simulation 420 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.440091132958, 16803.440091132958, 22802.8194698418, 16803.440091132958, 19603.440091132958]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 22401.467405903557, 27701.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36d9, Score: 8400
Depth 2: State = 0x36d9, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x36d9: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1319, Score: 11200
Depth 3: State = 0x1319, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1319: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x10be, Score: 14000
Depth 4: State = 0x10be, Legal Moves = [((1, 2), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x10be: [inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x107e, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9479900, N[0x3c25, ((2, 3), (2, 4))] = 416
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x36d9, ((0, 0), (0, 1))] = 16800, N[0x36d9, ((0, 0), (0, 1))] = 1
Updated Q[0x1319, ((0, 3), (1, 3))] = 16800, N[0x1319, ((0, 3), (1, 3))] = 1
Updated Q[0x10be, ((1, 2), (2, 2))] = 16800, N[0x10be, ((1, 2), (2, 2))] = 1

--- Simulation 421 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.440770151305, 16803.440770151305, 22788.389851482145, 16803.440770151305, 19603.440770151305]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bff, Score: 8400
Depth 2: State = 0x3bff, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bff: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c00, Score: 11200
Depth 3: State = 0x3c00, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c00: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c03, Score: 14000
Depth 4: State = 0x3c03, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c03: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3b19, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9499500, N[0x3c25, ((2, 3), (2, 4))] = 417
Updated Q[0x3c24, ((0, 2), (1, 2))] = 19600, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3bff, ((0, 4), (1, 4))] = 19600, N[0x3bff, ((0, 4), (1, 4))] = 1
Updated Q[0x3c00, ((0, 4), (1, 4))] = 19600, N[0x3c00, ((0, 4), (1, 4))] = 1
Updated Q[0x3c03, ((1, 3), (2, 3))] = 19600, N[0x3c03, ((1, 3), (2, 3))] = 1

--- Simulation 422 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.441447421366, 16803.441447421366, 22780.74406797364, 16803.441447421366, 19603.441447421366]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22401.16557645562, 22401.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36d8, Score: 8400
Depth 2: State = 0x36d8, Legal Moves = [((0, 0), (0, 1)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x36d8: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x15b8, Score: 11200
Depth 3: State = 0x15b8, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x15b8: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x159a, Score: 14000
Depth 4: State = 0x159a, Legal Moves = [((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x159a: [inf, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0xefc3, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9516300, N[0x3c25, ((2, 3), (2, 4))] = 418
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x36d8, ((0, 0), (0, 1))] = 16800, N[0x36d8, ((0, 0), (0, 1))] = 1
Updated Q[0x15b8, ((0, 2), (1, 2))] = 16800, N[0x15b8, ((0, 2), (1, 2))] = 1
Updated Q[0x159a, ((3, 0), (3, 1))] = 16800, N[0x159a, ((3, 0), (3, 1))] = 1

--- Simulation 423 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.44212295183, 16803.44212295183, 22766.436302320584, 16803.44212295183, 19603.44212295183]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x48fb, Score: 8400
Depth 2: State = 0x48fb, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48fb: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x45a8, Score: 14000
Depth 3: State = 0x45a8, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a8: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1319, Score: 22400
Depth 4: State = 0x1319, Legal Moves = [((2, 0), (3, 0)), ((2, 1), (2, 2)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x1319: [inf, inf, inf]
Selected move: ((2, 0), (3, 0))
New board state after move: 0x1319, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9541500, N[0x3c25, ((2, 3), (2, 4))] = 419
Updated Q[0x3c24, ((0, 0), (0, 1))] = 25200, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x48fb, ((1, 3), (2, 3))] = 25200, N[0x48fb, ((1, 3), (2, 3))] = 1
Updated Q[0x45a8, ((2, 0), (2, 1))] = 25200, N[0x45a8, ((2, 0), (2, 1))] = 1
Updated Q[0x1319, ((2, 0), (3, 0))] = 25200, N[0x1319, ((2, 0), (3, 0))] = 1

--- Simulation 424 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.442796751326, 16803.442796751326, 22772.244563942528, 16803.442796751326, 19603.442796751326]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.467405903557, 19601.467405903557, 21601.467405903557, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x36ff, Score: 14000
Depth 2: State = 0x36ff, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36ff: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x37ed, Score: 16800
Depth 3: State = 0x37ed, Legal Moves = [((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37ed: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d38, Score: 19600
Depth 4: State = 0x3d38, Legal Moves = [((4, 0), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d38: [inf, inf]
Selected move: ((4, 0), (4, 1))
New board state after move: 0x22c0, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9563900, N[0x3c25, ((2, 3), (2, 4))] = 420
Updated Q[0x3c25, ((2, 3), (2, 4))] = 22400, N[0x3c25, ((2, 3), (2, 4))] = 1
Updated Q[0x36ff, ((0, 1), (1, 1))] = 22400, N[0x36ff, ((0, 1), (1, 1))] = 1
Updated Q[0x37ed, ((2, 0), (2, 1))] = 22400, N[0x37ed, ((2, 0), (2, 1))] = 1
Updated Q[0x3d38, ((4, 0), (4, 1))] = 22400, N[0x3d38, ((4, 0), (4, 1))] = 1

--- Simulation 425 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.443468828413, 16803.443468828413, 22771.35850026452, 16803.443468828413, 19603.443468828413]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 25201.467405903557, 24501.467405903557, inf, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c27, Score: 8400
Depth 2: State = 0x3c27, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c27: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x301c, Score: 16800
Depth 3: State = 0x301c, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (0, 2)), ((0, 1), (1, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x301c: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1c20, Score: 22400
Depth 4: State = 0x1c20, Legal Moves = [((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1c20: [inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x1c20, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9589100, N[0x3c25, ((2, 3), (2, 4))] = 421
Updated Q[0x3c24, ((2, 3), (3, 3))] = 25200, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x3c27, ((2, 0), (2, 1))] = 25200, N[0x3c27, ((2, 0), (2, 1))] = 1
Updated Q[0x301c, ((0, 0), (0, 1))] = 25200, N[0x301c, ((0, 0), (0, 1))] = 1
Updated Q[0x1c20, ((2, 2), (2, 3))] = 25200, N[0x1c20, ((2, 2), (2, 3))] = 1

--- Simulation 426 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.444139191597, 16803.444139191597, 22777.127477025864, 16803.444139191597, 19603.444139191597]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [21701.16557645562, 34401.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3952, Score: 21700
Depth 2: State = 0x3952, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3952: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3d4a, Score: 24500
Depth 3: State = 0x3d4a, Legal Moves = [((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d4a: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x36ac, Score: 27300
Depth 4: State = 0x36ac, Legal Moves = [((0, 1), (0, 2)), ((1, 0), (2, 0)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36ac: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x39a0, Score: 30100
End of simulation with depth 5. Reward (Score): 30100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9619200, N[0x3c25, ((2, 3), (2, 4))] = 422
Updated Q[0x3c25, ((1, 3), (2, 3))] = 30100, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3952, ((1, 1), (2, 1))] = 30100, N[0x3952, ((1, 1), (2, 1))] = 1
Updated Q[0x3d4a, ((1, 1), (1, 2))] = 30100, N[0x3d4a, ((1, 1), (1, 2))] = 1
Updated Q[0x36ac, ((0, 1), (0, 2))] = 30100, N[0x36ac, ((0, 1), (0, 2))] = 1

--- Simulation 427 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.44480784931, 16803.44480784931, 22794.4804868309, 16803.44480784931, 19603.44480784931]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [27700.0, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c64, Score: 8400
Depth 2: State = 0x3c64, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c64: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3dbb, Score: 11200
Depth 3: State = 0x3dbb, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3dbb: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3db7, Score: 14000
Depth 4: State = 0x3db7, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3db7: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bbf, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9641600, N[0x3c25, ((2, 3), (2, 4))] = 423
Updated Q[0x3c24, ((0, 2), (1, 2))] = 22400, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c64, ((1, 3), (2, 3))] = 22400, N[0x3c64, ((1, 3), (2, 3))] = 1
Updated Q[0x3dbb, ((0, 3), (1, 3))] = 22400, N[0x3dbb, ((0, 3), (1, 3))] = 1
Updated Q[0x3db7, ((1, 2), (2, 2))] = 22400, N[0x3db7, ((1, 2), (2, 2))] = 1

--- Simulation 428 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.445474809938, 16803.445474809938, 22793.54813937516, 16803.445474809938, 19603.445474809938]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bb6, Score: 8400
Depth 1: State = 0x3bb6, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (0, 4)), ((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3bb6: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3d34, Score: 11200
Depth 2: State = 0x3d34, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3d34: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bff, Score: 29800
Depth 3: State = 0x3bff, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bff: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x1074, Score: 32600
Depth 4: State = 0x1074, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1074: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x1011, Score: 35400
End of simulation with depth 5. Reward (Score): 35400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9677000, N[0x3c25, ((2, 3), (2, 4))] = 424
Updated Q[0x3bb6, ((0, 1), (1, 1))] = 35400, N[0x3bb6, ((0, 1), (1, 1))] = 1
Updated Q[0x3d34, ((1, 2), (2, 2))] = 35400, N[0x3d34, ((1, 2), (2, 2))] = 1
Updated Q[0x3bff, ((0, 1), (1, 1))] = 35400, N[0x3bff, ((0, 1), (1, 1))] = 1
Updated Q[0x1074, ((0, 3), (1, 3))] = 35400, N[0x1074, ((0, 3), (1, 3))] = 1

--- Simulation 429 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.446140081793, 16803.446140081793, 22823.280566904225, 16803.446140081793, 19603.446140081793]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x456b, Score: 14000
Depth 2: State = 0x456b, Legal Moves = [((0, 3), (0, 4)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x456b: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x455f, Score: 16800
Depth 3: State = 0x455f, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x455f: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x455f, Score: 19600
Depth 4: State = 0x455f, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((1, 2), (1, 3)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x455f: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x47c1, Score: 30000
End of simulation with depth 5. Reward (Score): 30000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9707000, N[0x3c25, ((2, 3), (2, 4))] = 425
Updated Q[0x3c25, ((1, 3), (1, 4))] = 30000, N[0x3c25, ((1, 3), (1, 4))] = 1
Updated Q[0x456b, ((0, 3), (0, 4))] = 30000, N[0x456b, ((0, 3), (0, 4))] = 1
Updated Q[0x455f, ((1, 1), (2, 1))] = 30000, N[0x455f, ((1, 1), (2, 1))] = 1
Updated Q[0x455f, ((0, 1), (0, 2))] = 30000, N[0x455f, ((0, 1), (0, 2))] = 1

--- Simulation 430 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.44680367313, 16803.44680367313, 22840.167194536647, 16803.44680367313, 19603.44680367313]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14001.467405903555, 22401.467405903557, 21701.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x382c, Score: 8400
Depth 2: State = 0x382c, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x382c: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x21e9, Score: 11200
Depth 3: State = 0x21e9, Legal Moves = [((1, 3), (2, 3)), ((2, 1), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x21e9: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x21a9, Score: 14000
Depth 4: State = 0x21a9, Legal Moves = [((1, 2), (2, 2)), ((2, 1), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x21a9: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x218d, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9723800, N[0x3c25, ((2, 3), (2, 4))] = 426
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x382c, ((0, 0), (0, 1))] = 16800, N[0x382c, ((0, 0), (0, 1))] = 1
Updated Q[0x21e9, ((1, 3), (2, 3))] = 16800, N[0x21e9, ((1, 3), (2, 3))] = 1
Updated Q[0x21a9, ((1, 2), (2, 2))] = 16800, N[0x21a9, ((1, 2), (2, 2))] = 1

--- Simulation 431 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.447465592144, 16803.447465592144, 22825.988626497845, 16803.447465592144, 19603.447465592144]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43cb, Score: 8400
Depth 2: State = 0x43cb, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43cb: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4ab3, Score: 14000
Depth 3: State = 0x4ab3, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab3: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4ab7, Score: 16800
Depth 4: State = 0x4ab7, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab7: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4811, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9743400, N[0x3c25, ((2, 3), (2, 4))] = 427
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43cb, ((1, 3), (2, 3))] = 19600, N[0x43cb, ((1, 3), (2, 3))] = 1
Updated Q[0x4ab3, ((0, 3), (1, 3))] = 19600, N[0x4ab3, ((0, 3), (1, 3))] = 1
Updated Q[0x4ab7, ((2, 0), (2, 1))] = 19600, N[0x4ab7, ((2, 0), (2, 1))] = 1

--- Simulation 432 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.44812584698, 16803.44812584698, 22818.43384542798, 16803.44812584698, 19603.44812584698]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4ad8, Score: 8400
Depth 2: State = 0x4ad8, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ad8: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x52ee, Score: 11200
Depth 3: State = 0x52ee, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x52ee: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x22f8, Score: 14000
Depth 4: State = 0x22f8, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x22f8: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x1d4e, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9760200, N[0x3c25, ((2, 3), (2, 4))] = 428
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4ad8, ((0, 0), (0, 1))] = 16800, N[0x4ad8, ((0, 0), (0, 1))] = 1
Updated Q[0x52ee, ((0, 0), (0, 1))] = 16800, N[0x52ee, ((0, 0), (0, 1))] = 1
Updated Q[0x22f8, ((1, 3), (1, 4))] = 16800, N[0x22f8, ((1, 3), (1, 4))] = 1

--- Simulation 433 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.448784445707, 16803.448784445707, 22804.372310764964, 16803.448784445707, 19603.448784445707]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c42, Score: 8400
Depth 1: State = 0x3c42, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c42: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x2186, Score: 11200
Depth 2: State = 0x2186, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2186: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x22f4, Score: 14000
Depth 3: State = 0x22f4, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x22f4: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1da9, Score: 16800
Depth 4: State = 0x1da9, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x1da9: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x455d, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9779800, N[0x3c25, ((2, 3), (2, 4))] = 429
Updated Q[0x3c42, ((0, 0), (1, 0))] = 19600, N[0x3c42, ((0, 0), (1, 0))] = 1
Updated Q[0x2186, ((1, 3), (2, 3))] = 19600, N[0x2186, ((1, 3), (2, 3))] = 1
Updated Q[0x22f4, ((2, 0), (2, 1))] = 19600, N[0x22f4, ((2, 0), (2, 1))] = 1
Updated Q[0x1da9, ((1, 0), (1, 1))] = 19600, N[0x1da9, ((1, 0), (1, 1))] = 1

--- Simulation 434 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.449441396355, 16803.449441396355, 22796.903137336565, 16803.449441396355, 19603.449441396355]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c4c, Score: 8400
Depth 1: State = 0x3c4c, Legal Moves = [((0, 0), (1, 0)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4c: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x5441, Score: 11200
Depth 2: State = 0x5441, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5441: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2d9b, Score: 14000
Depth 3: State = 0x2d9b, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2d9b: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3c4c, Score: 25200
Depth 4: State = 0x3c4c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 0), (4, 0))]
UCB1 values for moves at state 0x3c4c: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bbe, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9807800, N[0x3c25, ((2, 3), (2, 4))] = 430
Updated Q[0x3c4c, ((0, 0), (1, 0))] = 28000, N[0x3c4c, ((0, 0), (1, 0))] = 1
Updated Q[0x5441, ((0, 0), (0, 1))] = 28000, N[0x5441, ((0, 0), (0, 1))] = 1
Updated Q[0x2d9b, ((0, 0), (1, 0))] = 28000, N[0x2d9b, ((0, 0), (1, 0))] = 1
Updated Q[0x3c4c, ((1, 2), (2, 2))] = 28000, N[0x3c4c, ((1, 2), (2, 2))] = 1

--- Simulation 435 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.45009670688, 16803.45009670688, 22809.003587739593, 16803.45009670688, 19603.45009670688]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x443d, Score: 8400
Depth 2: State = 0x443d, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443d: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x1c59, Score: 14000
Depth 3: State = 0x1c59, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1c59: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1eff, Score: 16800
Depth 4: State = 0x1eff, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1eff: [inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x1eff, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9827400, N[0x3c25, ((2, 3), (2, 4))] = 431
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x443d, ((1, 3), (2, 3))] = 19600, N[0x443d, ((1, 3), (2, 3))] = 1
Updated Q[0x1c59, ((2, 0), (2, 1))] = 19600, N[0x1c59, ((2, 0), (2, 1))] = 1
Updated Q[0x1eff, ((1, 0), (1, 1))] = 19600, N[0x1eff, ((1, 0), (1, 1))] = 1

--- Simulation 436 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.450750385196, 16803.450750385196, 22801.55832816624, 16803.450750385196, 19603.450750385196]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 21701.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x382c, Score: 8400
Depth 2: State = 0x382c, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x382c: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2071, Score: 11200
Depth 3: State = 0x2071, Legal Moves = [((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2071: [inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2078, Score: 14000
Depth 4: State = 0x2078, Legal Moves = [((2, 1), (2, 2)), ((2, 2), (3, 2)), ((3, 2), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2078: [inf, inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x1fe9, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9844200, N[0x3c25, ((2, 3), (2, 4))] = 432
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x382c, ((0, 0), (0, 1))] = 16800, N[0x382c, ((0, 0), (0, 1))] = 1
Updated Q[0x2071, ((1, 2), (1, 3))] = 16800, N[0x2071, ((1, 2), (1, 3))] = 1
Updated Q[0x2078, ((2, 1), (2, 2))] = 16800, N[0x2078, ((2, 1), (2, 2))] = 1

--- Simulation 437 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.45140243915, 16803.45140243915, 22787.666055677277, 16803.45140243915, 19603.45140243915]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22401.16557645562, 16801.16557645562, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x29b9, Score: 22100
Depth 2: State = 0x29b9, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x29b9: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1c5b, Score: 30500
Depth 3: State = 0x1c5b, Legal Moves = [((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x1c5b: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4562, Score: 33300
Depth 4: State = 0x4562, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9877500, N[0x3c25, ((2, 3), (2, 4))] = 433
Updated Q[0x3c24, ((1, 3), (1, 4))] = 33300, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x29b9, ((2, 0), (2, 1))] = 33300, N[0x29b9, ((2, 0), (2, 1))] = 1
Updated Q[0x1c5b, ((1, 2), (1, 3))] = 33300, N[0x1c5b, ((1, 2), (1, 3))] = 1

--- Simulation 438 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.452052876535, 16803.452052876535, 22811.944186067332, 16803.452052876535, 19603.452052876535]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 8400
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c09, Score: 11200
Depth 2: State = 0x3c09, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c09: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c6b, Score: 14000
Depth 3: State = 0x3c6b, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6b: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c1a, Score: 16800
Depth 4: State = 0x3c1a, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1a: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3952, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9897100, N[0x3c25, ((2, 3), (2, 4))] = 434
Updated Q[0x3c25, ((0, 2), (1, 2))] = 19600, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3c09, ((1, 3), (2, 3))] = 19600, N[0x3c09, ((1, 3), (2, 3))] = 1
Updated Q[0x3c6b, ((0, 2), (1, 2))] = 19600, N[0x3c6b, ((0, 2), (1, 2))] = 1
Updated Q[0x3c1a, ((1, 2), (1, 3))] = 19600, N[0x3c1a, ((1, 2), (1, 3))] = 1

--- Simulation 439 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.45270170509, 16803.45270170509, 22804.543615169783, 16803.45270170509, 19603.45270170509]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [30501.467405903557, 19601.467405903557, 28601.467405903557, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397e, Score: 8400
Depth 2: State = 0x397e, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397e: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2d4f, Score: 14000
Depth 3: State = 0x2d4f, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2d4f: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x2af4, Score: 16800
Depth 4: State = 0x2af4, Legal Moves = [((0, 1), (0, 2)), ((3, 3), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2af4: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x2dbc, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9916700, N[0x3c25, ((2, 3), (2, 4))] = 435
Updated Q[0x3c24, ((2, 0), (2, 1))] = 19600, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x397e, ((0, 0), (0, 1))] = 19600, N[0x397e, ((0, 0), (0, 1))] = 1
Updated Q[0x2d4f, ((1, 3), (1, 4))] = 19600, N[0x2d4f, ((1, 3), (1, 4))] = 1
Updated Q[0x2af4, ((0, 1), (0, 2))] = 19600, N[0x2af4, ((0, 1), (0, 2))] = 1

--- Simulation 440 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.453348932504, 16803.453348932504, 22797.17706966091, 16803.453348932504, 19603.453348932504]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.77609073765, 30501.77609073765, 24501.77609073765, 35601.77609073765, 16801.77609073765]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c21, Score: 8400
Depth 2: State = 0x3c21, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c21: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397b, Score: 11200
Depth 3: State = 0x397b, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397b: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3a8a, Score: 14000
Depth 4: State = 0x3a8a, Legal Moves = [((1, 2), (1, 3)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3a8a: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4ad1, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9933500, N[0x3c25, ((2, 3), (2, 4))] = 436
Updated Q[0x3c24, ((2, 3), (3, 3))] = 52400, N[0x3c24, ((2, 3), (3, 3))] = 2
Updated Q[0x3c21, ((2, 0), (2, 1))] = 16800, N[0x3c21, ((2, 0), (2, 1))] = 1
Updated Q[0x397b, ((0, 1), (0, 2))] = 16800, N[0x397b, ((0, 1), (0, 2))] = 1
Updated Q[0x3a8a, ((1, 2), (1, 3))] = 16800, N[0x3a8a, ((1, 2), (1, 3))] = 1

--- Simulation 441 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.453994566404, 16803.453994566404, 22783.42229707318, 16803.453994566404, 19603.453994566404]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [25200.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bfe, Score: 8400
Depth 2: State = 0x3bfe, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bfe: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c5d, Score: 11200
Depth 3: State = 0x3c5d, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5d: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c5d, Score: 14000
Depth 4: State = 0x3c5d, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9947500, N[0x3c25, ((2, 3), (2, 4))] = 437
Updated Q[0x3c24, ((0, 2), (1, 2))] = 14000, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3bfe, ((1, 3), (2, 3))] = 14000, N[0x3bfe, ((1, 3), (2, 3))] = 1
Updated Q[0x3c5d, ((2, 0), (2, 1))] = 14000, N[0x3c5d, ((2, 0), (2, 1))] = 1

--- Simulation 442 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.454638614367, 16803.454638614367, 22763.323152513127, 16803.454638614367, 19603.454638614367]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [24901.648374031523, 25201.648374031523, 25201.648374031523, 16801.648374031523, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x495b, Score: 16100
Depth 2: State = 0x495b, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x495b: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x43ee, Score: 27000
Depth 3: State = 0x43ee, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43ee: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1050, Score: 29800
Depth 4: State = 0x1050, Legal Moves = [((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1050: [inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x1029, Score: 32600
End of simulation with depth 5. Reward (Score): 32600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9980100, N[0x3c25, ((2, 3), (2, 4))] = 438
Updated Q[0x3c25, ((2, 3), (3, 3))] = 32600, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x495b, ((1, 3), (2, 3))] = 32600, N[0x495b, ((1, 3), (2, 3))] = 1
Updated Q[0x43ee, ((0, 0), (0, 1))] = 32600, N[0x43ee, ((0, 0), (0, 1))] = 1
Updated Q[0x1050, ((1, 1), (1, 2))] = 32600, N[0x1050, ((1, 1), (1, 2))] = 1

--- Simulation 443 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.455281083916, 16803.455281083916, 22785.7815380726, 16803.455281083916, 19603.455281083916]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c46, Score: 8400
Depth 1: State = 0x3c46, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c46: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x569c, Score: 11200
Depth 2: State = 0x569c, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x569c: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x5170, Score: 16800
Depth 3: State = 0x5170, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5170: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397c, Score: 25200
Depth 4: State = 0x397c, Legal Moves = [((1, 3), (2, 3))]
UCB1 values for moves at state 0x397c: [inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c6f, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10008100, N[0x3c25, ((2, 3), (2, 4))] = 439
Updated Q[0x3c46, ((0, 0), (1, 0))] = 28000, N[0x3c46, ((0, 0), (1, 0))] = 1
Updated Q[0x569c, ((1, 3), (1, 4))] = 28000, N[0x569c, ((1, 3), (1, 4))] = 1
Updated Q[0x5170, ((2, 0), (2, 1))] = 28000, N[0x5170, ((2, 0), (2, 1))] = 1
Updated Q[0x397c, ((1, 3), (2, 3))] = 28000, N[0x397c, ((1, 3), (2, 3))] = 1

--- Simulation 444 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.455921982524, 16803.455921982524, 22797.65924739615, 16803.455921982524, 19603.455921982524]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.467405903557, 25201.467405903557, 19601.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1f4b, Score: 24400
Depth 2: State = 0x1f4b, Legal Moves = [((1, 3), (1, 4)), ((2, 3), (2, 4)), ((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1f4b: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x1bf5, Score: 27200
Depth 3: State = 0x1bf5, Legal Moves = [((0, 3), (0, 4)), ((3, 2), (4, 2)), ((3, 3), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1bf5: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x1bf7, Score: 30000
Depth 4: State = 0x1bf7, Legal Moves = [((0, 3), (1, 3)), ((2, 2), (2, 3)), ((3, 2), (4, 2)), ((3, 3), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1bf7: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x1ca1, Score: 32800
End of simulation with depth 5. Reward (Score): 32800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10040900, N[0x3c25, ((2, 3), (2, 4))] = 440
Updated Q[0x3c24, ((2, 0), (2, 1))] = 32800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x1f4b, ((1, 3), (1, 4))] = 32800, N[0x1f4b, ((1, 3), (1, 4))] = 1
Updated Q[0x1bf5, ((0, 3), (0, 4))] = 32800, N[0x1bf5, ((0, 3), (0, 4))] = 1
Updated Q[0x1bf7, ((0, 3), (1, 3))] = 32800, N[0x1bf7, ((0, 3), (1, 3))] = 1

--- Simulation 445 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.456561317606, 16803.456561317606, 22820.39205782246, 16803.456561317606, 19603.456561317606]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 21701.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4852, Score: 11200
Depth 2: State = 0x4852, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((1, 0), (1, 1)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 4), (2, 4)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4852: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x21c8, Score: 16100
Depth 3: State = 0x21c8, Legal Moves = [((0, 0), (0, 1)), ((0, 0), (1, 0)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x21c8: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x15bd, Score: 21700
Depth 4: State = 0x15bd, Legal Moves = [((0, 0), (1, 0)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((4, 0), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x15bd: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3d71, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10065400, N[0x3c25, ((2, 3), (2, 4))] = 441
Updated Q[0x3c25, ((2, 0), (2, 1))] = 24500, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x4852, ((0, 1), (1, 1))] = 24500, N[0x4852, ((0, 1), (1, 1))] = 1
Updated Q[0x21c8, ((0, 0), (0, 1))] = 24500, N[0x21c8, ((0, 0), (0, 1))] = 1
Updated Q[0x15bd, ((0, 0), (1, 0))] = 24500, N[0x15bd, ((0, 0), (1, 0))] = 1

--- Simulation 446 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.45719909653, 16803.45719909653, 22824.200909707546, 16803.45719909653, 19603.45719909653]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x495e, Score: 8400
Depth 2: State = 0x495e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x495e: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4671, Score: 11200
Depth 3: State = 0x4671, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4671: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4a43, Score: 18900
Depth 4: State = 0x4a43, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a43: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3712, Score: 26500
End of simulation with depth 5. Reward (Score): 26500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10091900, N[0x3c25, ((2, 3), (2, 4))] = 442
Updated Q[0x3c25, ((0, 0), (0, 1))] = 26500, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x495e, ((1, 3), (2, 3))] = 26500, N[0x495e, ((1, 3), (2, 3))] = 1
Updated Q[0x4671, ((1, 2), (1, 3))] = 26500, N[0x4671, ((1, 2), (1, 3))] = 1
Updated Q[0x4a43, ((1, 1), (2, 1))] = 26500, N[0x4a43, ((1, 1), (2, 1))] = 1

--- Simulation 447 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.45783532661, 16803.45783532661, 22832.517413630438, 16803.45783532661, 19603.45783532661]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bfc, Score: 8400
Depth 1: State = 0x3bfc, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3bfc: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bbc, Score: 11200
Depth 2: State = 0x3bbc, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbc: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3bff, Score: 14000
Depth 3: State = 0x3bff, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bff: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x371d, Score: 16800
Depth 4: State = 0x371d, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x371d: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3719, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10111500, N[0x3c25, ((2, 3), (2, 4))] = 443
Updated Q[0x3bfc, ((1, 2), (2, 2))] = 19600, N[0x3bfc, ((1, 2), (2, 2))] = 1
Updated Q[0x3bbc, ((0, 3), (1, 3))] = 19600, N[0x3bbc, ((0, 3), (1, 3))] = 1
Updated Q[0x3bff, ((1, 3), (2, 3))] = 19600, N[0x3bff, ((1, 3), (2, 3))] = 1
Updated Q[0x371d, ((0, 3), (1, 3))] = 19600, N[0x371d, ((0, 3), (1, 3))] = 1

--- Simulation 448 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.458470015114, 16803.458470015114, 22825.220750277804, 16803.458470015114, 19603.458470015114]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bbf, Score: 8400
Depth 1: State = 0x3bbf, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbf: [19600.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3ab7, Score: 16100
Depth 2: State = 0x3ab7, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3ab7: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3ab7, Score: 18900
Depth 3: State = 0x3ab7, Legal Moves = [((3, 1), (4, 1))]
UCB1 values for moves at state 0x3ab7: [inf]
Selected move: ((3, 1), (4, 1))
New board state after move: 0x37e9, Score: 27300
Depth 4: State = 0x37e9, Legal Moves = [((2, 2), (3, 2)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x37e9: [inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x307e, Score: 32900
End of simulation with depth 5. Reward (Score): 32900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10144400, N[0x3c25, ((2, 3), (2, 4))] = 444
Updated Q[0x3bbf, ((1, 3), (2, 3))] = 32900, N[0x3bbf, ((1, 3), (2, 3))] = 1
Updated Q[0x3ab7, ((2, 0), (2, 1))] = 32900, N[0x3ab7, ((2, 0), (2, 1))] = 1
Updated Q[0x3ab7, ((3, 1), (4, 1))] = 32900, N[0x3ab7, ((3, 1), (4, 1))] = 1
Updated Q[0x37e9, ((2, 2), (3, 2))] = 32900, N[0x37e9, ((2, 2), (3, 2))] = 1

--- Simulation 449 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.459103169254, 16803.459103169254, 22847.91190951931, 16803.459103169254, 19603.459103169254]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x45b3, Score: 8400
Depth 2: State = 0x45b3, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45b3: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4afa, Score: 11200
Depth 3: State = 0x4afa, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4afa: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x47af, Score: 14000
Depth 4: State = 0x47af, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47af: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4a54, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10161200, N[0x3c25, ((2, 3), (2, 4))] = 445
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x45b3, ((1, 3), (1, 4))] = 16800, N[0x45b3, ((1, 3), (1, 4))] = 1
Updated Q[0x4afa, ((0, 1), (1, 1))] = 16800, N[0x4afa, ((0, 1), (1, 1))] = 1
Updated Q[0x47af, ((2, 0), (2, 1))] = 16800, N[0x47af, ((2, 0), (2, 1))] = 1

--- Simulation 450 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.45973479619, 16803.45973479619, 22834.321310529165, 16803.45973479619, 19603.45973479619]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3724, Score: 16100
Depth 2: State = 0x3724, Legal Moves = [((0, 4), (1, 4)), ((1, 1), (2, 1)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3724: [inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x36e0, Score: 21700
Depth 3: State = 0x36e0, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36e0: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x53fe, Score: 24500
Depth 4: State = 0x53fe, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x53fe: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x5437, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10188500, N[0x3c25, ((2, 3), (2, 4))] = 446
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27300, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3724, ((0, 4), (1, 4))] = 27300, N[0x3724, ((0, 4), (1, 4))] = 1
Updated Q[0x36e0, ((0, 1), (1, 1))] = 27300, N[0x36e0, ((0, 1), (1, 1))] = 1
Updated Q[0x53fe, ((0, 3), (1, 3))] = 27300, N[0x53fe, ((0, 3), (1, 3))] = 1

--- Simulation 451 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.460364903043, 16803.460364903043, 22844.33425661454, 16803.460364903043, 19603.460364903043]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22400.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d52, Score: 19600
Depth 2: State = 0x3d52, Legal Moves = [((0, 2), (1, 2)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3d52: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3d4e, Score: 22400
Depth 3: State = 0x3d4e, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3d4e: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3d52, Score: 25200
Depth 4: State = 0x3d52, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3d52: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c6f, Score: 30800
End of simulation with depth 5. Reward (Score): 30800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10219300, N[0x3c25, ((2, 3), (2, 4))] = 447
Updated Q[0x3c24, ((1, 3), (2, 3))] = 30800, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3d52, ((0, 2), (1, 2))] = 30800, N[0x3d52, ((0, 2), (1, 2))] = 1
Updated Q[0x3d4e, ((0, 3), (1, 3))] = 30800, N[0x3d4e, ((0, 3), (1, 3))] = 1
Updated Q[0x3d52, ((2, 0), (2, 1))] = 30800, N[0x3d52, ((2, 0), (2, 1))] = 1

--- Simulation 452 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.460993496876, 16803.460993496876, 22862.13237946464, 16803.460993496876, 19603.460993496876]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c6f, Score: 11200
Depth 1: State = 0x3c6f, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6f: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3be7, Score: 14000
Depth 2: State = 0x3be7, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be7: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3866, Score: 21700
Depth 3: State = 0x3866, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3866: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1597, Score: 27300
Depth 4: State = 0x1597, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1597: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1444, Score: 30100
End of simulation with depth 5. Reward (Score): 30100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10249400, N[0x3c25, ((2, 3), (2, 4))] = 448
Updated Q[0x3c6f, ((1, 2), (2, 2))] = 30100, N[0x3c6f, ((1, 2), (2, 2))] = 1
Updated Q[0x3be7, ((1, 3), (1, 4))] = 30100, N[0x3be7, ((1, 3), (1, 4))] = 1
Updated Q[0x3866, ((0, 2), (1, 2))] = 30100, N[0x3866, ((0, 2), (1, 2))] = 1
Updated Q[0x1597, ((2, 0), (2, 1))] = 30100, N[0x1597, ((2, 0), (2, 1))] = 1

--- Simulation 453 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.46162058471, 16803.46162058471, 22878.28854620001, 16803.46162058471, 19603.46162058471]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c6c, Score: 11200
Depth 2: State = 0x3c6c, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6c: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3d51, Score: 14000
Depth 3: State = 0x3d51, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d51: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3d3a, Score: 16800
Depth 4: State = 0x3d3a, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3d3a: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c2b, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10271800, N[0x3c25, ((2, 3), (2, 4))] = 449
Updated Q[0x3c24, ((1, 2), (2, 2))] = 22400, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3c6c, ((0, 1), (0, 2))] = 22400, N[0x3c6c, ((0, 1), (0, 2))] = 1
Updated Q[0x3d51, ((1, 2), (2, 2))] = 22400, N[0x3d51, ((1, 2), (2, 2))] = 1
Updated Q[0x3d3a, ((2, 0), (2, 1))] = 22400, N[0x3d3a, ((2, 0), (2, 1))] = 1

--- Simulation 454 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.462246173505, 16803.462246173505, 22877.223527129423, 16803.462246173505, 19603.462246173505]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [24401.16557645562, 22401.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d14, Score: 16100
Depth 2: State = 0x3d14, Legal Moves = [((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d14: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3ab2, Score: 21700
Depth 3: State = 0x3ab2, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10293500, N[0x3c25, ((2, 3), (2, 4))] = 450
Updated Q[0x3c25, ((1, 3), (2, 3))] = 21700, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3d14, ((2, 0), (2, 1))] = 21700, N[0x3d14, ((2, 0), (2, 1))] = 1

--- Simulation 455 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.46287027019, 16803.46287027019, 22874.607685714473, 16803.46287027019, 19603.46287027019]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3be0, Score: 8400
Depth 1: State = 0x3be0, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be0: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3800, Score: 14000
Depth 2: State = 0x3800, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3800: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x390f, Score: 16800
Depth 3: State = 0x390f, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x390f: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x391c, Score: 19600
Depth 4: State = 0x391c, Legal Moves = [((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x391c: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d15, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10315900, N[0x3c25, ((2, 3), (2, 4))] = 451
Updated Q[0x3be0, ((1, 3), (2, 3))] = 22400, N[0x3be0, ((1, 3), (2, 3))] = 1
Updated Q[0x3800, ((0, 1), (0, 2))] = 22400, N[0x3800, ((0, 1), (0, 2))] = 1
Updated Q[0x390f, ((1, 3), (2, 3))] = 22400, N[0x390f, ((1, 3), (2, 3))] = 1
Updated Q[0x391c, ((2, 0), (2, 1))] = 22400, N[0x391c, ((2, 0), (2, 1))] = 1

--- Simulation 456 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.463492881638, 16803.463492881638, 22873.555550707544, 16803.463492881638, 19603.463492881638]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a6c, Score: 8400
Depth 2: State = 0x4a6c, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a6c: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x46d9, Score: 11200
Depth 3: State = 0x46d9, Legal Moves = [((0, 1), (0, 2)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46d9: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x49ab, Score: 16800
Depth 4: State = 0x49ab, Legal Moves = [((0, 1), (1, 1)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x49ab: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x43b0, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10335500, N[0x3c25, ((2, 3), (2, 4))] = 452
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a6c, ((1, 3), (2, 3))] = 19600, N[0x4a6c, ((1, 3), (2, 3))] = 1
Updated Q[0x46d9, ((0, 1), (0, 2))] = 19600, N[0x46d9, ((0, 1), (0, 2))] = 1
Updated Q[0x49ab, ((0, 1), (1, 1))] = 19600, N[0x49ab, ((0, 1), (1, 1))] = 1

--- Simulation 457 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.46411401467, 16803.46411401467, 22866.31338069508, 16803.46411401467, 19603.46411401467]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 8400
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22401.16557645562, 19601.16557645562, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c61, Score: 11200
Depth 2: State = 0x3c61, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c61: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3829, Score: 14000
Depth 3: State = 0x3829, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3829: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3855, Score: 16800
Depth 4: State = 0x3855, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3855: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3855, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10355100, N[0x3c25, ((2, 3), (2, 4))] = 453
Updated Q[0x3c25, ((0, 4), (1, 4))] = 19600, N[0x3c25, ((0, 4), (1, 4))] = 1
Updated Q[0x3c61, ((1, 3), (2, 3))] = 19600, N[0x3c61, ((1, 3), (2, 3))] = 1
Updated Q[0x3829, ((1, 3), (2, 3))] = 19600, N[0x3829, ((1, 3), (2, 3))] = 1
Updated Q[0x3855, ((1, 2), (1, 3))] = 19600, N[0x3855, ((1, 2), (1, 3))] = 1

--- Simulation 458 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.46473367608, 16803.46473367608, 22859.10318473956, 16803.46473367608, 19603.46473367608]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4829, Score: 8400
Depth 2: State = 0x4829, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4829: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x52a5, Score: 14000
Depth 3: State = 0x52a5, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x52a5: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x53cc, Score: 29300
Depth 4: State = 0x53cc, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1))]
UCB1 values for moves at state 0x53cc: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x47e2, Score: 32100
End of simulation with depth 5. Reward (Score): 32100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10387200, N[0x3c25, ((2, 3), (2, 4))] = 454
Updated Q[0x3c25, ((0, 0), (0, 1))] = 32100, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4829, ((1, 3), (2, 3))] = 32100, N[0x4829, ((1, 3), (2, 3))] = 1
Updated Q[0x52a5, ((0, 1), (1, 1))] = 32100, N[0x52a5, ((0, 1), (1, 1))] = 1
Updated Q[0x53cc, ((1, 1), (2, 1))] = 32100, N[0x53cc, ((1, 1), (2, 1))] = 1

--- Simulation 459 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.46535187259, 16803.46535187259, 22879.457791206893, 16803.46535187259, 19603.46535187259]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c25, Score: 8400
Depth 2: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43d2, Score: 11200
Depth 3: State = 0x43d2, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43d2: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x442d, Score: 27700
Depth 4: State = 0x442d, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x442d: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x442d, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10417700, N[0x3c25, ((2, 3), (2, 4))] = 455
Updated Q[0x3c24, ((0, 4), (1, 4))] = 30500, N[0x3c24, ((0, 4), (1, 4))] = 1
Updated Q[0x3c25, ((0, 0), (0, 1))] = 30500, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x43d2, ((1, 2), (2, 2))] = 30500, N[0x43d2, ((1, 2), (2, 2))] = 1
Updated Q[0x442d, ((2, 0), (2, 1))] = 30500, N[0x442d, ((2, 0), (2, 1))] = 1

--- Simulation 460 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.465968610897, 16803.465968610897, 22896.206443158655, 16803.465968610897, 19603.465968610897]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22401.16557645562, 30801.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397e, Score: 8400
Depth 2: State = 0x397e, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((1, 2), (2, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397e: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2bd6, Score: 11200
Depth 3: State = 0x2bd6, Legal Moves = [((1, 2), (2, 2)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2bd6: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x294f, Score: 14000
Depth 4: State = 0x294f, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x294f: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x2aef, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10434500, N[0x3c25, ((2, 3), (2, 4))] = 456
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x397e, ((0, 0), (0, 1))] = 16800, N[0x397e, ((0, 0), (0, 1))] = 1
Updated Q[0x2bd6, ((1, 2), (2, 2))] = 16800, N[0x2bd6, ((1, 2), (2, 2))] = 1
Updated Q[0x294f, ((0, 2), (1, 2))] = 16800, N[0x294f, ((0, 2), (1, 2))] = 1

--- Simulation 461 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.46658389764, 16803.46658389764, 22882.837776261153, 16803.46658389764, 19603.46658389764]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3674, Score: 11200
Depth 2: State = 0x3674, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3674: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3a85, Score: 18900
Depth 3: State = 0x3a85, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3a85: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3d9a, Score: 21700
Depth 4: State = 0x3d9a, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d9a: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3a8f, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10459000, N[0x3c25, ((2, 3), (2, 4))] = 457
Updated Q[0x3c25, ((0, 2), (1, 2))] = 24500, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3674, ((1, 3), (2, 3))] = 24500, N[0x3674, ((1, 3), (2, 3))] = 1
Updated Q[0x3a85, ((0, 3), (1, 3))] = 24500, N[0x3a85, ((0, 3), (1, 3))] = 1
Updated Q[0x3d9a, ((1, 1), (2, 1))] = 24500, N[0x3d9a, ((1, 1), (2, 1))] = 1

--- Simulation 462 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.467197739425, 16803.467197739425, 22886.376630682505, 16803.467197739425, 19603.467197739425]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x456e, Score: 8400
Depth 2: State = 0x456e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x456e: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x479e, Score: 11200
Depth 3: State = 0x479e, Legal Moves = [((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x479e: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x47ab, Score: 16800
Depth 4: State = 0x47ab, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47ab: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x47ab, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10481400, N[0x3c25, ((2, 3), (2, 4))] = 458
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x456e, ((1, 3), (2, 3))] = 22400, N[0x456e, ((1, 3), (2, 3))] = 1
Updated Q[0x479e, ((1, 2), (1, 3))] = 22400, N[0x479e, ((1, 2), (1, 3))] = 1
Updated Q[0x47ab, ((2, 0), (2, 1))] = 22400, N[0x47ab, ((2, 0), (2, 1))] = 1

--- Simulation 463 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.467810142804, 16803.467810142804, 22885.314878554433, 16803.467810142804, 19603.467810142804]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bbb, Score: 11200
Depth 2: State = 0x3bbb, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbb: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d0d, Score: 14000
Depth 3: State = 0x3d0d, Legal Moves = [((1, 1), (2, 1)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x3d0d: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x399d, Score: 16800
Depth 4: State = 0x399d, Legal Moves = [((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x399d: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3d76, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10505900, N[0x3c25, ((2, 3), (2, 4))] = 459
Updated Q[0x3c24, ((1, 3), (2, 3))] = 24500, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3bbb, ((2, 0), (2, 1))] = 24500, N[0x3bbb, ((2, 0), (2, 1))] = 1
Updated Q[0x3d0d, ((1, 1), (2, 1))] = 24500, N[0x3d0d, ((1, 1), (2, 1))] = 1
Updated Q[0x399d, ((1, 2), (2, 2))] = 24500, N[0x399d, ((1, 2), (2, 2))] = 1

--- Simulation 464 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.468421114285, 16803.468421114285, 22888.832915998784, 16803.468421114285, 19603.468421114285]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc2, Score: 11200
Depth 1: State = 0x3bc2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc2: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37e5, Score: 14000
Depth 2: State = 0x37e5, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37e5: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x371a, Score: 19600
Depth 3: State = 0x371a, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x371a: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x386d, Score: 22400
Depth 4: State = 0x386d, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10528300, N[0x3c25, ((2, 3), (2, 4))] = 460
Updated Q[0x3bc2, ((1, 3), (2, 3))] = 22400, N[0x3bc2, ((1, 3), (2, 3))] = 1
Updated Q[0x37e5, ((1, 2), (1, 3))] = 22400, N[0x37e5, ((1, 2), (1, 3))] = 1
Updated Q[0x371a, ((2, 0), (2, 1))] = 22400, N[0x371a, ((2, 0), (2, 1))] = 1

--- Simulation 465 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.469030660337, 16803.469030660337, 22887.770440040706, 16803.469030660337, 19603.469030660337]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.467405903557, 22401.467405903557, 35701.46740590355, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x39c7, Score: 11200
Depth 2: State = 0x39c7, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39c7: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3dbf, Score: 14000
Depth 3: State = 0x3dbf, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10542300, N[0x3c25, ((2, 3), (2, 4))] = 461
Updated Q[0x3c25, ((2, 3), (3, 3))] = 14000, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x39c7, ((2, 0), (2, 1))] = 14000, N[0x39c7, ((2, 0), (2, 1))] = 1

--- Simulation 466 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.46963878739, 16803.46963878739, 22868.491315193183, 16803.46963878739, 19603.46963878739]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4678, Score: 8400
Depth 2: State = 0x4678, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4678: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4a8f, Score: 11200
Depth 3: State = 0x4a8f, Legal Moves = [((0, 1), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a8f: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x469a, Score: 14000
Depth 4: State = 0x469a, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x469a: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4940, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10559100, N[0x3c25, ((2, 3), (2, 4))] = 462
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4678, ((1, 3), (1, 4))] = 16800, N[0x4678, ((1, 3), (1, 4))] = 1
Updated Q[0x4a8f, ((0, 1), (1, 1))] = 16800, N[0x4a8f, ((0, 1), (1, 1))] = 1
Updated Q[0x469a, ((2, 0), (2, 1))] = 16800, N[0x469a, ((2, 0), (2, 1))] = 1

--- Simulation 467 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.470245501816, 16803.470245501816, 22855.356255627088, 16803.470245501816, 19603.470245501816]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c25: [16801.467405903557, 19601.467405903557, 30501.467405903557, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3bda, Score: 8400
Depth 2: State = 0x3bda, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bda: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3677, Score: 11200
Depth 3: State = 0x3677, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3677: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3699, Score: 14000
Depth 4: State = 0x3699, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3699: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3a91, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10575900, N[0x3c25, ((2, 3), (2, 4))] = 463
Updated Q[0x3c25, ((0, 4), (1, 4))] = 16800, N[0x3c25, ((0, 4), (1, 4))] = 1
Updated Q[0x3bda, ((1, 3), (2, 3))] = 16800, N[0x3bda, ((1, 3), (2, 3))] = 1
Updated Q[0x3677, ((1, 1), (2, 1))] = 16800, N[0x3677, ((1, 1), (2, 1))] = 1
Updated Q[0x3699, ((2, 0), (2, 1))] = 16800, N[0x3699, ((2, 0), (2, 1))] = 1

--- Simulation 468 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.470850809965, 16803.470850809965, 22842.277934786118, 16803.470850809965, 19603.470850809965]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.467405903557, 21701.467405903557, 25201.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397f, Score: 8400
Depth 2: State = 0x397f, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397f: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2fed, Score: 11200
Depth 3: State = 0x2fed, Legal Moves = [((1, 0), (1, 1)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2fed: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x2aa2, Score: 14000
Depth 4: State = 0x2aa2, Legal Moves = [((1, 2), (1, 3)), ((1, 2), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2aa2: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2aa9, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10592700, N[0x3c25, ((2, 3), (2, 4))] = 464
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x397f, ((0, 0), (0, 1))] = 16800, N[0x397f, ((0, 0), (0, 1))] = 1
Updated Q[0x2fed, ((1, 0), (1, 1))] = 16800, N[0x2fed, ((1, 0), (1, 1))] = 1
Updated Q[0x2aa2, ((1, 2), (1, 3))] = 16800, N[0x2aa2, ((1, 2), (1, 3))] = 1

--- Simulation 469 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.471454718125, 16803.471454718125, 22829.255985825668, 16803.471454718125, 19603.471454718125]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [30501.648374031523, 19601.648374031523, 28601.648374031523, 19601.648374031523, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x384b, Score: 23200
Depth 2: State = 0x384b, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x384b: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x5787, Score: 26000
Depth 3: State = 0x5787, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5787: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x5634, Score: 28800
Depth 4: State = 0x5634, Legal Moves = [((0, 2), (1, 2)), ((1, 1), (2, 1)), ((1, 2), (2, 2))]
UCB1 values for moves at state 0x5634: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x528a, Score: 31600
End of simulation with depth 5. Reward (Score): 31600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10624300, N[0x3c25, ((2, 3), (2, 4))] = 465
Updated Q[0x3c24, ((2, 3), (2, 4))] = 31600, N[0x3c24, ((2, 3), (2, 4))] = 1
Updated Q[0x384b, ((0, 2), (1, 2))] = 31600, N[0x384b, ((0, 2), (1, 2))] = 1
Updated Q[0x5787, ((2, 0), (2, 1))] = 31600, N[0x5787, ((2, 0), (2, 1))] = 1
Updated Q[0x5634, ((0, 2), (1, 2))] = 31600, N[0x5634, ((0, 2), (1, 2))] = 1

--- Simulation 470 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.472057232557, 16803.472057232557, 22848.118002046016, 16803.472057232557, 19603.472057232557]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [27700.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c24, Score: 8400
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a69, Score: 11200
Depth 3: State = 0x4a69, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a69: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4591, Score: 14000
Depth 4: State = 0x4591, Legal Moves = [((0, 1), (0, 2)), ((0, 1), (1, 1)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4591: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4aba, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10643900, N[0x3c25, ((2, 3), (2, 4))] = 466
Updated Q[0x3c24, ((0, 4), (1, 4))] = 19600, N[0x3c24, ((0, 4), (1, 4))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a69, ((1, 3), (2, 3))] = 19600, N[0x4a69, ((1, 3), (2, 3))] = 1
Updated Q[0x4591, ((0, 1), (0, 2))] = 19600, N[0x4591, ((0, 1), (0, 2))] = 1

--- Simulation 471 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.472658359475, 16803.472658359475, 22841.14799225559, 16803.472658359475, 19603.472658359475]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.648374031523, 27301.648374031523, 19601.648374031523, 16801.648374031523, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x3c65, Score: 16800
Depth 2: State = 0x3c65, Legal Moves = [((2, 2), (3, 2))]
UCB1 values for moves at state 0x3c65: [inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x3c24, Score: 22400
Depth 3: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 2), (2, 2))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4af0, Score: 25200
Depth 4: State = 0x4af0, Legal Moves = [((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (1, 3)), ((1, 2), (2, 2))]
UCB1 values for moves at state 0x4af0: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4ab3, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10671900, N[0x3c25, ((2, 3), (2, 4))] = 467
Updated Q[0x3c25, ((3, 0), (3, 1))] = 28000, N[0x3c25, ((3, 0), (3, 1))] = 1
Updated Q[0x3c65, ((2, 2), (3, 2))] = 28000, N[0x3c65, ((2, 2), (3, 2))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 28000, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4af0, ((0, 2), (1, 2))] = 28000, N[0x4af0, ((0, 2), (1, 2))] = 1

--- Simulation 472 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.47325810505, 16803.47325810505, 22852.194984459336, 16803.47325810505, 19603.47325810505]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [21700.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3867, Score: 19300
Depth 2: State = 0x3867, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3867: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3867, Score: 24900
Depth 3: State = 0x3867, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3867: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3b0c, Score: 27700
Depth 4: State = 0x3b0c, Legal Moves = [((2, 1), (3, 1)), ((2, 3), (2, 4)), ((3, 1), (4, 1))]
UCB1 values for moves at state 0x3b0c: [inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x45a3, Score: 33300
End of simulation with depth 5. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10705200, N[0x3c25, ((2, 3), (2, 4))] = 468
Updated Q[0x3c25, ((1, 3), (1, 4))] = 33300, N[0x3c25, ((1, 3), (1, 4))] = 1
Updated Q[0x3867, ((0, 2), (1, 2))] = 33300, N[0x3867, ((0, 2), (1, 2))] = 1
Updated Q[0x3867, ((2, 0), (2, 1))] = 33300, N[0x3867, ((2, 0), (2, 1))] = 1
Updated Q[0x3b0c, ((2, 1), (3, 1))] = 33300, N[0x3b0c, ((2, 1), (3, 1))] = 1

--- Simulation 473 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.47385647541, 16803.47385647541, 22874.519553431353, 16803.47385647541, 19603.47385647541]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x451a, Score: 11200
Depth 2: State = 0x451a, Legal Moves = [((0, 3), (0, 4)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x451a: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x47f2, Score: 14000
Depth 3: State = 0x47f2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47f2: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4411, Score: 16800
Depth 4: State = 0x4411, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4411: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4411, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10724800, N[0x3c25, ((2, 3), (2, 4))] = 469
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x451a, ((0, 3), (0, 4))] = 19600, N[0x451a, ((0, 3), (0, 4))] = 1
Updated Q[0x47f2, ((1, 3), (2, 3))] = 19600, N[0x47f2, ((1, 3), (2, 3))] = 1
Updated Q[0x4411, ((1, 3), (1, 4))] = 19600, N[0x4411, ((1, 3), (1, 4))] = 1

--- Simulation 474 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.474453476654, 16803.474453476654, 22867.537834075625, 16803.474453476654, 19603.474453476654]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 32801.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x382d, Score: 8400
Depth 2: State = 0x382d, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x382d: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x200f, Score: 11200
Depth 3: State = 0x200f, Legal Moves = [((0, 0), (0, 1)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x200f: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x3844, Score: 14000
Depth 4: State = 0x3844, Legal Moves = [((1, 2), (1, 3)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3844: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x386d, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10744400, N[0x3c25, ((2, 3), (2, 4))] = 470
Updated Q[0x3c25, ((2, 0), (2, 1))] = 19600, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x382d, ((0, 0), (0, 1))] = 19600, N[0x382d, ((0, 0), (0, 1))] = 1
Updated Q[0x200f, ((0, 0), (0, 1))] = 19600, N[0x200f, ((0, 0), (0, 1))] = 1
Updated Q[0x3844, ((1, 2), (1, 3))] = 19600, N[0x3844, ((1, 2), (1, 3))] = 1

--- Simulation 475 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.475049114837, 16803.475049114837, 22860.585823977788, 16803.475049114837, 19603.475049114837]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22401.648374031523, 19601.648374031523, 16801.648374031523, 39501.64837403152, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3ab0, Score: 11200
Depth 2: State = 0x3ab0, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3ab0: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x47c7, Score: 14000
Depth 3: State = 0x47c7, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c7: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x47c0, Score: 16800
Depth 4: State = 0x47c0, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c0: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x451b, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10764000, N[0x3c25, ((2, 3), (2, 4))] = 471
Updated Q[0x3c25, ((2, 3), (3, 3))] = 19600, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3ab0, ((0, 2), (0, 3))] = 19600, N[0x3ab0, ((0, 2), (0, 3))] = 1
Updated Q[0x47c7, ((1, 3), (1, 4))] = 19600, N[0x47c7, ((1, 3), (1, 4))] = 1
Updated Q[0x47c0, ((2, 0), (2, 1))] = 19600, N[0x47c0, ((2, 0), (2, 1))] = 1

--- Simulation 476 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.475643395963, 16803.475643395963, 22853.663333907458, 16803.475643395963, 19603.475643395963]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x452b, Score: 8400
Depth 2: State = 0x452b, Legal Moves = [((0, 3), (0, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x452b: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x43f1, Score: 11200
Depth 3: State = 0x43f1, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43f1: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x43aa, Score: 14000
Depth 4: State = 0x43aa, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43aa: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x43b1, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10780800, N[0x3c25, ((2, 3), (2, 4))] = 472
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x452b, ((0, 3), (0, 4))] = 16800, N[0x452b, ((0, 3), (0, 4))] = 1
Updated Q[0x43f1, ((1, 3), (2, 3))] = 16800, N[0x43f1, ((1, 3), (2, 3))] = 1
Updated Q[0x43aa, ((1, 3), (1, 4))] = 16800, N[0x43aa, ((1, 3), (1, 4))] = 1

--- Simulation 477 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.476236326012, 16803.476236326012, 22840.837972848072, 16803.476236326012, 19603.476236326012]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.648374031523, 19601.648374031523, 21601.648374031523, 22401.648374031523, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c2c, Score: 8400
Depth 2: State = 0x3c2c, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c2c: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3c2c, Score: 11200
Depth 3: State = 0x3c2c, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c2c: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1478, Score: 19600
Depth 4: State = 0x1478, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1478: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x47f3, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10803200, N[0x3c25, ((2, 3), (2, 4))] = 473
Updated Q[0x3c25, ((2, 3), (3, 3))] = 22400, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3c2c, ((1, 3), (1, 4))] = 22400, N[0x3c2c, ((1, 3), (1, 4))] = 1
Updated Q[0x3c2c, ((2, 0), (2, 1))] = 22400, N[0x3c2c, ((2, 0), (2, 1))] = 1
Updated Q[0x1478, ((1, 1), (2, 1))] = 22400, N[0x1478, ((1, 1), (2, 1))] = 1

--- Simulation 478 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.47682791092, 16803.47682791092, 22839.90616492908, 16803.47682791092, 19603.47682791092]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14001.648374031522, 19601.648374031523, 27301.648374031523, 19601.648374031523, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c27, Score: 8400
Depth 2: State = 0x3c27, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c27: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x380d, Score: 11200
Depth 3: State = 0x380d, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x380d: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x11cd, Score: 14000
Depth 4: State = 0x11cd, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x11cd: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x1212, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10820000, N[0x3c25, ((2, 3), (2, 4))] = 474
Updated Q[0x3c24, ((2, 3), (3, 3))] = 16800, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x3c27, ((1, 3), (1, 4))] = 16800, N[0x3c27, ((1, 3), (1, 4))] = 1
Updated Q[0x380d, ((1, 2), (1, 3))] = 16800, N[0x380d, ((1, 2), (1, 3))] = 1
Updated Q[0x11cd, ((1, 2), (2, 2))] = 16800, N[0x11cd, ((1, 2), (2, 2))] = 1

--- Simulation 479 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.477418156577, 16803.477418156577, 22827.163942515122, 16803.477418156577, 19603.477418156577]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bb8, Score: 8400
Depth 1: State = 0x3bb8, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb8: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3673, Score: 11200
Depth 2: State = 0x3673, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3673: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3677, Score: 14000
Depth 3: State = 0x3677, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (0, 4)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3677: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3bf8, Score: 16800
Depth 4: State = 0x3bf8, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bf8: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x3be8, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10842400, N[0x3c25, ((2, 3), (2, 4))] = 475
Updated Q[0x3bb8, ((1, 3), (2, 3))] = 22400, N[0x3bb8, ((1, 3), (2, 3))] = 1
Updated Q[0x3673, ((0, 3), (1, 3))] = 22400, N[0x3673, ((0, 3), (1, 3))] = 1
Updated Q[0x3677, ((0, 1), (1, 1))] = 22400, N[0x3677, ((0, 1), (1, 1))] = 1
Updated Q[0x3bf8, ((1, 1), (1, 2))] = 22400, N[0x3bf8, ((1, 1), (1, 2))] = 1

--- Simulation 480 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.478007068843, 16803.478007068843, 22826.264845066715, 16803.478007068843, 19603.478007068843]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.467405903557, 32801.46740590355, 19601.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c28, Score: 8400
Depth 2: State = 0x3c28, Legal Moves = [((0, 1), (0, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c28: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3a70, Score: 11200
Depth 3: State = 0x3a70, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3a70: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x37ca, Score: 14000
Depth 4: State = 0x37ca, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x37ca: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x3833, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10859200, N[0x3c25, ((2, 3), (2, 4))] = 476
Updated Q[0x3c25, ((2, 3), (3, 3))] = 16800, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3c28, ((0, 1), (0, 2))] = 16800, N[0x3c28, ((0, 1), (0, 2))] = 1
Updated Q[0x3a70, ((2, 0), (2, 1))] = 16800, N[0x3a70, ((2, 0), (2, 1))] = 1
Updated Q[0x37ca, ((4, 1), (4, 2))] = 16800, N[0x37ca, ((4, 1), (4, 2))] = 1

--- Simulation 481 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.47859465354, 16803.47859465354, 22813.604819275795, 16803.47859465354, 19603.47859465354]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [30500.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c3d, Score: 19300
Depth 2: State = 0x3c3d, Legal Moves = [((0, 0), (1, 0)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c3d: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3bb5, Score: 22100
Depth 3: State = 0x3bb5, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb5: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x37bd, Score: 24900
Depth 4: State = 0x37bd, Legal Moves = [((1, 1), (2, 1))]
UCB1 values for moves at state 0x37bd: [inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x1205, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10889700, N[0x3c25, ((2, 3), (2, 4))] = 477
Updated Q[0x3c25, ((1, 3), (2, 3))] = 30500, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3c3d, ((0, 0), (1, 0))] = 30500, N[0x3c3d, ((0, 0), (1, 0))] = 1
Updated Q[0x3bb5, ((2, 0), (2, 1))] = 30500, N[0x3bb5, ((2, 0), (2, 1))] = 1
Updated Q[0x37bd, ((1, 1), (2, 1))] = 30500, N[0x37bd, ((1, 1), (2, 1))] = 1

--- Simulation 482 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.479180916453, 16803.479180916453, 22829.719049178595, 16803.479180916453, 19603.479180916453]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 30001.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3852, Score: 13300
Depth 2: State = 0x3852, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3852: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3713, Score: 16100
Depth 3: State = 0x3713, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3713: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x5540, Score: 21700
Depth 4: State = 0x5540, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((2, 2), (2, 3)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x5540: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3844, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10914200, N[0x3c25, ((2, 3), (2, 4))] = 478
Updated Q[0x3c25, ((1, 3), (2, 3))] = 24500, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3852, ((0, 1), (1, 1))] = 24500, N[0x3852, ((0, 1), (1, 1))] = 1
Updated Q[0x3713, ((2, 0), (2, 1))] = 24500, N[0x3713, ((2, 0), (2, 1))] = 1
Updated Q[0x5540, ((0, 0), (1, 0))] = 24500, N[0x5540, ((0, 0), (1, 0))] = 1

--- Simulation 483 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.47976586332, 16803.47976586332, 22833.21355409138, 16803.47976586332, 19603.47976586332]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a43, Score: 8400
Depth 2: State = 0x4a43, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a43: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x43ac, Score: 11200
Depth 3: State = 0x43ac, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43ac: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x48f7, Score: 14000
Depth 4: State = 0x48f7, Legal Moves = [((2, 2), (2, 3)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x48f7: [inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x4946, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10933800, N[0x3c25, ((2, 3), (2, 4))] = 479
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a43, ((0, 1), (1, 1))] = 19600, N[0x4a43, ((0, 1), (1, 1))] = 1
Updated Q[0x43ac, ((2, 0), (2, 1))] = 19600, N[0x43ac, ((2, 0), (2, 1))] = 1
Updated Q[0x48f7, ((2, 2), (2, 3))] = 19600, N[0x48f7, ((2, 2), (2, 3))] = 1

--- Simulation 484 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.480349499856, 16803.480349499856, 22826.463822897713, 16803.480349499856, 19603.480349499856]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.467405903557, 22401.467405903557, 19601.467405903557, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c2c, Score: 10500
Depth 2: State = 0x3c2c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c2c: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c42, Score: 13300
Depth 3: State = 0x3c42, Legal Moves = [((0, 0), (1, 0)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3c42: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x100e, Score: 16100
Depth 4: State = 0x100e, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x100e: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x49a0, Score: 18900
End of simulation with depth 5. Reward (Score): 18900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10952700, N[0x3c25, ((2, 3), (2, 4))] = 480
Updated Q[0x3c25, ((2, 3), (2, 4))] = 18900, N[0x3c25, ((2, 3), (2, 4))] = 1
Updated Q[0x3c2c, ((1, 2), (2, 2))] = 18900, N[0x3c2c, ((1, 2), (2, 2))] = 1
Updated Q[0x3c42, ((0, 0), (1, 0))] = 18900, N[0x3c42, ((0, 0), (1, 0))] = 1
Updated Q[0x100e, ((0, 1), (1, 1))] = 18900, N[0x100e, ((0, 1), (1, 1))] = 1

--- Simulation 485 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48093183173, 16803.48093183173, 22818.28388207378, 16803.48093183173, 19603.48093183173]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [32100.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x382d, Score: 14000
Depth 2: State = 0x382d, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x382d: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1dd6, Score: 16800
Depth 3: State = 0x1dd6, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1dd6: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x510e, Score: 19600
Depth 4: State = 0x510e, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((1, 0), (2, 0)), ((1, 1), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x510e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x578a, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10975100, N[0x3c25, ((2, 3), (2, 4))] = 481
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x382d, ((0, 0), (0, 1))] = 22400, N[0x382d, ((0, 0), (0, 1))] = 1
Updated Q[0x1dd6, ((0, 2), (1, 2))] = 22400, N[0x1dd6, ((0, 2), (1, 2))] = 1
Updated Q[0x510e, ((0, 1), (0, 2))] = 22400, N[0x510e, ((0, 1), (0, 2))] = 1

--- Simulation 486 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48151286458, 16803.48151286458, 22817.414460578304, 16803.48151286458, 19603.48151286458]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.648374031523, 25201.648374031523, 19601.648374031523, 18901.648374031523, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c1a, Score: 8400
Depth 2: State = 0x3c1a, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1a: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c3c, Score: 11200
Depth 3: State = 0x3c3c, Legal Moves = [((0, 0), (1, 0)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c3c: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x1c35, Score: 14000
Depth 4: State = 0x1c35, Legal Moves = [((1, 0), (1, 1)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1c35: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x21c7, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10991900, N[0x3c25, ((2, 3), (2, 4))] = 482
Updated Q[0x3c24, ((2, 3), (3, 3))] = 16800, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x3c1a, ((0, 2), (1, 2))] = 16800, N[0x3c1a, ((0, 2), (1, 2))] = 1
Updated Q[0x3c3c, ((0, 0), (1, 0))] = 16800, N[0x3c3c, ((0, 0), (1, 0))] = 1
Updated Q[0x1c35, ((1, 0), (1, 1))] = 16800, N[0x1c35, ((1, 0), (1, 1))] = 1

--- Simulation 487 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.482092604, 16803.482092604, 22804.930389204364, 16803.482092604, 19603.482092604]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c61, Score: 14000
Depth 2: State = 0x3c61, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c61: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x39bc, Score: 16800
Depth 3: State = 0x39bc, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11008700, N[0x3c25, ((2, 3), (2, 4))] = 483
Updated Q[0x3c24, ((1, 2), (2, 2))] = 16800, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3c61, ((2, 0), (2, 1))] = 16800, N[0x3c61, ((2, 0), (2, 1))] = 1

--- Simulation 488 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48267105556, 16803.48267105556, 22792.498011533502, 16803.48267105556, 19603.48267105556]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [32101.16557645562, 22401.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1dee, Score: 13300
Depth 2: State = 0x1dee, Legal Moves = [((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1dee: [inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x1dee, Score: 16100
Depth 3: State = 0x1dee, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x1dee: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x1db1, Score: 18900
Depth 4: State = 0x1db1, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 18900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11027600, N[0x3c25, ((2, 3), (2, 4))] = 484
Updated Q[0x3c25, ((2, 0), (2, 1))] = 18900, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x1dee, ((1, 2), (1, 3))] = 18900, N[0x1dee, ((1, 2), (1, 3))] = 1
Updated Q[0x1dee, ((4, 1), (4, 2))] = 18900, N[0x1dee, ((4, 1), (4, 2))] = 1

--- Simulation 489 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.483248224784, 16803.483248224784, 22784.45585012592, 16803.483248224784, 19603.483248224784]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 24501.16557645562, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3be8, Score: 8400
Depth 2: State = 0x3be8, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be8: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c6d, Score: 11200
Depth 3: State = 0x3c6d, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6d: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c1b, Score: 14000
Depth 4: State = 0x3c1b, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1b: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x11e3, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11044400, N[0x3c25, ((2, 3), (2, 4))] = 485
Updated Q[0x3c25, ((0, 4), (1, 4))] = 16800, N[0x3c25, ((0, 4), (1, 4))] = 1
Updated Q[0x3be8, ((1, 3), (2, 3))] = 16800, N[0x3be8, ((1, 3), (2, 3))] = 1
Updated Q[0x3c6d, ((0, 2), (1, 2))] = 16800, N[0x3c6d, ((0, 2), (1, 2))] = 1
Updated Q[0x3c1b, ((1, 2), (1, 3))] = 16800, N[0x3c1b, ((1, 2), (1, 3))] = 1

--- Simulation 490 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48382411717, 16803.48382411717, 22772.116955190813, 16803.48382411717, 19603.48382411717]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [18901.16557645562, 22401.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c24, Score: 8400
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((2, 1), (3, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4412, Score: 11200
Depth 3: State = 0x4412, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x4412: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x43d4, Score: 14000
Depth 4: State = 0x43d4, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (2, 2))]
UCB1 values for moves at state 0x43d4: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x43d4, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11061200, N[0x3c25, ((2, 3), (2, 4))] = 486
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4412, ((4, 1), (4, 2))] = 16800, N[0x4412, ((4, 1), (4, 2))] = 1
Updated Q[0x43d4, ((1, 1), (2, 1))] = 16800, N[0x43d4, ((1, 1), (2, 1))] = 1

--- Simulation 491 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.484398738172, 16803.484398738172, 22759.828837429464, 16803.484398738172, 19603.484398738172]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.77609073765, 19601.77609073765, 16801.77609073765, 24501.77609073765, 32101.77609073765, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x2ee8, Score: 8400
Depth 2: State = 0x2ee8, Legal Moves = [((1, 0), (2, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x2ee8: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x37e7, Score: 11200
Depth 3: State = 0x37e7, Legal Moves = [((0, 0), (1, 0)), ((1, 4), (2, 4)), ((2, 3), (2, 4)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x37e7: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x4524, Score: 14000
Depth 4: State = 0x4524, Legal Moves = [((1, 0), (1, 1)), ((1, 4), (2, 4)), ((2, 3), (2, 4)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x4524: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x440e, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11078000, N[0x3c25, ((2, 3), (2, 4))] = 487
Updated Q[0x3c24, ((3, 0), (3, 1))] = 16800, N[0x3c24, ((3, 0), (3, 1))] = 1
Updated Q[0x2ee8, ((1, 0), (2, 0))] = 16800, N[0x2ee8, ((1, 0), (2, 0))] = 1
Updated Q[0x37e7, ((0, 0), (1, 0))] = 16800, N[0x37e7, ((0, 0), (1, 0))] = 1
Updated Q[0x4524, ((1, 0), (1, 1))] = 16800, N[0x4524, ((1, 0), (1, 1))] = 1

--- Simulation 492 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.484972093214, 16803.484972093214, 22747.591184046654, 16803.484972093214, 19603.484972093214]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [25200.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c27, Score: 8400
Depth 2: State = 0x3c27, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c27: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x397e, Score: 11200
Depth 3: State = 0x397e, Legal Moves = [((0, 0), (0, 1)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x397e: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2ae5, Score: 14000
Depth 4: State = 0x2ae5, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2ae5: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x1313, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11105700, N[0x3c25, ((2, 3), (2, 4))] = 488
Updated Q[0x3c24, ((0, 2), (1, 2))] = 27700, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c27, ((1, 3), (2, 3))] = 27700, N[0x3c27, ((1, 3), (2, 3))] = 1
Updated Q[0x397e, ((0, 0), (0, 1))] = 27700, N[0x397e, ((0, 0), (0, 1))] = 1
Updated Q[0x2ae5, ((1, 2), (1, 3))] = 27700, N[0x2ae5, ((1, 2), (1, 3))] = 1

--- Simulation 493 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.485544187686, 16803.485544187686, 22757.73975038481, 16803.485544187686, 19603.485544187686]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [14000.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c5e, Score: 8400
Depth 2: State = 0x3c5e, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5e: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x369c, Score: 11200
Depth 3: State = 0x369c, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x369c: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3a95, Score: 14000
Depth 4: State = 0x3a95, Legal Moves = [((2, 1), (2, 2))]
UCB1 values for moves at state 0x3a95: [inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x3b1c, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11122500, N[0x3c25, ((2, 3), (2, 4))] = 489
Updated Q[0x3c25, ((0, 2), (1, 2))] = 16800, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3c5e, ((0, 3), (1, 3))] = 16800, N[0x3c5e, ((0, 3), (1, 3))] = 1
Updated Q[0x369c, ((2, 0), (2, 1))] = 16800, N[0x369c, ((2, 0), (2, 1))] = 1
Updated Q[0x3a95, ((2, 1), (2, 2))] = 16800, N[0x3a95, ((2, 1), (2, 2))] = 1

--- Simulation 494 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48611502695, 16803.48611502695, 22745.556420577024, 16803.48611502695, 19603.48611502695]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x444e, Score: 8400
Depth 2: State = 0x444e, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x444e: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4a73, Score: 11200
Depth 3: State = 0x4a73, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a73: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x46f8, Score: 14000
Depth 4: State = 0x46f8, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46f8: [inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x4705, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11139300, N[0x3c25, ((2, 3), (2, 4))] = 490
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x444e, ((0, 1), (0, 2))] = 16800, N[0x444e, ((0, 1), (0, 2))] = 1
Updated Q[0x4a73, ((1, 3), (2, 3))] = 16800, N[0x4a73, ((1, 3), (2, 3))] = 1
Updated Q[0x46f8, ((0, 2), (0, 3))] = 16800, N[0x46f8, ((0, 2), (0, 3))] = 1

--- Simulation 495 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48668461632, 16803.48668461632, 22733.42281847774, 16803.48668461632, 19603.48668461632]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.648374031523, 22401.648374031523, 35701.64837403152, 14001.648374031522, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x569d, Score: 8400
Depth 2: State = 0x569d, Legal Moves = [((1, 0), (2, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x569d: [inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x2ea5, Score: 11200
Depth 3: State = 0x2ea5, Legal Moves = [((2, 3), (3, 3))]
UCB1 values for moves at state 0x2ea5: [inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x2e9b, Score: 14000
Depth 4: State = 0x2e9b, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11153300, N[0x3c25, ((2, 3), (2, 4))] = 491
Updated Q[0x3c25, ((3, 0), (3, 1))] = 14000, N[0x3c25, ((3, 0), (3, 1))] = 1
Updated Q[0x569d, ((1, 0), (2, 0))] = 14000, N[0x569d, ((1, 0), (2, 0))] = 1
Updated Q[0x2ea5, ((2, 3), (3, 3))] = 14000, N[0x2ea5, ((2, 3), (3, 3))] = 1

--- Simulation 496 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48725296109, 16803.48725296109, 22715.63599259431, 16803.48725296109, 19603.48725296109]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22401.16557645562, 21701.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d78, Score: 8400
Depth 2: State = 0x3d78, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d78: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x5413, Score: 11200
Depth 3: State = 0x5413, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x5413: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x5438, Score: 14000
Depth 4: State = 0x5438, Legal Moves = [((0, 1), (1, 1))]
UCB1 values for moves at state 0x5438: [inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x5504, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11170100, N[0x3c25, ((2, 3), (2, 4))] = 492
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3d78, ((0, 0), (0, 1))] = 16800, N[0x3d78, ((0, 0), (0, 1))] = 1
Updated Q[0x5413, ((4, 1), (4, 2))] = 16800, N[0x5413, ((4, 1), (4, 2))] = 1
Updated Q[0x5438, ((0, 1), (1, 1))] = 16800, N[0x5438, ((0, 1), (1, 1))] = 1

--- Simulation 497 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.487820066515, 16803.487820066515, 22703.612527625104, 16803.487820066515, 19603.487820066515]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43ed, Score: 8400
Depth 2: State = 0x43ed, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43ed: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4693, Score: 11200
Depth 3: State = 0x4693, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4693: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4829, Score: 14000
Depth 4: State = 0x4829, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x4829: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x516d, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11186900, N[0x3c25, ((2, 3), (2, 4))] = 493
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x43ed, ((1, 3), (2, 3))] = 16800, N[0x43ed, ((1, 3), (2, 3))] = 1
Updated Q[0x4693, ((1, 3), (2, 3))] = 16800, N[0x4693, ((1, 3), (2, 3))] = 1
Updated Q[0x4829, ((1, 0), (2, 0))] = 16800, N[0x4829, ((1, 0), (2, 0))] = 1

--- Simulation 498 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.488385937817, 16803.488385937817, 22691.63783922426, 16803.488385937817, 19603.488385937817]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.648374031523, 25201.648374031523, 24501.648374031523, 25201.648374031523, inf, inf]
Selected move: ((2, 4), (3, 4))
New board state after move: 0x3c25, Score: 8400
Depth 2: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4921, Score: 11200
Depth 3: State = 0x4921, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4921: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4544, Score: 14000
Depth 4: State = 0x4544, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4544: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x454d, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11203700, N[0x3c25, ((2, 3), (2, 4))] = 494
Updated Q[0x3c24, ((2, 4), (3, 4))] = 16800, N[0x3c24, ((2, 4), (3, 4))] = 1
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4921, ((0, 1), (0, 2))] = 16800, N[0x4921, ((0, 1), (0, 2))] = 1
Updated Q[0x4544, ((1, 2), (2, 2))] = 16800, N[0x4544, ((1, 2), (2, 2))] = 1

--- Simulation 499 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.488950580184, 16803.488950580184, 22679.711631178277, 16803.488950580184, 19603.488950580184]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x44fe, Score: 8400
Depth 2: State = 0x44fe, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x44fe: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a8a, Score: 11200
Depth 3: State = 0x4a8a, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a8a: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3955, Score: 16800
Depth 4: State = 0x3955, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3))]
UCB1 values for moves at state 0x3955: [inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3c64, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11223300, N[0x3c25, ((2, 3), (2, 4))] = 495
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x44fe, ((1, 3), (2, 3))] = 19600, N[0x44fe, ((1, 3), (2, 3))] = 1
Updated Q[0x4a8a, ((2, 0), (2, 1))] = 19600, N[0x4a8a, ((2, 0), (2, 1))] = 1
Updated Q[0x3955, ((0, 1), (1, 1))] = 19600, N[0x3955, ((0, 1), (1, 1))] = 1

--- Simulation 500 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48951399878, 16803.48951399878, 22673.490175323866, 16803.48951399878, 19603.48951399878]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c47, Score: 8400
Depth 1: State = 0x3c47, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c47: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3a8e, Score: 14000
Depth 2: State = 0x3a8e, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3a8e: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x37c6, Score: 16800
Depth 3: State = 0x37c6, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37c6: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x395c, Score: 25200
Depth 4: State = 0x395c, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x395c: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x36b7, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11251300, N[0x3c25, ((2, 3), (2, 4))] = 496
Updated Q[0x3c47, ((0, 0), (1, 0))] = 28000, N[0x3c47, ((0, 0), (1, 0))] = 1
Updated Q[0x3a8e, ((0, 1), (0, 2))] = 28000, N[0x3a8e, ((0, 1), (0, 2))] = 1
Updated Q[0x37c6, ((1, 3), (2, 3))] = 28000, N[0x37c6, ((1, 3), (2, 3))] = 1
Updated Q[0x395c, ((1, 1), (2, 1))] = 28000, N[0x395c, ((1, 1), (2, 1))] = 1

Best move selected: ((2, 3), (2, 4))

--- Summary of States Visited ---
State 0x3c25 visited 500 times
State 0x43d2 visited 1 times
State 0x11a9 visited 1 times
State 0x144f visited 1 times
State 0x36b8 visited 1 times
State 0x3d78 visited 1 times
State 0x510b visited 1 times
State 0x50e9 visited 1 times
State 0x5171 visited 1 times
State 0x3c25 visited 4 times
State 0x45ad visited 1 times
State 0x4917 visited 1 times
State 0x4acf visited 1 times
State 0x3c29 visited 1 times
State 0x3c22 visited 1 times
State 0x382a visited 1 times
State 0x57cb visited 1 times
State 0x2ee9 visited 1 times
State 0x2ee8 visited 1 times
State 0x2a8d visited 1 times
State 0x2b11 visited 1 times
State 0x3c24 visited 7 times
State 0x4a6c visited 1 times
State 0x4934 visited 1 times
State 0x43e9 visited 1 times
State 0x3c25 visited 1 times
State 0x3bb9 visited 1 times
State 0x3983 visited 1 times
State 0x3983 visited 1 times
State 0x3c25 visited 2 times
State 0x47ed visited 1 times
State 0x4525 visited 1 times
State 0x4522 visited 1 times
State 0x3c24 visited 1 times
State 0x46dc visited 1 times
State 0x453b visited 1 times
State 0x455d visited 1 times
State 0x3c24 visited 1 times
State 0x4a47 visited 1 times
State 0x46ff visited 1 times
State 0x46ff visited 1 times
State 0x3c25 visited 5 times
State 0x43d6 visited 1 times
State 0x47a9 visited 1 times
State 0x47a2 visited 1 times
State 0x3c5e visited 1 times
State 0x397b visited 1 times
State 0x3b0a visited 1 times
State 0x3b0a visited 1 times
State 0x3c25 visited 5 times
State 0x464c visited 1 times
State 0x469a visited 1 times
State 0x47ec visited 1 times
State 0x3c25 visited 6 times
State 0x482a visited 1 times
State 0x46b9 visited 1 times
State 0x441d visited 1 times
State 0x3c24 visited 2 times
State 0x4a51 visited 1 times
State 0x4a65 visited 1 times
State 0x4a70 visited 1 times
State 0x3bbf visited 1 times
State 0x3b19 visited 1 times
State 0x53b7 visited 1 times
State 0x3c24 visited 5 times
State 0x4590 visited 1 times
State 0x4836 visited 1 times
State 0x3c24 visited 2 times
State 0x4833 visited 1 times
State 0x3695 visited 1 times
State 0x3c43 visited 1 times
State 0x3c25 visited 2 times
State 0x4a55 visited 1 times
State 0x4547 visited 1 times
State 0x1d52 visited 1 times
State 0x3c25 visited 3 times
State 0x493c visited 1 times
State 0x4aaa visited 1 times
State 0x46b2 visited 1 times
State 0x3c24 visited 1 times
State 0x45ac visited 1 times
State 0x45a9 visited 1 times
State 0x4503 visited 1 times
State 0x3c5d visited 1 times
State 0x3c28 visited 1 times
State 0x3b11 visited 1 times
State 0x3d95 visited 1 times
State 0x3c25 visited 3 times
State 0x4565 visited 1 times
State 0x4a8f visited 1 times
State 0x4a88 visited 1 times
State 0x3c25 visited 5 times
State 0x480b visited 1 times
State 0x11ea visited 1 times
State 0x5547 visited 1 times
State 0x3c24 visited 3 times
State 0x4437 visited 1 times
State 0x43ce visited 1 times
State 0x43ce visited 1 times
State 0x3c24 visited 4 times
State 0x4702 visited 1 times
State 0x4934 visited 1 times
State 0x3bbf visited 1 times
State 0x3866 visited 1 times
State 0x3b0b visited 1 times
State 0x5671 visited 1 times
State 0x3c24 visited 4 times
State 0x46c2 visited 1 times
State 0x454a visited 1 times
State 0x4942 visited 1 times
State 0x3c24 visited 4 times
State 0x456b visited 1 times
State 0x45a5 visited 1 times
State 0x45a8 visited 1 times
State 0x3c47 visited 1 times
State 0x3a8e visited 1 times
State 0x384e visited 1 times
State 0x3d71 visited 1 times
State 0x3c25 visited 4 times
State 0x43f1 visited 1 times
State 0x43cb visited 1 times
State 0x441c visited 1 times
State 0x3c24 visited 5 times
State 0x47c2 visited 1 times
State 0x442c visited 1 times
State 0x48f5 visited 1 times
State 0x3d0a visited 1 times
State 0x3d08 visited 1 times
State 0x3d3a visited 1 times
State 0x3c24 visited 3 times
State 0x458d visited 1 times
State 0x1dd9 visited 1 times
State 0x21f7 visited 1 times
State 0x3bb8 visited 1 times
State 0x3bb8 visited 1 times
State 0x3b0f visited 1 times
State 0x36d3 visited 1 times
State 0x3c62 visited 1 times
State 0x380b visited 1 times
State 0x36bb visited 1 times
State 0x3bb5 visited 1 times
State 0x3bd7 visited 1 times
State 0x3bda visited 1 times
State 0x3c43 visited 1 times
State 0x3c06 visited 1 times
State 0x3c06 visited 1 times
State 0x214a visited 1 times
State 0x218d visited 1 times
State 0x3c25 visited 4 times
State 0x43c8 visited 1 times
State 0x4aae visited 1 times
State 0x4a71 visited 1 times
State 0x43d5 visited 1 times
State 0x4419 visited 1 times
State 0x3d9d visited 1 times
State 0x3c25 visited 3 times
State 0x46dd visited 1 times
State 0x4af4 visited 1 times
State 0x484f visited 1 times
State 0x3b16 visited 1 times
State 0x29e8 visited 1 times
State 0x214e visited 1 times
State 0x3c5e visited 1 times
State 0x36d3 visited 1 times
State 0x3674 visited 1 times
State 0x3997 visited 1 times
State 0x3c25 visited 1 times
State 0x49a2 visited 1 times
State 0x4a4f visited 1 times
State 0x4a52 visited 1 times
State 0x3c40 visited 1 times
State 0x4acf visited 1 times
State 0x443b visited 1 times
State 0xf65e visited 1 times
State 0x3c24 visited 9 times
State 0x491d visited 1 times
State 0x443b visited 1 times
State 0x104b visited 1 times
State 0x3c25 visited 2 times
State 0x4a99 visited 1 times
State 0x4913 visited 1 times
State 0x1d88 visited 1 times
State 0x3c24 visited 3 times
State 0x4913 visited 1 times
State 0x44f8 visited 1 times
State 0x43c7 visited 1 times
State 0x3c6c visited 1 times
State 0x3919 visited 1 times
State 0x3916 visited 1 times
State 0x36be visited 1 times
State 0x3c24 visited 5 times
State 0x43f3 visited 1 times
State 0x4a87 visited 1 times
State 0x45ab visited 1 times
State 0x3c24 visited 3 times
State 0x47c2 visited 1 times
State 0x4858 visited 1 times
State 0x493b visited 1 times
State 0x3c25 visited 2 times
State 0x4570 visited 1 times
State 0x4582 visited 1 times
State 0x44f8 visited 1 times
State 0x3c24 visited 1 times
State 0x46b7 visited 1 times
State 0x45a5 visited 1 times
State 0x4a76 visited 1 times
State 0x3c24 visited 3 times
State 0x443a visited 1 times
State 0x1161 visited 1 times
State 0x29dd visited 1 times
State 0x3c24 visited 5 times
State 0x4aac visited 1 times
State 0x455e visited 1 times
State 0x47f2 visited 1 times
State 0x3c24 visited 3 times
State 0x452b visited 1 times
State 0x48f5 visited 1 times
State 0x49a1 visited 1 times
State 0x368c visited 1 times
State 0x4450 visited 1 times
State 0x4848 visited 1 times
State 0x3c24 visited 6 times
State 0x43f9 visited 1 times
State 0x4705 visited 1 times
State 0x4705 visited 1 times
State 0x3d2e visited 1 times
State 0x3d50 visited 1 times
State 0x3957 visited 1 times
State 0x3c24 visited 3 times
State 0x46d5 visited 1 times
State 0x4825 visited 1 times
State 0x3c24 visited 1 times
State 0x46c1 visited 1 times
State 0x455d visited 1 times
State 0x440a visited 1 times
State 0x3be4 visited 1 times
State 0x3c06 visited 1 times
State 0x3c02 visited 1 times
State 0x3c06 visited 1 times
State 0x3c5e visited 1 times
State 0x3865 visited 1 times
State 0x382d visited 1 times
State 0x21ee visited 1 times
State 0x1f48 visited 1 times
State 0x3c25 visited 1 times
State 0x4852 visited 1 times
State 0x4a6a visited 1 times
State 0x47e3 visited 1 times
State 0x3c24 visited 2 times
State 0x4aed visited 1 times
State 0x4aba visited 1 times
State 0x36d9 visited 1 times
State 0x3c25 visited 2 times
State 0x4965 visited 1 times
State 0x480b visited 1 times
State 0x482c visited 1 times
State 0x3c24 visited 1 times
State 0x47a4 visited 1 times
State 0x47c0 visited 1 times
State 0x46b8 visited 1 times
State 0x3c24 visited 2 times
State 0x46e3 visited 1 times
State 0x4ad5 visited 1 times
State 0x4aca visited 1 times
State 0x3c25 visited 3 times
State 0x4957 visited 1 times
State 0x4a66 visited 1 times
State 0x3c24 visited 4 times
State 0x43d4 visited 1 times
State 0x43fb visited 1 times
State 0x1412 visited 1 times
State 0x3c24 visited 2 times
State 0x48f7 visited 1 times
State 0x4a91 visited 1 times
State 0x4a6c visited 1 times
State 0x3c24 visited 4 times
State 0x47ec visited 1 times
State 0x47f3 visited 1 times
State 0x4834 visited 1 times
State 0x3c25 visited 2 times
State 0x465a visited 1 times
State 0x4a92 visited 1 times
State 0x4a8c visited 1 times
State 0x395d visited 1 times
State 0x39bc visited 1 times
State 0x3b0f visited 1 times
State 0x3c24 visited 1 times
State 0x46e3 visited 1 times
State 0x4705 visited 1 times
State 0x3c25 visited 3 times
State 0x452c visited 1 times
State 0x4580 visited 1 times
State 0x4935 visited 1 times
State 0x3c24 visited 2 times
State 0x43f3 visited 1 times
State 0x4456 visited 1 times
State 0x43a8 visited 1 times
State 0x3c24 visited 3 times
State 0x4832 visited 1 times
State 0x3d51 visited 1 times
State 0x3d5d visited 1 times
State 0x3c24 visited 2 times
State 0x464e visited 1 times
State 0x4ad5 visited 1 times
State 0x482f visited 1 times
State 0x3c25 visited 4 times
State 0x4419 visited 1 times
State 0x43b3 visited 1 times
State 0x499a visited 1 times
State 0x3bbc visited 1 times
State 0x3917 visited 1 times
State 0x2bdb visited 1 times
State 0x3a69 visited 1 times
State 0x371e visited 1 times
State 0x2017 visited 1 times
State 0x3c25 visited 3 times
State 0x46b1 visited 1 times
State 0x4413 visited 1 times
State 0x4ab1 visited 1 times
State 0x3c24 visited 4 times
State 0x4520 visited 1 times
State 0x4ab3 visited 1 times
State 0x4ab3 visited 1 times
State 0x3c2c visited 1 times
State 0x46c3 visited 1 times
State 0x46d9 visited 1 times
State 0x3c25 visited 4 times
State 0x47af visited 1 times
State 0x47ac visited 1 times
State 0x4412 visited 1 times
State 0x3c24 visited 3 times
State 0x43d4 visited 1 times
State 0x46d2 visited 1 times
State 0x1443 visited 1 times
State 0x3c4d visited 1 times
State 0x5289 visited 1 times
State 0x53d5 visited 1 times
State 0x5573 visited 1 times
State 0x3c25 visited 3 times
State 0x4a4b visited 1 times
State 0x4837 visited 1 times
State 0x4592 visited 1 times
State 0x3c25 visited 2 times
State 0x4438 visited 1 times
State 0x4677 visited 1 times
State 0x479e visited 1 times
State 0x3c6d visited 1 times
State 0x399e visited 1 times
State 0x3845 visited 1 times
State 0x3845 visited 1 times
State 0x3c24 visited 2 times
State 0x456b visited 1 times
State 0x43d5 visited 1 times
State 0x3c24 visited 1 times
State 0x469f visited 1 times
State 0x4a52 visited 1 times
State 0x1f0b visited 1 times
State 0x37c9 visited 1 times
State 0x3bc2 visited 1 times
State 0x11cd visited 1 times
State 0x3c24 visited 1 times
State 0x4459 visited 1 times
State 0x4677 visited 1 times
State 0x4524 visited 1 times
State 0x3c24 visited 3 times
State 0x4561 visited 1 times
State 0x482c visited 1 times
State 0x4858 visited 1 times
State 0x3c61 visited 1 times
State 0x1d51 visited 1 times
State 0x231d visited 1 times
State 0x21ca visited 1 times
State 0x3c24 visited 3 times
State 0x4956 visited 1 times
State 0x4412 visited 1 times
State 0x480a visited 1 times
State 0x3c25 visited 2 times
State 0x44f9 visited 1 times
State 0x4678 visited 1 times
State 0x469a visited 1 times
State 0x3c24 visited 1 times
State 0x4aed visited 1 times
State 0x466d visited 1 times
State 0x43c7 visited 1 times
State 0x3c25 visited 3 times
State 0x43b4 visited 1 times
State 0x443d visited 1 times
State 0x442e visited 1 times
State 0x3d36 visited 1 times
State 0x3c07 visited 1 times
State 0x391c visited 1 times
State 0x3975 visited 1 times
State 0x3670 visited 1 times
State 0x3c24 visited 3 times
State 0x482b visited 1 times
State 0x47eb visited 1 times
State 0x47e4 visited 1 times
State 0x3c25 visited 1 times
State 0x4ad6 visited 1 times
State 0x47cb visited 1 times
State 0x4671 visited 1 times
State 0x3c25 visited 4 times
State 0x466e visited 1 times
State 0x4546 visited 1 times
State 0x4698 visited 1 times
State 0x3c24 visited 2 times
State 0x4923 visited 1 times
State 0x4935 visited 1 times
State 0x453d visited 1 times
State 0x3c4c visited 1 times
State 0x3ab6 visited 1 times
State 0x3974 visited 1 times
State 0x46d2 visited 1 times
State 0x3c24 visited 2 times
State 0x4ab3 visited 1 times
State 0x43f6 visited 1 times
State 0x4942 visited 1 times
State 0x4903 visited 1 times
State 0x57f7 visited 1 times
State 0x550e visited 1 times
State 0x3c5f visited 1 times
State 0x4580 visited 1 times
State 0x39b9 visited 1 times
State 0x3c25 visited 3 times
State 0x4584 visited 1 times
State 0x482a visited 1 times
State 0x4570 visited 1 times
State 0x3c25 visited 1 times
State 0x4afb visited 1 times
State 0x495a visited 1 times
State 0x2184 visited 1 times
State 0x3d99 visited 1 times
State 0x3c24 visited 2 times
State 0x43f3 visited 1 times
State 0x45a1 visited 1 times
State 0x4847 visited 1 times
State 0x3c25 visited 3 times
State 0x4aee visited 1 times
State 0x45a9 visited 1 times
State 0x484f visited 1 times
State 0x3c6b visited 1 times
State 0x20a0 visited 1 times
State 0x2096 visited 1 times
State 0x3c4d visited 1 times
State 0x541f visited 1 times
State 0x5136 visited 1 times
State 0x5136 visited 1 times
State 0x3c40 visited 2 times
State 0x29b9 visited 1 times
State 0x2977 visited 1 times
State 0x10b1 visited 1 times
State 0x3c24 visited 3 times
State 0x4430 visited 1 times
State 0x46be visited 1 times
State 0x46b7 visited 1 times
State 0x3c25 visited 2 times
State 0x4815 visited 1 times
State 0x4add visited 1 times
State 0x4ab1 visited 1 times
State 0x4524 visited 1 times
State 0x47c0 visited 1 times
State 0x39a1 visited 1 times
State 0x3c1a visited 1 times
State 0x397b visited 1 times
State 0x39bf visited 1 times
State 0x3da1 visited 1 times
State 0x118e visited 1 times
State 0x3c24 visited 2 times
State 0x453c visited 1 times
State 0x454a visited 1 times
State 0x454b visited 1 times
State 0x3c25 visited 2 times
State 0x4540 visited 1 times
State 0x47a1 visited 1 times
State 0x467e visited 1 times
State 0x1c1d visited 1 times
State 0x1c61 visited 1 times
State 0x1fe9 visited 1 times
State 0x3c6c visited 1 times
State 0x3975 visited 1 times
State 0x4957 visited 1 times
State 0x4804 visited 1 times
State 0x3c24 visited 3 times
State 0x47ca visited 1 times
State 0x482f visited 1 times
State 0x4830 visited 1 times
State 0x3c0a visited 1 times
State 0x3be0 visited 1 times
State 0x3bdd visited 1 times
State 0x3bde visited 1 times
State 0x3af6 visited 1 times
State 0x3d4b visited 1 times
State 0x36cf visited 1 times
State 0x3c24 visited 1 times
State 0x53ce visited 1 times
State 0x5524 visited 1 times
State 0x5103 visited 1 times
State 0x3c24 visited 4 times
State 0x46f4 visited 1 times
State 0x464e visited 1 times
State 0x464e visited 1 times
State 0x3c65 visited 1 times
State 0x3917 visited 1 times
State 0x3917 visited 1 times
State 0x3c25 visited 5 times
State 0x43d9 visited 1 times
State 0x45a2 visited 1 times
State 0x4aaa visited 1 times
State 0x3bdb visited 1 times
State 0x3871 visited 1 times
State 0x3d78 visited 1 times
State 0x5812 visited 1 times
State 0x3c24 visited 2 times
State 0x47a1 visited 1 times
State 0x4811 visited 1 times
State 0x47a1 visited 1 times
State 0x3c25 visited 3 times
State 0x4653 visited 1 times
State 0x4588 visited 1 times
State 0x4588 visited 1 times
State 0x3c25 visited 2 times
State 0x4935 visited 1 times
State 0x4939 visited 1 times
State 0x3c25 visited 3 times
State 0x4693 visited 1 times
State 0x4656 visited 1 times
State 0x4656 visited 1 times
State 0x3bfe visited 1 times
State 0x3701 visited 1 times
State 0x54ea visited 1 times
State 0x563d visited 1 times
State 0x3c24 visited 2 times
State 0x469c visited 1 times
State 0x1c34 visited 1 times
State 0x1d43 visited 1 times
State 0x3c1e visited 1 times
State 0x3c40 visited 1 times
State 0x53ad visited 1 times
State 0x5413 visited 1 times
State 0x3c27 visited 1 times
State 0x3c27 visited 1 times
State 0x3d7a visited 1 times
State 0x3c25 visited 5 times
State 0x484c visited 1 times
State 0x47a9 visited 1 times
State 0x47ac visited 1 times
State 0x3c1a visited 1 times
State 0x3d8f visited 1 times
State 0x368b visited 1 times
State 0x366c visited 1 times
State 0x368e visited 1 times
State 0x371a visited 1 times
State 0x3bc1 visited 1 times
State 0x3d7a visited 1 times
State 0x2c67 visited 1 times
State 0x2c5e visited 1 times
State 0x39bd visited 1 times
State 0x4584 visited 1 times
State 0x46d7 visited 1 times
State 0x3c25 visited 1 times
State 0x47c4 visited 1 times
State 0x4852 visited 1 times
State 0x4852 visited 1 times
State 0x3c25 visited 4 times
State 0x47cb visited 1 times
State 0x4658 visited 1 times
State 0x3720 visited 1 times
State 0x3d55 visited 1 times
State 0x3af4 visited 1 times
State 0x5287 visited 1 times
State 0x567f visited 1 times
State 0x3c24 visited 2 times
State 0x442d visited 1 times
State 0x4509 visited 1 times
State 0x47af visited 1 times
State 0x3c25 visited 4 times
State 0x4837 visited 1 times
State 0x45a9 visited 1 times
State 0x456b visited 1 times
State 0x3c24 visited 1 times
State 0x47f2 visited 1 times
State 0x45a5 visited 1 times
State 0x4ad6 visited 1 times
State 0x57ce visited 1 times
State 0x5245 visited 1 times
State 0x56d6 visited 1 times
State 0x3c25 visited 1 times
State 0x47c4 visited 1 times
State 0x3c24 visited 2 times
State 0x4a91 visited 1 times
State 0x4589 visited 1 times
State 0x457f visited 1 times
State 0x3c02 visited 1 times
State 0x3b18 visited 1 times
State 0x3c6b visited 1 times
State 0x563a visited 1 times
State 0x3915 visited 1 times
State 0x3a68 visited 1 times
State 0x36f7 visited 1 times
State 0x3bb6 visited 1 times
State 0x371b visited 1 times
State 0x1f48 visited 1 times
State 0x1c40 visited 1 times
State 0x3bbf visited 2 times
State 0x3bbf visited 1 times
State 0x3bbf visited 1 times
State 0x3c4e visited 1 times
State 0x29a5 visited 1 times
State 0x29a4 visited 1 times
State 0x3c24 visited 1 times
State 0x469f visited 1 times
State 0x4aed visited 1 times
State 0x4ab9 visited 1 times
State 0x3c25 visited 1 times
State 0x46da visited 1 times
State 0x4808 visited 1 times
State 0x495b visited 1 times
State 0x3c25 visited 3 times
State 0x454e visited 1 times
State 0x2d69 visited 1 times
State 0x300f visited 1 times
State 0x3c02 visited 1 times
State 0x36fb visited 1 times
State 0x4568 visited 1 times
State 0x4567 visited 1 times
State 0x3d70 visited 1 times
State 0x22b4 visited 1 times
State 0x5260 visited 1 times
State 0x3aa7 visited 1 times
State 0x15fd visited 1 times
State 0x11ab visited 1 times
State 0x3c24 visited 3 times
State 0x45a5 visited 1 times
State 0x4702 visited 1 times
State 0x4a98 visited 1 times
State 0x36ac visited 1 times
State 0x3986 visited 1 times
State 0x393a visited 1 times
State 0x3c47 visited 1 times
State 0x56d7 visited 1 times
State 0x5242 visited 1 times
State 0x107b visited 1 times
State 0x3c24 visited 1 times
State 0x4854 visited 1 times
State 0x46e3 visited 1 times
State 0x46e3 visited 1 times
State 0x3bb6 visited 1 times
State 0x3d08 visited 1 times
State 0x3d56 visited 1 times
State 0x3982 visited 1 times
State 0x3978 visited 1 times
State 0x3982 visited 1 times
State 0x3c25 visited 3 times
State 0x46d3 visited 1 times
State 0x44f9 visited 1 times
State 0x4a44 visited 1 times
State 0x3bf9 visited 1 times
State 0x3aed visited 1 times
State 0xedaf visited 1 times
State 0x3bb8 visited 1 times
State 0x1470 visited 1 times
State 0x22bb visited 1 times
State 0x2346 visited 1 times
State 0x3bbe visited 1 times
State 0x5789 visited 1 times
State 0x5637 visited 1 times
State 0x391d visited 1 times
State 0x1f2c visited 1 times
State 0x2d99 visited 1 times
State 0x3c25 visited 1 times
State 0x47a2 visited 1 times
State 0x4a88 visited 1 times
State 0x4a8c visited 1 times
State 0x3c3f visited 1 times
State 0x440e visited 1 times
State 0x4415 visited 1 times
State 0x4a88 visited 1 times
State 0x3d96 visited 1 times
State 0x3db8 visited 1 times
State 0x3dbf visited 1 times
State 0xee0b visited 1 times
State 0xedaf visited 1 times
State 0xf1eb visited 1 times
State 0x3c24 visited 2 times
State 0x440b visited 1 times
State 0x4a8b visited 1 times
State 0x4ab7 visited 1 times
State 0x39bc visited 1 times
State 0x39a1 visited 1 times
State 0x391d visited 1 times
State 0x3be2 visited 1 times
State 0x3bb9 visited 1 times
State 0x3c1b visited 1 times
State 0x1c62 visited 1 times
State 0x3bb8 visited 1 times
State 0x3bbb visited 1 times
State 0x393b visited 1 times
State 0x3673 visited 1 times
State 0xf227 visited 1 times
State 0x131a visited 1 times
State 0x3c24 visited 4 times
State 0x467c visited 1 times
State 0x4655 visited 1 times
State 0x4655 visited 1 times
State 0x3975 visited 1 times
State 0x391d visited 1 times
State 0x3a70 visited 1 times
State 0x3c24 visited 2 times
State 0x4a91 visited 1 times
State 0x21c4 visited 1 times
State 0x47c0 visited 1 times
State 0x3bd9 visited 1 times
State 0x3d0d visited 1 times
State 0x3806 visited 1 times
State 0x3806 visited 1 times
State 0x3bfc visited 1 times
State 0x3807 visited 1 times
State 0x3aad visited 1 times
State 0x3c24 visited 2 times
State 0x4549 visited 1 times
State 0x454a visited 1 times
State 0x49a8 visited 1 times
State 0x3c24 visited 5 times
State 0x148e visited 1 times
State 0x57c9 visited 1 times
State 0x22fb visited 1 times
State 0x3da1 visited 1 times
State 0x3be7 visited 1 times
State 0x3be7 visited 1 times
State 0x3af6 visited 1 times
State 0x3d6d visited 1 times
State 0x213c visited 1 times
State 0x3c69 visited 1 times
State 0x3bb9 visited 1 times
State 0x11cb visited 1 times
State 0x4678 visited 1 times
State 0x3c24 visited 2 times
State 0x4afa visited 1 times
State 0x4ad9 visited 1 times
State 0x53dc visited 1 times
State 0x3c25 visited 5 times
State 0x48fc visited 1 times
State 0x4566 visited 1 times
State 0x4ab1 visited 1 times
State 0x3c24 visited 1 times
State 0x46fe visited 1 times
State 0x47f2 visited 1 times
State 0x454c visited 1 times
State 0x3bd7 visited 1 times
State 0x36f4 visited 1 times
State 0x3677 visited 1 times
State 0x37eb visited 1 times
State 0x3c24 visited 2 times
State 0x45ab visited 1 times
State 0x4ad1 visited 1 times
State 0x1df4 visited 1 times
State 0x3be8 visited 1 times
State 0x3bd7 visited 1 times
State 0x3d2a visited 1 times
State 0x3c25 visited 1 times
State 0x49a2 visited 1 times
State 0x443c visited 1 times
State 0x1300 visited 1 times
State 0x3b16 visited 1 times
State 0x1d56 visited 1 times
State 0x1d55 visited 1 times
State 0x3c24 visited 6 times
State 0x4960 visited 1 times
State 0x465c visited 1 times
State 0x465c visited 1 times
State 0x3d37 visited 1 times
State 0x29c3 visited 1 times
State 0x2c68 visited 1 times
State 0x1f4b visited 1 times
State 0x458b visited 1 times
State 0x4581 visited 1 times
State 0x3d90 visited 1 times
State 0x1dee visited 1 times
State 0x2094 visited 1 times
State 0x3c24 visited 2 times
State 0x46e0 visited 1 times
State 0x2ee1 visited 1 times
State 0x2ee1 visited 1 times
State 0x3d4b visited 1 times
State 0x2b29 visited 1 times
State 0x2b34 visited 1 times
State 0x3c24 visited 2 times
State 0x47ab visited 1 times
State 0x47af visited 1 times
State 0x4902 visited 1 times
State 0x3c46 visited 1 times
State 0x3be0 visited 1 times
State 0x3825 visited 1 times
State 0x3c68 visited 1 times
State 0x3bda visited 1 times
State 0x386d visited 1 times
State 0x2c62 visited 1 times
State 0x1212 visited 1 times
State 0x3719 visited 1 times
State 0x3db8 visited 1 times
State 0x3ab0 visited 1 times
State 0x3d7f visited 1 times
State 0x3913 visited 1 times
State 0x5129 visited 1 times
State 0x3c0a visited 1 times
State 0x3c27 visited 1 times
State 0x382f visited 1 times
State 0x3874 visited 1 times
State 0x3c21 visited 1 times
State 0x397b visited 1 times
State 0x120a visited 1 times
State 0x3c6f visited 1 times
State 0x3c67 visited 1 times
State 0x3be0 visited 1 times
State 0x3c25 visited 1 times
State 0x3c24 visited 1 times
State 0x4506 visited 1 times
State 0x4a76 visited 1 times
State 0x47d1 visited 1 times
State 0x3c25 visited 2 times
State 0x48f8 visited 1 times
State 0x499a visited 1 times
State 0x46bb visited 1 times
State 0x3c24 visited 2 times
State 0x4705 visited 1 times
State 0x4527 visited 1 times
State 0x4527 visited 1 times
State 0x3c3b visited 1 times
State 0x46d2 visited 1 times
State 0x46d2 visited 1 times
State 0x3c1b visited 1 times
State 0x1d45 visited 1 times
State 0x2038 visited 1 times
State 0x3c24 visited 1 times
State 0x4a72 visited 1 times
State 0x4a94 visited 1 times
State 0x37ca visited 1 times
State 0x3a70 visited 1 times
State 0x2c8a visited 1 times
State 0x3c4d visited 1 times
State 0x1f51 visited 1 times
State 0x1f07 visited 1 times
State 0x1efd visited 1 times
State 0x3d78 visited 1 times
State 0x578a visited 1 times
State 0x57ce visited 1 times
State 0x3c25 visited 1 times
State 0x464f visited 1 times
State 0x48f5 visited 1 times
State 0x44fd visited 1 times
State 0x36d8 visited 1 times
State 0x15eb visited 1 times
State 0x56c4 visited 1 times
State 0x3bc6 visited 1 times
State 0x3bc6 visited 1 times
State 0x3c06 visited 1 times
State 0x3673 visited 1 times
State 0x3d4f visited 1 times
State 0x3d15 visited 1 times
State 0x3821 visited 1 times
State 0x4912 visited 1 times
State 0x4915 visited 1 times
State 0x3c24 visited 3 times
State 0x4506 visited 1 times
State 0x45af visited 1 times
State 0x4afa visited 1 times
State 0x3c25 visited 2 times
State 0x4431 visited 1 times
State 0x4a4b visited 1 times
State 0x4a4f visited 1 times
State 0x36da visited 1 times
State 0x11c1 visited 1 times
State 0x2dae visited 1 times
State 0x3829 visited 1 times
State 0x3d74 visited 1 times
State 0x2d2c visited 1 times
State 0x3bc0 visited 1 times
State 0x39a5 visited 1 times
State 0x37bd visited 1 times
State 0x3910 visited 1 times
State 0x3c24 visited 2 times
State 0x46f4 visited 1 times
State 0x4ab3 visited 1 times
State 0x4ab4 visited 1 times
State 0x3c24 visited 3 times
State 0x4967 visited 1 times
State 0x469f visited 1 times
State 0x469f visited 1 times
State 0x382d visited 1 times
State 0x2293 visited 1 times
State 0x2bf9 visited 1 times
State 0x3c1a visited 1 times
State 0x3bb9 visited 1 times
State 0x2d6e visited 1 times
State 0x3bb8 visited 1 times
State 0x37de visited 1 times
State 0x3bbf visited 1 times
State 0x3c1e visited 1 times
State 0x3825 visited 1 times
State 0x440f visited 1 times
State 0x43c7 visited 1 times
State 0x3bbc visited 1 times
State 0x3c61 visited 1 times
State 0x39bc visited 1 times
State 0x3c25 visited 1 times
State 0x495e visited 1 times
State 0x4852 visited 1 times
State 0x57a6 visited 1 times
State 0x3c4d visited 1 times
State 0x1f51 visited 1 times
State 0x22d3 visited 1 times
State 0x2346 visited 1 times
State 0x5434 visited 1 times
State 0x5431 visited 1 times
State 0x3c5d visited 1 times
State 0x3865 visited 1 times
State 0x380e visited 1 times
State 0x37ed visited 1 times
State 0x5570 visited 1 times
State 0x52df visited 1 times
State 0x5675 visited 1 times
State 0x567c visited 1 times
State 0x56de visited 1 times
State 0x36d8 visited 1 times
State 0x15eb visited 1 times
State 0x1587 visited 1 times
State 0x3d5d visited 1 times
State 0x39a5 visited 1 times
State 0x3932 visited 1 times
State 0x36b8 visited 1 times
State 0x3c24 visited 2 times
State 0x49ab visited 1 times
State 0x43d5 visited 1 times
State 0x39b9 visited 1 times
State 0x3b0c visited 1 times
State 0x3823 visited 1 times
State 0x399a visited 1 times
State 0x1d47 visited 1 times
State 0x1c57 visited 1 times
State 0x3c03 visited 1 times
State 0x3c40 visited 1 times
State 0x484c visited 1 times
State 0x4aae visited 1 times
State 0x3bc7 visited 1 times
State 0x3871 visited 1 times
State 0x3844 visited 1 times
State 0x3942 visited 1 times
State 0x3c1b visited 1 times
State 0x3873 visited 1 times
State 0x39c6 visited 1 times
State 0x37c7 visited 1 times
State 0x3c24 visited 1 times
State 0x4afa visited 1 times
State 0x43c7 visited 1 times
State 0x4565 visited 1 times
State 0x3d4f visited 1 times
State 0x3d59 visited 1 times
State 0x36bb visited 1 times
State 0x3bc3 visited 1 times
State 0x3d7c visited 1 times
State 0x565d visited 1 times
State 0x5661 visited 1 times
State 0x3c24 visited 1 times
State 0x4804 visited 1 times
State 0x5693 visited 1 times
State 0x3871 visited 1 times
State 0x3874 visited 1 times
State 0x3874 visited 1 times
State 0x3c24 visited 1 times
State 0x47cd visited 1 times
State 0x479e visited 1 times
State 0x300f visited 1 times
State 0x3d78 visited 1 times
State 0x10c0 visited 1 times
State 0x109a visited 1 times
State 0x3d29 visited 1 times
State 0x3930 visited 1 times
State 0x3974 visited 1 times
State 0x3980 visited 1 times
State 0x2932 visited 1 times
State 0x29db visited 1 times
State 0x3c25 visited 4 times
State 0x47c4 visited 1 times
State 0x4943 visited 1 times
State 0x4859 visited 1 times
State 0x3c25 visited 1 times
State 0x46b2 visited 1 times
State 0x46c2 visited 1 times
State 0x46f8 visited 1 times
State 0x3bc7 visited 1 times
State 0x3d19 visited 1 times
State 0x3ab7 visited 1 times
State 0x3964 visited 1 times
State 0x3957 visited 1 times
State 0x3957 visited 1 times
State 0x3c44 visited 1 times
State 0x15e2 visited 1 times
State 0x1f48 visited 1 times
State 0x1df5 visited 1 times
State 0x3c21 visited 1 times
State 0x36d6 visited 1 times
State 0x3721 visited 1 times
State 0x3c43 visited 1 times
State 0x3806 visited 1 times
State 0x37bc visited 1 times
State 0x3812 visited 1 times
State 0x3852 visited 1 times
State 0x3826 visited 1 times
State 0x3bff visited 1 times
State 0x3870 visited 1 times
State 0x3c62 visited 1 times
State 0x3c62 visited 1 times
State 0x3d77 visited 1 times
State 0x529d visited 1 times
State 0x5543 visited 1 times
State 0x3d0e visited 1 times
State 0x3996 visited 1 times
State 0x453c visited 1 times
State 0x397f visited 1 times
State 0x2aaf visited 1 times
State 0x2aa2 visited 1 times
State 0x3bc3 visited 1 times
State 0x1d96 visited 1 times
State 0x14b0 visited 1 times
State 0x37c0 visited 1 times
State 0x2293 visited 1 times
State 0x484b visited 1 times
State 0x3c69 visited 1 times
State 0x3c06 visited 1 times
State 0x3961 visited 1 times
State 0x3c3c visited 1 times
State 0x15da visited 1 times
State 0x15e1 visited 1 times
State 0x3c6b visited 1 times
State 0x3db4 visited 1 times
State 0x564e visited 1 times
State 0x3c24 visited 2 times
State 0x491f visited 1 times
State 0x1447 visited 1 times
State 0x4a68 visited 1 times
State 0x47cd visited 1 times
State 0x4811 visited 1 times
State 0x43d5 visited 1 times
State 0x3c1d visited 1 times
State 0x3977 visited 1 times
State 0x15bb visited 1 times
State 0x1471 visited 1 times
State 0x3dbc visited 1 times
State 0x3d59 visited 1 times
State 0x3c27 visited 1 times
State 0x393e visited 1 times
State 0x397e visited 1 times
State 0x2981 visited 1 times
State 0x393f visited 1 times
State 0x393c visited 1 times
State 0x36d3 visited 1 times
State 0x3975 visited 1 times
State 0x4a44 visited 1 times
State 0x479f visited 1 times
State 0x3bc5 visited 1 times
State 0x3bbc visited 1 times
State 0x3c6b visited 1 times
State 0x3c6c visited 1 times
State 0x2a8b visited 1 times
State 0x2a84 visited 1 times
State 0x2d2a visited 1 times
State 0x3c24 visited 1 times
State 0x484e visited 1 times
State 0x1c19 visited 1 times
State 0x3d90 visited 1 times
State 0x466e visited 1 times
State 0x1554 visited 1 times
State 0x3c24 visited 2 times
State 0x43af visited 1 times
State 0x43b0 visited 1 times
State 0x4434 visited 1 times
State 0x3c25 visited 1 times
State 0x4416 visited 1 times
State 0x441a visited 1 times
State 0x3c25 visited 2 times
State 0x48f2 visited 1 times
State 0x45a6 visited 1 times
State 0x4565 visited 1 times
State 0x3bff visited 1 times
State 0x3c28 visited 1 times
State 0x3be4 visited 1 times
State 0x36e1 visited 1 times
State 0x36da visited 1 times
State 0x1321 visited 1 times
State 0x3c25 visited 1 times
State 0x5573 visited 1 times
State 0x57d5 visited 1 times
State 0x3c4d visited 1 times
State 0x5572 visited 1 times
State 0x36fb visited 1 times
State 0x3832 visited 1 times
State 0x3985 visited 1 times
State 0x519c visited 1 times
State 0x3c5d visited 1 times
State 0x3865 visited 1 times
State 0x37c3 visited 1 times
State 0x386c visited 1 times
State 0x3af0 visited 1 times
State 0x399d visited 1 times
State 0x3c22 visited 1 times
State 0x3be0 visited 1 times
State 0x3bdd visited 1 times
State 0x382c visited 1 times
State 0x2180 visited 1 times
State 0x22d3 visited 1 times
State 0x3c24 visited 3 times
State 0x453c visited 1 times
State 0x43ce visited 1 times
State 0x48f7 visited 1 times
State 0x3833 visited 1 times
State 0x519c visited 1 times
State 0x14ad visited 1 times
State 0x3c5f visited 1 times
State 0x3953 visited 1 times
State 0x3bf9 visited 1 times
State 0x3c24 visited 2 times
State 0x444e visited 1 times
State 0x45b2 visited 1 times
State 0x4705 visited 1 times
State 0x3bd6 visited 1 times
State 0x5277 visited 1 times
State 0x540e visited 1 times
State 0x3bc2 visited 1 times
State 0x3964 visited 1 times
State 0x1dff visited 1 times
State 0x201d visited 1 times
State 0x3c25 visited 2 times
State 0x4957 visited 1 times
State 0x2b09 visited 1 times
State 0xf3de visited 1 times
State 0x3c61 visited 1 times
State 0x3bb8 visited 1 times
State 0x3c29 visited 1 times
State 0x3bd6 visited 1 times
State 0x3d29 visited 1 times
State 0x3d3a visited 1 times
State 0x3910 visited 1 times
State 0x3979 visited 1 times
State 0x3979 visited 1 times
State 0x3c22 visited 1 times
State 0x3c20 visited 1 times
State 0x37ee visited 1 times
State 0x3be7 visited 1 times
State 0x3854 visited 1 times
State 0x43d8 visited 1 times
State 0x47ae visited 1 times
State 0x3c65 visited 1 times
State 0x3c24 visited 1 times
State 0x48fb visited 1 times
State 0x48f4 visited 1 times
State 0x3c24 visited 2 times
State 0x4a46 visited 1 times
State 0x48f7 visited 1 times
State 0x48f7 visited 1 times
State 0x3be0 visited 1 times
State 0x3a72 visited 1 times
State 0x37bf visited 1 times
State 0x3677 visited 1 times
State 0x37ca visited 1 times
State 0x36dd visited 1 times
State 0x523c visited 1 times
State 0x3d77 visited 1 times
State 0x3c1a visited 1 times
State 0x1c9a visited 1 times
State 0x3c25 visited 1 times
State 0x45a2 visited 1 times
State 0x45a9 visited 1 times
State 0x49a2 visited 1 times
State 0x3c24 visited 2 times
State 0x47a5 visited 1 times
State 0x443b visited 1 times
State 0xf43b visited 1 times
State 0x3c24 visited 3 times
State 0x48f4 visited 1 times
State 0x2f00 visited 1 times
State 0x4aa9 visited 1 times
State 0x3bbc visited 1 times
State 0x3845 visited 1 times
State 0x2950 visited 1 times
State 0x3d77 visited 1 times
State 0x567d visited 1 times
State 0x5103 visited 1 times
State 0x3c3c visited 1 times
State 0x2180 visited 1 times
State 0x1ec9 visited 1 times
State 0x216f visited 1 times
State 0x3c0a visited 1 times
State 0x37e9 visited 1 times
State 0x37df visited 1 times
State 0x37dd visited 1 times
State 0x36f4 visited 1 times
State 0xefc2 visited 1 times
State 0xefc3 visited 1 times
State 0x3c2b visited 1 times
State 0x3bd6 visited 1 times
State 0x37de visited 1 times
State 0x3c27 visited 1 times
State 0x390f visited 1 times
State 0x5430 visited 1 times
State 0x3bbc visited 1 times
State 0x3671 visited 1 times
State 0x3c66 visited 1 times
State 0x397e visited 1 times
State 0x301f visited 1 times
State 0x3017 visited 1 times
State 0x3d77 visited 1 times
State 0x567a visited 1 times
State 0x567a visited 1 times
State 0x3c40 visited 1 times
State 0x12d3 visited 1 times
State 0x484b visited 1 times
State 0x3be0 visited 1 times
State 0x3a8d visited 1 times
State 0x3aec visited 1 times
State 0x3c69 visited 1 times
State 0x3702 visited 1 times
State 0x3064 visited 1 times
State 0x3c1a visited 1 times
State 0x3c5e visited 1 times
State 0x3c64 visited 1 times
State 0x3977 visited 1 times
State 0x3999 visited 1 times
State 0x3d0a visited 1 times
State 0x3c06 visited 1 times
State 0x37c7 visited 1 times
State 0x37c7 visited 1 times
State 0x3674 visited 1 times
State 0x3c24 visited 3 times
State 0x47c6 visited 1 times
State 0x47c6 visited 1 times
State 0x49a4 visited 1 times
State 0x3c28 visited 1 times
State 0x3c4c visited 1 times
State 0x57b2 visited 1 times
State 0x3c07 visited 1 times
State 0x391c visited 1 times
State 0x36d9 visited 1 times
State 0x11a1 visited 1 times
State 0x3d78 visited 1 times
State 0x563f visited 1 times
State 0x56a4 visited 1 times
State 0x3c47 visited 1 times
State 0x48fb visited 1 times
State 0x493e visited 1 times
State 0x12df visited 1 times
State 0x1343 visited 1 times
State 0x133f visited 1 times
State 0x4547 visited 1 times
State 0x213d visited 1 times
State 0x2181 visited 1 times
State 0x3c24 visited 1 times
State 0x452b visited 1 times
State 0x43cb visited 1 times
State 0xee48 visited 1 times
State 0x43f6 visited 1 times
State 0x43f6 visited 1 times
State 0x3c25 visited 1 times
State 0x4af5 visited 1 times
State 0x4412 visited 1 times
State 0x43b1 visited 1 times
State 0x1ff4 visited 1 times
State 0x1ff4 visited 1 times
State 0x1f0a visited 1 times
State 0x231e visited 1 times
State 0x231e visited 1 times
State 0x2079 visited 1 times
State 0x3c24 visited 2 times
State 0x455e visited 1 times
State 0x4901 visited 1 times
State 0x443e visited 1 times
State 0x3c21 visited 1 times
State 0x3d8f visited 1 times
State 0x551d visited 1 times
State 0x36d8 visited 1 times
State 0x11cd visited 1 times
State 0x2c89 visited 1 times
State 0x3c2c visited 1 times
State 0x3c5e visited 1 times
State 0x3c5f visited 1 times
State 0x3c24 visited 1 times
State 0x4836 visited 1 times
State 0x493e visited 1 times
State 0x4a91 visited 1 times
State 0x3c24 visited 1 times
State 0x455e visited 1 times
State 0x47f3 visited 1 times
State 0x4a73 visited 1 times
State 0x4673 visited 1 times
State 0x3db7 visited 1 times
State 0x3c1f visited 1 times
State 0x37f0 visited 1 times
State 0x3a92 visited 1 times
State 0x2dde visited 1 times
State 0x3c25 visited 1 times
State 0x47b0 visited 1 times
State 0x491d visited 1 times
State 0x4920 visited 1 times
State 0x3956 visited 1 times
State 0x1335 visited 1 times
State 0x564e visited 1 times
State 0x3bc2 visited 1 times
State 0x3869 visited 1 times
State 0x1317 visited 1 times
State 0x43ed visited 1 times
State 0x3ae9 visited 1 times
State 0x12cf visited 1 times
State 0x12d0 visited 1 times
State 0x3c1e visited 1 times
State 0x3979 visited 1 times
State 0x100c visited 1 times
State 0x3c25 visited 1 times
State 0x4ab4 visited 1 times
State 0x4925 visited 1 times
State 0x4a77 visited 1 times
State 0x3c25 visited 1 times
State 0x46c2 visited 1 times
State 0x4815 visited 1 times
State 0x4968 visited 1 times
State 0x3c25 visited 1 times
State 0x493c visited 1 times
State 0x43ea visited 1 times
State 0x453d visited 1 times
State 0x386f visited 1 times
State 0x386f visited 1 times
State 0x36bd visited 1 times
State 0x3c24 visited 1 times
State 0x493e visited 1 times
State 0x49aa visited 1 times
State 0x48f7 visited 1 times
State 0x3bbc visited 1 times
State 0x3d74 visited 1 times
State 0x397c visited 1 times
State 0x3953 visited 1 times
State 0x3ab7 visited 1 times
State 0x1216 visited 1 times
State 0x1074 visited 1 times
State 0x37bc visited 1 times
State 0x3a65 visited 1 times
State 0x3a83 visited 1 times
State 0x367a visited 1 times
State 0x366d visited 1 times
State 0x3692 visited 1 times
State 0x3c29 visited 1 times
State 0x3c62 visited 1 times
State 0x386a visited 1 times
State 0x3d4c visited 1 times
State 0x48f2 visited 1 times
State 0x4a44 visited 1 times
State 0x3c24 visited 1 times
State 0x4ad8 visited 1 times
State 0x5267 visited 1 times
State 0x3c64 visited 1 times
State 0x39bf visited 1 times
State 0x3aa7 visited 1 times
State 0x3ab6 visited 1 times
State 0x3d5c visited 1 times
State 0x3c1e visited 1 times
State 0x3d71 visited 1 times
State 0x4808 visited 1 times
State 0x3c02 visited 1 times
State 0x3c46 visited 1 times
State 0x1dd5 visited 1 times
State 0x1c82 visited 1 times
State 0x368f visited 1 times
State 0x3d2d visited 1 times
State 0x39bf visited 1 times
State 0x3bfc visited 1 times
State 0x3919 visited 1 times
State 0x3919 visited 1 times
State 0x3919 visited 1 times
State 0x3670 visited 1 times
State 0x390f visited 1 times
State 0x39a8 visited 1 times
State 0x36da visited 1 times
State 0x14ab visited 1 times
State 0x4aaa visited 1 times
State 0x3bde visited 1 times
State 0x3c5f visited 1 times
State 0x3b0c visited 1 times
State 0x3c68 visited 1 times
State 0x3847 visited 1 times
State 0x3c09 visited 1 times
State 0x50f2 visited 1 times
State 0x458d visited 1 times
State 0x1dbb visited 1 times
State 0x107f visited 1 times
State 0x3bff visited 1 times
State 0x3c64 visited 1 times
State 0x386c visited 1 times
State 0x1bfb visited 1 times
State 0x3af6 visited 1 times
State 0x390f visited 1 times
State 0x1007 visited 1 times
State 0x3d76 visited 1 times
State 0x567a visited 1 times
State 0x5176 visited 1 times
State 0x10b1 visited 1 times
State 0x1203 visited 1 times
State 0x1204 visited 1 times
State 0x3afa visited 1 times
State 0x2ffe visited 1 times
State 0x2fee visited 1 times
State 0x3c5e visited 1 times
State 0x3c2b visited 1 times
State 0x3aa6 visited 1 times
State 0x3c5e visited 1 times
State 0x36d6 visited 1 times
State 0x3bff visited 1 times
State 0x3bde visited 1 times
State 0x3dbb visited 1 times
State 0x380d visited 1 times
State 0x37c7 visited 1 times
State 0x37cd visited 1 times
State 0x3bfb visited 1 times
State 0x3956 visited 1 times
State 0x3bbb visited 1 times
State 0x3c25 visited 1 times
State 0x465a visited 1 times
State 0x46a0 visited 1 times
State 0x3a63 visited 1 times
State 0x2e9b visited 1 times
State 0x2e80 visited 1 times
State 0x3c1d visited 1 times
State 0x3876 visited 1 times
State 0x3872 visited 1 times
State 0x3d2d visited 1 times
State 0x397f visited 1 times
State 0x2bff visited 1 times
State 0x2fd9 visited 1 times
State 0x3bde visited 1 times
State 0x3c06 visited 1 times
State 0x3bc2 visited 1 times
State 0x160a visited 1 times
State 0x36d9 visited 1 times
State 0x12fb visited 1 times
State 0x1ee9 visited 1 times
State 0x36d3 visited 1 times
State 0x36d3 visited 1 times
State 0x3c1e visited 1 times
State 0x3c0a visited 1 times
State 0x366e visited 1 times
State 0x3be1 visited 1 times
State 0x4830 visited 1 times
State 0x397e visited 1 times
State 0x2c3c visited 1 times
State 0x2996 visited 1 times
State 0x569d visited 1 times
State 0x5634 visited 1 times
State 0x3be7 visited 1 times
State 0x3c28 visited 1 times
State 0x3982 visited 1 times
State 0x20a0 visited 1 times
State 0x3bbf visited 1 times
State 0x3c43 visited 1 times
State 0x45a8 visited 1 times
State 0x45a8 visited 1 times
State 0x3c64 visited 1 times
State 0x3bdd visited 1 times
State 0x3d2f visited 1 times
State 0x3d29 visited 1 times
State 0x36d9 visited 1 times
State 0x1319 visited 1 times
State 0x10be visited 1 times
State 0x3bff visited 1 times
State 0x3c00 visited 1 times
State 0x3c03 visited 1 times
State 0x36d8 visited 1 times
State 0x15b8 visited 1 times
State 0x159a visited 1 times
State 0x3c24 visited 2 times
State 0x48fb visited 1 times
State 0x45a8 visited 1 times
State 0x1319 visited 1 times
State 0x36ff visited 1 times
State 0x37ed visited 1 times
State 0x3d38 visited 1 times
State 0x3c27 visited 1 times
State 0x301c visited 1 times
State 0x1c20 visited 1 times
State 0x3952 visited 1 times
State 0x3d4a visited 1 times
State 0x36ac visited 1 times
State 0x3c64 visited 1 times
State 0x3dbb visited 1 times
State 0x3db7 visited 1 times
State 0x3bb6 visited 1 times
State 0x3d34 visited 1 times
State 0x3bff visited 1 times
State 0x1074 visited 1 times
State 0x456b visited 1 times
State 0x455f visited 1 times
State 0x455f visited 1 times
State 0x382c visited 1 times
State 0x21e9 visited 1 times
State 0x21a9 visited 1 times
State 0x3c24 visited 1 times
State 0x43cb visited 1 times
State 0x4ab3 visited 1 times
State 0x4ab7 visited 1 times
State 0x3c24 visited 1 times
State 0x4ad8 visited 1 times
State 0x52ee visited 1 times
State 0x22f8 visited 1 times
State 0x3c42 visited 1 times
State 0x2186 visited 1 times
State 0x22f4 visited 1 times
State 0x1da9 visited 1 times
State 0x3c4c visited 1 times
State 0x5441 visited 1 times
State 0x2d9b visited 1 times
State 0x3c4c visited 1 times
State 0x3c24 visited 1 times
State 0x443d visited 1 times
State 0x1c59 visited 1 times
State 0x1eff visited 1 times
State 0x382c visited 1 times
State 0x2071 visited 1 times
State 0x2078 visited 1 times
State 0x29b9 visited 1 times
State 0x1c5b visited 1 times
State 0x3c09 visited 1 times
State 0x3c6b visited 1 times
State 0x3c1a visited 1 times
State 0x397e visited 1 times
State 0x2d4f visited 1 times
State 0x2af4 visited 1 times
State 0x3c21 visited 1 times
State 0x397b visited 1 times
State 0x3a8a visited 1 times
State 0x3bfe visited 1 times
State 0x3c5d visited 1 times
State 0x495b visited 1 times
State 0x43ee visited 1 times
State 0x1050 visited 1 times
State 0x3c46 visited 1 times
State 0x569c visited 1 times
State 0x5170 visited 1 times
State 0x397c visited 1 times
State 0x1f4b visited 1 times
State 0x1bf5 visited 1 times
State 0x1bf7 visited 1 times
State 0x4852 visited 1 times
State 0x21c8 visited 1 times
State 0x15bd visited 1 times
State 0x3c25 visited 1 times
State 0x495e visited 1 times
State 0x4671 visited 1 times
State 0x4a43 visited 1 times
State 0x3bfc visited 1 times
State 0x3bbc visited 1 times
State 0x3bff visited 1 times
State 0x371d visited 1 times
State 0x3ab7 visited 1 times
State 0x3ab7 visited 1 times
State 0x37e9 visited 1 times
State 0x3c24 visited 1 times
State 0x45b3 visited 1 times
State 0x4afa visited 1 times
State 0x47af visited 1 times
State 0x3724 visited 1 times
State 0x36e0 visited 1 times
State 0x53fe visited 1 times
State 0x3d52 visited 1 times
State 0x3d4e visited 1 times
State 0x3d52 visited 1 times
State 0x3c6f visited 1 times
State 0x3be7 visited 1 times
State 0x3866 visited 1 times
State 0x1597 visited 1 times
State 0x3c6c visited 1 times
State 0x3d51 visited 1 times
State 0x3d3a visited 1 times
State 0x3d14 visited 1 times
State 0x3be0 visited 1 times
State 0x3800 visited 1 times
State 0x390f visited 1 times
State 0x391c visited 1 times
State 0x3c24 visited 1 times
State 0x4a6c visited 1 times
State 0x46d9 visited 1 times
State 0x49ab visited 1 times
State 0x3c61 visited 1 times
State 0x3829 visited 1 times
State 0x3855 visited 1 times
State 0x3c25 visited 3 times
State 0x4829 visited 1 times
State 0x52a5 visited 1 times
State 0x53cc visited 1 times
State 0x3c25 visited 1 times
State 0x43d2 visited 1 times
State 0x442d visited 1 times
State 0x397e visited 1 times
State 0x2bd6 visited 1 times
State 0x294f visited 1 times
State 0x3674 visited 1 times
State 0x3a85 visited 1 times
State 0x3d9a visited 1 times
State 0x3c24 visited 1 times
State 0x456e visited 1 times
State 0x479e visited 1 times
State 0x47ab visited 1 times
State 0x3bbb visited 1 times
State 0x3d0d visited 1 times
State 0x399d visited 1 times
State 0x3bc2 visited 1 times
State 0x37e5 visited 1 times
State 0x371a visited 1 times
State 0x39c7 visited 1 times
State 0x3c25 visited 1 times
State 0x4678 visited 1 times
State 0x4a8f visited 1 times
State 0x469a visited 1 times
State 0x3bda visited 1 times
State 0x3677 visited 1 times
State 0x3699 visited 1 times
State 0x397f visited 1 times
State 0x2fed visited 1 times
State 0x2aa2 visited 1 times
State 0x384b visited 1 times
State 0x5787 visited 1 times
State 0x5634 visited 1 times
State 0x3c24 visited 1 times
State 0x4a69 visited 1 times
State 0x4591 visited 1 times
State 0x3c65 visited 1 times
State 0x3c24 visited 1 times
State 0x4af0 visited 1 times
State 0x3867 visited 1 times
State 0x3867 visited 1 times
State 0x3b0c visited 1 times
State 0x3c24 visited 1 times
State 0x451a visited 1 times
State 0x47f2 visited 1 times
State 0x4411 visited 1 times
State 0x382d visited 1 times
State 0x200f visited 1 times
State 0x3844 visited 1 times
State 0x3ab0 visited 1 times
State 0x47c7 visited 1 times
State 0x47c0 visited 1 times
State 0x3c24 visited 1 times
State 0x452b visited 1 times
State 0x43f1 visited 1 times
State 0x43aa visited 1 times
State 0x3c2c visited 1 times
State 0x3c2c visited 1 times
State 0x1478 visited 1 times
State 0x3c27 visited 1 times
State 0x380d visited 1 times
State 0x11cd visited 1 times
State 0x3bb8 visited 1 times
State 0x3673 visited 1 times
State 0x3677 visited 1 times
State 0x3bf8 visited 1 times
State 0x3c28 visited 1 times
State 0x3a70 visited 1 times
State 0x37ca visited 1 times
State 0x3c3d visited 1 times
State 0x3bb5 visited 1 times
State 0x37bd visited 1 times
State 0x3852 visited 1 times
State 0x3713 visited 1 times
State 0x5540 visited 1 times
State 0x3c24 visited 1 times
State 0x4a43 visited 1 times
State 0x43ac visited 1 times
State 0x48f7 visited 1 times
State 0x3c2c visited 1 times
State 0x3c42 visited 1 times
State 0x100e visited 1 times
State 0x382d visited 1 times
State 0x1dd6 visited 1 times
State 0x510e visited 1 times
State 0x3c1a visited 1 times
State 0x3c3c visited 1 times
State 0x1c35 visited 1 times
State 0x3c61 visited 1 times
State 0x1dee visited 1 times
State 0x1dee visited 1 times
State 0x3be8 visited 1 times
State 0x3c6d visited 1 times
State 0x3c1b visited 1 times
State 0x3c24 visited 1 times
State 0x4412 visited 1 times
State 0x43d4 visited 1 times
State 0x2ee8 visited 1 times
State 0x37e7 visited 1 times
State 0x4524 visited 1 times
State 0x3c27 visited 1 times
State 0x397e visited 1 times
State 0x2ae5 visited 1 times
State 0x3c5e visited 1 times
State 0x369c visited 1 times
State 0x3a95 visited 1 times
State 0x3c24 visited 1 times
State 0x444e visited 1 times
State 0x4a73 visited 1 times
State 0x46f8 visited 1 times
State 0x569d visited 1 times
State 0x2ea5 visited 1 times
State 0x3d78 visited 1 times
State 0x5413 visited 1 times
State 0x5438 visited 1 times
State 0x3c25 visited 1 times
State 0x43ed visited 1 times
State 0x4693 visited 1 times
State 0x4829 visited 1 times
State 0x3c25 visited 1 times
State 0x4921 visited 1 times
State 0x4544 visited 1 times
State 0x3c24 visited 1 times
State 0x44fe visited 1 times
State 0x4a8a visited 1 times
State 0x3955 visited 1 times
State 0x3c47 visited 1 times
State 0x3a8e visited 1 times
State 0x37c6 visited 1 times
State 0x395c visited 1 times
: 16800
Depth 4: State = 0x3997, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3997: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3c6c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 866600, N[0x3c25, ((2, 3), (2, 4))] = 39
Updated Q[0x3c5e, ((0, 3), (1, 3))] = 19600, N[0x3c5e, ((0, 3), (1, 3))] = 1
Updated Q[0x36d3, ((0, 3), (1, 3))] = 19600, N[0x36d3, ((0, 3), (1, 3))] = 1
Updated Q[0x3674, ((1, 3), (2, 3))] = 19600, N[0x3674, ((1, 3), (2, 3))] = 1
Updated Q[0x3997, ((0, 3), (1, 3))] = 19600, N[0x3997, ((0, 3), (1, 3))] = 1

--- Simulation 44 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.715133924277, 16802.715133924277, 22220.947589895448, 16802.715133924277, 19602.715133924277]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x49a2, Score: 8400
Depth 2: State = 0x49a2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x49a2: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a4f, Score: 11200
Depth 3: State = 0x4a4f, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a4f: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4a52, Score: 14000
Depth 4: State = 0x4a52, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a52: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x47c1, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 883400, N[0x3c25, ((2, 3), (2, 4))] = 40
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x49a2, ((1, 3), (2, 3))] = 16800, N[0x49a2, ((1, 3), (2, 3))] = 1
Updated Q[0x4a4f, ((0, 3), (1, 3))] = 16800, N[0x4a4f, ((0, 3), (1, 3))] = 1
Updated Q[0x4a52, ((0, 1), (1, 1))] = 16800, N[0x4a52, ((0, 1), (1, 1))] = 1

--- Simulation 45 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.7234191162, 16802.7234191162, 22085.43061037152, 16802.7234191162, 19602.7234191162]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c40, Score: 8400
Depth 1: State = 0x3c40, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c40: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x4acf, Score: 11200
Depth 2: State = 0x4acf, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4acf: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x443b, Score: 14000
Depth 3: State = 0x443b, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443b: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0xf65e, Score: 16800
Depth 4: State = 0xf65e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0xf65e: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x11d1, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 903000, N[0x3c25, ((2, 3), (2, 4))] = 41
Updated Q[0x3c40, ((0, 0), (1, 0))] = 19600, N[0x3c40, ((0, 0), (1, 0))] = 1
Updated Q[0x4acf, ((1, 3), (2, 3))] = 19600, N[0x4acf, ((1, 3), (2, 3))] = 1
Updated Q[0x443b, ((0, 0), (0, 1))] = 19600, N[0x443b, ((0, 0), (0, 1))] = 1
Updated Q[0xf65e, ((1, 3), (2, 3))] = 19600, N[0xf65e, ((1, 3), (2, 3))] = 1

--- Simulation 46 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.7314938184, 16802.7314938184, 22024.816831567634, 16802.7314938184, 19602.7314938184]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x491d, Score: 8400
Depth 2: State = 0x491d, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x491d: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x443b, Score: 14000
Depth 3: State = 0x443b, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443b: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x104b, Score: 16800
Depth 4: State = 0x104b, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x104b: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x117c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 922600, N[0x3c25, ((2, 3), (2, 4))] = 42
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x491d, ((1, 3), (2, 3))] = 19600, N[0x491d, ((1, 3), (2, 3))] = 1
Updated Q[0x443b, ((0, 0), (0, 1))] = 19600, N[0x443b, ((0, 0), (0, 1))] = 1
Updated Q[0x104b, ((0, 1), (0, 2))] = 19600, N[0x104b, ((0, 1), (0, 2))] = 1

--- Simulation 47 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.739368017832, 16802.739368017832, 21967.0893603286, 16802.739368017832, 19602.739368017832]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a99, Score: 8400
Depth 2: State = 0x4a99, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a99: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4913, Score: 11200
Depth 3: State = 0x4913, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4913: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1d88, Score: 16800
Depth 4: State = 0x1d88, Legal Moves = [((0, 2), (1, 2)), ((1, 0), (1, 1)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1d88: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0xf3d9, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 942200, N[0x3c25, ((2, 3), (2, 4))] = 43
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4a99, ((1, 3), (2, 3))] = 19600, N[0x4a99, ((1, 3), (2, 3))] = 1
Updated Q[0x4913, ((2, 0), (2, 1))] = 19600, N[0x4913, ((2, 0), (2, 1))] = 1
Updated Q[0x1d88, ((0, 2), (1, 2))] = 19600, N[0x1d88, ((0, 2), (1, 2))] = 1

--- Simulation 48 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.7470510187, 16802.7470510187, 21912.046828329727, 16802.7470510187, 19602.7470510187]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4913, Score: 8400
Depth 2: State = 0x4913, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4913: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x44f8, Score: 11200
Depth 3: State = 0x44f8, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x44f8: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x43c7, Score: 14000
Depth 4: State = 0x43c7, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x43c7: [inf, inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4a65, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 959000, N[0x3c25, ((2, 3), (2, 4))] = 44
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4913, ((0, 3), (1, 3))] = 16800, N[0x4913, ((0, 3), (1, 3))] = 1
Updated Q[0x44f8, ((0, 1), (0, 2))] = 16800, N[0x44f8, ((0, 1), (0, 2))] = 1
Updated Q[0x43c7, ((2, 0), (2, 1))] = 16800, N[0x43c7, ((2, 0), (2, 1))] = 1

--- Simulation 49 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.754551502763, 16802.754551502763, 21795.8698097182, 16802.754551502763, 19602.754551502763]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c6c, Score: 8400
Depth 1: State = 0x3c6c, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6c: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3919, Score: 14000
Depth 2: State = 0x3919, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3919: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3916, Score: 16800
Depth 3: State = 0x3916, Legal Moves = [((0, 1), (0, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3916: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x36be, Score: 19600
Depth 4: State = 0x36be, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x36be: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x36b1, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 981400, N[0x3c25, ((2, 3), (2, 4))] = 45
Updated Q[0x3c6c, ((1, 3), (2, 3))] = 22400, N[0x3c6c, ((1, 3), (2, 3))] = 1
Updated Q[0x3919, ((0, 3), (1, 3))] = 22400, N[0x3919, ((0, 3), (1, 3))] = 1
Updated Q[0x3916, ((0, 1), (0, 2))] = 22400, N[0x3916, ((0, 1), (0, 2))] = 1
Updated Q[0x36be, ((0, 3), (1, 3))] = 22400, N[0x36be, ((0, 3), (1, 3))] = 1

--- Simulation 50 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.761877583147, 16802.761877583147, 21809.300605290322, 16802.761877583147, 19602.761877583147]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43f3, Score: 8400
Depth 2: State = 0x43f3, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43f3: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4a87, Score: 16800
Depth 3: State = 0x4a87, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a87: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x45ab, Score: 24400
Depth 4: State = 0x45ab, Legal Moves = [((2, 0), (2, 1)), ((4, 0), (4, 1)), ((4, 1), (4, 2)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x45ab: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x10bb, Score: 27200
End of simulation with depth 5. Reward (Score): 27200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1008600, N[0x3c25, ((2, 3), (2, 4))] = 46
Updated Q[0x3c24, ((0, 0), (0, 1))] = 27200, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43f3, ((1, 2), (2, 2))] = 27200, N[0x43f3, ((1, 2), (2, 2))] = 1
Updated Q[0x4a87, ((2, 0), (2, 1))] = 27200, N[0x4a87, ((2, 0), (2, 1))] = 1
Updated Q[0x45ab, ((2, 0), (2, 1))] = 27200, N[0x45ab, ((2, 0), (2, 1))] = 1

--- Simulation 51 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.769036852525, 16802.769036852525, 21926.495228731943, 16802.769036852525, 19602.769036852525]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47c2, Score: 8400
Depth 2: State = 0x47c2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x47c2: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4858, Score: 11200
Depth 3: State = 0x4858, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x4858: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x493b, Score: 14000
Depth 4: State = 0x493b, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x493b: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4937, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1028200, N[0x3c25, ((2, 3), (2, 4))] = 47
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47c2, ((1, 3), (2, 3))] = 19600, N[0x47c2, ((1, 3), (2, 3))] = 1
Updated Q[0x4858, ((1, 1), (2, 1))] = 19600, N[0x4858, ((1, 1), (2, 1))] = 1
Updated Q[0x493b, ((1, 3), (1, 4))] = 19600, N[0x493b, ((1, 3), (1, 4))] = 1

--- Simulation 52 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.776036426298, 16802.776036426298, 21877.00067121057, 16802.776036426298, 19602.776036426298]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4570, Score: 8400
Depth 2: State = 0x4570, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4570: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4582, Score: 11200
Depth 3: State = 0x4582, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4582: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x44f8, Score: 14000
Depth 4: State = 0x44f8, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x44f8: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x47a5, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1045000, N[0x3c25, ((2, 3), (2, 4))] = 48
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4570, ((0, 2), (1, 2))] = 16800, N[0x4570, ((0, 2), (1, 2))] = 1
Updated Q[0x4582, ((1, 2), (2, 2))] = 16800, N[0x4582, ((1, 2), (2, 2))] = 1
Updated Q[0x44f8, ((0, 1), (1, 1))] = 16800, N[0x44f8, ((0, 1), (1, 1))] = 1

--- Simulation 53 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.782882981446, 16802.782882981446, 21771.23500789295, 16802.782882981446, 19602.782882981446]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46b7, Score: 11200
Depth 2: State = 0x46b7, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x46b7: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x45a5, Score: 14000
Depth 3: State = 0x45a5, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a5: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4a76, Score: 16800
Depth 4: State = 0x4a76, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a76: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x47d1, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1064600, N[0x3c25, ((2, 3), (2, 4))] = 49
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46b7, ((1, 3), (2, 3))] = 19600, N[0x46b7, ((1, 3), (2, 3))] = 1
Updated Q[0x45a5, ((0, 1), (0, 2))] = 19600, N[0x45a5, ((0, 1), (0, 2))] = 1
Updated Q[0x4a76, ((1, 1), (2, 1))] = 19600, N[0x4a76, ((1, 1), (2, 1))] = 1

--- Simulation 54 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.789582791487, 16802.789582791487, 21726.929124072252, 16802.789582791487, 19602.789582791487]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x443a, Score: 8400
Depth 2: State = 0x443a, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443a: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1161, Score: 11200
Depth 3: State = 0x1161, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (1, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1161: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x29dd, Score: 14000
Depth 4: State = 0x29dd, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x29dd: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x3719, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1081400, N[0x3c25, ((2, 3), (2, 4))] = 50
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x443a, ((0, 0), (0, 1))] = 16800, N[0x443a, ((0, 0), (0, 1))] = 1
Updated Q[0x1161, ((0, 0), (1, 0))] = 16800, N[0x1161, ((0, 0), (1, 0))] = 1
Updated Q[0x29dd, ((1, 0), (1, 1))] = 16800, N[0x29dd, ((1, 0), (1, 1))] = 1

--- Simulation 55 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.796141758077, 16802.796141758077, 21628.395434159658, 16802.796141758077, 19602.796141758077]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4aac, Score: 8400
Depth 2: State = 0x4aac, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aac: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x455e, Score: 11200
Depth 3: State = 0x455e, Legal Moves = [((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x455e: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x47f2, Score: 16800
Depth 4: State = 0x47f2, Legal Moves = [((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47f2: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4a98, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1101000, N[0x3c25, ((2, 3), (2, 4))] = 51
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4aac, ((1, 3), (2, 3))] = 19600, N[0x4aac, ((1, 3), (2, 3))] = 1
Updated Q[0x455e, ((1, 2), (1, 3))] = 19600, N[0x455e, ((1, 2), (1, 3))] = 1
Updated Q[0x47f2, ((2, 0), (2, 1))] = 19600, N[0x47f2, ((2, 0), (2, 1))] = 1

--- Simulation 56 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.802565439568, 16802.802565439568, 21588.627731774566, 16802.802565439568, 19602.802565439568]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x452b, Score: 8400
Depth 2: State = 0x452b, Legal Moves = [((0, 3), (0, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x452b: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x48f5, Score: 11200
Depth 3: State = 0x48f5, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f5: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x49a1, Score: 14000
Depth 4: State = 0x49a1, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x49a1: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4af7, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1117800, N[0x3c25, ((2, 3), (2, 4))] = 52
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x452b, ((0, 3), (0, 4))] = 16800, N[0x452b, ((0, 3), (0, 4))] = 1
Updated Q[0x48f5, ((1, 2), (2, 2))] = 16800, N[0x48f5, ((1, 2), (2, 2))] = 1
Updated Q[0x49a1, ((1, 3), (2, 3))] = 16800, N[0x49a1, ((1, 3), (2, 3))] = 1

--- Simulation 57 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.808859076893, 16802.808859076893, 21496.543364824127, 16802.808859076893, 19602.808859076893]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x368c, Score: 11200
Depth 2: State = 0x368c, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x368c: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4450, Score: 16800
Depth 3: State = 0x4450, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((3, 3), (4, 3)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x4450: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x4848, Score: 19600
Depth 4: State = 0x4848, Legal Moves = [((2, 0), (2, 1)), ((3, 2), (4, 2)), ((3, 3), (4, 3)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x4848: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4450, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1140200, N[0x3c25, ((2, 3), (2, 4))] = 53
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x368c, ((2, 0), (2, 1))] = 22400, N[0x368c, ((2, 0), (2, 1))] = 1
Updated Q[0x4450, ((0, 1), (1, 1))] = 22400, N[0x4450, ((0, 1), (1, 1))] = 1
Updated Q[0x4848, ((2, 0), (2, 1))] = 22400, N[0x4848, ((2, 0), (2, 1))] = 1

--- Simulation 58 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.815027617085, 16802.815027617085, 21513.594220950825, 16802.815027617085, 19602.815027617085]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43f9, Score: 8400
Depth 2: State = 0x43f9, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43f9: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4705, Score: 11200
Depth 3: State = 0x4705, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4705: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4705, Score: 14000
Depth 4: State = 0x4705, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4705: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4946, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1159800, N[0x3c25, ((2, 3), (2, 4))] = 54
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43f9, ((1, 3), (2, 3))] = 19600, N[0x43f9, ((1, 3), (2, 3))] = 1
Updated Q[0x4705, ((2, 0), (2, 1))] = 19600, N[0x4705, ((2, 0), (2, 1))] = 1
Updated Q[0x4705, ((1, 3), (1, 4))] = 19600, N[0x4705, ((1, 3), (1, 4))] = 1

--- Simulation 59 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.821075734657, 16802.821075734657, 21478.161677559758, 16802.821075734657, 19602.821075734657]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d2e, Score: 13300
Depth 2: State = 0x3d2e, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d2e: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3d50, Score: 16100
Depth 3: State = 0x3d50, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d50: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3957, Score: 18900
Depth 4: State = 0x3957, Legal Moves = [((1, 1), (2, 1))]
UCB1 values for moves at state 0x3957: [inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3af1, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1181500, N[0x3c25, ((2, 3), (2, 4))] = 55
Updated Q[0x3c25, ((1, 3), (2, 3))] = 21700, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3d2e, ((1, 2), (1, 3))] = 21700, N[0x3d2e, ((1, 2), (1, 3))] = 1
Updated Q[0x3d50, ((2, 0), (2, 1))] = 21700, N[0x3d50, ((2, 0), (2, 1))] = 1
Updated Q[0x3957, ((1, 1), (2, 1))] = 21700, N[0x3957, ((1, 1), (2, 1))] = 1

--- Simulation 60 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.82700785108, 16802.82700785108, 21482.199375479056, 16802.82700785108, 19602.82700785108]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46d5, Score: 8400
Depth 2: State = 0x46d5, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46d5: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4825, Score: 11200
Depth 3: State = 0x4825, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4825: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4825, Score: 14000
Depth 4: State = 0x4825, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1195500, N[0x3c25, ((2, 3), (2, 4))] = 56
Updated Q[0x3c24, ((0, 0), (0, 1))] = 14000, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46d5, ((1, 3), (2, 3))] = 14000, N[0x46d5, ((1, 3), (2, 3))] = 1
Updated Q[0x4825, ((1, 1), (2, 1))] = 14000, N[0x4825, ((1, 1), (2, 1))] = 1

--- Simulation 61 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.832828152565, 16802.832828152565, 21348.592838299377, 16802.832828152565, 19602.832828152565]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46c1, Score: 8400
Depth 2: State = 0x46c1, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46c1: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x455d, Score: 11200
Depth 3: State = 0x455d, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x455d: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x440a, Score: 14000
Depth 4: State = 0x440a, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 1), (2, 2)), ((2, 2), (2, 3))]
UCB1 values for moves at state 0x440a: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x47a6, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1212300, N[0x3c25, ((2, 3), (2, 4))] = 57
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46c1, ((1, 3), (2, 3))] = 16800, N[0x46c1, ((1, 3), (2, 3))] = 1
Updated Q[0x455d, ((1, 1), (2, 1))] = 16800, N[0x455d, ((1, 1), (2, 1))] = 1
Updated Q[0x440a, ((0, 1), (0, 2))] = 16800, N[0x440a, ((0, 1), (0, 2))] = 1

--- Simulation 62 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.838540606328, 16802.838540606328, 21268.797026519573, 16802.838540606328, 19602.838540606328]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3be4, Score: 8400
Depth 2: State = 0x3be4, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be4: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c06, Score: 11200
Depth 3: State = 0x3c06, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c06: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3c02, Score: 14000
Depth 4: State = 0x3c02, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c02: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3d3a, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1231900, N[0x3c25, ((2, 3), (2, 4))] = 58
Updated Q[0x3c25, ((0, 2), (1, 2))] = 19600, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3be4, ((1, 2), (2, 2))] = 19600, N[0x3be4, ((1, 2), (2, 2))] = 1
Updated Q[0x3c06, ((1, 3), (1, 4))] = 19600, N[0x3c06, ((1, 3), (1, 4))] = 1
Updated Q[0x3c02, ((1, 1), (2, 1))] = 19600, N[0x3c02, ((1, 1), (2, 1))] = 1

--- Simulation 63 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.844148975473, 16802.844148975473, 21240.028627470285, 16802.844148975473, 19602.844148975473]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c06, Score: 8400
Depth 2: State = 0x3c06, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c06: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c5e, Score: 14000
Depth 3: State = 0x3c5e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3865, Score: 16800
Depth 4: State = 0x3865, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x3865: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x3832, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1251500, N[0x3c25, ((2, 3), (2, 4))] = 59
Updated Q[0x3c24, ((0, 2), (1, 2))] = 19600, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c06, ((1, 2), (2, 2))] = 19600, N[0x3c06, ((1, 2), (2, 2))] = 1
Updated Q[0x3c5e, ((2, 0), (2, 1))] = 19600, N[0x3c5e, ((2, 0), (2, 1))] = 1
Updated Q[0x3865, ((4, 1), (4, 2))] = 19600, N[0x3865, ((4, 1), (4, 2))] = 1

--- Simulation 64 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.849656832626, 16802.849656832626, 21212.23540049937, 16802.849656832626, 19602.849656832626]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 21701.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x382d, Score: 8400
Depth 2: State = 0x382d, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (1, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x382d: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x21ee, Score: 11200
Depth 3: State = 0x21ee, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x21ee: [inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x1f48, Score: 14000
Depth 4: State = 0x1f48, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x1f48: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x1f47, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1268300, N[0x3c25, ((2, 3), (2, 4))] = 60
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x382d, ((0, 0), (0, 1))] = 16800, N[0x382d, ((0, 0), (0, 1))] = 1
Updated Q[0x21ee, ((0, 1), (1, 1))] = 16800, N[0x21ee, ((0, 1), (1, 1))] = 1
Updated Q[0x1f48, ((4, 1), (4, 2))] = 16800, N[0x1f48, ((4, 1), (4, 2))] = 1

--- Simulation 65 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.855067572473, 16802.855067572473, 21138.701920972017, 16802.855067572473, 19602.855067572473]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4852, Score: 8400
Depth 2: State = 0x4852, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4852: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a6a, Score: 16100
Depth 3: State = 0x4a6a, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a6a: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x47e3, Score: 29800
Depth 4: State = 0x47e3, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47e3: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x46de, Score: 32600
End of simulation with depth 5. Reward (Score): 32600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1300900, N[0x3c25, ((2, 3), (2, 4))] = 61
Updated Q[0x3c25, ((0, 0), (0, 1))] = 32600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4852, ((1, 3), (2, 3))] = 32600, N[0x4852, ((1, 3), (2, 3))] = 1
Updated Q[0x4a6a, ((2, 0), (2, 1))] = 32600, N[0x4a6a, ((2, 0), (2, 1))] = 1
Updated Q[0x47e3, ((0, 3), (1, 3))] = 32600, N[0x47e3, ((0, 3), (1, 3))] = 1

--- Simulation 66 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.86038442329, 16802.86038442329, 21326.595742893685, 16802.86038442329, 19602.86038442329]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4aed, Score: 8400
Depth 2: State = 0x4aed, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aed: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4aba, Score: 11200
Depth 3: State = 0x4aba, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aba: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x36d9, Score: 16800
Depth 4: State = 0x36d9, Legal Moves = [((0, 0), (0, 1)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d9: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0xf3c9, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1320500, N[0x3c25, ((2, 3), (2, 4))] = 62
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4aed, ((0, 3), (1, 3))] = 19600, N[0x4aed, ((0, 3), (1, 3))] = 1
Updated Q[0x4aba, ((0, 2), (1, 2))] = 19600, N[0x4aba, ((0, 2), (1, 2))] = 1
Updated Q[0x36d9, ((0, 0), (0, 1))] = 19600, N[0x36d9, ((0, 0), (0, 1))] = 1

--- Simulation 67 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.865610457542, 16802.865610457542, 21298.751029666233, 16802.865610457542, 19602.865610457542]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4965, Score: 8400
Depth 2: State = 0x4965, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4965: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x480b, Score: 11200
Depth 3: State = 0x480b, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x480b: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x482c, Score: 14000
Depth 4: State = 0x482c, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x482c: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a4e, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1337300, N[0x3c25, ((2, 3), (2, 4))] = 63
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4965, ((0, 1), (0, 2))] = 16800, N[0x4965, ((0, 1), (0, 2))] = 1
Updated Q[0x480b, ((0, 2), (1, 2))] = 16800, N[0x480b, ((0, 2), (1, 2))] = 1
Updated Q[0x482c, ((1, 3), (2, 3))] = 16800, N[0x482c, ((1, 3), (2, 3))] = 1

--- Simulation 68 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.870748601672, 16802.870748601672, 21227.345807311583, 16802.870748601672, 19602.870748601672]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47a4, Score: 8400
Depth 2: State = 0x47a4, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47a4: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x47c0, Score: 14000
Depth 3: State = 0x47c0, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c0: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x46b8, Score: 16800
Depth 4: State = 0x46b8, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46b8: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x46b8, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1356900, N[0x3c25, ((2, 3), (2, 4))] = 64
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47a4, ((1, 2), (2, 2))] = 19600, N[0x47a4, ((1, 2), (2, 2))] = 1
Updated Q[0x47c0, ((0, 3), (1, 3))] = 19600, N[0x47c0, ((0, 3), (1, 3))] = 1
Updated Q[0x46b8, ((2, 0), (2, 1))] = 19600, N[0x46b8, ((2, 0), (2, 1))] = 1

--- Simulation 69 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.875801645132, 16802.875801645132, 21201.92197520564, 16802.875801645132, 19602.875801645132]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46e3, Score: 8400
Depth 2: State = 0x46e3, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46e3: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4ad5, Score: 11200
Depth 3: State = 0x4ad5, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ad5: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4aca, Score: 14000
Depth 4: State = 0x4aca, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aca: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4aaf, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1376500, N[0x3c25, ((2, 3), (2, 4))] = 65
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46e3, ((1, 3), (2, 3))] = 19600, N[0x46e3, ((1, 3), (2, 3))] = 1
Updated Q[0x4ad5, ((0, 3), (1, 3))] = 19600, N[0x4ad5, ((0, 3), (1, 3))] = 1
Updated Q[0x4aca, ((1, 1), (2, 1))] = 19600, N[0x4aca, ((1, 1), (2, 1))] = 1

--- Simulation 70 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.88077224872, 16802.88077224872, 21177.28039274436, 16802.88077224872, 19602.88077224872]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4957, Score: 14000
Depth 2: State = 0x4957, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4957: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4a66, Score: 16800
Depth 3: State = 0x4a66, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a66: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x43c8, Score: 19600
Depth 4: State = 0x43c8, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1396100, N[0x3c25, ((2, 3), (2, 4))] = 66
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4957, ((0, 3), (1, 3))] = 19600, N[0x4957, ((0, 3), (1, 3))] = 1
Updated Q[0x4a66, ((2, 0), (2, 1))] = 19600, N[0x4a66, ((2, 0), (2, 1))] = 1

--- Simulation 71 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.885662952325, 16802.885662952325, 21153.38550358557, 16802.885662952325, 19602.885662952325]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43d4, Score: 8400
Depth 2: State = 0x43d4, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43d4: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x43fb, Score: 11200
Depth 3: State = 0x43fb, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43fb: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1412, Score: 16800
Depth 4: State = 0x1412, Legal Moves = [((0, 0), (0, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1412: [inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x50f4, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1415700, N[0x3c25, ((2, 3), (2, 4))] = 67
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43d4, ((1, 2), (2, 2))] = 19600, N[0x43d4, ((1, 2), (2, 2))] = 1
Updated Q[0x43fb, ((2, 0), (2, 1))] = 19600, N[0x43fb, ((2, 0), (2, 1))] = 1
Updated Q[0x1412, ((0, 0), (0, 1))] = 19600, N[0x1412, ((0, 0), (0, 1))] = 1

--- Simulation 72 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.890476182052, 16802.890476182052, 21130.203874137744, 16802.890476182052, 19602.890476182052]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x48f7, Score: 8400
Depth 2: State = 0x48f7, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f7: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a91, Score: 11200
Depth 3: State = 0x4a91, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a91: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4a6c, Score: 22100
Depth 4: State = 0x4a6c, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a6c: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4919, Score: 24900
End of simulation with depth 5. Reward (Score): 24900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1440600, N[0x3c25, ((2, 3), (2, 4))] = 68
Updated Q[0x3c24, ((0, 0), (0, 1))] = 24900, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x48f7, ((1, 3), (2, 3))] = 24900, N[0x48f7, ((1, 3), (2, 3))] = 1
Updated Q[0x4a91, ((0, 3), (1, 3))] = 24900, N[0x4a91, ((0, 3), (1, 3))] = 1
Updated Q[0x4a6c, ((2, 0), (2, 1))] = 24900, N[0x4a6c, ((2, 0), (2, 1))] = 1

--- Simulation 73 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.895214256885, 16802.895214256885, 21185.645213946762, 16802.895214256885, 19602.895214256885]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47ec, Score: 8400
Depth 2: State = 0x47ec, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47ec: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x47f3, Score: 11200
Depth 3: State = 0x47f3, Legal Moves = [((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x47f3: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x4834, Score: 14000
Depth 4: State = 0x4834, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4834: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x3961, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1457400, N[0x3c25, ((2, 3), (2, 4))] = 69
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47ec, ((1, 3), (1, 4))] = 16800, N[0x47ec, ((1, 3), (1, 4))] = 1
Updated Q[0x47f3, ((1, 1), (1, 2))] = 16800, N[0x47f3, ((1, 1), (1, 2))] = 1
Updated Q[0x4834, ((0, 0), (0, 1))] = 16800, N[0x4834, ((0, 0), (0, 1))] = 1

--- Simulation 74 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.899879394845, 16802.899879394845, 21122.08823488958, 16802.899879394845, 19602.899879394845]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x465a, Score: 8400
Depth 2: State = 0x465a, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x465a: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a92, Score: 11200
Depth 3: State = 0x4a92, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a92: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4a8c, Score: 14000
Depth 4: State = 0x4a8c, Legal Moves = [((0, 3), (0, 4)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x4a8c: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x4a87, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1474200, N[0x3c25, ((2, 3), (2, 4))] = 70
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x465a, ((1, 3), (2, 3))] = 16800, N[0x465a, ((1, 3), (2, 3))] = 1
Updated Q[0x4a92, ((0, 3), (1, 3))] = 16800, N[0x4a92, ((0, 3), (1, 3))] = 1
Updated Q[0x4a8c, ((0, 3), (0, 4))] = 16800, N[0x4a8c, ((0, 3), (0, 4))] = 1

--- Simulation 75 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.90447371871, 16802.90447371871, 21060.347151008365, 16802.90447371871, 19602.90447371871]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [24900.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x395d, Score: 16100
Depth 2: State = 0x395d, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x395d: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x39bc, Score: 18900
Depth 3: State = 0x39bc, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39bc: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3b0f, Score: 21700
Depth 4: State = 0x3b0f, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3b0f: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x1c7c, Score: 32100
End of simulation with depth 5. Reward (Score): 32100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1506300, N[0x3c25, ((2, 3), (2, 4))] = 71
Updated Q[0x3c24, ((1, 3), (2, 3))] = 32100, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x395d, ((0, 2), (1, 2))] = 32100, N[0x395d, ((0, 2), (1, 2))] = 1
Updated Q[0x39bc, ((1, 3), (2, 3))] = 32100, N[0x39bc, ((1, 3), (2, 3))] = 1
Updated Q[0x3b0f, ((1, 1), (2, 1))] = 32100, N[0x3b0f, ((1, 1), (2, 1))] = 1

--- Simulation 76 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.908999261348, 16802.908999261348, 21215.838192443185, 16802.908999261348, 19602.908999261348]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 25201.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c24, Score: 8400
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((1, 0), (1, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46e3, Score: 11200
Depth 3: State = 0x46e3, Legal Moves = [((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x46e3: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x4705, Score: 16800
Depth 4: State = 0x4705, Legal Moves = [((0, 1), (0, 2)), ((0, 1), (1, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4705: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x469f, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1525900, N[0x3c25, ((2, 3), (2, 4))] = 72
Updated Q[0x3c24, ((2, 0), (2, 1))] = 19600, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46e3, ((1, 0), (1, 1))] = 19600, N[0x46e3, ((1, 0), (1, 1))] = 1
Updated Q[0x4705, ((0, 1), (0, 2))] = 19600, N[0x4705, ((0, 1), (0, 2))] = 1

--- Simulation 77 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.913457970688, 16802.913457970688, 21193.398909870182, 16802.913457970688, 19602.913457970688]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x452c, Score: 8400
Depth 2: State = 0x452c, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x452c: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4580, Score: 14000
Depth 3: State = 0x4580, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4580: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4935, Score: 16800
Depth 4: State = 0x4935, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4935: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x48f1, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1545500, N[0x3c25, ((2, 3), (2, 4))] = 73
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x452c, ((1, 3), (1, 4))] = 19600, N[0x452c, ((1, 3), (1, 4))] = 1
Updated Q[0x4580, ((0, 1), (0, 2))] = 19600, N[0x4580, ((0, 1), (0, 2))] = 1
Updated Q[0x4935, ((1, 2), (1, 3))] = 19600, N[0x4935, ((1, 2), (1, 3))] = 1

--- Simulation 78 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.917851714334, 16802.917851714334, 21171.574385424323, 16802.917851714334, 19602.917851714334]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43f3, Score: 8400
Depth 2: State = 0x43f3, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43f3: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4456, Score: 16800
Depth 3: State = 0x4456, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4456: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x43a8, Score: 19600
Depth 4: State = 0x43a8, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43a8: [inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x4a43, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1570700, N[0x3c25, ((2, 3), (2, 4))] = 74
Updated Q[0x3c24, ((0, 0), (0, 1))] = 25200, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43f3, ((1, 2), (2, 2))] = 25200, N[0x43f3, ((1, 2), (2, 2))] = 1
Updated Q[0x4456, ((0, 2), (1, 2))] = 25200, N[0x4456, ((0, 2), (1, 2))] = 1
Updated Q[0x43a8, ((0, 3), (0, 4))] = 25200, N[0x43a8, ((0, 3), (0, 4))] = 1

--- Simulation 79 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.922182283895, 16802.922182283895, 21226.015372466158, 16802.922182283895, 19602.922182283895]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4832, Score: 8400
Depth 2: State = 0x4832, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4832: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x3d51, Score: 11200
Depth 3: State = 0x3d51, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d51: [inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3d5d, Score: 14000
Depth 4: State = 0x3d5d, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d5d: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3a62, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1587500, N[0x3c25, ((2, 3), (2, 4))] = 75
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4832, ((0, 0), (0, 1))] = 16800, N[0x4832, ((0, 0), (0, 1))] = 1
Updated Q[0x3d51, ((0, 4), (1, 4))] = 16800, N[0x3d51, ((0, 4), (1, 4))] = 1
Updated Q[0x3d5d, ((1, 3), (1, 4))] = 16800, N[0x3d5d, ((1, 3), (1, 4))] = 1

--- Simulation 80 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.92645139902, 16802.92645139902, 21167.004584167265, 16802.92645139902, 19602.92645139902]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x464e, Score: 8400
Depth 2: State = 0x464e, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x464e: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4ad5, Score: 11200
Depth 3: State = 0x4ad5, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ad5: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x482f, Score: 14000
Depth 4: State = 0x482f, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3))]
UCB1 values for moves at state 0x482f: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4a73, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1607100, N[0x3c25, ((2, 3), (2, 4))] = 76
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x464e, ((1, 3), (1, 4))] = 19600, N[0x464e, ((1, 3), (1, 4))] = 1
Updated Q[0x4ad5, ((1, 1), (2, 1))] = 19600, N[0x4ad5, ((1, 1), (2, 1))] = 1
Updated Q[0x482f, ((1, 2), (2, 2))] = 19600, N[0x482f, ((1, 2), (2, 2))] = 1

--- Simulation 81 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.930660711165, 16802.930660711165, 21146.388801417834, 16802.930660711165, 19602.930660711165]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4419, Score: 8400
Depth 2: State = 0x4419, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x4419: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x43b3, Score: 11200
Depth 3: State = 0x43b3, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43b3: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x499a, Score: 14000
Depth 4: State = 0x499a, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x499a: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x46d6, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1623900, N[0x3c25, ((2, 3), (2, 4))] = 77
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4419, ((0, 2), (1, 2))] = 16800, N[0x4419, ((0, 2), (1, 2))] = 1
Updated Q[0x43b3, ((1, 3), (2, 3))] = 16800, N[0x43b3, ((1, 3), (2, 3))] = 1
Updated Q[0x499a, ((0, 3), (1, 3))] = 16800, N[0x499a, ((0, 3), (1, 3))] = 1

--- Simulation 82 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.93481180711, 16802.93481180711, 21089.944842455727, 16802.93481180711, 19602.93481180711]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bbc, Score: 13300
Depth 2: State = 0x3bbc, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbc: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3917, Score: 16100
Depth 3: State = 0x3917, Legal Moves = [((0, 0), (0, 1)), ((0, 0), (1, 0)), ((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3917: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2bdb, Score: 18900
Depth 4: State = 0x2bdb, Legal Moves = [((0, 2), (0, 3)), ((1, 0), (1, 1)), ((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2bdb: [inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x5104, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1645600, N[0x3c25, ((2, 3), (2, 4))] = 78
Updated Q[0x3c24, ((1, 2), (2, 2))] = 21700, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3bbc, ((2, 0), (2, 1))] = 21700, N[0x3bbc, ((2, 0), (2, 1))] = 1
Updated Q[0x3917, ((0, 0), (0, 1))] = 21700, N[0x3917, ((0, 0), (0, 1))] = 1
Updated Q[0x2bdb, ((0, 2), (0, 3))] = 21700, N[0x2bdb, ((0, 2), (0, 3))] = 1

--- Simulation 83 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.93890621229, 16802.93890621229, 21097.768663036866, 16802.93890621229, 19602.93890621229]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3a69, Score: 14000
Depth 2: State = 0x3a69, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3a69: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x371e, Score: 19600
Depth 3: State = 0x371e, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((3, 2), (4, 2))]
UCB1 values for moves at state 0x371e: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x2017, Score: 22400
Depth 4: State = 0x2017, Legal Moves = [((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2017: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x1dcb, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1672900, N[0x3c25, ((2, 3), (2, 4))] = 79
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27300, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3a69, ((0, 1), (0, 2))] = 27300, N[0x3a69, ((0, 1), (0, 2))] = 1
Updated Q[0x371e, ((1, 0), (2, 0))] = 27300, N[0x371e, ((1, 0), (2, 0))] = 1
Updated Q[0x2017, ((1, 2), (2, 2))] = 27300, N[0x2017, ((1, 2), (2, 2))] = 1

--- Simulation 84 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.94294539387, 16802.94294539387, 21176.28047431418, 16802.94294539387, 19602.94294539387]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46b1, Score: 8400
Depth 2: State = 0x46b1, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46b1: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4413, Score: 13300
Depth 3: State = 0x4413, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4413: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4ab1, Score: 16100
Depth 4: State = 0x4ab1, Legal Moves = [((2, 0), (2, 1))]
UCB1 values for moves at state 0x4ab1: [inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x22fc, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1694600, N[0x3c25, ((2, 3), (2, 4))] = 80
Updated Q[0x3c25, ((0, 0), (0, 1))] = 21700, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x46b1, ((0, 3), (1, 3))] = 21700, N[0x46b1, ((0, 3), (1, 3))] = 1
Updated Q[0x4413, ((1, 1), (2, 1))] = 21700, N[0x4413, ((1, 1), (2, 1))] = 1
Updated Q[0x4ab1, ((2, 0), (2, 1))] = 21700, N[0x4ab1, ((2, 0), (2, 1))] = 1

--- Simulation 85 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.946930763646, 16802.946930763646, 21182.829476875624, 16802.946930763646, 19602.946930763646]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4520, Score: 8400
Depth 2: State = 0x4520, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4520: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4ab3, Score: 11200
Depth 3: State = 0x4ab3, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab3: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4ab3, Score: 14000
Depth 4: State = 0x4ab3, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab3: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4415, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1714200, N[0x3c25, ((2, 3), (2, 4))] = 81
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4520, ((1, 3), (2, 3))] = 19600, N[0x4520, ((1, 3), (2, 3))] = 1
Updated Q[0x4ab3, ((0, 3), (1, 3))] = 19600, N[0x4ab3, ((0, 3), (1, 3))] = 1
Updated Q[0x4ab3, ((1, 3), (1, 4))] = 19600, N[0x4ab3, ((1, 3), (1, 4))] = 1

--- Simulation 86 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.95086368081, 16802.95086368081, 21163.290836705277, 16802.95086368081, 19602.95086368081]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.467405903557, 21701.467405903557, 16801.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c2c, Score: 8400
Depth 2: State = 0x3c2c, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c2c: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x46c3, Score: 14000
Depth 3: State = 0x46c3, Legal Moves = [((2, 1), (2, 2)), ((2, 2), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x46c3: [inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x46d9, Score: 16800
Depth 4: State = 0x46d9, Legal Moves = [((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x46d9: [inf, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x37c3, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1736600, N[0x3c25, ((2, 3), (2, 4))] = 82
Updated Q[0x3c25, ((2, 3), (3, 3))] = 22400, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3c2c, ((2, 0), (2, 1))] = 22400, N[0x3c2c, ((2, 0), (2, 1))] = 1
Updated Q[0x46c3, ((2, 1), (2, 2))] = 22400, N[0x46c3, ((2, 1), (2, 2))] = 1
Updated Q[0x46d9, ((3, 0), (3, 1))] = 22400, N[0x46d9, ((3, 0), (3, 1))] = 1

--- Simulation 87 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.95474545446, 16802.95474545446, 21178.375077537505, 16802.95474545446, 19602.95474545446]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47af, Score: 8400
Depth 2: State = 0x47af, Legal Moves = [((0, 3), (0, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47af: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x47ac, Score: 11200
Depth 3: State = 0x47ac, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47ac: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4412, Score: 14000
Depth 4: State = 0x4412, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4412: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x148f, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1756200, N[0x3c25, ((2, 3), (2, 4))] = 83
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x47af, ((0, 3), (0, 4))] = 19600, N[0x47af, ((0, 3), (0, 4))] = 1
Updated Q[0x47ac, ((1, 3), (2, 3))] = 19600, N[0x47ac, ((1, 3), (2, 3))] = 1
Updated Q[0x4412, ((2, 0), (2, 1))] = 19600, N[0x4412, ((2, 0), (2, 1))] = 1

--- Simulation 88 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.95857734605, 16802.95857734605, 21159.360890631324, 16802.95857734605, 19602.95857734605]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43d4, Score: 8400
Depth 2: State = 0x43d4, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43d4: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x46d2, Score: 11200
Depth 3: State = 0x46d2, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46d2: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1443, Score: 16800
Depth 4: State = 0x1443, Legal Moves = [((4, 0), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1443: [inf, inf]
Selected move: ((4, 0), (4, 1))
New board state after move: 0x119e, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1775800, N[0x3c25, ((2, 3), (2, 4))] = 84
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43d4, ((1, 3), (2, 3))] = 19600, N[0x43d4, ((1, 3), (2, 3))] = 1
Updated Q[0x46d2, ((2, 0), (2, 1))] = 19600, N[0x46d2, ((2, 0), (2, 1))] = 1
Updated Q[0x1443, ((4, 0), (4, 1))] = 19600, N[0x1443, ((4, 0), (4, 1))] = 1

--- Simulation 89 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.962360571633, 16802.962360571633, 21140.79941051322, 16802.962360571633, 19602.962360571633]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c4d, Score: 8400
Depth 1: State = 0x3c4d, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4d: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x5289, Score: 11200
Depth 2: State = 0x5289, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5289: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x53d5, Score: 16800
Depth 3: State = 0x53d5, Legal Moves = [((0, 3), (0, 4)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x53d5: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x5573, Score: 19600
Depth 4: State = 0x5573, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5573: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x56c6, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1798200, N[0x3c25, ((2, 3), (2, 4))] = 85
Updated Q[0x3c4d, ((0, 0), (1, 0))] = 22400, N[0x3c4d, ((0, 0), (1, 0))] = 1
Updated Q[0x5289, ((1, 3), (2, 3))] = 22400, N[0x5289, ((1, 3), (2, 3))] = 1
Updated Q[0x53d5, ((0, 3), (0, 4))] = 22400, N[0x53d5, ((0, 3), (0, 4))] = 1
Updated Q[0x5573, ((2, 0), (2, 1))] = 22400, N[0x5573, ((2, 0), (2, 1))] = 1

--- Simulation 90 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.96609630401, 16802.96609630401, 21155.615835961642, 16802.96609630401, 19602.96609630401]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a4b, Score: 8400
Depth 2: State = 0x4a4b, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a4b: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4837, Score: 11200
Depth 3: State = 0x4837, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4837: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4592, Score: 14000
Depth 4: State = 0x4592, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x4592: [inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3043, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1815000, N[0x3c25, ((2, 3), (2, 4))] = 86
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4a4b, ((1, 3), (2, 3))] = 16800, N[0x4a4b, ((1, 3), (2, 3))] = 1
Updated Q[0x4837, ((2, 0), (2, 1))] = 16800, N[0x4837, ((2, 0), (2, 1))] = 1
Updated Q[0x4592, ((0, 1), (1, 1))] = 16800, N[0x4592, ((0, 1), (1, 1))] = 1

--- Simulation 91 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.969785674733, 16802.969785674733, 21104.971403015825, 16802.969785674733, 19602.969785674733]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4438, Score: 8400
Depth 2: State = 0x4438, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4438: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4677, Score: 22100
Depth 3: State = 0x4677, Legal Moves = [((1, 0), (1, 1)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4677: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x479e, Score: 27700
Depth 4: State = 0x479e, Legal Moves = [((0, 3), (0, 4)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x479e: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x47ae, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1845500, N[0x3c25, ((2, 3), (2, 4))] = 87
Updated Q[0x3c25, ((0, 0), (0, 1))] = 30500, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4438, ((1, 3), (2, 3))] = 30500, N[0x4438, ((1, 3), (2, 3))] = 1
Updated Q[0x4677, ((1, 0), (1, 1))] = 30500, N[0x4677, ((1, 0), (1, 1))] = 1
Updated Q[0x479e, ((0, 3), (0, 4))] = 30500, N[0x479e, ((0, 3), (0, 4))] = 1

--- Simulation 92 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.973429775993, 16802.973429775993, 21212.96246329435, 16802.973429775993, 19602.973429775993]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c6d, Score: 8400
Depth 1: State = 0x3c6d, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6d: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x399e, Score: 11200
Depth 2: State = 0x399e, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x399e: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3845, Score: 16100
Depth 3: State = 0x3845, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3845: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3845, Score: 18900
Depth 4: State = 0x3845, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1))]
UCB1 values for moves at state 0x3845: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x36f2, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1867200, N[0x3c25, ((2, 3), (2, 4))] = 88
Updated Q[0x3c6d, ((1, 3), (2, 3))] = 21700, N[0x3c6d, ((1, 3), (2, 3))] = 1
Updated Q[0x399e, ((0, 2), (1, 2))] = 21700, N[0x399e, ((0, 2), (1, 2))] = 1
Updated Q[0x3845, ((1, 1), (2, 1))] = 21700, N[0x3845, ((1, 1), (2, 1))] = 1
Updated Q[0x3845, ((1, 1), (2, 1))] = 21700, N[0x3845, ((1, 1), (2, 1))] = 1

--- Simulation 93 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.977029662434, 16802.977029662434, 21218.499170610143, 16802.977029662434, 19602.977029662434]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x456b, Score: 8400
Depth 2: State = 0x456b, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x456b: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x43d5, Score: 18900
Depth 3: State = 0x43d5, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x43d5: [inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x43b3, Score: 21700
Depth 4: State = 0x43b3, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1888900, N[0x3c25, ((2, 3), (2, 4))] = 89
Updated Q[0x3c24, ((0, 0), (0, 1))] = 21700, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x456b, ((1, 3), (2, 3))] = 21700, N[0x456b, ((1, 3), (2, 3))] = 1
Updated Q[0x43d5, ((1, 1), (1, 2))] = 21700, N[0x43d5, ((1, 1), (1, 2))] = 1

--- Simulation 94 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.980586352813, 16802.980586352813, 21223.911447139493, 16802.980586352813, 19602.980586352813]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x469f, Score: 11200
Depth 2: State = 0x469f, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x469f: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a52, Score: 16800
Depth 3: State = 0x4a52, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a52: [inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x1f0b, Score: 19600
Depth 4: State = 0x1f0b, Legal Moves = [((1, 1), (1, 2))]
UCB1 values for moves at state 0x1f0b: [inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x1eba, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1911300, N[0x3c25, ((2, 3), (2, 4))] = 90
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x469f, ((1, 3), (2, 3))] = 22400, N[0x469f, ((1, 3), (2, 3))] = 1
Updated Q[0x4a52, ((1, 0), (2, 0))] = 22400, N[0x4a52, ((1, 0), (2, 0))] = 1
Updated Q[0x1f0b, ((1, 1), (1, 2))] = 22400, N[0x1f0b, ((1, 1), (1, 2))] = 1

--- Simulation 95 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.984100831614, 16802.984100831614, 21236.981218513185, 16802.984100831614, 19602.984100831614]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37c9, Score: 11200
Depth 2: State = 0x37c9, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37c9: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3bc2, Score: 14000
Depth 3: State = 0x3bc2, Legal Moves = [((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 4), (3, 4))]
UCB1 values for moves at state 0x3bc2: [inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x11cd, Score: 16800
Depth 4: State = 0x11cd, Legal Moves = [((2, 2), (3, 2)), ((2, 4), (3, 4)), ((3, 1), (4, 1))]
UCB1 values for moves at state 0x11cd: [inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x11e6, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1930900, N[0x3c25, ((2, 3), (2, 4))] = 91
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x37c9, ((2, 0), (2, 1))] = 19600, N[0x37c9, ((2, 0), (2, 1))] = 1
Updated Q[0x3bc2, ((2, 1), (3, 1))] = 19600, N[0x3bc2, ((2, 1), (3, 1))] = 1
Updated Q[0x11cd, ((2, 2), (3, 2))] = 19600, N[0x11cd, ((2, 2), (3, 2))] = 1

--- Simulation 96 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.987574050552, 16802.987574050552, 21218.9945015389, 16802.987574050552, 19602.987574050552]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4459, Score: 11200
Depth 2: State = 0x4459, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4459: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4677, Score: 19600
Depth 3: State = 0x4677, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4677: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4524, Score: 22400
Depth 4: State = 0x4524, Legal Moves = [((4, 0), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4524: [inf, inf]
Selected move: ((4, 0), (4, 1))
New board state after move: 0x5260, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1956100, N[0x3c25, ((2, 3), (2, 4))] = 92
Updated Q[0x3c24, ((0, 0), (0, 1))] = 25200, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4459, ((1, 3), (2, 3))] = 25200, N[0x4459, ((1, 3), (2, 3))] = 1
Updated Q[0x4677, ((2, 0), (2, 1))] = 25200, N[0x4677, ((2, 0), (2, 1))] = 1
Updated Q[0x4524, ((4, 0), (4, 1))] = 25200, N[0x4524, ((4, 0), (4, 1))] = 1

--- Simulation 97 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.991006929995, 16802.991006929995, 21262.268355767857, 16802.991006929995, 19602.991006929995]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4561, Score: 8400
Depth 2: State = 0x4561, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4561: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x482c, Score: 11200
Depth 3: State = 0x482c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x482c: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4858, Score: 14000
Depth 4: State = 0x4858, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4858: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x5288, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 1975700, N[0x3c25, ((2, 3), (2, 4))] = 93
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4561, ((0, 1), (0, 2))] = 19600, N[0x4561, ((0, 1), (0, 2))] = 1
Updated Q[0x482c, ((1, 2), (2, 2))] = 19600, N[0x482c, ((1, 2), (2, 2))] = 1
Updated Q[0x4858, ((2, 0), (2, 1))] = 19600, N[0x4858, ((2, 0), (2, 1))] = 1

--- Simulation 98 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.994400360316, 16802.994400360316, 21244.39652635821, 16802.994400360316, 19602.994400360316]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c61, Score: 8400
Depth 1: State = 0x3c61, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c61: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x1d51, Score: 14000
Depth 2: State = 0x1d51, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1d51: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x231d, Score: 16800
Depth 3: State = 0x231d, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x231d: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x21ca, Score: 19600
Depth 4: State = 0x21ca, Legal Moves = [((0, 0), (0, 1)), ((0, 0), (1, 0)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((2, 0), (2, 1))]
UCB1 values for moves at state 0x21ca: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1dd2, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2000900, N[0x3c25, ((2, 3), (2, 4))] = 94
Updated Q[0x3c61, ((1, 3), (2, 3))] = 25200, N[0x3c61, ((1, 3), (2, 3))] = 1
Updated Q[0x1d51, ((1, 3), (2, 3))] = 25200, N[0x1d51, ((1, 3), (2, 3))] = 1
Updated Q[0x231d, ((2, 0), (2, 1))] = 25200, N[0x231d, ((2, 0), (2, 1))] = 1
Updated Q[0x21ca, ((0, 0), (0, 1))] = 25200, N[0x21ca, ((0, 0), (0, 1))] = 1

--- Simulation 99 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19602.99775520318, 16802.99775520318, 21286.479407606723, 16802.99775520318, 19602.99775520318]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4956, Score: 8400
Depth 2: State = 0x4956, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4956: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4412, Score: 11200
Depth 3: State = 0x4412, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4412: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x480a, Score: 14000
Depth 4: State = 0x480a, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x480a: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x45af, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2017700, N[0x3c25, ((2, 3), (2, 4))] = 95
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4956, ((0, 3), (1, 3))] = 16800, N[0x4956, ((0, 3), (1, 3))] = 1
Updated Q[0x4412, ((2, 0), (2, 1))] = 16800, N[0x4412, ((2, 0), (2, 1))] = 1
Updated Q[0x480a, ((0, 1), (1, 1))] = 16800, N[0x480a, ((0, 1), (1, 1))] = 1

--- Simulation 100 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.001072292744, 16803.001072292744, 21239.255271941594, 16803.001072292744, 19603.001072292744]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x44f9, Score: 8400
Depth 2: State = 0x44f9, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x44f9: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x4678, Score: 11200
Depth 3: State = 0x4678, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4678: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x469a, Score: 14000
Depth 4: State = 0x469a, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x469a: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x43f4, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2034500, N[0x3c25, ((2, 3), (2, 4))] = 96
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x44f9, ((0, 1), (1, 1))] = 16800, N[0x44f9, ((0, 1), (1, 1))] = 1
Updated Q[0x4678, ((0, 1), (0, 2))] = 16800, N[0x4678, ((0, 1), (0, 2))] = 1
Updated Q[0x469a, ((1, 1), (2, 1))] = 16800, N[0x469a, ((1, 1), (2, 1))] = 1

--- Simulation 101 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.004352436805, 16803.004352436805, 21193.0149637699, 16803.004352436805, 19603.004352436805]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4aed, Score: 8400
Depth 2: State = 0x4aed, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aed: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x466d, Score: 11200
Depth 3: State = 0x466d, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x466d: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x43c7, Score: 14000
Depth 4: State = 0x43c7, Legal Moves = [((2, 1), (2, 2)), ((2, 3), (2, 4)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x43c7: [inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x5818, Score: 38100
End of simulation with depth 5. Reward (Score): 38100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2072600, N[0x3c25, ((2, 3), (2, 4))] = 97
Updated Q[0x3c24, ((0, 0), (0, 1))] = 38100, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4aed, ((0, 3), (1, 3))] = 38100, N[0x4aed, ((0, 3), (1, 3))] = 1
Updated Q[0x466d, ((2, 0), (2, 1))] = 38100, N[0x466d, ((2, 0), (2, 1))] = 1
Updated Q[0x43c7, ((2, 1), (2, 2))] = 38100, N[0x43c7, ((2, 1), (2, 2))] = 1

--- Simulation 102 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.00759641791, 16803.00759641791, 21367.31568442727, 16803.00759641791, 19603.00759641791]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43b4, Score: 8400
Depth 2: State = 0x43b4, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43b4: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x443d, Score: 11200
Depth 3: State = 0x443d, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443d: [inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x442e, Score: 14000
Depth 4: State = 0x442e, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x442e: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4a6d, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2089400, N[0x3c25, ((2, 3), (2, 4))] = 98
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x43b4, ((1, 2), (2, 2))] = 16800, N[0x43b4, ((1, 2), (2, 2))] = 1
Updated Q[0x443d, ((0, 3), (0, 4))] = 16800, N[0x443d, ((0, 3), (0, 4))] = 1
Updated Q[0x442e, ((0, 2), (1, 2))] = 16800, N[0x442e, ((0, 2), (1, 2))] = 1

--- Simulation 103 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.010804994356, 16803.010804994356, 21320.712300497926, 16803.010804994356, 19603.010804994356]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d36, Score: 11200
Depth 2: State = 0x3d36, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d36: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3db5, Score: 19600
Depth 3: State = 0x3db5, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2109000, N[0x3c25, ((2, 3), (2, 4))] = 99
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3d36, ((2, 0), (2, 1))] = 19600, N[0x3d36, ((2, 0), (2, 1))] = 1

--- Simulation 104 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.01397890121, 16803.01397890121, 21303.333219307315, 16803.01397890121, 19603.01397890121]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c07, Score: 8400
Depth 1: State = 0x3c07, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c07: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x391c, Score: 11200
Depth 2: State = 0x391c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x391c: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3975, Score: 14000
Depth 3: State = 0x3975, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3975: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3670, Score: 16800
Depth 4: State = 0x3670, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3670: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3d0e, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2128600, N[0x3c25, ((2, 3), (2, 4))] = 100
Updated Q[0x3c07, ((0, 1), (0, 2))] = 19600, N[0x3c07, ((0, 1), (0, 2))] = 1
Updated Q[0x391c, ((1, 2), (2, 2))] = 19600, N[0x391c, ((1, 2), (2, 2))] = 1
Updated Q[0x3975, ((0, 3), (1, 3))] = 19600, N[0x3975, ((0, 3), (1, 3))] = 1
Updated Q[0x3670, ((1, 1), (2, 1))] = 19600, N[0x3670, ((1, 1), (2, 1))] = 1

--- Simulation 105 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.017118851207, 16803.017118851207, 21286.30171188512, 16803.017118851207, 19603.017118851207]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x482b, Score: 8400
Depth 2: State = 0x482b, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x482b: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x47eb, Score: 11200
Depth 3: State = 0x47eb, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47eb: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x47e4, Score: 14000
Depth 4: State = 0x47e4, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47e4: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x53f0, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2151000, N[0x3c25, ((2, 3), (2, 4))] = 101
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x482b, ((1, 3), (2, 3))] = 22400, N[0x482b, ((1, 3), (2, 3))] = 1
Updated Q[0x47eb, ((0, 3), (1, 3))] = 22400, N[0x47eb, ((0, 3), (1, 3))] = 1
Updated Q[0x47e4, ((2, 0), (2, 1))] = 22400, N[0x47e4, ((2, 0), (2, 1))] = 1

--- Simulation 106 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.02022553567, 16803.02022553567, 21297.33022664338, 16803.02022553567, 19603.02022553567]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4ad6, Score: 8400
Depth 2: State = 0x4ad6, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ad6: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x47cb, Score: 19600
Depth 3: State = 0x47cb, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47cb: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4671, Score: 25200
Depth 4: State = 0x4671, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4671: [inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x47e2, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2179000, N[0x3c25, ((2, 3), (2, 4))] = 102
Updated Q[0x3c25, ((0, 0), (0, 1))] = 28000, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4ad6, ((1, 3), (2, 3))] = 28000, N[0x4ad6, ((1, 3), (2, 3))] = 1
Updated Q[0x47cb, ((0, 1), (0, 2))] = 28000, N[0x47cb, ((0, 1), (0, 2))] = 1
Updated Q[0x4671, ((0, 1), (1, 1))] = 28000, N[0x4671, ((0, 1), (1, 1))] = 1

--- Simulation 107 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.02329962532, 16803.02329962532, 21363.044449308785, 16803.02329962532, 19603.02329962532]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x466e, Score: 8400
Depth 2: State = 0x466e, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x466e: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4546, Score: 13300
Depth 3: State = 0x4546, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4546: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4698, Score: 16100
Depth 4: State = 0x4698, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4698: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x47eb, Score: 18900
End of simulation with depth 5. Reward (Score): 18900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2197900, N[0x3c25, ((2, 3), (2, 4))] = 103
Updated Q[0x3c25, ((0, 0), (0, 1))] = 18900, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x466e, ((0, 3), (1, 3))] = 18900, N[0x466e, ((0, 3), (1, 3))] = 1
Updated Q[0x4546, ((0, 1), (0, 2))] = 18900, N[0x4546, ((0, 1), (0, 2))] = 1
Updated Q[0x4698, ((1, 1), (2, 1))] = 18900, N[0x4698, ((1, 1), (2, 1))] = 1

--- Simulation 108 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.026341771107, 16803.026341771107, 21339.133145771593, 16803.026341771107, 19603.026341771107]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4923, Score: 8400
Depth 2: State = 0x4923, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4923: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4935, Score: 11200
Depth 3: State = 0x4935, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4935: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x453d, Score: 14000
Depth 4: State = 0x453d, Legal Moves = [((0, 1), (0, 2)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x453d: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4690, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2214700, N[0x3c25, ((2, 3), (2, 4))] = 104
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4923, ((1, 2), (2, 2))] = 16800, N[0x4923, ((1, 2), (2, 2))] = 1
Updated Q[0x4935, ((2, 0), (2, 1))] = 16800, N[0x4935, ((2, 0), (2, 1))] = 1
Updated Q[0x453d, ((0, 1), (0, 2))] = 16800, N[0x453d, ((0, 1), (0, 2))] = 1

--- Simulation 109 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.029352604957, 16803.029352604957, 21295.489360154737, 16803.029352604957, 19603.029352604957]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c4c, Score: 8400
Depth 1: State = 0x3c4c, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4c: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3ab6, Score: 11200
Depth 2: State = 0x3ab6, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3ab6: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3974, Score: 14000
Depth 3: State = 0x3974, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3974: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x46d2, Score: 19600
Depth 4: State = 0x46d2, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46d2: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x5430, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2237100, N[0x3c25, ((2, 3), (2, 4))] = 105
Updated Q[0x3c4c, ((0, 0), (1, 0))] = 22400, N[0x3c4c, ((0, 0), (1, 0))] = 1
Updated Q[0x3ab6, ((1, 3), (2, 3))] = 22400, N[0x3ab6, ((1, 3), (2, 3))] = 1
Updated Q[0x3974, ((0, 1), (1, 1))] = 22400, N[0x3974, ((0, 1), (1, 1))] = 1
Updated Q[0x46d2, ((1, 0), (2, 0))] = 22400, N[0x46d2, ((1, 0), (2, 0))] = 1

--- Simulation 110 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.03233274051, 16803.03233274051, 21306.010211088553, 16803.03233274051, 19603.03233274051]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4ab3, Score: 8400
Depth 2: State = 0x4ab3, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab3: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x43f6, Score: 14000
Depth 3: State = 0x43f6, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x43f6: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4942, Score: 16800
Depth 4: State = 0x4942, Legal Moves = [((0, 2), (0, 3)), ((3, 1), (3, 2)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x4942: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x1ebf, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2256700, N[0x3c25, ((2, 3), (2, 4))] = 106
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4ab3, ((1, 3), (1, 4))] = 19600, N[0x4ab3, ((1, 3), (1, 4))] = 1
Updated Q[0x43f6, ((2, 0), (2, 1))] = 19600, N[0x43f6, ((2, 0), (2, 1))] = 1
Updated Q[0x4942, ((0, 2), (0, 3))] = 19600, N[0x4942, ((0, 2), (0, 3))] = 1

--- Simulation 111 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.035282773806, 16803.035282773806, 21289.91745423408, 16803.035282773806, 19603.035282773806]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4903, Score: 19600
Depth 2: State = 0x4903, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (0, 2)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((3, 0), (3, 1)), ((3, 2), (4, 2))]
UCB1 values for moves at state 0x4903: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x57f7, Score: 22400
Depth 3: State = 0x57f7, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x57f7: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x550e, Score: 25200
Depth 4: State = 0x550e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x550e: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x54fc, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2284700, N[0x3c25, ((2, 3), (2, 4))] = 107
Updated Q[0x3c24, ((1, 3), (1, 4))] = 28000, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x4903, ((0, 0), (1, 0))] = 28000, N[0x4903, ((0, 0), (1, 0))] = 1
Updated Q[0x57f7, ((0, 1), (0, 2))] = 28000, N[0x57f7, ((0, 1), (0, 2))] = 1
Updated Q[0x550e, ((1, 3), (2, 3))] = 28000, N[0x550e, ((1, 3), (2, 3))] = 1

--- Simulation 112 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.038203283944, 16803.038203283944, 21352.630162795704, 16803.038203283944, 19603.038203283944]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22400.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c5f, Score: 13300
Depth 2: State = 0x3c5f, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5f: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4580, Score: 16100
Depth 3: State = 0x4580, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4580: [inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x39b9, Score: 18900
Depth 4: State = 0x39b9, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39b9: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c5f, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2306400, N[0x3c25, ((2, 3), (2, 4))] = 108
Updated Q[0x3c25, ((1, 3), (2, 3))] = 21700, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3c5f, ((1, 2), (1, 3))] = 21700, N[0x3c5f, ((1, 2), (1, 3))] = 1
Updated Q[0x4580, ((0, 1), (1, 1))] = 21700, N[0x4580, ((0, 1), (1, 1))] = 1
Updated Q[0x39b9, ((2, 0), (2, 1))] = 21700, N[0x39b9, ((2, 0), (2, 1))] = 1

--- Simulation 113 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.04109483373, 16803.04109483373, 21355.84818504237, 16803.04109483373, 19603.04109483373]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4584, Score: 8400
Depth 2: State = 0x4584, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4584: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x482a, Score: 11200
Depth 3: State = 0x482a, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x482a: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4570, Score: 14000
Depth 4: State = 0x4570, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (4, 2))]
UCB1 values for moves at state 0x4570: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4569, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2323200, N[0x3c25, ((2, 3), (2, 4))] = 109
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4584, ((1, 3), (2, 3))] = 16800, N[0x4584, ((1, 3), (2, 3))] = 1
Updated Q[0x482a, ((1, 2), (2, 2))] = 16800, N[0x482a, ((1, 2), (2, 2))] = 1
Updated Q[0x4570, ((1, 3), (1, 4))] = 16800, N[0x4570, ((1, 3), (1, 4))] = 1

--- Simulation 114 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.043957970254, 16803.043957970254, 21314.05302618541, 16803.043957970254, 19603.043957970254]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4afb, Score: 8400
Depth 2: State = 0x4afb, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4afb: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x495a, Score: 11200
Depth 3: State = 0x495a, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x495a: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2184, Score: 16800
Depth 4: State = 0x2184, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (0, 2)), ((1, 2), (1, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2184: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x104f, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2342800, N[0x3c25, ((2, 3), (2, 4))] = 110
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4afb, ((1, 3), (2, 3))] = 19600, N[0x4afb, ((1, 3), (2, 3))] = 1
Updated Q[0x495a, ((2, 0), (2, 1))] = 19600, N[0x495a, ((2, 0), (2, 1))] = 1
Updated Q[0x2184, ((0, 0), (0, 1))] = 19600, N[0x2184, ((0, 0), (0, 1))] = 1

--- Simulation 115 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.046793225483, 16803.046793225483, 21298.472318517586, 16803.046793225483, 19603.046793225483]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 21701.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d99, Score: 19600
Depth 2: State = 0x3d99, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d99: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x390f, Score: 25200
Depth 3: State = 0x390f, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2368000, N[0x3c25, ((2, 3), (2, 4))] = 111
Updated Q[0x3c24, ((1, 3), (2, 3))] = 25200, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3d99, ((2, 0), (2, 1))] = 25200, N[0x3d99, ((2, 0), (2, 1))] = 1

--- Simulation 116 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.0496011168, 16803.0496011168, 21333.62278866172, 16803.0496011168, 19603.0496011168]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43f3, Score: 8400
Depth 2: State = 0x43f3, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43f3: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x45a1, Score: 16100
Depth 3: State = 0x45a1, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a1: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4847, Score: 18900
Depth 4: State = 0x4847, Legal Moves = [((2, 1), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4847: [inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x53cb, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2389700, N[0x3c25, ((2, 3), (2, 4))] = 112
Updated Q[0x3c24, ((0, 0), (0, 1))] = 21700, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43f3, ((1, 3), (2, 3))] = 21700, N[0x43f3, ((1, 3), (2, 3))] = 1
Updated Q[0x45a1, ((2, 0), (2, 1))] = 21700, N[0x45a1, ((2, 0), (2, 1))] = 1
Updated Q[0x4847, ((2, 1), (3, 1))] = 21700, N[0x4847, ((2, 1), (3, 1))] = 1

--- Simulation 117 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.052382147533, 16803.052382147533, 21336.895565859595, 16803.052382147533, 19603.052382147533]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4aee, Score: 8400
Depth 2: State = 0x4aee, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aee: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x45a9, Score: 11200
Depth 3: State = 0x45a9, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a9: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x484f, Score: 14000
Depth 4: State = 0x484f, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2))]
UCB1 values for moves at state 0x484f: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x2c5e, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2412100, N[0x3c25, ((2, 3), (2, 4))] = 113
Updated Q[0x3c25, ((0, 0), (0, 1))] = 22400, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4aee, ((0, 3), (1, 3))] = 22400, N[0x4aee, ((0, 3), (1, 3))] = 1
Updated Q[0x45a9, ((2, 0), (2, 1))] = 22400, N[0x45a9, ((2, 0), (2, 1))] = 1
Updated Q[0x484f, ((1, 1), (2, 1))] = 22400, N[0x484f, ((1, 1), (2, 1))] = 1

--- Simulation 118 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.055136807445, 16803.055136807445, 21346.305102210095, 16803.055136807445, 19603.055136807445]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c6b, Score: 14000
Depth 2: State = 0x3c6b, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 0), (1, 1)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3c6b: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x20a0, Score: 16800
Depth 3: State = 0x20a0, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x20a0: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x2096, Score: 22400
Depth 4: State = 0x2096, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2096: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2096, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2437300, N[0x3c25, ((2, 3), (2, 4))] = 114
Updated Q[0x3c24, ((1, 3), (2, 3))] = 25200, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3c6b, ((0, 1), (1, 1))] = 25200, N[0x3c6b, ((0, 1), (1, 1))] = 1
Updated Q[0x20a0, ((0, 3), (1, 3))] = 25200, N[0x20a0, ((0, 3), (1, 3))] = 1
Updated Q[0x2096, ((2, 0), (2, 1))] = 25200, N[0x2096, ((2, 0), (2, 1))] = 1

--- Simulation 119 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.05786557323, 16803.05786557323, 21380.11095675447, 16803.05786557323, 19603.05786557323]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c4d, Score: 8400
Depth 1: State = 0x3c4d, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4d: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x541f, Score: 11200
Depth 2: State = 0x541f, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x541f: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x5136, Score: 14000
Depth 3: State = 0x5136, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5136: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x5136, Score: 16800
Depth 4: State = 0x5136, Legal Moves = [((2, 3), (2, 4))]
UCB1 values for moves at state 0x5136: [inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x512c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2456900, N[0x3c25, ((2, 3), (2, 4))] = 115
Updated Q[0x3c4d, ((0, 0), (1, 0))] = 19600, N[0x3c4d, ((0, 0), (1, 0))] = 1
Updated Q[0x541f, ((1, 3), (1, 4))] = 19600, N[0x541f, ((1, 3), (1, 4))] = 1
Updated Q[0x5136, ((1, 1), (2, 1))] = 19600, N[0x5136, ((1, 1), (2, 1))] = 1
Updated Q[0x5136, ((2, 3), (2, 4))] = 19600, N[0x5136, ((2, 3), (2, 4))] = 1

--- Simulation 120 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.06056890896, 16803.06056890896, 21364.633225609312, 16803.06056890896, 19603.06056890896]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c40, Score: 8400
Depth 1: State = 0x3c40, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c40: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x29b9, Score: 11200
Depth 2: State = 0x29b9, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x29b9: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x2977, Score: 14000
Depth 3: State = 0x2977, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2977: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x10b1, Score: 16800
Depth 4: State = 0x10b1, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x10b1: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x10b2, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2476500, N[0x3c25, ((2, 3), (2, 4))] = 116
Updated Q[0x3c40, ((0, 0), (1, 0))] = 19600, N[0x3c40, ((0, 0), (1, 0))] = 1
Updated Q[0x29b9, ((1, 2), (2, 2))] = 19600, N[0x29b9, ((1, 2), (2, 2))] = 1
Updated Q[0x2977, ((0, 0), (0, 1))] = 19600, N[0x2977, ((0, 0), (0, 1))] = 1
Updated Q[0x10b1, ((0, 4), (1, 4))] = 19600, N[0x10b1, ((0, 4), (1, 4))] = 1

--- Simulation 121 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.06324726652, 16803.06324726652, 21349.422346403022, 16803.06324726652, 19603.06324726652]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4430, Score: 8400
Depth 2: State = 0x4430, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4430: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x46be, Score: 11200
Depth 3: State = 0x46be, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46be: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x46b7, Score: 14000
Depth 4: State = 0x46b7, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46b7: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x44ff, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2498200, N[0x3c25, ((2, 3), (2, 4))] = 117
Updated Q[0x3c24, ((0, 0), (0, 1))] = 21700, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4430, ((1, 3), (2, 3))] = 21700, N[0x4430, ((1, 3), (2, 3))] = 1
Updated Q[0x46be, ((0, 3), (1, 3))] = 21700, N[0x46be, ((0, 3), (1, 3))] = 1
Updated Q[0x46b7, ((1, 2), (1, 3))] = 21700, N[0x46b7, ((1, 2), (1, 3))] = 1

--- Simulation 122 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.065901086036, 16803.065901086036, 21352.420194792427, 16803.065901086036, 19603.065901086036]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4815, Score: 8400
Depth 2: State = 0x4815, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4815: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4add, Score: 11200
Depth 3: State = 0x4add, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4add: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4ab1, Score: 14000
Depth 4: State = 0x4ab1, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x4ab1: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2f07, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2517800, N[0x3c25, ((2, 3), (2, 4))] = 118
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4815, ((0, 3), (1, 3))] = 19600, N[0x4815, ((0, 3), (1, 3))] = 1
Updated Q[0x4add, ((1, 2), (2, 2))] = 19600, N[0x4add, ((1, 2), (2, 2))] = 1
Updated Q[0x4ab1, ((2, 0), (2, 1))] = 19600, N[0x4ab1, ((2, 0), (2, 1))] = 1

--- Simulation 123 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.068530796274, 16803.068530796274, 21337.57061674975, 16803.068530796274, 19603.068530796274]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 19601.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4524, Score: 11200
Depth 2: State = 0x4524, Legal Moves = [((0, 3), (0, 4)), ((1, 0), (1, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4524: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x47c0, Score: 14000
Depth 3: State = 0x47c0, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((1, 0), (1, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x47c0: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x39a1, Score: 21700
Depth 4: State = 0x39a1, Legal Moves = [((2, 1), (2, 2)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x39a1: [inf, inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x3953, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2542300, N[0x3c25, ((2, 3), (2, 4))] = 119
Updated Q[0x3c24, ((2, 0), (2, 1))] = 24500, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x4524, ((0, 3), (0, 4))] = 24500, N[0x4524, ((0, 3), (0, 4))] = 1
Updated Q[0x47c0, ((0, 1), (1, 1))] = 24500, N[0x47c0, ((0, 1), (1, 1))] = 1
Updated Q[0x39a1, ((2, 1), (2, 2))] = 24500, N[0x39a1, ((2, 1), (2, 2))] = 1

--- Simulation 124 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.071136815015, 16803.071136815015, 21364.147076868736, 16803.071136815015, 19603.071136815015]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c1a, Score: 8400
Depth 1: State = 0x3c1a, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1a: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x397b, Score: 11200
Depth 2: State = 0x397b, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x397b: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4433, Score: 24900
Depth 3: State = 0x4433, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 24900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2567200, N[0x3c25, ((2, 3), (2, 4))] = 120
Updated Q[0x3c1a, ((0, 3), (1, 3))] = 24900, N[0x3c1a, ((0, 3), (1, 3))] = 1
Updated Q[0x397b, ((2, 0), (2, 1))] = 24900, N[0x397b, ((2, 0), (2, 1))] = 1

--- Simulation 125 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.073719549437, 16803.073719549437, 21393.613924255445, 16803.073719549437, 19603.073719549437]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x39bf, Score: 11200
Depth 2: State = 0x39bf, Legal Moves = [((0, 1), (0, 2)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39bf: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3da1, Score: 14000
Depth 3: State = 0x3da1, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3da1: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x118e, Score: 16800
Depth 4: State = 0x118e, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x118e: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0xee8d, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2586800, N[0x3c25, ((2, 3), (2, 4))] = 121
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x39bf, ((0, 1), (0, 2))] = 19600, N[0x39bf, ((0, 1), (0, 2))] = 1
Updated Q[0x3da1, ((0, 2), (1, 2))] = 19600, N[0x3da1, ((0, 2), (1, 2))] = 1
Updated Q[0x118e, ((2, 0), (2, 1))] = 19600, N[0x118e, ((2, 0), (2, 1))] = 1

--- Simulation 126 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.076279396464, 16803.076279396464, 21378.79205845753, 16803.076279396464, 19603.076279396464]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x453c, Score: 8400
Depth 2: State = 0x453c, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x453c: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x454a, Score: 14000
Depth 3: State = 0x454a, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x454a: [inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x454b, Score: 19600
Depth 4: State = 0x454b, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x454b: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x454b, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2617300, N[0x3c25, ((2, 3), (2, 4))] = 122
Updated Q[0x3c24, ((0, 0), (0, 1))] = 30500, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x453c, ((0, 3), (1, 3))] = 30500, N[0x453c, ((0, 3), (1, 3))] = 1
Updated Q[0x454a, ((0, 3), (0, 4))] = 30500, N[0x454a, ((0, 3), (0, 4))] = 1
Updated Q[0x454b, ((2, 0), (2, 1))] = 30500, N[0x454b, ((2, 0), (2, 1))] = 1

--- Simulation 127 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.078816743106, 16803.078816743106, 21453.557431495356, 16803.078816743106, 19603.078816743106]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4540, Score: 8400
Depth 2: State = 0x4540, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4540: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x47a1, Score: 14000
Depth 3: State = 0x47a1, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47a1: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x467e, Score: 16800
Depth 4: State = 0x467e, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x467e: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4655, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2636900, N[0x3c25, ((2, 3), (2, 4))] = 123
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4540, ((1, 3), (2, 3))] = 19600, N[0x4540, ((1, 3), (2, 3))] = 1
Updated Q[0x47a1, ((1, 2), (2, 2))] = 19600, N[0x47a1, ((1, 2), (2, 2))] = 1
Updated Q[0x467e, ((0, 3), (1, 3))] = 19600, N[0x467e, ((0, 3), (1, 3))] = 1

--- Simulation 128 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.081331966772, 16803.081331966772, 21438.4892164607, 16803.081331966772, 19603.081331966772]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1c1d, Score: 11200
Depth 2: State = 0x1c1d, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 4), (2, 4)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1c1d: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x1c61, Score: 14000
Depth 3: State = 0x1c61, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((1, 4), (2, 4)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1c61: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x1fe9, Score: 16800
Depth 4: State = 0x1fe9, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 2), (2, 2)), ((1, 4), (2, 4)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1fe9: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x2074, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2664600, N[0x3c25, ((2, 3), (2, 4))] = 124
Updated Q[0x3c24, ((2, 0), (2, 1))] = 27700, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x1c1d, ((0, 1), (1, 1))] = 27700, N[0x1c1d, ((0, 1), (1, 1))] = 1
Updated Q[0x1c61, ((1, 0), (1, 1))] = 27700, N[0x1c61, ((1, 0), (1, 1))] = 1
Updated Q[0x1fe9, ((0, 1), (1, 1))] = 27700, N[0x1fe9, ((0, 1), (1, 1))] = 1

--- Simulation 129 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.083825435606, 16803.083825435606, 21488.986613118737, 16803.083825435606, 19603.083825435606]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c6c, Score: 14000
Depth 1: State = 0x3c6c, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6c: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3975, Score: 16800
Depth 2: State = 0x3975, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3975: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4957, Score: 19600
Depth 3: State = 0x4957, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4957: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4804, Score: 22400
Depth 4: State = 0x4804, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (1, 1)), ((0, 3), (0, 4)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 2), (2, 3)), ((2, 3), (2, 4))]
UCB1 values for moves at state 0x4804: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x228f, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2689800, N[0x3c25, ((2, 3), (2, 4))] = 125
Updated Q[0x3c6c, ((1, 3), (2, 3))] = 25200, N[0x3c6c, ((1, 3), (2, 3))] = 1
Updated Q[0x3975, ((1, 2), (1, 3))] = 25200, N[0x3975, ((1, 2), (1, 3))] = 1
Updated Q[0x4957, ((1, 1), (2, 1))] = 25200, N[0x4957, ((1, 1), (2, 1))] = 1
Updated Q[0x4804, ((0, 0), (1, 0))] = 25200, N[0x4804, ((0, 0), (1, 0))] = 1

--- Simulation 130 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.086297508755, 16803.086297508755, 21518.676046841138, 16803.086297508755, 19603.086297508755]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47ca, Score: 8400
Depth 2: State = 0x47ca, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47ca: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x482f, Score: 14000
Depth 3: State = 0x482f, Legal Moves = [((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x482f: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x4830, Score: 16800
Depth 4: State = 0x4830, Legal Moves = [((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x4830: [inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x4830, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2709400, N[0x3c25, ((2, 3), (2, 4))] = 126
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47ca, ((1, 2), (2, 2))] = 19600, N[0x47ca, ((1, 2), (2, 2))] = 1
Updated Q[0x482f, ((0, 4), (1, 4))] = 19600, N[0x482f, ((0, 4), (1, 4))] = 1
Updated Q[0x4830, ((0, 4), (1, 4))] = 19600, N[0x4830, ((0, 4), (1, 4))] = 1

--- Simulation 131 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.088748536687, 16803.088748536687, 21503.44977076456, 16803.088748536687, 19603.088748536687]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c0a, Score: 8400
Depth 1: State = 0x3c0a, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c0a: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3be0, Score: 11200
Depth 2: State = 0x3be0, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be0: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3bdd, Score: 14000
Depth 3: State = 0x3bdd, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bdd: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3bde, Score: 16800
Depth 4: State = 0x3bde, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bde: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3be7, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2729000, N[0x3c25, ((2, 3), (2, 4))] = 127
Updated Q[0x3c0a, ((1, 2), (2, 2))] = 19600, N[0x3c0a, ((1, 2), (2, 2))] = 1
Updated Q[0x3be0, ((0, 3), (1, 3))] = 19600, N[0x3be0, ((0, 3), (1, 3))] = 1
Updated Q[0x3bdd, ((1, 3), (1, 4))] = 19600, N[0x3bdd, ((1, 3), (1, 4))] = 1
Updated Q[0x3bde, ((0, 3), (0, 4))] = 19600, N[0x3bde, ((0, 3), (0, 4))] = 1

--- Simulation 132 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.09117886145, 16803.09117886145, 21488.4632741464, 16803.09117886145, 19603.09117886145]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3af6, Score: 16800
Depth 2: State = 0x3af6, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3af6: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3d4b, Score: 19600
Depth 3: State = 0x3d4b, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d4b: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x36cf, Score: 22400
Depth 4: State = 0x36cf, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36cf: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36cf, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2754200, N[0x3c25, ((2, 3), (2, 4))] = 128
Updated Q[0x3c24, ((1, 3), (2, 3))] = 25200, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3af6, ((0, 1), (1, 1))] = 25200, N[0x3af6, ((0, 1), (1, 1))] = 1
Updated Q[0x3d4b, ((0, 0), (1, 0))] = 25200, N[0x3d4b, ((0, 0), (1, 0))] = 1
Updated Q[0x36cf, ((2, 0), (2, 1))] = 25200, N[0x36cf, ((2, 0), (2, 1))] = 1

--- Simulation 133 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.093588816937, 16803.093588816937, 21517.460937203832, 16803.093588816937, 19603.093588816937]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x53ce, Score: 13300
Depth 2: State = 0x53ce, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x53ce: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x5524, Score: 16100
Depth 3: State = 0x5524, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5524: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x5103, Score: 18900
Depth 4: State = 0x5103, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5103: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x50e4, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2778700, N[0x3c25, ((2, 3), (2, 4))] = 129
Updated Q[0x3c24, ((0, 0), (0, 1))] = 24500, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x53ce, ((1, 3), (2, 3))] = 24500, N[0x53ce, ((1, 3), (2, 3))] = 1
Updated Q[0x5524, ((0, 1), (1, 1))] = 24500, N[0x5524, ((0, 1), (1, 1))] = 1
Updated Q[0x5103, ((0, 3), (1, 3))] = 24500, N[0x5103, ((0, 3), (1, 3))] = 1

--- Simulation 134 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.095978729143, 16803.095978729143, 21540.582663247187, 16803.095978729143, 19603.095978729143]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46f4, Score: 8400
Depth 2: State = 0x46f4, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46f4: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x464e, Score: 11200
Depth 3: State = 0x464e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x464e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x464e, Score: 14000
Depth 4: State = 0x464e, Legal Moves = [((2, 1), (2, 2)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x464e: [inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x46f5, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2795500, N[0x3c25, ((2, 3), (2, 4))] = 130
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46f4, ((0, 2), (1, 2))] = 16800, N[0x46f4, ((0, 2), (1, 2))] = 1
Updated Q[0x464e, ((2, 0), (2, 1))] = 16800, N[0x464e, ((2, 0), (2, 1))] = 1
Updated Q[0x464e, ((2, 1), (2, 2))] = 16800, N[0x464e, ((2, 1), (2, 2))] = 1

--- Simulation 135 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.098348916425, 16803.098348916425, 21504.11789702253, 16803.098348916425, 19603.098348916425]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c65, Score: 8400
Depth 2: State = 0x3c65, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c65: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3917, Score: 19300
Depth 3: State = 0x3917, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3917: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3917, Score: 22100
Depth 4: State = 0x3917, Legal Moves = [((1, 1), (2, 1))]
UCB1 values for moves at state 0x3917: [inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x1dfc, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2823200, N[0x3c25, ((2, 3), (2, 4))] = 131
Updated Q[0x3c24, ((0, 2), (1, 2))] = 27700, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c65, ((1, 3), (1, 4))] = 27700, N[0x3c65, ((1, 3), (1, 4))] = 1
Updated Q[0x3917, ((2, 0), (2, 1))] = 27700, N[0x3917, ((2, 0), (2, 1))] = 1
Updated Q[0x3917, ((1, 1), (2, 1))] = 27700, N[0x3917, ((1, 1), (2, 1))] = 1

--- Simulation 136 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.100699689705, 16803.100699689705, 21551.415947557678, 16803.100699689705, 19603.100699689705]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43d9, Score: 8400
Depth 2: State = 0x43d9, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43d9: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x45a2, Score: 11200
Depth 3: State = 0x45a2, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a2: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4aaa, Score: 14000
Depth 4: State = 0x4aaa, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aaa: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x451b, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2842800, N[0x3c25, ((2, 3), (2, 4))] = 132
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x43d9, ((1, 3), (2, 3))] = 19600, N[0x43d9, ((1, 3), (2, 3))] = 1
Updated Q[0x45a2, ((0, 1), (0, 2))] = 19600, N[0x45a2, ((0, 1), (0, 2))] = 1
Updated Q[0x4aaa, ((0, 3), (1, 3))] = 19600, N[0x4aaa, ((0, 3), (1, 3))] = 1

--- Simulation 137 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.103031352734, 16803.103031352734, 21536.633720575755, 16803.103031352734, 19603.103031352734]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bdb, Score: 8400
Depth 1: State = 0x3bdb, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bdb: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3871, Score: 11200
Depth 2: State = 0x3871, Legal Moves = [((0, 1), (0, 2)), ((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3871: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3d78, Score: 14000
Depth 3: State = 0x3d78, Legal Moves = [((0, 0), (0, 1)), ((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d78: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x5812, Score: 16800
Depth 4: State = 0x5812, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5812: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3080, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2862400, N[0x3c25, ((2, 3), (2, 4))] = 133
Updated Q[0x3bdb, ((1, 3), (2, 3))] = 19600, N[0x3bdb, ((1, 3), (2, 3))] = 1
Updated Q[0x3871, ((0, 1), (0, 2))] = 19600, N[0x3871, ((0, 1), (0, 2))] = 1
Updated Q[0x3d78, ((0, 0), (0, 1))] = 19600, N[0x3d78, ((0, 0), (0, 1))] = 1
Updated Q[0x5812, ((0, 2), (1, 2))] = 19600, N[0x5812, ((0, 2), (1, 2))] = 1

--- Simulation 138 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.10534420228, 16803.10534420228, 21522.073778769856, 16803.10534420228, 19603.10534420228]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47a1, Score: 8400
Depth 2: State = 0x47a1, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x47a1: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4811, Score: 11200
Depth 3: State = 0x4811, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4811: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x47a1, Score: 14000
Depth 4: State = 0x47a1, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47a1: [inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x4807, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2879200, N[0x3c25, ((2, 3), (2, 4))] = 134
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47a1, ((1, 2), (2, 2))] = 16800, N[0x47a1, ((1, 2), (2, 2))] = 1
Updated Q[0x4811, ((1, 2), (2, 2))] = 16800, N[0x4811, ((1, 2), (2, 2))] = 1
Updated Q[0x47a1, ((1, 1), (1, 2))] = 16800, N[0x47a1, ((1, 1), (1, 2))] = 1

--- Simulation 139 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.107638528352, 16803.107638528352, 21486.835623259383, 16803.107638528352, 19603.107638528352]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4653, Score: 8400
Depth 2: State = 0x4653, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4653: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4588, Score: 11200
Depth 3: State = 0x4588, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4588: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4588, Score: 14000
Depth 4: State = 0x4588, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (0, 2)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x4588: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2079, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2901600, N[0x3c25, ((2, 3), (2, 4))] = 135
Updated Q[0x3c25, ((0, 0), (0, 1))] = 22400, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4653, ((1, 3), (2, 3))] = 22400, N[0x4653, ((1, 3), (2, 3))] = 1
Updated Q[0x4588, ((1, 1), (2, 1))] = 22400, N[0x4588, ((1, 1), (2, 1))] = 1
Updated Q[0x4588, ((0, 0), (0, 1))] = 22400, N[0x4588, ((0, 0), (0, 1))] = 1

--- Simulation 140 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.10991461441, 16803.10991461441, 21493.60099216688, 16803.10991461441, 19603.10991461441]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4935, Score: 8400
Depth 2: State = 0x4935, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4935: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4939, Score: 11200
Depth 3: State = 0x4939, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4939: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4540, Score: 14000
Depth 4: State = 0x4540, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2915600, N[0x3c25, ((2, 3), (2, 4))] = 136
Updated Q[0x3c25, ((0, 0), (0, 1))] = 14000, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4935, ((0, 3), (1, 3))] = 14000, N[0x4935, ((0, 3), (1, 3))] = 1
Updated Q[0x4939, ((2, 0), (2, 1))] = 14000, N[0x4939, ((2, 0), (2, 1))] = 1

--- Simulation 141 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.112172737543, 16803.112172737543, 21438.50216072825, 16803.112172737543, 19603.112172737543]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4693, Score: 8400
Depth 2: State = 0x4693, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4693: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4656, Score: 11200
Depth 3: State = 0x4656, Legal Moves = [((0, 3), (1, 3)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4656: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4656, Score: 14000
Depth 4: State = 0x4656, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4656: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x2d75, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2932400, N[0x3c25, ((2, 3), (2, 4))] = 137
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4693, ((1, 3), (2, 3))] = 16800, N[0x4693, ((1, 3), (2, 3))] = 1
Updated Q[0x4656, ((0, 3), (1, 3))] = 16800, N[0x4656, ((0, 3), (1, 3))] = 1
Updated Q[0x4656, ((1, 0), (2, 0))] = 16800, N[0x4656, ((1, 0), (2, 0))] = 1

--- Simulation 142 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.114413168663, 16803.114413168663, 21404.64564431779, 16803.114413168663, 19603.114413168663]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bfe, Score: 8400
Depth 1: State = 0x3bfe, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bfe: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3701, Score: 11200
Depth 2: State = 0x3701, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3701: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x54ea, Score: 14000
Depth 3: State = 0x54ea, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x54ea: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x563d, Score: 16800
Depth 4: State = 0x563d, Legal Moves = [((3, 3), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x563d: [inf, inf]
Selected move: ((3, 3), (3, 4))
New board state after move: 0x56a0, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2954800, N[0x3c25, ((2, 3), (2, 4))] = 138
Updated Q[0x3bfe, ((1, 3), (1, 4))] = 22400, N[0x3bfe, ((1, 3), (1, 4))] = 1
Updated Q[0x3701, ((0, 2), (1, 2))] = 22400, N[0x3701, ((0, 2), (1, 2))] = 1
Updated Q[0x54ea, ((2, 0), (2, 1))] = 22400, N[0x54ea, ((2, 0), (2, 1))] = 1
Updated Q[0x563d, ((3, 3), (3, 4))] = 22400, N[0x563d, ((3, 3), (3, 4))] = 1

--- Simulation 143 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.116636172686, 16803.116636172686, 21411.859508588153, 16803.116636172686, 19603.116636172686]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x469c, Score: 8400
Depth 2: State = 0x469c, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x469c: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x1c34, Score: 14000
Depth 3: State = 0x1c34, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1c34: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x1d43, Score: 16800
Depth 4: State = 0x1d43, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 0), (2, 0)), ((2, 0), (2, 1)), ((2, 4), (3, 4))]
UCB1 values for moves at state 0x1d43: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x1f03, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2974400, N[0x3c25, ((2, 3), (2, 4))] = 139
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x469c, ((1, 3), (2, 3))] = 19600, N[0x469c, ((1, 3), (2, 3))] = 1
Updated Q[0x1c34, ((1, 0), (2, 0))] = 19600, N[0x1c34, ((1, 0), (2, 0))] = 1
Updated Q[0x1d43, ((0, 1), (1, 1))] = 19600, N[0x1d43, ((0, 1), (1, 1))] = 1

--- Simulation 144 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.118842008713, 16803.118842008713, 21398.825687805656, 16803.118842008713, 19603.118842008713]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c1e, Score: 8400
Depth 1: State = 0x3c1e, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1e: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3c40, Score: 11200
Depth 2: State = 0x3c40, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c40: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x53ad, Score: 14000
Depth 3: State = 0x53ad, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x53ad: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5413, Score: 16800
Depth 4: State = 0x5413, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x5413: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x580c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 2994000, N[0x3c25, ((2, 3), (2, 4))] = 140
Updated Q[0x3c1e, ((0, 3), (1, 3))] = 19600, N[0x3c1e, ((0, 3), (1, 3))] = 1
Updated Q[0x3c40, ((0, 0), (1, 0))] = 19600, N[0x3c40, ((0, 0), (1, 0))] = 1
Updated Q[0x53ad, ((1, 2), (1, 3))] = 19600, N[0x53ad, ((1, 2), (1, 3))] = 1
Updated Q[0x5413, ((2, 0), (2, 1))] = 19600, N[0x5413, ((2, 0), (2, 1))] = 1

--- Simulation 145 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.121030930186, 16803.121030930186, 21385.978060971265, 16803.121030930186, 19603.121030930186]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.467405903557, 25201.467405903557, 19601.467405903557, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c27, Score: 10500
Depth 2: State = 0x3c27, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c27: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c27, Score: 13300
Depth 3: State = 0x3c27, Legal Moves = [((2, 1), (3, 1)), ((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c27: [inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x3d7a, Score: 16100
Depth 4: State = 0x3d7a, Legal Moves = [((0, 1), (1, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d7a: [inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x1189, Score: 18900
End of simulation with depth 5. Reward (Score): 18900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3012900, N[0x3c25, ((2, 3), (2, 4))] = 141
Updated Q[0x3c24, ((2, 3), (2, 4))] = 18900, N[0x3c24, ((2, 3), (2, 4))] = 1
Updated Q[0x3c27, ((2, 0), (2, 1))] = 18900, N[0x3c27, ((2, 0), (2, 1))] = 1
Updated Q[0x3c27, ((2, 1), (3, 1))] = 18900, N[0x3c27, ((2, 1), (3, 1))] = 1
Updated Q[0x3d7a, ((0, 1), (1, 1))] = 18900, N[0x3d7a, ((0, 1), (1, 1))] = 1

--- Simulation 146 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.123203185056, 16803.123203185056, 21368.348127539197, 16803.123203185056, 19603.123203185056]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x484c, Score: 8400
Depth 2: State = 0x484c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x484c: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x47a9, Score: 11200
Depth 3: State = 0x47a9, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47a9: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x47ac, Score: 14000
Depth 4: State = 0x47ac, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47ac: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x45ac, Score: 24900
End of simulation with depth 5. Reward (Score): 24900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3037800, N[0x3c25, ((2, 3), (2, 4))] = 142
Updated Q[0x3c25, ((0, 0), (0, 1))] = 24900, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x484c, ((1, 2), (2, 2))] = 24900, N[0x484c, ((1, 2), (2, 2))] = 1
Updated Q[0x47a9, ((0, 3), (1, 3))] = 24900, N[0x47a9, ((0, 3), (1, 3))] = 1
Updated Q[0x47ac, ((1, 3), (2, 3))] = 24900, N[0x47ac, ((1, 3), (2, 3))] = 1

--- Simulation 147 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.125359015947, 16803.125359015947, 21393.22002078129, 16803.125359015947, 19603.125359015947]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 27701.16557645562, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3c1a, Score: 8400
Depth 2: State = 0x3c1a, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1a: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3d8f, Score: 11200
Depth 3: State = 0x3d8f, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d8f: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x368b, Score: 14000
Depth 4: State = 0x368b, Legal Moves = [((1, 0), (1, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x368b: [inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x3869, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3060200, N[0x3c25, ((2, 3), (2, 4))] = 143
Updated Q[0x3c24, ((0, 3), (0, 4))] = 22400, N[0x3c24, ((0, 3), (0, 4))] = 1
Updated Q[0x3c1a, ((0, 3), (1, 3))] = 22400, N[0x3c1a, ((0, 3), (1, 3))] = 1
Updated Q[0x3d8f, ((0, 2), (1, 2))] = 22400, N[0x3d8f, ((0, 2), (1, 2))] = 1
Updated Q[0x368b, ((1, 0), (1, 1))] = 22400, N[0x368b, ((1, 0), (1, 1))] = 1

--- Simulation 148 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.127498660284, 16803.127498660284, 21400.2615345766, 16803.127498660284, 19603.127498660284]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x366c, Score: 18200
Depth 2: State = 0x366c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x366c: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x368e, Score: 21000
Depth 3: State = 0x368e, Legal Moves = [((0, 2), (1, 2)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x368e: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x371a, Score: 23800
Depth 4: State = 0x371a, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x371a: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x386d, Score: 26600
End of simulation with depth 5. Reward (Score): 26600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3086800, N[0x3c25, ((2, 3), (2, 4))] = 144
Updated Q[0x3c24, ((1, 3), (2, 3))] = 26600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x366c, ((1, 2), (2, 2))] = 26600, N[0x366c, ((1, 2), (2, 2))] = 1
Updated Q[0x368e, ((0, 2), (1, 2))] = 26600, N[0x368e, ((0, 2), (1, 2))] = 1
Updated Q[0x371a, ((2, 0), (2, 1))] = 26600, N[0x371a, ((2, 0), (2, 1))] = 1

--- Simulation 149 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.129622350472, 16803.129622350472, 21436.37191297365, 16803.129622350472, 19603.129622350472]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc1, Score: 8400
Depth 1: State = 0x3bc1, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc1: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d7a, Score: 11200
Depth 2: State = 0x3d7a, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d7a: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2c67, Score: 14000
Depth 3: State = 0x2c67, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2c67: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2c5e, Score: 22400
Depth 4: State = 0x2c5e, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2c5e: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x46d6, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3112000, N[0x3c25, ((2, 3), (2, 4))] = 145
Updated Q[0x3bc1, ((1, 3), (2, 3))] = 25200, N[0x3bc1, ((1, 3), (2, 3))] = 1
Updated Q[0x3d7a, ((1, 2), (1, 3))] = 25200, N[0x3d7a, ((1, 2), (1, 3))] = 1
Updated Q[0x2c67, ((1, 2), (1, 3))] = 25200, N[0x2c67, ((1, 2), (1, 3))] = 1
Updated Q[0x2c5e, ((1, 0), (1, 1))] = 25200, N[0x2c5e, ((1, 0), (1, 1))] = 1

--- Simulation 150 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.131730314006, 16803.131730314006, 21462.329041563942, 16803.131730314006, 19603.131730314006]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x39bd, Score: 11200
Depth 2: State = 0x39bd, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39bd: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4584, Score: 14000
Depth 3: State = 0x4584, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4584: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x46d7, Score: 16800
Depth 4: State = 0x46d7, Legal Moves = [((1, 1), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x46d7: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4431, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3134400, N[0x3c25, ((2, 3), (2, 4))] = 146
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x39bd, ((1, 2), (1, 3))] = 22400, N[0x39bd, ((1, 2), (1, 3))] = 1
Updated Q[0x4584, ((1, 1), (2, 1))] = 22400, N[0x4584, ((1, 1), (2, 1))] = 1
Updated Q[0x46d7, ((1, 1), (2, 1))] = 22400, N[0x46d7, ((1, 1), (2, 1))] = 1

--- Simulation 151 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.133822773616, 16803.133822773616, 21468.75250770306, 16803.133822773616, 19603.133822773616]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47c4, Score: 8400
Depth 2: State = 0x47c4, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c4: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4852, Score: 11200
Depth 3: State = 0x4852, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4852: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4852, Score: 14000
Depth 4: State = 0x4852, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x4852: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x49a5, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3151200, N[0x3c25, ((2, 3), (2, 4))] = 147
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x47c4, ((1, 3), (2, 3))] = 16800, N[0x47c4, ((1, 3), (2, 3))] = 1
Updated Q[0x4852, ((0, 3), (1, 3))] = 16800, N[0x4852, ((0, 3), (1, 3))] = 1
Updated Q[0x4852, ((2, 0), (2, 1))] = 16800, N[0x4852, ((2, 0), (2, 1))] = 1

--- Simulation 152 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.135899947407, 16803.135899947407, 21436.99333854595, 16803.135899947407, 19603.135899947407]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47cb, Score: 8400
Depth 2: State = 0x47cb, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47cb: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4658, Score: 24900
Depth 3: State = 0x4658, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4658: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3720, Score: 30500
Depth 4: State = 0x3720, Legal Moves = [((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3720: [inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x368b, Score: 33300
End of simulation with depth 5. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3184500, N[0x3c25, ((2, 3), (2, 4))] = 148
Updated Q[0x3c25, ((0, 0), (0, 1))] = 33300, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x47cb, ((1, 3), (2, 3))] = 33300, N[0x47cb, ((1, 3), (2, 3))] = 1
Updated Q[0x4658, ((1, 1), (2, 1))] = 33300, N[0x4658, ((1, 1), (2, 1))] = 1
Updated Q[0x3720, ((2, 2), (3, 2))] = 33300, N[0x3720, ((2, 2), (3, 2))] = 1

--- Simulation 153 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.137962048982, 16803.137962048982, 21517.149830783423, 16803.137962048982, 19603.137962048982]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d55, Score: 13300
Depth 2: State = 0x3d55, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d55: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2c8c, Score: 29800
Depth 3: State = 0x2c8c, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 29800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3214300, N[0x3c25, ((2, 3), (2, 4))] = 149
Updated Q[0x3c24, ((1, 3), (2, 3))] = 29800, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3d55, ((2, 0), (2, 1))] = 29800, N[0x3d55, ((2, 0), (2, 1))] = 1

--- Simulation 154 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.140009287556, 16803.140009287556, 21572.740461060417, 16803.140009287556, 19603.140009287556]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22400.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3af4, Score: 11200
Depth 2: State = 0x3af4, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3af4: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x5287, Score: 14000
Depth 3: State = 0x5287, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5287: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x567f, Score: 16800
Depth 4: State = 0x567f, Legal Moves = [((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x567f: [inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x5816, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3233900, N[0x3c25, ((2, 3), (2, 4))] = 150
Updated Q[0x3c25, ((1, 3), (2, 3))] = 19600, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3af4, ((0, 2), (0, 3))] = 19600, N[0x3af4, ((0, 2), (0, 3))] = 1
Updated Q[0x5287, ((2, 0), (2, 1))] = 19600, N[0x5287, ((2, 0), (2, 1))] = 1
Updated Q[0x567f, ((2, 1), (3, 1))] = 19600, N[0x567f, ((2, 1), (3, 1))] = 1

--- Simulation 155 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.142041868075, 16803.142041868075, 21559.589879977575, 16803.142041868075, 19603.142041868075]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x442d, Score: 8400
Depth 2: State = 0x442d, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x442d: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4509, Score: 11200
Depth 3: State = 0x4509, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x4509: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x47af, Score: 14000
Depth 4: State = 0x47af, Legal Moves = [((2, 1), (3, 1)), ((3, 4), (4, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x47af: [inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x3855, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3250700, N[0x3c25, ((2, 3), (2, 4))] = 151
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x442d, ((0, 2), (1, 2))] = 16800, N[0x442d, ((0, 2), (1, 2))] = 1
Updated Q[0x4509, ((2, 0), (2, 1))] = 16800, N[0x4509, ((2, 0), (2, 1))] = 1
Updated Q[0x47af, ((2, 1), (3, 1))] = 16800, N[0x47af, ((2, 1), (3, 1))] = 1

--- Simulation 156 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.144059991344, 16803.144059991344, 21528.070429509888, 16803.144059991344, 19603.144059991344]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4837, Score: 8400
Depth 2: State = 0x4837, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4837: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x45a9, Score: 11200
Depth 3: State = 0x45a9, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a9: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x456b, Score: 14000
Depth 4: State = 0x456b, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x456b: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1f4d, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3270300, N[0x3c25, ((2, 3), (2, 4))] = 152
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4837, ((1, 3), (1, 4))] = 19600, N[0x4837, ((1, 3), (1, 4))] = 1
Updated Q[0x45a9, ((0, 3), (1, 3))] = 19600, N[0x45a9, ((0, 3), (1, 3))] = 1
Updated Q[0x456b, ((2, 0), (2, 1))] = 19600, N[0x456b, ((2, 0), (2, 1))] = 1

--- Simulation 157 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.14606385412, 16803.14606385412, 21515.38675842206, 16803.14606385412, 19603.14606385412]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47f2, Score: 8400
Depth 2: State = 0x47f2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47f2: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x45a5, Score: 11200
Depth 3: State = 0x45a5, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a5: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4ad6, Score: 14000
Depth 4: State = 0x4ad6, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ad6: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4ada, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3287100, N[0x3c25, ((2, 3), (2, 4))] = 153
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47f2, ((1, 3), (2, 3))] = 16800, N[0x47f2, ((1, 3), (2, 3))] = 1
Updated Q[0x45a5, ((0, 1), (0, 2))] = 16800, N[0x45a5, ((0, 1), (0, 2))] = 1
Updated Q[0x4ad6, ((0, 3), (1, 3))] = 16800, N[0x4ad6, ((0, 3), (1, 3))] = 1

--- Simulation 158 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.148053649238, 16803.148053649238, 21484.56823054335, 16803.148053649238, 19603.148053649238]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 27301.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x57ce, Score: 11200
Depth 2: State = 0x57ce, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x57ce: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x5245, Score: 14000
Depth 3: State = 0x5245, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x5245: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x56d6, Score: 24900
Depth 4: State = 0x56d6, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x56d6: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3953, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3314800, N[0x3c25, ((2, 3), (2, 4))] = 154
Updated Q[0x3c24, ((2, 0), (2, 1))] = 27700, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x57ce, ((1, 0), (1, 1))] = 27700, N[0x57ce, ((1, 0), (1, 1))] = 1
Updated Q[0x5245, ((4, 1), (4, 2))] = 27700, N[0x5245, ((4, 1), (4, 2))] = 1
Updated Q[0x56d6, ((0, 1), (1, 1))] = 27700, N[0x56d6, ((0, 1), (1, 1))] = 1

--- Simulation 159 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.15002956569, 16803.15002956569, 21524.929161291464, 16803.15002956569, 19603.15002956569]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22401.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c25, Score: 11200
Depth 2: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47c4, Score: 14000
Depth 3: State = 0x47c4, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x47c4: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x47e5, Score: 16800
Depth 4: State = 0x47e5, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3331600, N[0x3c25, ((2, 3), (2, 4))] = 155
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x47c4, ((4, 1), (4, 2))] = 16800, N[0x47c4, ((4, 1), (4, 2))] = 1

--- Simulation 160 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.15199178875, 16803.15199178875, 21494.446722460027, 16803.15199178875, 19603.15199178875]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a91, Score: 8400
Depth 2: State = 0x4a91, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a91: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4589, Score: 14000
Depth 3: State = 0x4589, Legal Moves = [((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4589: [inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x457f, Score: 16800
Depth 4: State = 0x457f, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x457f: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x46d2, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3351200, N[0x3c25, ((2, 3), (2, 4))] = 156
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a91, ((1, 3), (2, 3))] = 19600, N[0x4a91, ((1, 3), (2, 3))] = 1
Updated Q[0x4589, ((1, 4), (2, 4))] = 19600, N[0x4589, ((1, 4), (2, 4))] = 1
Updated Q[0x457f, ((2, 0), (2, 1))] = 19600, N[0x457f, ((2, 0), (2, 1))] = 1

--- Simulation 161 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.15394050005, 16803.15394050005, 21482.303799386023, 16803.15394050005, 19603.15394050005]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c02, Score: 8400
Depth 1: State = 0x3c02, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c02: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3b18, Score: 14000
Depth 2: State = 0x3b18, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3b18: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c6b, Score: 16800
Depth 3: State = 0x3c6b, Legal Moves = [((1, 1), (2, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3c6b: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x563a, Score: 19600
Depth 4: State = 0x563a, Legal Moves = [((2, 0), (2, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x563a: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x5394, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3373600, N[0x3c25, ((2, 3), (2, 4))] = 157
Updated Q[0x3c02, ((1, 3), (2, 3))] = 22400, N[0x3c02, ((1, 3), (2, 3))] = 1
Updated Q[0x3b18, ((2, 0), (2, 1))] = 22400, N[0x3b18, ((2, 0), (2, 1))] = 1
Updated Q[0x3c6b, ((1, 1), (2, 1))] = 22400, N[0x3c6b, ((1, 1), (2, 1))] = 1
Updated Q[0x563a, ((2, 0), (2, 1))] = 22400, N[0x563a, ((2, 0), (2, 1))] = 1

--- Simulation 162 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.15587587769, 16803.15587587769, 21488.14995548667, 16803.15587587769, 19603.15587587769]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3915, Score: 11200
Depth 2: State = 0x3915, Legal Moves = [((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3915: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3a68, Score: 14000
Depth 3: State = 0x3a68, Legal Moves = [((0, 2), (1, 2)), ((2, 4), (3, 4)), ((3, 3), (4, 3)), ((4, 0), (4, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3a68: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x36f7, Score: 16800
Depth 4: State = 0x36f7, Legal Moves = [((2, 4), (3, 4)), ((3, 3), (4, 3)), ((4, 0), (4, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x36f7: [inf, inf, inf, inf]
Selected move: ((2, 4), (3, 4))
New board state after move: 0x36f8, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3393200, N[0x3c25, ((2, 3), (2, 4))] = 158
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3915, ((2, 0), (2, 1))] = 19600, N[0x3915, ((2, 0), (2, 1))] = 1
Updated Q[0x3a68, ((0, 2), (1, 2))] = 19600, N[0x3a68, ((0, 2), (1, 2))] = 1
Updated Q[0x36f7, ((2, 4), (3, 4))] = 19600, N[0x36f7, ((2, 4), (3, 4))] = 1

--- Simulation 163 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.15779809631, 16803.15779809631, 21476.200588016356, 16803.15779809631, 19603.15779809631]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bb6, Score: 8400
Depth 1: State = 0x3bb6, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb6: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x371b, Score: 11200
Depth 2: State = 0x371b, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x371b: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1f48, Score: 16800
Depth 3: State = 0x1f48, Legal Moves = [((2, 1), (3, 1)), ((2, 2), (3, 2))]
UCB1 values for moves at state 0x1f48: [inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x1c40, Score: 22400
Depth 4: State = 0x1c40, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((2, 1), (2, 2)), ((3, 2), (4, 2))]
UCB1 values for moves at state 0x1c40: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x2169, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3421200, N[0x3c25, ((2, 3), (2, 4))] = 159
Updated Q[0x3bb6, ((0, 1), (1, 1))] = 28000, N[0x3bb6, ((0, 1), (1, 1))] = 1
Updated Q[0x371b, ((2, 0), (2, 1))] = 28000, N[0x371b, ((2, 0), (2, 1))] = 1
Updated Q[0x1f48, ((2, 1), (3, 1))] = 28000, N[0x1f48, ((2, 1), (3, 1))] = 1
Updated Q[0x1c40, ((0, 2), (1, 2))] = 28000, N[0x1c40, ((0, 2), (1, 2))] = 1

--- Simulation 164 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.159707327202, 16803.159707327202, 21517.231713166097, 16803.159707327202, 19603.159707327202]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bbf, Score: 8400
Depth 2: State = 0x3bbf, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbf: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3bbf, Score: 14000
Depth 3: State = 0x3bbf, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbf: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3bbf, Score: 16800
Depth 4: State = 0x3bbf, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbf: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c46, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3440800, N[0x3c25, ((2, 3), (2, 4))] = 160
Updated Q[0x3c25, ((0, 2), (1, 2))] = 19600, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3bbf, ((1, 3), (1, 4))] = 19600, N[0x3bbf, ((1, 3), (1, 4))] = 1
Updated Q[0x3bbf, ((1, 3), (1, 4))] = 19600, N[0x3bbf, ((1, 3), (1, 4))] = 1
Updated Q[0x3bbf, ((1, 3), (2, 3))] = 19600, N[0x3bbf, ((1, 3), (2, 3))] = 1

--- Simulation 165 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.16160373838, 16803.16160373838, 21505.249946721804, 16803.16160373838, 19603.16160373838]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [27200.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c4e, Score: 8400
Depth 2: State = 0x3c4e, Legal Moves = [((0, 0), (1, 0)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c4e: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x29a5, Score: 11200
Depth 3: State = 0x29a5, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x29a5: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x29a4, Score: 14000
Depth 4: State = 0x29a4, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x29a4: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x29a4, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3457600, N[0x3c25, ((2, 3), (2, 4))] = 161
Updated Q[0x3c24, ((0, 2), (1, 2))] = 16800, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c4e, ((0, 0), (1, 0))] = 16800, N[0x3c4e, ((0, 0), (1, 0))] = 1
Updated Q[0x29a5, ((1, 2), (2, 2))] = 16800, N[0x29a5, ((1, 2), (2, 2))] = 1
Updated Q[0x29a4, ((1, 2), (1, 3))] = 16800, N[0x29a4, ((1, 2), (1, 3))] = 1

--- Simulation 166 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.163487494658, 16803.163487494658, 21476.025715256983, 16803.163487494658, 19603.163487494658]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x469f, Score: 8400
Depth 2: State = 0x469f, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x469f: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4aed, Score: 11200
Depth 3: State = 0x4aed, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aed: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4ab9, Score: 14000
Depth 4: State = 0x4ab9, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab9: [inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x36fa, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3477200, N[0x3c25, ((2, 3), (2, 4))] = 162
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x469f, ((1, 3), (2, 3))] = 19600, N[0x469f, ((1, 3), (2, 3))] = 1
Updated Q[0x4aed, ((0, 2), (1, 2))] = 19600, N[0x4aed, ((0, 2), (1, 2))] = 1
Updated Q[0x4ab9, ((1, 0), (2, 0))] = 19600, N[0x4ab9, ((1, 0), (2, 0))] = 1

--- Simulation 167 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.165358757735, 16803.165358757735, 21464.446224935582, 16803.165358757735, 19603.165358757735]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46da, Score: 8400
Depth 2: State = 0x46da, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46da: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4808, Score: 11200
Depth 3: State = 0x4808, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4808: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x495b, Score: 14000
Depth 4: State = 0x495b, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2))]
UCB1 values for moves at state 0x495b: [inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x4a48, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3494000, N[0x3c25, ((2, 3), (2, 4))] = 163
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x46da, ((1, 3), (2, 3))] = 16800, N[0x46da, ((1, 3), (2, 3))] = 1
Updated Q[0x4808, ((1, 1), (2, 1))] = 16800, N[0x4808, ((1, 1), (2, 1))] = 1
Updated Q[0x495b, ((0, 1), (1, 1))] = 16800, N[0x495b, ((0, 1), (1, 1))] = 1

--- Simulation 168 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.16721768629, 16803.16721768629, 21435.830897720905, 16803.16721768629, 19603.16721768629]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x454e, Score: 8400
Depth 2: State = 0x454e, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x454e: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x2d69, Score: 18800
Depth 3: State = 0x2d69, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2d69: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x300f, Score: 21600
Depth 4: State = 0x300f, Legal Moves = [((3, 0), (3, 1))]
UCB1 values for moves at state 0x300f: [inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x2ac3, Score: 24400
End of simulation with depth 5. Reward (Score): 24400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3518400, N[0x3c25, ((2, 3), (2, 4))] = 164
Updated Q[0x3c25, ((0, 0), (0, 1))] = 24400, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x454e, ((1, 3), (1, 4))] = 24400, N[0x454e, ((1, 3), (1, 4))] = 1
Updated Q[0x2d69, ((2, 0), (2, 1))] = 24400, N[0x2d69, ((2, 0), (2, 1))] = 1
Updated Q[0x300f, ((3, 0), (3, 1))] = 24400, N[0x300f, ((3, 0), (3, 1))] = 1

--- Simulation 169 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.169064436017, 16803.169064436017, 21453.905998942686, 16803.169064436017, 19603.169064436017]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c02, Score: 8400
Depth 1: State = 0x3c02, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c02: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x36fb, Score: 11200
Depth 2: State = 0x36fb, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (0, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x36fb: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4568, Score: 14000
Depth 3: State = 0x4568, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x4568: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4567, Score: 16800
Depth 4: State = 0x4567, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4567: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4676, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3540800, N[0x3c25, ((2, 3), (2, 4))] = 165
Updated Q[0x3c02, ((1, 3), (1, 4))] = 22400, N[0x3c02, ((1, 3), (1, 4))] = 1
Updated Q[0x36fb, ((0, 2), (1, 2))] = 22400, N[0x36fb, ((0, 2), (1, 2))] = 1
Updated Q[0x4568, ((0, 2), (1, 2))] = 22400, N[0x4568, ((0, 2), (1, 2))] = 1
Updated Q[0x4567, ((2, 0), (2, 1))] = 22400, N[0x4567, ((2, 0), (2, 1))] = 1

--- Simulation 170 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.17089915974, 16803.17089915974, 21459.64079355873, 16803.17089915974, 19603.17089915974]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22400.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d70, Score: 26000
Depth 2: State = 0x3d70, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3d70: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x22b4, Score: 31600
Depth 3: State = 0x22b4, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 2), (3, 3)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x22b4: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x5260, Score: 40000
Depth 4: State = 0x5260, Legal Moves = [((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 1), (4, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x5260: [inf, inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x52a0, Score: 42800
End of simulation with depth 5. Reward (Score): 42800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3583600, N[0x3c25, ((2, 3), (2, 4))] = 166
Updated Q[0x3c24, ((1, 3), (2, 3))] = 42800, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3d70, ((2, 0), (2, 1))] = 42800, N[0x3d70, ((2, 0), (2, 1))] = 1
Updated Q[0x22b4, ((0, 0), (0, 1))] = 42800, N[0x22b4, ((0, 0), (0, 1))] = 1
Updated Q[0x5260, ((2, 2), (3, 2))] = 42800, N[0x5260, ((2, 2), (3, 2))] = 1

--- Simulation 171 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.17272200746, 16803.17272200746, 21588.19805821432, 16803.17272200746, 19603.17272200746]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3aa7, Score: 11200
Depth 2: State = 0x3aa7, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3aa7: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x15fd, Score: 14000
Depth 3: State = 0x15fd, Legal Moves = [((0, 3), (0, 4)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x15fd: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x11ab, Score: 16800
Depth 4: State = 0x11ab, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x11ab: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x15a4, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3603200, N[0x3c25, ((2, 3), (2, 4))] = 167
Updated Q[0x3c25, ((1, 3), (2, 3))] = 19600, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3aa7, ((0, 2), (1, 2))] = 19600, N[0x3aa7, ((0, 2), (1, 2))] = 1
Updated Q[0x15fd, ((0, 3), (0, 4))] = 19600, N[0x15fd, ((0, 3), (0, 4))] = 1
Updated Q[0x11ab, ((2, 0), (2, 1))] = 19600, N[0x11ab, ((2, 0), (2, 1))] = 1

--- Simulation 172 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.17453312642, 16803.17453312642, 21576.29355694018, 16803.17453312642, 19603.17453312642]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x45a5, Score: 8400
Depth 2: State = 0x45a5, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a5: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4702, Score: 11200
Depth 3: State = 0x4702, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4702: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4a98, Score: 16800
Depth 4: State = 0x4a98, Legal Moves = [((0, 2), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((3, 0), (3, 1)), ((3, 0), (4, 0)), ((3, 2), (4, 2))]
UCB1 values for moves at state 0x4a98: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x46f8, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3622800, N[0x3c25, ((2, 3), (2, 4))] = 168
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x45a5, ((1, 3), (1, 4))] = 19600, N[0x45a5, ((1, 3), (1, 4))] = 1
Updated Q[0x4702, ((1, 2), (2, 2))] = 19600, N[0x4702, ((1, 2), (2, 2))] = 1
Updated Q[0x4a98, ((0, 2), (1, 2))] = 19600, N[0x4a98, ((0, 2), (1, 2))] = 1

--- Simulation 173 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.17633266119, 16803.17633266119, 21564.53077367082, 16803.17633266119, 19603.17633266119]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22400.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x36ac, Score: 11200
Depth 2: State = 0x36ac, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x36ac: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3986, Score: 14000
Depth 3: State = 0x3986, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3986: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x393a, Score: 16800
Depth 4: State = 0x393a, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x393a: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x5260, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3645200, N[0x3c25, ((2, 3), (2, 4))] = 169
Updated Q[0x3c24, ((1, 3), (2, 3))] = 22400, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x36ac, ((0, 1), (0, 2))] = 22400, N[0x36ac, ((0, 1), (0, 2))] = 1
Updated Q[0x3986, ((1, 1), (1, 2))] = 22400, N[0x3986, ((1, 1), (1, 2))] = 1
Updated Q[0x393a, ((0, 0), (1, 0))] = 22400, N[0x393a, ((0, 0), (1, 0))] = 1

--- Simulation 174 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.178120753717, 16803.178120753717, 21569.47524005798, 16803.178120753717, 19603.178120753717]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c47, Score: 13200
Depth 1: State = 0x3c47, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c47: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x56d7, Score: 21600
Depth 2: State = 0x56d7, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x56d7: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x5242, Score: 24400
Depth 3: State = 0x5242, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5242: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x107b, Score: 30000
Depth 4: State = 0x107b, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 2), (2, 2))]
UCB1 values for moves at state 0x107b: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x104e, Score: 32800
End of simulation with depth 5. Reward (Score): 32800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3678000, N[0x3c25, ((2, 3), (2, 4))] = 170
Updated Q[0x3c47, ((0, 0), (1, 0))] = 32800, N[0x3c47, ((0, 0), (1, 0))] = 1
Updated Q[0x56d7, ((0, 3), (1, 3))] = 32800, N[0x56d7, ((0, 3), (1, 3))] = 1
Updated Q[0x5242, ((2, 0), (2, 1))] = 32800, N[0x5242, ((2, 0), (2, 1))] = 1
Updated Q[0x107b, ((0, 3), (1, 3))] = 32800, N[0x107b, ((0, 3), (1, 3))] = 1

--- Simulation 175 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.179897543392, 16803.179897543392, 21635.53800465545, 16803.179897543392, 19603.179897543392]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4854, Score: 8400
Depth 2: State = 0x4854, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4854: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x46e3, Score: 11200
Depth 3: State = 0x46e3, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46e3: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x46e3, Score: 14000
Depth 4: State = 0x46e3, Legal Moves = [((2, 1), (3, 1))]
UCB1 values for moves at state 0x46e3: [inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x46e3, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3694800, N[0x3c25, ((2, 3), (2, 4))] = 171
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4854, ((1, 3), (1, 4))] = 16800, N[0x4854, ((1, 3), (1, 4))] = 1
Updated Q[0x46e3, ((2, 0), (2, 1))] = 16800, N[0x46e3, ((2, 0), (2, 1))] = 1
Updated Q[0x46e3, ((2, 1), (3, 1))] = 16800, N[0x46e3, ((2, 1), (3, 1))] = 1

--- Simulation 176 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.181663167103, 16803.181663167103, 21607.26085172312, 16803.181663167103, 19603.181663167103]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bb6, Score: 23800
Depth 2: State = 0x3bb6, Legal Moves = [((1, 0), (1, 1)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((3, 0), (3, 1)), ((3, 3), (3, 4)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3bb6: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x3d08, Score: 26600
Depth 3: State = 0x3d08, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 0), (4, 0)), ((3, 3), (3, 4)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3d08: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3d56, Score: 32200
Depth 4: State = 0x3d56, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1)), ((3, 0), (4, 0)), ((3, 3), (3, 4)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3d56: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d5d, Score: 35000
End of simulation with depth 5. Reward (Score): 35000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3729800, N[0x3c25, ((2, 3), (2, 4))] = 172
Updated Q[0x3c25, ((1, 3), (2, 3))] = 35000, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3bb6, ((1, 0), (1, 1))] = 35000, N[0x3bb6, ((1, 0), (1, 1))] = 1
Updated Q[0x3d08, ((1, 2), (2, 2))] = 35000, N[0x3d08, ((1, 2), (2, 2))] = 1
Updated Q[0x3d56, ((1, 3), (1, 4))] = 35000, N[0x3d56, ((1, 3), (1, 4))] = 1

--- Simulation 177 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.18341775931, 16803.18341775931, 21685.126454258767, 16803.18341775931, 19603.18341775931]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 19601.467405903557, 24501.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3982, Score: 11200
Depth 2: State = 0x3982, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3982: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3978, Score: 14000
Depth 3: State = 0x3978, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3978: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3982, Score: 16800
Depth 4: State = 0x3982, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3982: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2e86, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3752200, N[0x3c25, ((2, 3), (2, 4))] = 173
Updated Q[0x3c24, ((2, 3), (3, 3))] = 22400, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x3982, ((1, 3), (1, 4))] = 22400, N[0x3982, ((1, 3), (1, 4))] = 1
Updated Q[0x3978, ((1, 3), (2, 3))] = 22400, N[0x3978, ((1, 3), (2, 3))] = 1
Updated Q[0x3982, ((2, 0), (2, 1))] = 22400, N[0x3982, ((2, 0), (2, 1))] = 1

--- Simulation 178 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.185161452086, 16803.185161452086, 21689.259504381364, 16803.185161452086, 19603.185161452086]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46d3, Score: 11200
Depth 2: State = 0x46d3, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46d3: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x44f9, Score: 14000
Depth 3: State = 0x44f9, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x44f9: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4a44, Score: 16800
Depth 4: State = 0x4a44, Legal Moves = [((2, 1), (2, 2))]
UCB1 values for moves at state 0x4a44: [inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x4815, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3779500, N[0x3c25, ((2, 3), (2, 4))] = 174
Updated Q[0x3c25, ((0, 0), (0, 1))] = 27300, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x46d3, ((0, 3), (1, 3))] = 27300, N[0x46d3, ((0, 3), (1, 3))] = 1
Updated Q[0x44f9, ((1, 1), (2, 1))] = 27300, N[0x44f9, ((1, 1), (2, 1))] = 1
Updated Q[0x4a44, ((2, 1), (2, 2))] = 27300, N[0x4a44, ((2, 1), (2, 2))] = 1

--- Simulation 179 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.186894375183, 16803.186894375183, 21721.505965655186, 16803.186894375183, 19603.186894375183]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bf9, Score: 8400
Depth 1: State = 0x3bf9, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bf9: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3aed, Score: 11200
Depth 2: State = 0x3aed, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3aed: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0xedaf, Score: 14000
Depth 3: State = 0xedaf, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0xedaf: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3bb8, Score: 16800
Depth 4: State = 0x3bb8, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb8: [inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x3bf9, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3799100, N[0x3c25, ((2, 3), (2, 4))] = 175
Updated Q[0x3bf9, ((0, 3), (1, 3))] = 19600, N[0x3bf9, ((0, 3), (1, 3))] = 1
Updated Q[0x3aed, ((0, 2), (1, 2))] = 19600, N[0x3aed, ((0, 2), (1, 2))] = 1
Updated Q[0xedaf, ((1, 2), (1, 3))] = 19600, N[0xedaf, ((1, 2), (1, 3))] = 1
Updated Q[0x3bb8, ((0, 2), (0, 3))] = 19600, N[0x3bb8, ((0, 2), (0, 3))] = 1

--- Simulation 180 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.188616656083, 16803.188616656083, 21709.383893905666, 16803.188616656083, 19603.188616656083]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.648374031523, 19601.648374031523, 24501.648374031523, 22401.648374031523, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x1470, Score: 8400
Depth 2: State = 0x1470, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x1470: [inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x22bb, Score: 11200
Depth 3: State = 0x22bb, Legal Moves = [((2, 3), (3, 3))]
UCB1 values for moves at state 0x22bb: [inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x2346, Score: 16800
Depth 4: State = 0x2346, Legal Moves = [((2, 2), (3, 2))]
UCB1 values for moves at state 0x2346: [inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x233c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3818700, N[0x3c25, ((2, 3), (2, 4))] = 176
Updated Q[0x3c24, ((3, 0), (3, 1))] = 19600, N[0x3c24, ((3, 0), (3, 1))] = 1
Updated Q[0x1470, ((0, 0), (1, 0))] = 19600, N[0x1470, ((0, 0), (1, 0))] = 1
Updated Q[0x22bb, ((2, 3), (3, 3))] = 19600, N[0x22bb, ((2, 3), (3, 3))] = 1
Updated Q[0x2346, ((2, 2), (3, 2))] = 19600, N[0x2346, ((2, 2), (3, 2))] = 1

--- Simulation 181 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.190328420045, 16803.190328420045, 21697.399570961985, 16803.190328420045, 19603.190328420045]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [18900.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3bbe, Score: 14000
Depth 2: State = 0x3bbe, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbe: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5789, Score: 16800
Depth 3: State = 0x5789, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5789: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x5637, Score: 19600
Depth 4: State = 0x5637, Legal Moves = [((2, 2), (2, 3))]
UCB1 values for moves at state 0x5637: [inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x567a, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3841100, N[0x3c25, ((2, 3), (2, 4))] = 177
Updated Q[0x3c25, ((1, 3), (1, 4))] = 22400, N[0x3c25, ((1, 3), (1, 4))] = 1
Updated Q[0x3bbe, ((1, 2), (1, 3))] = 22400, N[0x3bbe, ((1, 2), (1, 3))] = 1
Updated Q[0x5789, ((2, 0), (2, 1))] = 22400, N[0x5789, ((2, 0), (2, 1))] = 1
Updated Q[0x5637, ((2, 2), (2, 3))] = 22400, N[0x5637, ((2, 2), (2, 3))] = 1

--- Simulation 182 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.192029790163, 16803.192029790163, 21701.369871154126, 16803.192029790163, 19603.192029790163]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x391d, Score: 16800
Depth 2: State = 0x391d, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x391d: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x1f2c, Score: 19600
Depth 3: State = 0x1f2c, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1f2c: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x2d99, Score: 27200
Depth 4: State = 0x2d99, Legal Moves = [((0, 3), (0, 4)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((4, 0), (4, 1))]
UCB1 values for moves at state 0x2d99: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x29bf, Score: 30000
End of simulation with depth 5. Reward (Score): 30000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3871100, N[0x3c25, ((2, 3), (2, 4))] = 178
Updated Q[0x3c24, ((1, 3), (2, 3))] = 30000, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x391d, ((1, 1), (2, 1))] = 30000, N[0x391d, ((1, 1), (2, 1))] = 1
Updated Q[0x1f2c, ((1, 1), (2, 1))] = 30000, N[0x1f2c, ((1, 1), (2, 1))] = 1
Updated Q[0x2d99, ((0, 3), (0, 4))] = 30000, N[0x2d99, ((0, 3), (0, 4))] = 1

--- Simulation 183 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.193720887408, 16803.193720887408, 21747.992188489854, 16803.193720887408, 19603.193720887408]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47a2, Score: 8400
Depth 2: State = 0x47a2, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47a2: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4a88, Score: 11200
Depth 3: State = 0x4a88, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a88: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4a8c, Score: 14000
Depth 4: State = 0x4a8c, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a8c: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x4a6d, Score: 24900
End of simulation with depth 5. Reward (Score): 24900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3896000, N[0x3c25, ((2, 3), (2, 4))] = 179
Updated Q[0x3c25, ((0, 0), (0, 1))] = 24900, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x47a2, ((1, 3), (1, 4))] = 24900, N[0x47a2, ((1, 3), (1, 4))] = 1
Updated Q[0x4a88, ((1, 2), (1, 3))] = 24900, N[0x4a88, ((1, 2), (1, 3))] = 1
Updated Q[0x4a8c, ((0, 2), (0, 3))] = 24900, N[0x4a8c, ((0, 2), (0, 3))] = 1

--- Simulation 184 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.19540183069, 16803.19540183069, 21765.60196403799, 16803.19540183069, 19603.19540183069]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c3f, Score: 11200
Depth 1: State = 0x3c3f, Legal Moves = [((0, 0), (1, 0)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c3f: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x440e, Score: 14000
Depth 2: State = 0x440e, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x440e: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4415, Score: 16800
Depth 3: State = 0x4415, Legal Moves = [((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4415: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4a88, Score: 24500
Depth 4: State = 0x4a88, Legal Moves = [((1, 0), (1, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a88: [inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x491e, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3923300, N[0x3c25, ((2, 3), (2, 4))] = 180
Updated Q[0x3c3f, ((0, 0), (1, 0))] = 27300, N[0x3c3f, ((0, 0), (1, 0))] = 1
Updated Q[0x440e, ((1, 2), (2, 2))] = 27300, N[0x440e, ((1, 2), (2, 2))] = 1
Updated Q[0x4415, ((0, 3), (1, 3))] = 27300, N[0x4415, ((0, 3), (1, 3))] = 1
Updated Q[0x4a88, ((1, 0), (1, 1))] = 27300, N[0x4a88, ((1, 0), (1, 1))] = 1

--- Simulation 185 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.197072736883, 16803.197072736883, 21796.349406843397, 16803.197072736883, 19603.197072736883]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d96, Score: 14000
Depth 2: State = 0x3d96, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3d96: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3db8, Score: 16800
Depth 3: State = 0x3db8, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3db8: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3dbf, Score: 19600
Depth 4: State = 0x3dbf, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3dbf: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x36da, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3945700, N[0x3c25, ((2, 3), (2, 4))] = 181
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3d96, ((0, 1), (0, 2))] = 22400, N[0x3d96, ((0, 1), (0, 2))] = 1
Updated Q[0x3db8, ((0, 3), (0, 4))] = 22400, N[0x3db8, ((0, 3), (0, 4))] = 1
Updated Q[0x3dbf, ((0, 3), (0, 4))] = 22400, N[0x3dbf, ((0, 3), (0, 4))] = 1

--- Simulation 186 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.19873372089, 16803.19873372089, 21799.68527381717, 16803.19873372089, 19603.19873372089]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [21700.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0xee0b, Score: 26000
Depth 2: State = 0xee0b, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0xee0b: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0xedaf, Score: 28800
Depth 3: State = 0xedaf, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0xedaf: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0xf1eb, Score: 31600
Depth 4: State = 0xf1eb, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0xf1eb: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0xf009, Score: 34400
End of simulation with depth 5. Reward (Score): 34400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 3980100, N[0x3c25, ((2, 3), (2, 4))] = 182
Updated Q[0x3c25, ((1, 3), (1, 4))] = 34400, N[0x3c25, ((1, 3), (1, 4))] = 1
Updated Q[0xee0b, ((0, 3), (0, 4))] = 34400, N[0xee0b, ((0, 3), (0, 4))] = 1
Updated Q[0xedaf, ((1, 2), (1, 3))] = 34400, N[0xedaf, ((1, 2), (1, 3))] = 1
Updated Q[0xf1eb, ((0, 3), (1, 3))] = 34400, N[0xf1eb, ((0, 3), (1, 3))] = 1

--- Simulation 187 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.200384895677, 16803.200384895677, 21868.918546993016, 16803.200384895677, 19603.200384895677]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x440b, Score: 8400
Depth 2: State = 0x440b, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x440b: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4a8b, Score: 19300
Depth 3: State = 0x4a8b, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a8b: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4ab7, Score: 22100
Depth 4: State = 0x4ab7, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x4ab7: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x456c, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4007800, N[0x3c25, ((2, 3), (2, 4))] = 183
Updated Q[0x3c24, ((0, 0), (0, 1))] = 27700, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x440b, ((0, 2), (1, 2))] = 27700, N[0x440b, ((0, 2), (1, 2))] = 1
Updated Q[0x4a8b, ((1, 2), (2, 2))] = 27700, N[0x4a8b, ((1, 2), (2, 2))] = 1
Updated Q[0x4ab7, ((2, 0), (2, 1))] = 27700, N[0x4ab7, ((2, 0), (2, 1))] = 1

--- Simulation 188 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.20202637232, 16803.20202637232, 21900.78314868789, 16803.20202637232, 19603.20202637232]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x39bc, Score: 11200
Depth 2: State = 0x39bc, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39bc: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x39a1, Score: 24900
Depth 3: State = 0x39a1, Legal Moves = [((0, 2), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39a1: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x391d, Score: 27700
Depth 4: State = 0x391d, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x391d: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3bc3, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4038300, N[0x3c25, ((2, 3), (2, 4))] = 184
Updated Q[0x3c25, ((1, 3), (2, 3))] = 30500, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x39bc, ((1, 2), (2, 2))] = 30500, N[0x39bc, ((1, 2), (2, 2))] = 1
Updated Q[0x39a1, ((0, 2), (1, 2))] = 30500, N[0x39a1, ((0, 2), (1, 2))] = 1
Updated Q[0x391d, ((1, 1), (2, 1))] = 30500, N[0x391d, ((1, 1), (2, 1))] = 1

--- Simulation 189 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.203658260045, 16803.203658260045, 21947.518785516007, 16803.203658260045, 19603.203658260045]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3be2, Score: 8400
Depth 1: State = 0x3be2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be2: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bb9, Score: 16100
Depth 2: State = 0x3bb9, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb9: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x3c1b, Score: 18900
Depth 3: State = 0x3c1b, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3c1b: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x1c62, Score: 24500
Depth 4: State = 0x1c62, Legal Moves = [((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1c62: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1c85, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4065600, N[0x3c25, ((2, 3), (2, 4))] = 185
Updated Q[0x3be2, ((1, 3), (2, 3))] = 27300, N[0x3be2, ((1, 3), (2, 3))] = 1
Updated Q[0x3bb9, ((0, 2), (0, 3))] = 27300, N[0x3bb9, ((0, 2), (0, 3))] = 1
Updated Q[0x3c1b, ((0, 2), (0, 3))] = 27300, N[0x3c1b, ((0, 2), (0, 3))] = 1
Updated Q[0x1c62, ((0, 2), (1, 2))] = 27300, N[0x1c62, ((0, 2), (1, 2))] = 1

--- Simulation 190 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.20528066626, 16803.20528066626, 21976.45187313759, 16803.20528066626, 19603.20528066626]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [18901.16557645562, 22401.16557645562, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bb8, Score: 13300
Depth 2: State = 0x3bb8, Legal Moves = [((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb8: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bbb, Score: 16100
Depth 3: State = 0x3bbb, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbb: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x393b, Score: 21700
Depth 4: State = 0x393b, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x393b: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3a8e, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4090100, N[0x3c25, ((2, 3), (2, 4))] = 186
Updated Q[0x3c25, ((1, 3), (2, 3))] = 24500, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3bb8, ((1, 2), (2, 2))] = 24500, N[0x3bb8, ((1, 2), (2, 2))] = 1
Updated Q[0x3bbb, ((0, 3), (1, 3))] = 24500, N[0x3bbb, ((0, 3), (1, 3))] = 1
Updated Q[0x393b, ((2, 0), (2, 1))] = 24500, N[0x393b, ((2, 0), (2, 1))] = 1

--- Simulation 191 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.20689369662, 16803.20689369662, 21990.020087090954, 16803.20689369662, 19603.20689369662]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 27301.467405903557, 27701.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3673, Score: 14000
Depth 2: State = 0x3673, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3673: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0xf227, Score: 30500
Depth 3: State = 0xf227, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0xf227: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x131a, Score: 33300
Depth 4: State = 0x131a, Legal Moves = [((0, 0), (1, 0)), ((0, 2), (1, 2)), ((1, 3), (1, 4)), ((2, 2), (2, 3)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x131a: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x14b1, Score: 36100
End of simulation with depth 5. Reward (Score): 36100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4126200, N[0x3c25, ((2, 3), (2, 4))] = 187
Updated Q[0x3c24, ((2, 3), (3, 3))] = 36100, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x3673, ((1, 2), (1, 3))] = 36100, N[0x3673, ((1, 2), (1, 3))] = 1
Updated Q[0xf227, ((1, 1), (2, 1))] = 36100, N[0xf227, ((1, 1), (2, 1))] = 1
Updated Q[0x131a, ((0, 0), (1, 0))] = 36100, N[0x131a, ((0, 0), (1, 0))] = 1

--- Simulation 192 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.208497455034, 16803.208497455034, 22065.475270282404, 16803.208497455034, 19603.208497455034]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x467c, Score: 11200
Depth 2: State = 0x467c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x467c: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4655, Score: 14000
Depth 3: State = 0x4655, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4655: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4655, Score: 16800
Depth 4: State = 0x4655, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4655: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x43af, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4145800, N[0x3c25, ((2, 3), (2, 4))] = 188
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x467c, ((1, 2), (2, 2))] = 19600, N[0x467c, ((1, 2), (2, 2))] = 1
Updated Q[0x4655, ((0, 3), (1, 3))] = 19600, N[0x4655, ((0, 3), (1, 3))] = 1
Updated Q[0x4655, ((2, 0), (2, 1))] = 19600, N[0x4655, ((2, 0), (2, 1))] = 1

--- Simulation 193 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.210092043722, 16803.210092043722, 22052.3617795988, 16803.210092043722, 19603.210092043722]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3975, Score: 11200
Depth 2: State = 0x3975, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3975: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x391d, Score: 14000
Depth 3: State = 0x391d, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x391d: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3a70, Score: 16800
Depth 4: State = 0x3a70, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3a70: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x36dd, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4168200, N[0x3c25, ((2, 3), (2, 4))] = 189
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3975, ((1, 3), (2, 3))] = 22400, N[0x3975, ((1, 3), (2, 3))] = 1
Updated Q[0x391d, ((1, 1), (2, 1))] = 22400, N[0x391d, ((1, 1), (2, 1))] = 1
Updated Q[0x3a70, ((0, 1), (0, 2))] = 22400, N[0x3a70, ((0, 1), (0, 2))] = 1

--- Simulation 194 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.211677563246, 16803.211677563246, 22054.201869135577, 16803.211677563246, 19603.211677563246]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a91, Score: 8400
Depth 2: State = 0x4a91, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a91: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x21c4, Score: 22100
Depth 3: State = 0x21c4, Legal Moves = [((0, 0), (1, 0)), ((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x21c4: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x47c0, Score: 27700
Depth 4: State = 0x47c0, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c0: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x2d26, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4198700, N[0x3c25, ((2, 3), (2, 4))] = 190
Updated Q[0x3c24, ((0, 0), (0, 1))] = 30500, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a91, ((1, 3), (2, 3))] = 30500, N[0x4a91, ((1, 3), (2, 3))] = 1
Updated Q[0x21c4, ((0, 0), (1, 0))] = 30500, N[0x21c4, ((0, 0), (1, 0))] = 1
Updated Q[0x47c0, ((1, 0), (2, 0))] = 30500, N[0x47c0, ((1, 0), (2, 0))] = 1

--- Simulation 195 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.213254112543, 16803.213254112543, 22098.654166586002, 16803.213254112543, 19603.213254112543]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bd9, Score: 8400
Depth 1: State = 0x3bd9, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bd9: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d0d, Score: 11200
Depth 2: State = 0x3d0d, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3d0d: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3806, Score: 14000
Depth 3: State = 0x3806, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3806: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3806, Score: 16800
Depth 4: State = 0x3806, Legal Moves = [((3, 3), (3, 4))]
UCB1 values for moves at state 0x3806: [inf]
Selected move: ((3, 3), (3, 4))
New board state after move: 0x3806, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4218300, N[0x3c25, ((2, 3), (2, 4))] = 191
Updated Q[0x3bd9, ((1, 3), (1, 4))] = 19600, N[0x3bd9, ((1, 3), (1, 4))] = 1
Updated Q[0x3d0d, ((1, 1), (2, 1))] = 19600, N[0x3d0d, ((1, 1), (2, 1))] = 1
Updated Q[0x3806, ((2, 0), (2, 1))] = 19600, N[0x3806, ((2, 0), (2, 1))] = 1
Updated Q[0x3806, ((3, 3), (3, 4))] = 19600, N[0x3806, ((3, 3), (3, 4))] = 1

--- Simulation 196 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.214821788963, 16803.214821788963, 22085.572930476832, 16803.214821788963, 19603.214821788963]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bfc, Score: 11200
Depth 2: State = 0x3bfc, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bfc: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3807, Score: 14000
Depth 3: State = 0x3807, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3807: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3aad, Score: 16800
Depth 4: State = 0x3aad, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3))]
UCB1 values for moves at state 0x3aad: [inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3986, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4237900, N[0x3c25, ((2, 3), (2, 4))] = 192
Updated Q[0x3c24, ((1, 2), (2, 2))] = 19600, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3bfc, ((1, 3), (2, 3))] = 19600, N[0x3bfc, ((1, 3), (2, 3))] = 1
Updated Q[0x3807, ((2, 0), (2, 1))] = 19600, N[0x3807, ((2, 0), (2, 1))] = 1
Updated Q[0x3aad, ((0, 1), (1, 1))] = 19600, N[0x3aad, ((0, 1), (1, 1))] = 1

--- Simulation 197 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.216380688304, 16803.216380688304, 22072.627955615357, 16803.216380688304, 19603.216380688304]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4549, Score: 8400
Depth 2: State = 0x4549, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4549: [inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x454a, Score: 11200
Depth 3: State = 0x454a, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x454a: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x49a8, Score: 14000
Depth 4: State = 0x49a8, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x49a8: [inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x54eb, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4254700, N[0x3c25, ((2, 3), (2, 4))] = 193
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4549, ((0, 4), (1, 4))] = 16800, N[0x4549, ((0, 4), (1, 4))] = 1
Updated Q[0x454a, ((1, 3), (2, 3))] = 16800, N[0x454a, ((1, 3), (2, 3))] = 1
Updated Q[0x49a8, ((0, 2), (0, 3))] = 16800, N[0x49a8, ((0, 2), (0, 3))] = 1

--- Simulation 198 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.21793090484, 16803.21793090484, 22045.309351942265, 16803.21793090484, 19603.21793090484]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x148e, Score: 11200
Depth 2: State = 0x148e, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x148e: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x57c9, Score: 22100
Depth 3: State = 0x57c9, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x57c9: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x22fb, Score: 27700
Depth 4: State = 0x22fb, Legal Moves = [((0, 2), (0, 3)), ((2, 1), (3, 1)), ((2, 3), (2, 4)), ((4, 0), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x22fb: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x2299, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4285200, N[0x3c25, ((2, 3), (2, 4))] = 194
Updated Q[0x3c24, ((0, 0), (0, 1))] = 30500, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x148e, ((0, 0), (1, 0))] = 30500, N[0x148e, ((0, 0), (1, 0))] = 1
Updated Q[0x57c9, ((2, 0), (2, 1))] = 30500, N[0x57c9, ((2, 0), (2, 1))] = 1
Updated Q[0x22fb, ((0, 2), (0, 3))] = 30500, N[0x22fb, ((0, 2), (0, 3))] = 1

--- Simulation 199 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.219472531357, 16803.219472531357, 22088.890938471468, 16803.219472531357, 19603.219472531357]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3da1, Score: 14000
Depth 2: State = 0x3da1, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3da1: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3be7, Score: 16800
Depth 3: State = 0x3be7, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be7: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3be7, Score: 19600
Depth 4: State = 0x3be7, Legal Moves = [((1, 1), (1, 2)), ((1, 1), (2, 1))]
UCB1 values for moves at state 0x3be7: [inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x3c2b, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4307600, N[0x3c25, ((2, 3), (2, 4))] = 195
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3da1, ((0, 1), (0, 2))] = 22400, N[0x3da1, ((0, 1), (0, 2))] = 1
Updated Q[0x3be7, ((2, 0), (2, 1))] = 22400, N[0x3be7, ((2, 0), (2, 1))] = 1
Updated Q[0x3be7, ((1, 1), (1, 2))] = 22400, N[0x3be7, ((1, 1), (1, 2))] = 1

--- Simulation 200 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.22100565918, 16803.22100565918, 22090.4870712626, 16803.22100565918, 19603.22100565918]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14000.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3af6, Score: 11200
Depth 2: State = 0x3af6, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3af6: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3d6d, Score: 14000
Depth 3: State = 0x3d6d, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d6d: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x213c, Score: 16800
Depth 4: State = 0x213c, Legal Moves = [((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x213c: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1d44, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4327200, N[0x3c25, ((2, 3), (2, 4))] = 196
Updated Q[0x3c24, ((1, 3), (1, 4))] = 19600, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x3af6, ((0, 1), (1, 1))] = 19600, N[0x3af6, ((0, 1), (1, 1))] = 1
Updated Q[0x3d6d, ((0, 1), (1, 1))] = 19600, N[0x3d6d, ((0, 1), (1, 1))] = 1
Updated Q[0x213c, ((2, 0), (2, 1))] = 19600, N[0x213c, ((2, 0), (2, 1))] = 1

--- Simulation 201 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.222530378203, 16803.222530378203, 22077.78120114946, 16803.222530378203, 19603.222530378203]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c69, Score: 8400
Depth 1: State = 0x3c69, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c69: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bb9, Score: 14000
Depth 2: State = 0x3bb9, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb9: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x11cb, Score: 22400
Depth 3: State = 0x11cb, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x11cb: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4678, Score: 25200
Depth 4: State = 0x4678, Legal Moves = [((2, 2), (2, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4678: [inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x4503, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4355200, N[0x3c25, ((2, 3), (2, 4))] = 197
Updated Q[0x3c69, ((1, 2), (2, 2))] = 28000, N[0x3c69, ((1, 2), (2, 2))] = 1
Updated Q[0x3bb9, ((2, 0), (2, 1))] = 28000, N[0x3bb9, ((2, 0), (2, 1))] = 1
Updated Q[0x11cb, ((1, 1), (2, 1))] = 28000, N[0x11cb, ((1, 1), (2, 1))] = 1
Updated Q[0x4678, ((2, 2), (2, 3))] = 28000, N[0x4678, ((2, 2), (2, 3))] = 1

--- Simulation 202 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.224046776922, 16803.224046776922, 22107.843917019847, 16803.224046776922, 19603.224046776922]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4afa, Score: 8400
Depth 2: State = 0x4afa, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4afa: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4ad9, Score: 11200
Depth 3: State = 0x4ad9, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ad9: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x53dc, Score: 14000
Depth 4: State = 0x53dc, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x53dc: [inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x56a1, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4372000, N[0x3c25, ((2, 3), (2, 4))] = 198
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4afa, ((1, 2), (2, 2))] = 16800, N[0x4afa, ((1, 2), (2, 2))] = 1
Updated Q[0x4ad9, ((0, 0), (0, 1))] = 16800, N[0x4ad9, ((0, 0), (0, 1))] = 1
Updated Q[0x53dc, ((0, 3), (0, 4))] = 16800, N[0x53dc, ((0, 3), (0, 4))] = 1

--- Simulation 203 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.225554942474, 16803.225554942474, 22081.037311016207, 16803.225554942474, 19603.225554942474]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x48fc, Score: 8400
Depth 2: State = 0x48fc, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48fc: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4566, Score: 14000
Depth 3: State = 0x4566, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4566: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4ab1, Score: 16800
Depth 4: State = 0x4ab1, Legal Moves = [((2, 1), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x4ab1: [inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x3aad, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4391600, N[0x3c25, ((2, 3), (2, 4))] = 199
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x48fc, ((1, 3), (2, 3))] = 19600, N[0x48fc, ((1, 3), (2, 3))] = 1
Updated Q[0x4566, ((2, 0), (2, 1))] = 19600, N[0x4566, ((2, 0), (2, 1))] = 1
Updated Q[0x4ab1, ((2, 1), (3, 1))] = 19600, N[0x4ab1, ((2, 1), (3, 1))] = 1

--- Simulation 204 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.22705496063, 16803.22705496063, 22068.570468403625, 16803.22705496063, 19603.22705496063]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46fe, Score: 8400
Depth 2: State = 0x46fe, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46fe: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x47f2, Score: 11200
Depth 3: State = 0x47f2, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47f2: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x454c, Score: 14000
Depth 4: State = 0x454c, Legal Moves = [((0, 1), (0, 2))]
UCB1 values for moves at state 0x454c: [inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x43d8, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4408400, N[0x3c25, ((2, 3), (2, 4))] = 200
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46fe, ((1, 3), (1, 4))] = 16800, N[0x46fe, ((1, 3), (1, 4))] = 1
Updated Q[0x47f2, ((1, 1), (2, 1))] = 16800, N[0x47f2, ((1, 1), (2, 1))] = 1
Updated Q[0x454c, ((0, 1), (0, 2))] = 16800, N[0x454c, ((0, 1), (0, 2))] = 1

--- Simulation 205 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.228546915863, 16803.228546915863, 22042.22829274176, 16803.228546915863, 19603.228546915863]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bd7, Score: 8400
Depth 1: State = 0x3bd7, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bd7: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x36f4, Score: 13300
Depth 2: State = 0x36f4, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36f4: [inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x3677, Score: 16100
Depth 3: State = 0x3677, Legal Moves = [((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3677: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x37eb, Score: 18900
Depth 4: State = 0x37eb, Legal Moves = [((0, 3), (0, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37eb: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x380e, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4430100, N[0x3c25, ((2, 3), (2, 4))] = 201
Updated Q[0x3bd7, ((0, 3), (1, 3))] = 21700, N[0x3bd7, ((0, 3), (1, 3))] = 1
Updated Q[0x36f4, ((0, 2), (0, 3))] = 21700, N[0x36f4, ((0, 2), (0, 3))] = 1
Updated Q[0x3677, ((1, 2), (2, 2))] = 21700, N[0x3677, ((1, 2), (2, 2))] = 1
Updated Q[0x37eb, ((0, 3), (0, 4))] = 21700, N[0x37eb, ((0, 3), (0, 4))] = 1

--- Simulation 206 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.230030891355, 16803.230030891355, 22040.526336275514, 16803.230030891355, 19603.230030891355]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x45ab, Score: 8400
Depth 2: State = 0x45ab, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45ab: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4ad1, Score: 16800
Depth 3: State = 0x4ad1, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ad1: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1df4, Score: 22400
Depth 4: State = 0x1df4, Legal Moves = [((1, 1), (1, 2)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x1df4: [inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x1df4, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4455300, N[0x3c25, ((2, 3), (2, 4))] = 202
Updated Q[0x3c24, ((0, 0), (0, 1))] = 25200, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x45ab, ((1, 3), (2, 3))] = 25200, N[0x45ab, ((1, 3), (2, 3))] = 1
Updated Q[0x4ad1, ((2, 0), (2, 1))] = 25200, N[0x4ad1, ((2, 0), (2, 1))] = 1
Updated Q[0x1df4, ((1, 1), (1, 2))] = 25200, N[0x1df4, ((1, 1), (1, 2))] = 1

--- Simulation 207 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.23150696902, 16803.23150696902, 22056.167962096322, 16803.23150696902, 19603.23150696902]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3be8, Score: 14000
Depth 2: State = 0x3be8, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be8: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bd7, Score: 16800
Depth 3: State = 0x3bd7, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bd7: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d2a, Score: 19600
Depth 4: State = 0x3d2a, Legal Moves = [((2, 1), (2, 2))]
UCB1 values for moves at state 0x3d2a: [inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x3d73, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4480500, N[0x3c25, ((2, 3), (2, 4))] = 203
Updated Q[0x3c24, ((1, 2), (2, 2))] = 25200, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3be8, ((1, 3), (2, 3))] = 25200, N[0x3be8, ((1, 3), (2, 3))] = 1
Updated Q[0x3bd7, ((2, 0), (2, 1))] = 25200, N[0x3bd7, ((2, 0), (2, 1))] = 1
Updated Q[0x3d2a, ((2, 1), (2, 2))] = 25200, N[0x3d2a, ((2, 1), (2, 2))] = 1

--- Simulation 208 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.232975229537, 16803.232975229537, 22071.655481806, 16803.232975229537, 19603.232975229537]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 10500
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x49a2, Score: 13300
Depth 2: State = 0x49a2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x49a2: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x443c, Score: 16100
Depth 3: State = 0x443c, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443c: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1300, Score: 18900
Depth 4: State = 0x1300, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1300: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x12bf, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4502200, N[0x3c25, ((2, 3), (2, 4))] = 204
Updated Q[0x3c25, ((0, 0), (0, 1))] = 21700, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x49a2, ((1, 3), (2, 3))] = 21700, N[0x49a2, ((1, 3), (2, 3))] = 1
Updated Q[0x443c, ((0, 0), (0, 1))] = 21700, N[0x443c, ((0, 0), (0, 1))] = 1
Updated Q[0x1300, ((0, 2), (1, 2))] = 21700, N[0x1300, ((0, 2), (1, 2))] = 1

--- Simulation 209 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.234435752373, 16803.234435752373, 22069.83429893561, 16803.234435752373, 19603.234435752373]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3b16, Score: 11200
Depth 2: State = 0x3b16, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3b16: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x1d56, Score: 14000
Depth 3: State = 0x1d56, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1d56: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x1d55, Score: 16800
Depth 4: State = 0x1d55, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1d55: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3020, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4521800, N[0x3c25, ((2, 3), (2, 4))] = 205
Updated Q[0x3c25, ((1, 3), (2, 3))] = 19600, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3b16, ((0, 2), (0, 3))] = 19600, N[0x3b16, ((0, 2), (0, 3))] = 1
Updated Q[0x1d56, ((1, 3), (1, 4))] = 19600, N[0x1d56, ((1, 3), (1, 4))] = 1
Updated Q[0x1d55, ((1, 2), (1, 3))] = 19600, N[0x1d55, ((1, 2), (1, 3))] = 1

--- Simulation 210 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.235888615796, 16803.235888615796, 22057.786979874054, 16803.235888615796, 19603.235888615796]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4960, Score: 8400
Depth 2: State = 0x4960, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4960: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x465c, Score: 14000
Depth 3: State = 0x465c, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x465c: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x465c, Score: 16800
Depth 4: State = 0x465c, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x465c: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x465d, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4541400, N[0x3c25, ((2, 3), (2, 4))] = 206
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4960, ((1, 3), (2, 3))] = 19600, N[0x4960, ((1, 3), (2, 3))] = 1
Updated Q[0x465c, ((1, 3), (1, 4))] = 19600, N[0x465c, ((1, 3), (1, 4))] = 1
Updated Q[0x465c, ((0, 4), (1, 4))] = 19600, N[0x465c, ((0, 4), (1, 4))] = 1

--- Simulation 211 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.23733389693, 16803.23733389693, 22045.85662370159, 16803.23733389693, 19603.23733389693]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d37, Score: 11200
Depth 2: State = 0x3d37, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d37: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x29c3, Score: 14000
Depth 3: State = 0x29c3, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x29c3: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2c68, Score: 16800
Depth 4: State = 0x2c68, Legal Moves = [((1, 1), (1, 2)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x2c68: [inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x2bd4, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4561000, N[0x3c25, ((2, 3), (2, 4))] = 207
Updated Q[0x3c24, ((1, 3), (1, 4))] = 19600, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x3d37, ((1, 2), (1, 3))] = 19600, N[0x3d37, ((1, 2), (1, 3))] = 1
Updated Q[0x29c3, ((2, 0), (2, 1))] = 19600, N[0x29c3, ((2, 0), (2, 1))] = 1
Updated Q[0x2c68, ((1, 1), (1, 2))] = 19600, N[0x2c68, ((1, 1), (1, 2))] = 1

--- Simulation 212 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.23877167173, 16803.23877167173, 22034.04153531324, 16803.23877167173, 19603.23877167173]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.648374031523, 21701.648374031523, 16801.648374031523, 22401.648374031523, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x1f4b, Score: 11200
Depth 2: State = 0x1f4b, Legal Moves = [((1, 0), (2, 0)), ((2, 0), (2, 1)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x1f4b: [inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x458b, Score: 14000
Depth 3: State = 0x458b, Legal Moves = [((2, 2), (2, 3)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x458b: [inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x4581, Score: 18900
Depth 4: State = 0x4581, Legal Moves = [((2, 3), (2, 4))]
UCB1 values for moves at state 0x4581: [inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x4584, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4585500, N[0x3c25, ((2, 3), (2, 4))] = 208
Updated Q[0x3c25, ((3, 0), (3, 1))] = 24500, N[0x3c25, ((3, 0), (3, 1))] = 1
Updated Q[0x1f4b, ((1, 0), (2, 0))] = 24500, N[0x1f4b, ((1, 0), (2, 0))] = 1
Updated Q[0x458b, ((2, 2), (2, 3))] = 24500, N[0x458b, ((2, 2), (2, 3))] = 1
Updated Q[0x4581, ((2, 3), (2, 4))] = 24500, N[0x4581, ((2, 3), (2, 4))] = 1

--- Simulation 213 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.240202015055, 16803.240202015055, 22045.897744509773, 16803.240202015055, 19603.240202015055]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [21700.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d90, Score: 11200
Depth 2: State = 0x3d90, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d90: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1dee, Score: 14000
Depth 3: State = 0x1dee, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1dee: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2094, Score: 16800
Depth 4: State = 0x2094, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 1), (4, 1))]
UCB1 values for moves at state 0x2094: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0xf3dd, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4607900, N[0x3c25, ((2, 3), (2, 4))] = 209
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3d90, ((0, 2), (1, 2))] = 22400, N[0x3d90, ((0, 2), (1, 2))] = 1
Updated Q[0x1dee, ((2, 0), (2, 1))] = 22400, N[0x1dee, ((2, 0), (2, 1))] = 1
Updated Q[0x2094, ((0, 1), (1, 1))] = 22400, N[0x2094, ((0, 1), (1, 1))] = 1

--- Simulation 214 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.241625000643, 16803.241625000643, 22047.592648942566, 16803.241625000643, 19603.241625000643]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46e0, Score: 8400
Depth 2: State = 0x46e0, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46e0: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2ee1, Score: 11200
Depth 3: State = 0x2ee1, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2ee1: [inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x2ee1, Score: 14000
Depth 4: State = 0x2ee1, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2ee1: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x2ddc, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4624700, N[0x3c25, ((2, 3), (2, 4))] = 210
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46e0, ((0, 0), (0, 1))] = 16800, N[0x46e0, ((0, 0), (0, 1))] = 1
Updated Q[0x2ee1, ((0, 4), (1, 4))] = 16800, N[0x2ee1, ((0, 4), (1, 4))] = 1
Updated Q[0x2ee1, ((1, 3), (2, 3))] = 16800, N[0x2ee1, ((1, 3), (2, 3))] = 1

--- Simulation 215 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.24304070117, 16803.24304070117, 22022.604743450498, 16803.24304070117, 19603.24304070117]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [30500.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d4b, Score: 11200
Depth 2: State = 0x3d4b, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d4b: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2b29, Score: 14000
Depth 3: State = 0x2b29, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2b29: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x2b34, Score: 16800
Depth 4: State = 0x2b34, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2b34: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x2ab0, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4644300, N[0x3c25, ((2, 3), (2, 4))] = 211
Updated Q[0x3c24, ((1, 3), (1, 4))] = 19600, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x3d4b, ((1, 2), (1, 3))] = 19600, N[0x3d4b, ((1, 2), (1, 3))] = 1
Updated Q[0x2b29, ((1, 3), (1, 4))] = 19600, N[0x2b29, ((1, 3), (1, 4))] = 1
Updated Q[0x2b34, ((1, 2), (2, 2))] = 19600, N[0x2b34, ((1, 2), (2, 2))] = 1

--- Simulation 216 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.24444918825, 16803.24444918825, 22011.123831027027, 16803.24444918825, 19603.24444918825]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47ab, Score: 8400
Depth 2: State = 0x47ab, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47ab: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x47af, Score: 11200
Depth 3: State = 0x47af, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47af: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4902, Score: 14000
Depth 4: State = 0x4902, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x4902: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x4921, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4663900, N[0x3c25, ((2, 3), (2, 4))] = 212
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47ab, ((1, 2), (2, 2))] = 19600, N[0x47ab, ((1, 2), (2, 2))] = 1
Updated Q[0x47af, ((2, 0), (2, 1))] = 19600, N[0x47af, ((2, 0), (2, 1))] = 1
Updated Q[0x4902, ((4, 1), (4, 2))] = 19600, N[0x4902, ((4, 1), (4, 2))] = 1

--- Simulation 217 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.245850532458, 16803.245850532458, 21999.751227816607, 16803.245850532458, 19603.245850532458]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c46, Score: 8400
Depth 1: State = 0x3c46, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c46: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3be0, Score: 11200
Depth 2: State = 0x3be0, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be0: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3825, Score: 19600
Depth 3: State = 0x3825, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((0, 2), (1, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3825: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3c68, Score: 32100
Depth 4: State = 0x3c68, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c68: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c46, Score: 34900
End of simulation with depth 5. Reward (Score): 34900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4698800, N[0x3c25, ((2, 3), (2, 4))] = 213
Updated Q[0x3c46, ((0, 0), (1, 0))] = 34900, N[0x3c46, ((0, 0), (1, 0))] = 1
Updated Q[0x3be0, ((1, 3), (2, 3))] = 34900, N[0x3be0, ((1, 3), (2, 3))] = 1
Updated Q[0x3825, ((0, 1), (0, 2))] = 34900, N[0x3825, ((0, 1), (0, 2))] = 1
Updated Q[0x3c68, ((0, 2), (1, 2))] = 34900, N[0x3c68, ((0, 2), (1, 2))] = 1

--- Simulation 218 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.24724480336, 16803.24724480336, 22060.316394261343, 16803.24724480336, 19603.24724480336]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bda, Score: 8400
Depth 1: State = 0x3bda, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bda: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x386d, Score: 11200
Depth 2: State = 0x386d, Legal Moves = [((0, 1), (0, 2)), ((0, 1), (1, 1)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x386d: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x2c62, Score: 16800
Depth 3: State = 0x2c62, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2c62: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x1212, Score: 19600
Depth 4: State = 0x1212, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1212: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x11c0, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4721200, N[0x3c25, ((2, 3), (2, 4))] = 214
Updated Q[0x3bda, ((1, 3), (2, 3))] = 22400, N[0x3bda, ((1, 3), (2, 3))] = 1
Updated Q[0x386d, ((0, 1), (0, 2))] = 22400, N[0x386d, ((0, 1), (0, 2))] = 1
Updated Q[0x2c62, ((0, 2), (0, 3))] = 22400, N[0x2c62, ((0, 2), (0, 3))] = 1
Updated Q[0x1212, ((0, 2), (1, 2))] = 22400, N[0x1212, ((0, 2), (1, 2))] = 1

--- Simulation 219 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.248632069513, 16803.248632069513, 22061.904314907133, 16803.248632069513, 19603.248632069513]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [30500.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3719, Score: 11200
Depth 2: State = 0x3719, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3719: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3db8, Score: 14000
Depth 3: State = 0x3db8, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (2, 2)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3db8: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3ab0, Score: 16800
Depth 4: State = 0x3ab0, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (1, 3)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3ab0: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x2d4e, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4740800, N[0x3c25, ((2, 3), (2, 4))] = 215
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3719, ((2, 0), (2, 1))] = 19600, N[0x3719, ((2, 0), (2, 1))] = 1
Updated Q[0x3db8, ((1, 1), (2, 1))] = 19600, N[0x3db8, ((1, 1), (2, 1))] = 1
Updated Q[0x3ab0, ((0, 2), (0, 3))] = 19600, N[0x3ab0, ((0, 2), (0, 3))] = 1

--- Simulation 220 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.250012398505, 16803.250012398505, 22050.454207145434, 16803.250012398505, 19603.250012398505]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [24400.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d7f, Score: 11200
Depth 2: State = 0x3d7f, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d7f: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3913, Score: 14000
Depth 3: State = 0x3913, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3913: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x5129, Score: 19600
Depth 4: State = 0x5129, Legal Moves = [((1, 3), (2, 3))]
UCB1 values for moves at state 0x5129: [inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x53fe, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4763200, N[0x3c25, ((2, 3), (2, 4))] = 216
Updated Q[0x3c25, ((1, 3), (1, 4))] = 22400, N[0x3c25, ((1, 3), (1, 4))] = 1
Updated Q[0x3d7f, ((0, 2), (1, 2))] = 22400, N[0x3d7f, ((0, 2), (1, 2))] = 1
Updated Q[0x3913, ((2, 0), (2, 1))] = 22400, N[0x3913, ((2, 0), (2, 1))] = 1
Updated Q[0x5129, ((1, 3), (2, 3))] = 22400, N[0x5129, ((1, 3), (2, 3))] = 1

--- Simulation 221 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.251385856962, 16803.251385856962, 22052.07308063814, 16803.251385856962, 19603.251385856962]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c0a, Score: 8400
Depth 1: State = 0x3c0a, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c0a: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c27, Score: 11200
Depth 2: State = 0x3c27, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c27: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x382f, Score: 14000
Depth 3: State = 0x382f, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x382f: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x3874, Score: 16800
Depth 4: State = 0x3874, Legal Moves = [((2, 3), (2, 4))]
UCB1 values for moves at state 0x3874: [inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3867, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4782800, N[0x3c25, ((2, 3), (2, 4))] = 217
Updated Q[0x3c0a, ((1, 2), (2, 2))] = 19600, N[0x3c0a, ((1, 2), (2, 2))] = 1
Updated Q[0x3c27, ((2, 0), (2, 1))] = 19600, N[0x3c27, ((2, 0), (2, 1))] = 1
Updated Q[0x382f, ((4, 1), (4, 2))] = 19600, N[0x382f, ((4, 1), (4, 2))] = 1
Updated Q[0x3874, ((2, 3), (2, 4))] = 19600, N[0x3874, ((2, 3), (2, 4))] = 1

--- Simulation 222 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.25275251056, 16803.25275251056, 22040.773806620124, 16803.25275251056, 19603.25275251056]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c21, Score: 11200
Depth 2: State = 0x3c21, Legal Moves = [((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3c21: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397b, Score: 14000
Depth 3: State = 0x397b, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (1, 1)), ((2, 1), (3, 1)), ((2, 4), (3, 4)), ((3, 3), (3, 4)), ((3, 3), (4, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397b: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x120a, Score: 16800
Depth 4: State = 0x120a, Legal Moves = [((2, 1), (3, 1)), ((2, 4), (3, 4)), ((3, 3), (3, 4)), ((3, 3), (4, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x120a: [inf, inf, inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x144a, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4813300, N[0x3c25, ((2, 3), (2, 4))] = 218
Updated Q[0x3c25, ((1, 2), (2, 2))] = 30500, N[0x3c25, ((1, 2), (2, 2))] = 1
Updated Q[0x3c21, ((2, 0), (2, 1))] = 30500, N[0x3c21, ((2, 0), (2, 1))] = 1
Updated Q[0x397b, ((0, 0), (1, 0))] = 30500, N[0x397b, ((0, 0), (1, 0))] = 1
Updated Q[0x120a, ((2, 1), (3, 1))] = 30500, N[0x120a, ((2, 1), (3, 1))] = 1

--- Simulation 223 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.254112424067, 16803.254112424067, 22079.57819446862, 16803.254112424067, 19603.254112424067]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c6f, Score: 8400
Depth 1: State = 0x3c6f, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c6f: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c67, Score: 11200
Depth 2: State = 0x3c67, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c67: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3be0, Score: 25200
Depth 3: State = 0x3be0, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be0: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c25, Score: 28000
Depth 4: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x445a, Score: 30800
End of simulation with depth 5. Reward (Score): 30800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4844100, N[0x3c25, ((2, 3), (2, 4))] = 219
Updated Q[0x3c6f, ((1, 2), (2, 2))] = 30800, N[0x3c6f, ((1, 2), (2, 2))] = 1
Updated Q[0x3c67, ((0, 3), (1, 3))] = 30800, N[0x3c67, ((0, 3), (1, 3))] = 1
Updated Q[0x3be0, ((0, 2), (1, 2))] = 30800, N[0x3be0, ((0, 2), (1, 2))] = 1
Updated Q[0x3c25, ((0, 0), (0, 1))] = 30800, N[0x3c25, ((0, 0), (0, 1))] = 1

--- Simulation 224 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.255465661325, 16803.255465661325, 22119.398066174926, 16803.255465661325, 19603.255465661325]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4506, Score: 11200
Depth 2: State = 0x4506, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4506: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a76, Score: 16800
Depth 3: State = 0x4a76, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a76: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x47d1, Score: 19600
Depth 4: State = 0x47d1, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 1), (4, 1))]
UCB1 values for moves at state 0x47d1: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x37ef, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4866500, N[0x3c25, ((2, 3), (2, 4))] = 220
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4506, ((1, 3), (2, 3))] = 22400, N[0x4506, ((1, 3), (2, 3))] = 1
Updated Q[0x4a76, ((1, 1), (2, 1))] = 22400, N[0x4a76, ((1, 1), (2, 1))] = 1
Updated Q[0x47d1, ((0, 0), (0, 1))] = 22400, N[0x47d1, ((0, 0), (0, 1))] = 1

--- Simulation 225 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.256812285294, 16803.256812285294, 22120.674119694024, 16803.256812285294, 19603.256812285294]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x48f8, Score: 8400
Depth 2: State = 0x48f8, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x48f8: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x499a, Score: 11200
Depth 3: State = 0x499a, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x499a: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x46bb, Score: 14000
Depth 4: State = 0x46bb, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46bb: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x469c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4886100, N[0x3c25, ((2, 3), (2, 4))] = 221
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x48f8, ((1, 2), (2, 2))] = 19600, N[0x48f8, ((1, 2), (2, 2))] = 1
Updated Q[0x499a, ((0, 3), (1, 3))] = 19600, N[0x499a, ((0, 3), (1, 3))] = 1
Updated Q[0x46bb, ((0, 3), (1, 3))] = 19600, N[0x46bb, ((0, 3), (1, 3))] = 1

--- Simulation 226 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.25815235806, 16803.25815235806, 22109.26894080065, 16803.25815235806, 19603.25815235806]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4705, Score: 8400
Depth 2: State = 0x4705, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4705: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4527, Score: 11200
Depth 3: State = 0x4527, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4527: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4527, Score: 14000
Depth 4: State = 0x4527, Legal Moves = [((1, 3), (1, 4)), ((1, 4), (2, 4)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x4527: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x452a, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4902900, N[0x3c25, ((2, 3), (2, 4))] = 222
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4705, ((1, 3), (2, 3))] = 16800, N[0x4705, ((1, 3), (2, 3))] = 1
Updated Q[0x4527, ((1, 1), (2, 1))] = 16800, N[0x4527, ((1, 1), (2, 1))] = 1
Updated Q[0x4527, ((1, 3), (1, 4))] = 16800, N[0x4527, ((1, 3), (1, 4))] = 1

--- Simulation 227 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.259485940845, 16803.259485940845, 22085.353897507746, 16803.259485940845, 19603.259485940845]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [24900.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c3b, Score: 11200
Depth 2: State = 0x3c3b, Legal Moves = [((0, 0), (1, 0)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3c3b: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x46d2, Score: 16800
Depth 3: State = 0x46d2, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x46d2: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x46d2, Score: 19600
Depth 4: State = 0x46d2, Legal Moves = [((3, 2), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x46d2: [inf, inf]
Selected move: ((3, 2), (3, 3))
New board state after move: 0x46e3, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4928100, N[0x3c25, ((2, 3), (2, 4))] = 223
Updated Q[0x3c25, ((1, 2), (2, 2))] = 25200, N[0x3c25, ((1, 2), (2, 2))] = 1
Updated Q[0x3c3b, ((0, 0), (1, 0))] = 25200, N[0x3c3b, ((0, 0), (1, 0))] = 1
Updated Q[0x46d2, ((2, 0), (2, 1))] = 25200, N[0x46d2, ((2, 0), (2, 1))] = 1
Updated Q[0x46d2, ((3, 2), (3, 3))] = 25200, N[0x46d2, ((3, 2), (3, 3))] = 1

--- Simulation 228 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.26081309404, 16803.26081309404, 22099.321499209094, 16803.26081309404, 19603.26081309404]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c1b, Score: 13300
Depth 2: State = 0x3c1b, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1b: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x1d45, Score: 16100
Depth 3: State = 0x1d45, Legal Moves = [((1, 0), (1, 1)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1d45: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x2038, Score: 18900
Depth 4: State = 0x2038, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x2038: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x36b8, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4949800, N[0x3c25, ((2, 3), (2, 4))] = 224
Updated Q[0x3c25, ((1, 3), (2, 3))] = 21700, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3c1b, ((1, 2), (1, 3))] = 21700, N[0x3c1b, ((1, 2), (1, 3))] = 1
Updated Q[0x1d45, ((1, 0), (1, 1))] = 21700, N[0x1d45, ((1, 0), (1, 1))] = 1
Updated Q[0x2038, ((0, 0), (0, 1))] = 21700, N[0x2038, ((0, 0), (0, 1))] = 1

--- Simulation 229 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.262133877197, 16803.262133877197, 22097.539389059253, 16803.262133877197, 19603.262133877197]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c24, Score: 8400
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 1), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a72, Score: 11200
Depth 3: State = 0x4a72, Legal Moves = [((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4a72: [inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x4a94, Score: 14000
Depth 4: State = 0x4a94, Legal Moves = [((1, 4), (2, 4)), ((2, 3), (2, 4)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4a94: [inf, inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x4a91, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4966600, N[0x3c25, ((2, 3), (2, 4))] = 225
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a72, ((1, 1), (1, 2))] = 16800, N[0x4a72, ((1, 1), (1, 2))] = 1
Updated Q[0x4a94, ((1, 4), (2, 4))] = 16800, N[0x4a94, ((1, 4), (2, 4))] = 1

--- Simulation 230 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.26344834906, 16803.26344834906, 22073.99534100105, 16803.26344834906, 19603.26344834906]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14000.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x37ca, Score: 11200
Depth 2: State = 0x37ca, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37ca: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3a70, Score: 14000
Depth 3: State = 0x3a70, Legal Moves = [((2, 1), (3, 1)), ((2, 2), (2, 3)), ((3, 1), (4, 1))]
UCB1 values for moves at state 0x3a70: [inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x2c8a, Score: 19600
Depth 4: State = 0x2c8a, Legal Moves = [((1, 1), (2, 1))]
UCB1 values for moves at state 0x2c8a: [inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3083, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 4989000, N[0x3c25, ((2, 3), (2, 4))] = 226
Updated Q[0x3c24, ((1, 3), (1, 4))] = 22400, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x37ca, ((2, 0), (2, 1))] = 22400, N[0x37ca, ((2, 0), (2, 1))] = 1
Updated Q[0x3a70, ((2, 1), (3, 1))] = 22400, N[0x3a70, ((2, 1), (3, 1))] = 1
Updated Q[0x2c8a, ((1, 1), (2, 1))] = 22400, N[0x2c8a, ((1, 1), (2, 1))] = 1

--- Simulation 231 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.26475656757, 16803.26475656757, 22075.43840731453, 16803.26475656757, 19603.26475656757]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c4d, Score: 11200
Depth 1: State = 0x3c4d, Legal Moves = [((0, 0), (1, 0)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4d: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x1f51, Score: 14000
Depth 2: State = 0x1f51, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1f51: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x1f07, Score: 16800
Depth 3: State = 0x1f07, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1f07: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x1efd, Score: 19600
Depth 4: State = 0x1efd, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1efd: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1efd, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5011400, N[0x3c25, ((2, 3), (2, 4))] = 227
Updated Q[0x3c4d, ((0, 0), (1, 0))] = 22400, N[0x3c4d, ((0, 0), (1, 0))] = 1
Updated Q[0x1f51, ((1, 2), (2, 2))] = 22400, N[0x1f51, ((1, 2), (2, 2))] = 1
Updated Q[0x1f07, ((0, 3), (1, 3))] = 22400, N[0x1f07, ((0, 3), (1, 3))] = 1
Updated Q[0x1efd, ((2, 0), (2, 1))] = 22400, N[0x1efd, ((2, 0), (2, 1))] = 1

--- Simulation 232 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.266058589896, 16803.266058589896, 22076.86875830117, 16803.266058589896, 19603.266058589896]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 22401.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d78, Score: 8400
Depth 2: State = 0x3d78, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d78: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x578a, Score: 11200
Depth 3: State = 0x578a, Legal Moves = [((2, 2), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x578a: [inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x57ce, Score: 14000
Depth 4: State = 0x57ce, Legal Moves = [((0, 2), (1, 2)), ((2, 3), (3, 3)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x57ce: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x541a, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5028200, N[0x3c25, ((2, 3), (2, 4))] = 228
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3d78, ((0, 0), (0, 1))] = 16800, N[0x3d78, ((0, 0), (0, 1))] = 1
Updated Q[0x578a, ((2, 2), (2, 3))] = 16800, N[0x578a, ((2, 2), (2, 3))] = 1
Updated Q[0x57ce, ((0, 2), (1, 2))] = 16800, N[0x57ce, ((0, 2), (1, 2))] = 1

--- Simulation 233 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.267354472424, 16803.267354472424, 22053.72515776586, 16803.267354472424, 19603.267354472424]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 8400
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x464f, Score: 11200
Depth 2: State = 0x464f, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x464f: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x48f5, Score: 14000
Depth 3: State = 0x48f5, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f5: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x44fd, Score: 16800
Depth 4: State = 0x44fd, Legal Moves = [((1, 3), (2, 3)), ((2, 2), (2, 3)), ((2, 3), (2, 4))]
UCB1 values for moves at state 0x44fd: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4506, Score: 27200
End of simulation with depth 5. Reward (Score): 27200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5055400, N[0x3c25, ((2, 3), (2, 4))] = 229
Updated Q[0x3c25, ((0, 0), (0, 1))] = 27200, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x464f, ((1, 3), (2, 3))] = 27200, N[0x464f, ((1, 3), (2, 3))] = 1
Updated Q[0x48f5, ((1, 1), (2, 1))] = 27200, N[0x48f5, ((1, 1), (2, 1))] = 1
Updated Q[0x44fd, ((1, 3), (2, 3))] = 27200, N[0x44fd, ((1, 3), (2, 3))] = 1

--- Simulation 234 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.268644270793, 16803.268644270793, 22076.198530844333, 16803.268644270793, 19603.268644270793]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 29801.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36d8, Score: 8400
Depth 2: State = 0x36d8, Legal Moves = [((0, 0), (0, 1)), ((1, 1), (2, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x36d8: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x15eb, Score: 11200
Depth 3: State = 0x15eb, Legal Moves = [((1, 1), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x15eb: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x56c4, Score: 14000
Depth 4: State = 0x56c4, Legal Moves = [((0, 0), (0, 1)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x56c4: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4adb, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5072200, N[0x3c25, ((2, 3), (2, 4))] = 230
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x36d8, ((0, 0), (0, 1))] = 16800, N[0x36d8, ((0, 0), (0, 1))] = 1
Updated Q[0x15eb, ((1, 1), (2, 1))] = 16800, N[0x15eb, ((1, 1), (2, 1))] = 1
Updated Q[0x56c4, ((0, 0), (0, 1))] = 16800, N[0x56c4, ((0, 0), (0, 1))] = 1

--- Simulation 235 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.269928039896, 16803.269928039896, 22053.25909093076, 16803.269928039896, 19603.269928039896]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bc6, Score: 11200
Depth 2: State = 0x3bc6, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc6: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3bc6, Score: 14000
Depth 3: State = 0x3bc6, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x3bc6: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x3c06, Score: 16800
Depth 4: State = 0x3c06, Legal Moves = [((0, 1), (0, 2))]
UCB1 values for moves at state 0x3c06: [inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3986, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5094600, N[0x3c25, ((2, 3), (2, 4))] = 231
Updated Q[0x3c24, ((1, 2), (2, 2))] = 22400, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3bc6, ((2, 0), (2, 1))] = 22400, N[0x3bc6, ((2, 0), (2, 1))] = 1
Updated Q[0x3bc6, ((4, 1), (4, 2))] = 22400, N[0x3bc6, ((4, 1), (4, 2))] = 1
Updated Q[0x3c06, ((0, 1), (0, 2))] = 22400, N[0x3c06, ((0, 1), (0, 2))] = 1

--- Simulation 236 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.2712058339, 16803.2712058339, 22054.760684087752, 16803.2712058339, 19603.2712058339]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 29801.467405903557, 16801.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3673, Score: 11200
Depth 2: State = 0x3673, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3673: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3d4f, Score: 14000
Depth 3: State = 0x3d4f, Legal Moves = [((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d4f: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3d15, Score: 16800
Depth 4: State = 0x3d15, Legal Moves = [((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d15: [inf, inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x37c9, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5114200, N[0x3c25, ((2, 3), (2, 4))] = 232
Updated Q[0x3c24, ((2, 3), (3, 3))] = 19600, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x3673, ((0, 3), (0, 4))] = 19600, N[0x3673, ((0, 3), (0, 4))] = 1
Updated Q[0x3d4f, ((0, 4), (1, 4))] = 19600, N[0x3d4f, ((0, 4), (1, 4))] = 1
Updated Q[0x3d15, ((2, 0), (2, 1))] = 19600, N[0x3d15, ((2, 0), (2, 1))] = 1

--- Simulation 237 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.272477706243, 16803.272477706243, 22044.18036592849, 16803.272477706243, 19603.272477706243]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3821, Score: 16800
Depth 2: State = 0x3821, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3821: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4912, Score: 19600
Depth 3: State = 0x4912, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4912: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4915, Score: 22400
Depth 4: State = 0x4915, Legal Moves = [((0, 1), (1, 1)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4915: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x43d1, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5139400, N[0x3c25, ((2, 3), (2, 4))] = 233
Updated Q[0x3c24, ((1, 3), (2, 3))] = 25200, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3821, ((1, 1), (2, 1))] = 25200, N[0x3821, ((1, 1), (2, 1))] = 1
Updated Q[0x4912, ((1, 3), (2, 3))] = 25200, N[0x4912, ((1, 3), (2, 3))] = 1
Updated Q[0x4915, ((0, 1), (1, 1))] = 25200, N[0x4915, ((0, 1), (1, 1))] = 1

--- Simulation 238 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.273743709673, 16803.273743709673, 22057.725199695047, 16803.273743709673, 19603.273743709673]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4506, Score: 11200
Depth 2: State = 0x4506, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4506: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x45af, Score: 14000
Depth 3: State = 0x45af, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45af: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4afa, Score: 16800
Depth 4: State = 0x4afa, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4afa: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3081, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5159000, N[0x3c25, ((2, 3), (2, 4))] = 234
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4506, ((1, 2), (2, 2))] = 19600, N[0x4506, ((1, 2), (2, 2))] = 1
Updated Q[0x45af, ((2, 0), (2, 1))] = 19600, N[0x45af, ((2, 0), (2, 1))] = 1
Updated Q[0x4afa, ((2, 0), (2, 1))] = 19600, N[0x4afa, ((2, 0), (2, 1))] = 1

--- Simulation 239 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.27500389624, 16803.27500389624, 22047.222640710777, 16803.27500389624, 19603.27500389624]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4431, Score: 8400
Depth 2: State = 0x4431, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x4431: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a4b, Score: 11200
Depth 3: State = 0x4a4b, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x4a4b: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4a4f, Score: 14000
Depth 4: State = 0x4a4f, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x4a4f: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x4aaa, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5175800, N[0x3c25, ((2, 3), (2, 4))] = 235
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4431, ((1, 3), (2, 3))] = 16800, N[0x4431, ((1, 3), (2, 3))] = 1
Updated Q[0x4a4b, ((1, 3), (1, 4))] = 16800, N[0x4a4b, ((1, 3), (1, 4))] = 1
Updated Q[0x4a4f, ((0, 2), (0, 3))] = 16800, N[0x4a4f, ((0, 2), (0, 3))] = 1

--- Simulation 240 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.276258317317, 16803.276258317317, 22024.894570591325, 16803.276258317317, 19603.276258317317]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 22401.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36da, Score: 8400
Depth 2: State = 0x36da, Legal Moves = [((0, 0), (0, 1)), ((1, 1), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x36da: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x11c1, Score: 11200
Depth 3: State = 0x11c1, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x11c1: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x2dae, Score: 14000
Depth 4: State = 0x2dae, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((1, 4), (2, 4)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2dae: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x3845, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5192600, N[0x3c25, ((2, 3), (2, 4))] = 236
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x36da, ((0, 0), (0, 1))] = 16800, N[0x36da, ((0, 0), (0, 1))] = 1
Updated Q[0x11c1, ((1, 1), (2, 1))] = 16800, N[0x11c1, ((1, 1), (2, 1))] = 1
Updated Q[0x2dae, ((0, 0), (0, 1))] = 16800, N[0x2dae, ((0, 0), (0, 1))] = 1

--- Simulation 241 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.277507023602, 16803.277507023602, 22002.755720416422, 16803.277507023602, 19603.277507023602]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3829, Score: 19300
Depth 2: State = 0x3829, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3829: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d74, Score: 22100
Depth 3: State = 0x3d74, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x3d74: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x2d2c, Score: 24900
Depth 4: State = 0x2d2c, Legal Moves = [((0, 1), (0, 2)), ((0, 1), (1, 1)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x2d2c: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x2934, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5220300, N[0x3c25, ((2, 3), (2, 4))] = 237
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27700, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3829, ((2, 0), (2, 1))] = 27700, N[0x3829, ((2, 0), (2, 1))] = 1
Updated Q[0x3d74, ((1, 1), (2, 1))] = 27700, N[0x3d74, ((1, 1), (2, 1))] = 1
Updated Q[0x2d2c, ((0, 1), (0, 2))] = 27700, N[0x2d2c, ((0, 1), (0, 2))] = 1

--- Simulation 242 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.27875006514, 16803.27875006514, 22026.795256184225, 16803.27875006514, 19603.27875006514]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc0, Score: 8400
Depth 1: State = 0x3bc0, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc0: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x39a5, Score: 11200
Depth 2: State = 0x39a5, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x39a5: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x37bd, Score: 14000
Depth 3: State = 0x37bd, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x37bd: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3910, Score: 19600
Depth 4: State = 0x3910, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 0), (1, 1)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 3), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3910: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x37c1, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5242700, N[0x3c25, ((2, 3), (2, 4))] = 238
Updated Q[0x3bc0, ((1, 3), (1, 4))] = 22400, N[0x3bc0, ((1, 3), (1, 4))] = 1
Updated Q[0x39a5, ((0, 1), (1, 1))] = 22400, N[0x39a5, ((0, 1), (1, 1))] = 1
Updated Q[0x37bd, ((1, 1), (2, 1))] = 22400, N[0x37bd, ((1, 1), (2, 1))] = 1
Updated Q[0x3910, ((0, 1), (1, 1))] = 22400, N[0x3910, ((0, 1), (1, 1))] = 1

--- Simulation 243 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.27998749133, 16803.27998749133, 22028.36387051471, 16803.27998749133, 19603.27998749133]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46f4, Score: 8400
Depth 2: State = 0x46f4, Legal Moves = [((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46f4: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4ab3, Score: 11200
Depth 3: State = 0x4ab3, Legal Moves = [((0, 4), (1, 4)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab3: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x4ab4, Score: 14000
Depth 4: State = 0x4ab4, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab4: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4416, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5259500, N[0x3c25, ((2, 3), (2, 4))] = 239
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x46f4, ((0, 3), (1, 3))] = 16800, N[0x46f4, ((0, 3), (1, 3))] = 1
Updated Q[0x4ab3, ((0, 4), (1, 4))] = 16800, N[0x4ab3, ((0, 4), (1, 4))] = 1
Updated Q[0x4ab4, ((1, 1), (2, 1))] = 16800, N[0x4ab4, ((1, 1), (2, 1))] = 1

--- Simulation 244 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.281219350934, 16803.281219350934, 22006.488395063443, 16803.281219350934, 19603.281219350934]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4967, Score: 8400
Depth 2: State = 0x4967, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4967: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x469f, Score: 11200
Depth 3: State = 0x469f, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x469f: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x469f, Score: 14000
Depth 4: State = 0x469f, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x469f: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4945, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5279100, N[0x3c25, ((2, 3), (2, 4))] = 240
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4967, ((1, 3), (2, 3))] = 19600, N[0x4967, ((1, 3), (2, 3))] = 1
Updated Q[0x469f, ((1, 2), (1, 3))] = 19600, N[0x469f, ((1, 2), (1, 3))] = 1
Updated Q[0x469f, ((0, 3), (1, 3))] = 19600, N[0x469f, ((0, 3), (1, 3))] = 1

--- Simulation 245 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.282445692097, 16803.282445692097, 21996.461880958337, 16803.282445692097, 19603.282445692097]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 30501.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x382d, Score: 11200
Depth 2: State = 0x382d, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 1), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x382d: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2293, Score: 14000
Depth 3: State = 0x2293, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 1), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2293: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x2bf9, Score: 19600
Depth 4: State = 0x2bf9, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((1, 1), (1, 2)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2bf9: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3038, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5301500, N[0x3c25, ((2, 3), (2, 4))] = 241
Updated Q[0x3c25, ((2, 0), (2, 1))] = 22400, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x382d, ((0, 0), (0, 1))] = 22400, N[0x382d, ((0, 0), (0, 1))] = 1
Updated Q[0x2293, ((0, 1), (0, 2))] = 22400, N[0x2293, ((0, 1), (0, 2))] = 1
Updated Q[0x2bf9, ((0, 1), (1, 1))] = 22400, N[0x2bf9, ((0, 1), (1, 1))] = 1

--- Simulation 246 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.283666562347, 16803.283666562347, 21998.13683076082, 16803.283666562347, 19603.283666562347]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22400.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c1a, Score: 8400
Depth 2: State = 0x3c1a, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1a: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bb9, Score: 11200
Depth 3: State = 0x3bb9, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb9: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2d6e, Score: 16800
Depth 4: State = 0x2d6e, Legal Moves = [((0, 1), (1, 1)), ((2, 2), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2d6e: [inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x2932, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5321100, N[0x3c25, ((2, 3), (2, 4))] = 242
Updated Q[0x3c25, ((0, 2), (1, 2))] = 19600, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3c1a, ((0, 2), (1, 2))] = 19600, N[0x3c1a, ((0, 2), (1, 2))] = 1
Updated Q[0x3bb9, ((2, 0), (2, 1))] = 19600, N[0x3bb9, ((2, 0), (2, 1))] = 1
Updated Q[0x2d6e, ((0, 1), (1, 1))] = 19600, N[0x2d6e, ((0, 1), (1, 1))] = 1

--- Simulation 247 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.2848820086, 16803.2848820086, 21988.22768913868, 16803.2848820086, 19603.2848820086]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bb8, Score: 8400
Depth 1: State = 0x3bb8, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb8: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x37de, Score: 11200
Depth 2: State = 0x37de, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37de: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3bbf, Score: 14000
Depth 3: State = 0x3bbf, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3bbf: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x3c1e, Score: 16800
Depth 4: State = 0x3c1e, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1e: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bd7, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5340700, N[0x3c25, ((2, 3), (2, 4))] = 243
Updated Q[0x3bb8, ((1, 3), (1, 4))] = 19600, N[0x3bb8, ((1, 3), (1, 4))] = 1
Updated Q[0x37de, ((0, 3), (1, 3))] = 19600, N[0x37de, ((0, 3), (1, 3))] = 1
Updated Q[0x3bbf, ((0, 2), (0, 3))] = 19600, N[0x3bbf, ((0, 2), (0, 3))] = 1
Updated Q[0x3c1e, ((0, 2), (1, 2))] = 19600, N[0x3c1e, ((0, 2), (1, 2))] = 1

--- Simulation 248 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.286092077193, 16803.286092077193, 21978.400103316562, 16803.286092077193, 19603.286092077193]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3825, Score: 14000
Depth 2: State = 0x3825, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3825: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x440f, Score: 19600
Depth 3: State = 0x440f, Legal Moves = [((1, 1), (1, 2)), ((2, 1), (3, 1))]
UCB1 values for moves at state 0x440f: [inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x43c7, Score: 22400
Depth 4: State = 0x43c7, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 1), (3, 1))]
UCB1 values for moves at state 0x43c7: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x458e, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5365900, N[0x3c25, ((2, 3), (2, 4))] = 244
Updated Q[0x3c24, ((1, 3), (1, 4))] = 25200, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x3825, ((2, 0), (2, 1))] = 25200, N[0x3825, ((2, 0), (2, 1))] = 1
Updated Q[0x440f, ((1, 1), (1, 2))] = 25200, N[0x440f, ((1, 1), (1, 2))] = 1
Updated Q[0x43c7, ((0, 1), (0, 2))] = 25200, N[0x43c7, ((0, 1), (0, 2))] = 1

--- Simulation 249 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.28729681387, 16803.28729681387, 21991.60389023668, 16803.28729681387, 19603.28729681387]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [27201.16557645562, 16801.16557645562, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3bbc, Score: 8400
Depth 2: State = 0x3bbc, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3bbc: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c61, Score: 11200
Depth 3: State = 0x3c61, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c61: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x39bc, Score: 14000
Depth 4: State = 0x39bc, Legal Moves = [((1, 0), (1, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x39bc: [inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x3c61, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5382700, N[0x3c25, ((2, 3), (2, 4))] = 245
Updated Q[0x3c24, ((0, 4), (1, 4))] = 16800, N[0x3c24, ((0, 4), (1, 4))] = 1
Updated Q[0x3bbc, ((1, 2), (2, 2))] = 16800, N[0x3bbc, ((1, 2), (2, 2))] = 1
Updated Q[0x3c61, ((2, 0), (2, 1))] = 16800, N[0x3c61, ((2, 0), (2, 1))] = 1
Updated Q[0x39bc, ((1, 0), (1, 1))] = 16800, N[0x39bc, ((1, 0), (1, 1))] = 1

--- Simulation 250 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.288496263805, 16803.288496263805, 21970.414175952355, 16803.288496263805, 19603.288496263805]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x495e, Score: 8400
Depth 2: State = 0x495e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x495e: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4852, Score: 11200
Depth 3: State = 0x4852, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4852: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x57a6, Score: 21700
Depth 4: State = 0x57a6, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x57a6: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4693, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5407200, N[0x3c25, ((2, 3), (2, 4))] = 246
Updated Q[0x3c25, ((0, 0), (0, 1))] = 24500, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x495e, ((1, 3), (2, 3))] = 24500, N[0x495e, ((1, 3), (2, 3))] = 1
Updated Q[0x4852, ((0, 2), (1, 2))] = 24500, N[0x4852, ((0, 2), (1, 2))] = 1
Updated Q[0x57a6, ((0, 2), (1, 2))] = 24500, N[0x57a6, ((0, 2), (1, 2))] = 1

--- Simulation 251 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.28969047161, 16803.28969047161, 21980.69754788184, 16803.28969047161, 19603.28969047161]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c4d, Score: 14000
Depth 1: State = 0x3c4d, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4d: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x1f51, Score: 16800
Depth 2: State = 0x1f51, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1f51: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x22d3, Score: 19600
Depth 3: State = 0x22d3, Legal Moves = [((0, 1), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x22d3: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x2346, Score: 22400
Depth 4: State = 0x2346, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2346: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x29c3, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5432400, N[0x3c25, ((2, 3), (2, 4))] = 247
Updated Q[0x3c4d, ((0, 0), (1, 0))] = 25200, N[0x3c4d, ((0, 0), (1, 0))] = 1
Updated Q[0x1f51, ((1, 3), (2, 3))] = 25200, N[0x1f51, ((1, 3), (2, 3))] = 1
Updated Q[0x22d3, ((0, 1), (1, 1))] = 25200, N[0x22d3, ((0, 1), (1, 1))] = 1
Updated Q[0x2346, ((1, 0), (2, 0))] = 25200, N[0x2346, ((1, 0), (2, 0))] = 1

--- Simulation 252 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.290879481337, 16803.290879481337, 21993.731660853555, 16803.290879481337, 19603.290879481337]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.648374031523, 27301.648374031523, 27701.648374031523, 36101.64837403152, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x5434, Score: 16800
Depth 2: State = 0x5434, Legal Moves = [((1, 3), (1, 4)), ((2, 3), (2, 4))]
UCB1 values for moves at state 0x5434: [inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x5431, Score: 22400
Depth 3: State = 0x5431, Legal Moves = [((1, 4), (2, 4))]
UCB1 values for moves at state 0x5431: [inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x53b4, Score: 25200
Depth 4: State = 0x53b4, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5457600, N[0x3c25, ((2, 3), (2, 4))] = 248
Updated Q[0x3c24, ((3, 0), (3, 1))] = 25200, N[0x3c24, ((3, 0), (3, 1))] = 1
Updated Q[0x5434, ((1, 3), (1, 4))] = 25200, N[0x5434, ((1, 3), (1, 4))] = 1
Updated Q[0x5431, ((1, 4), (2, 4))] = 25200, N[0x5431, ((1, 4), (2, 4))] = 1

--- Simulation 253 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.2920633365, 16803.2920633365, 22006.66065913414, 16803.2920633365, 19603.2920633365]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14000.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c5d, Score: 11200
Depth 2: State = 0x3c5d, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5d: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3865, Score: 14000
Depth 3: State = 0x3865, Legal Moves = [((2, 2), (3, 2))]
UCB1 values for moves at state 0x3865: [inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x380e, Score: 16800
Depth 4: State = 0x380e, Legal Moves = [((0, 1), (0, 2)), ((1, 3), (2, 3))]
UCB1 values for moves at state 0x380e: [inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3a92, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5477200, N[0x3c25, ((2, 3), (2, 4))] = 249
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3c5d, ((2, 0), (2, 1))] = 19600, N[0x3c5d, ((2, 0), (2, 1))] = 1
Updated Q[0x3865, ((2, 2), (3, 2))] = 19600, N[0x3865, ((2, 2), (3, 2))] = 1
Updated Q[0x380e, ((0, 1), (0, 2))] = 19600, N[0x380e, ((0, 1), (0, 2))] = 1

--- Simulation 254 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.293242080064, 16803.293242080064, 21996.995849331273, 16803.293242080064, 19603.293242080064]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 44201.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37ed, Score: 11200
Depth 2: State = 0x37ed, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37ed: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5570, Score: 14000
Depth 3: State = 0x5570, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5570: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x52df, Score: 16800
Depth 4: State = 0x52df, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x52df: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x56d7, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5496800, N[0x3c25, ((2, 3), (2, 4))] = 250
Updated Q[0x3c25, ((1, 3), (2, 3))] = 19600, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x37ed, ((1, 2), (1, 3))] = 19600, N[0x37ed, ((1, 2), (1, 3))] = 1
Updated Q[0x5570, ((1, 3), (1, 4))] = 19600, N[0x5570, ((1, 3), (1, 4))] = 1
Updated Q[0x52df, ((2, 0), (2, 1))] = 19600, N[0x52df, ((2, 0), (2, 1))] = 1

--- Simulation 255 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.294415754477, 16803.294415754477, 21987.408357146876, 16803.294415754477, 19603.294415754477]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [21701.16557645562, 22401.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x5675, Score: 16800
Depth 2: State = 0x5675, Legal Moves = [((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x5675: [inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x567c, Score: 19600
Depth 3: State = 0x567c, Legal Moves = [((0, 2), (0, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x567c: [inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x56de, Score: 22400
Depth 4: State = 0x56de, Legal Moves = [((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x56de: [inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x5635, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5522000, N[0x3c25, ((2, 3), (2, 4))] = 251
Updated Q[0x3c25, ((2, 0), (2, 1))] = 25200, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x5675, ((2, 3), (2, 4))] = 25200, N[0x5675, ((2, 3), (2, 4))] = 1
Updated Q[0x567c, ((0, 2), (0, 3))] = 25200, N[0x567c, ((0, 2), (0, 3))] = 1
Updated Q[0x56de, ((2, 2), (3, 2))] = 25200, N[0x56de, ((2, 2), (3, 2))] = 1

--- Simulation 256 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.29558440167, 16803.29558440167, 22000.208015442928, 16803.29558440167, 19603.29558440167]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14001.16557645562, 19601.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36d8, Score: 8400
Depth 2: State = 0x36d8, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x36d8: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x15eb, Score: 11200
Depth 3: State = 0x15eb, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x15eb: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x1587, Score: 14000
Depth 4: State = 0x1587, Legal Moves = [((0, 1), (0, 2)), ((1, 3), (1, 4)), ((2, 3), (2, 4))]
UCB1 values for moves at state 0x1587: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x56a3, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5544400, N[0x3c25, ((2, 3), (2, 4))] = 252
Updated Q[0x3c24, ((2, 0), (2, 1))] = 22400, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x36d8, ((0, 0), (0, 1))] = 22400, N[0x36d8, ((0, 0), (0, 1))] = 1
Updated Q[0x15eb, ((4, 1), (4, 2))] = 22400, N[0x15eb, ((4, 1), (4, 2))] = 1
Updated Q[0x1587, ((0, 1), (0, 2))] = 22400, N[0x1587, ((0, 1), (0, 2))] = 1

--- Simulation 257 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.296748063043, 16803.296748063043, 22001.794977194684, 16803.296748063043, 19603.296748063043]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3d5d, Score: 19300
Depth 1: State = 0x3d5d, Legal Moves = [((0, 1), (0, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d5d: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x39a5, Score: 22100
Depth 2: State = 0x39a5, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39a5: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3932, Score: 24900
Depth 3: State = 0x3932, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3932: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x36b8, Score: 30500
Depth 4: State = 0x36b8, Legal Moves = [((0, 2), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 0), (4, 0)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x36b8: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x384f, Score: 33300
End of simulation with depth 5. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5577700, N[0x3c25, ((2, 3), (2, 4))] = 253
Updated Q[0x3d5d, ((0, 1), (0, 2))] = 33300, N[0x3d5d, ((0, 1), (0, 2))] = 1
Updated Q[0x39a5, ((1, 3), (1, 4))] = 33300, N[0x39a5, ((1, 3), (1, 4))] = 1
Updated Q[0x3932, ((1, 0), (1, 1))] = 33300, N[0x3932, ((1, 0), (1, 1))] = 1
Updated Q[0x36b8, ((0, 2), (1, 2))] = 33300, N[0x36b8, ((0, 2), (1, 2))] = 1

--- Simulation 258 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.297906779517, 16803.297906779517, 22046.452396911336, 16803.297906779517, 19603.297906779517]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x49ab, Score: 8400
Depth 2: State = 0x49ab, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x49ab: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x43d5, Score: 11200
Depth 3: State = 0x43d5, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43d5: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4528, Score: 14000
Depth 4: State = 0x4528, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5591700, N[0x3c25, ((2, 3), (2, 4))] = 254
Updated Q[0x3c24, ((0, 0), (0, 1))] = 14000, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x49ab, ((1, 3), (1, 4))] = 14000, N[0x49ab, ((1, 3), (1, 4))] = 1
Updated Q[0x43d5, ((2, 0), (2, 1))] = 14000, N[0x43d5, ((2, 0), (2, 1))] = 1

--- Simulation 259 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.299060591507, 16803.299060591507, 22014.773930605825, 16803.299060591507, 19603.299060591507]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [33300.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x39b9, Score: 11200
Depth 2: State = 0x39b9, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39b9: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3b0c, Score: 14000
Depth 3: State = 0x3b0c, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 1), (2, 2)), ((2, 2), (3, 2))]
UCB1 values for moves at state 0x3b0c: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3823, Score: 19600
Depth 4: State = 0x3823, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x3823: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3d93, Score: 29400
End of simulation with depth 5. Reward (Score): 29400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5621100, N[0x3c25, ((2, 3), (2, 4))] = 255
Updated Q[0x3c25, ((1, 3), (2, 3))] = 29400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x39b9, ((2, 0), (2, 1))] = 29400, N[0x39b9, ((2, 0), (2, 1))] = 1
Updated Q[0x3b0c, ((0, 1), (1, 1))] = 29400, N[0x3b0c, ((0, 1), (1, 1))] = 1
Updated Q[0x3823, ((1, 2), (2, 2))] = 29400, N[0x3823, ((1, 2), (2, 2))] = 1

--- Simulation 260 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.300209538942, 16803.300209538942, 22043.736078902602, 16803.300209538942, 19603.300209538942]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x399a, Score: 14000
Depth 2: State = 0x399a, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x399a: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1d47, Score: 16800
Depth 3: State = 0x1d47, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1d47: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x1c57, Score: 19600
Depth 4: State = 0x1c57, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1c57: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x2d47, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5643500, N[0x3c25, ((2, 3), (2, 4))] = 256
Updated Q[0x3c25, ((1, 2), (2, 2))] = 22400, N[0x3c25, ((1, 2), (2, 2))] = 1
Updated Q[0x399a, ((0, 2), (1, 2))] = 22400, N[0x399a, ((0, 2), (1, 2))] = 1
Updated Q[0x1d47, ((0, 1), (0, 2))] = 22400, N[0x1d47, ((0, 1), (0, 2))] = 1
Updated Q[0x1c57, ((1, 0), (2, 0))] = 22400, N[0x1c57, ((1, 0), (2, 0))] = 1

--- Simulation 261 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.30135366127, 16803.30135366127, 22045.12820960383, 16803.30135366127, 19603.30135366127]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c03, Score: 8400
Depth 1: State = 0x3c03, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c03: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c40, Score: 16800
Depth 2: State = 0x3c40, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (1, 3)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c40: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x484c, Score: 19600
Depth 3: State = 0x484c, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x484c: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x4aae, Score: 22400
Depth 4: State = 0x4aae, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aae: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x47c4, Score: 36100
End of simulation with depth 5. Reward (Score): 36100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5679600, N[0x3c25, ((2, 3), (2, 4))] = 257
Updated Q[0x3c03, ((1, 3), (2, 3))] = 36100, N[0x3c03, ((1, 3), (2, 3))] = 1
Updated Q[0x3c40, ((0, 0), (1, 0))] = 36100, N[0x3c40, ((0, 0), (1, 0))] = 1
Updated Q[0x484c, ((0, 1), (1, 1))] = 36100, N[0x484c, ((0, 1), (1, 1))] = 1
Updated Q[0x4aae, ((2, 0), (2, 1))] = 36100, N[0x4aae, ((2, 0), (2, 1))] = 1

--- Simulation 262 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.30249299747, 16803.30249299747, 22099.816898794856, 16803.30249299747, 19603.30249299747]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc7, Score: 8400
Depth 1: State = 0x3bc7, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc7: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3871, Score: 11200
Depth 2: State = 0x3871, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3871: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3844, Score: 24900
Depth 3: State = 0x3844, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3844: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3942, Score: 29800
Depth 4: State = 0x3942, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3942: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x36be, Score: 35400
End of simulation with depth 5. Reward (Score): 35400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5715000, N[0x3c25, ((2, 3), (2, 4))] = 258
Updated Q[0x3bc7, ((1, 3), (2, 3))] = 35400, N[0x3bc7, ((1, 3), (2, 3))] = 1
Updated Q[0x3871, ((0, 3), (1, 3))] = 35400, N[0x3871, ((0, 3), (1, 3))] = 1
Updated Q[0x3844, ((0, 2), (1, 2))] = 35400, N[0x3844, ((0, 2), (1, 2))] = 1
Updated Q[0x3942, ((0, 1), (0, 2))] = 35400, N[0x3942, ((0, 1), (0, 2))] = 1

--- Simulation 263 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.303627586058, 16803.303627586058, 22151.36846556742, 16803.303627586058, 19603.303627586058]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c1b, Score: 8400
Depth 1: State = 0x3c1b, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1b: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3873, Score: 19300
Depth 2: State = 0x3873, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3873: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x39c6, Score: 22100
Depth 3: State = 0x39c6, Legal Moves = [((0, 2), (1, 2)), ((2, 1), (3, 1))]
UCB1 values for moves at state 0x39c6: [inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x37c7, Score: 24900
Depth 4: State = 0x37c7, Legal Moves = [((2, 1), (3, 1)), ((2, 2), (2, 3))]
UCB1 values for moves at state 0x37c7: [inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x3696, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5742700, N[0x3c25, ((2, 3), (2, 4))] = 259
Updated Q[0x3c1b, ((0, 3), (1, 3))] = 27700, N[0x3c1b, ((0, 3), (1, 3))] = 1
Updated Q[0x3873, ((2, 0), (2, 1))] = 27700, N[0x3873, ((2, 0), (2, 1))] = 1
Updated Q[0x39c6, ((0, 2), (1, 2))] = 27700, N[0x39c6, ((0, 2), (1, 2))] = 1
Updated Q[0x37c7, ((2, 1), (3, 1))] = 27700, N[0x37c7, ((2, 1), (3, 1))] = 1

--- Simulation 264 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.304757465092, 16803.304757465092, 22172.79222022415, 16803.304757465092, 19603.304757465092]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4afa, Score: 8400
Depth 2: State = 0x4afa, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4afa: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x43c7, Score: 11200
Depth 3: State = 0x43c7, Legal Moves = [((0, 1), (0, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43c7: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4565, Score: 14000
Depth 4: State = 0x4565, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4565: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4412, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5759500, N[0x3c25, ((2, 3), (2, 4))] = 260
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4afa, ((1, 3), (2, 3))] = 16800, N[0x4afa, ((1, 3), (2, 3))] = 1
Updated Q[0x43c7, ((0, 1), (0, 2))] = 16800, N[0x43c7, ((0, 1), (0, 2))] = 1
Updated Q[0x4565, ((2, 0), (2, 1))] = 16800, N[0x4565, ((2, 0), (2, 1))] = 1

--- Simulation 265 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.30588267217, 16803.30588267217, 22152.12809906299, 16803.30588267217, 19603.30588267217]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d4f, Score: 16100
Depth 2: State = 0x3d4f, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d4f: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3d59, Score: 18900
Depth 3: State = 0x3d59, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d59: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36bb, Score: 21700
Depth 4: State = 0x36bb, Legal Moves = [((2, 3), (3, 3))]
UCB1 values for moves at state 0x36bb: [inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3702, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5786800, N[0x3c25, ((2, 3), (2, 4))] = 261
Updated Q[0x3c25, ((1, 3), (2, 3))] = 27300, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3d4f, ((1, 2), (2, 2))] = 27300, N[0x3d4f, ((1, 2), (2, 2))] = 1
Updated Q[0x3d59, ((2, 0), (2, 1))] = 27300, N[0x3d59, ((2, 0), (2, 1))] = 1
Updated Q[0x36bb, ((2, 3), (3, 3))] = 27300, N[0x36bb, ((2, 3), (3, 3))] = 1

--- Simulation 266 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.30700324447, 16803.30700324447, 22171.852207940487, 16803.30700324447, 19603.30700324447]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc3, Score: 11200
Depth 1: State = 0x3bc3, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc3: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d7c, Score: 14000
Depth 2: State = 0x3d7c, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d7c: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x565d, Score: 16800
Depth 3: State = 0x565d, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x565d: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5661, Score: 19600
Depth 4: State = 0x5661, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5661: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5630, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5812000, N[0x3c25, ((2, 3), (2, 4))] = 262
Updated Q[0x3bc3, ((1, 3), (2, 3))] = 25200, N[0x3bc3, ((1, 3), (2, 3))] = 1
Updated Q[0x3d7c, ((1, 2), (1, 3))] = 25200, N[0x3d7c, ((1, 2), (1, 3))] = 1
Updated Q[0x565d, ((1, 2), (1, 3))] = 25200, N[0x565d, ((1, 2), (1, 3))] = 1
Updated Q[0x5661, ((1, 2), (1, 3))] = 25200, N[0x5661, ((1, 2), (1, 3))] = 1

--- Simulation 267 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.308119218713, 16803.308119218713, 22183.410483158095, 16803.308119218713, 19603.308119218713]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c24, Score: 8400
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4804, Score: 11200
Depth 3: State = 0x4804, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4804: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x5693, Score: 21700
Depth 4: State = 0x5693, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5693: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x5129, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5836500, N[0x3c25, ((2, 3), (2, 4))] = 263
Updated Q[0x3c24, ((0, 4), (1, 4))] = 24500, N[0x3c24, ((0, 4), (1, 4))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 24500, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4804, ((0, 2), (1, 2))] = 24500, N[0x4804, ((0, 2), (1, 2))] = 1
Updated Q[0x5693, ((1, 3), (2, 3))] = 24500, N[0x5693, ((1, 3), (2, 3))] = 1

--- Simulation 268 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.3092306312, 16803.3092306312, 22192.219265027852, 16803.3092306312, 19603.3092306312]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3871, Score: 13300
Depth 2: State = 0x3871, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3871: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3874, Score: 16100
Depth 3: State = 0x3874, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3874: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3874, Score: 18900
Depth 4: State = 0x3874, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1))]
UCB1 values for moves at state 0x3874: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4ada, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5858200, N[0x3c25, ((2, 3), (2, 4))] = 264
Updated Q[0x3c25, ((1, 3), (2, 3))] = 21700, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3871, ((1, 3), (1, 4))] = 21700, N[0x3871, ((1, 3), (1, 4))] = 1
Updated Q[0x3874, ((2, 0), (2, 1))] = 21700, N[0x3874, ((2, 0), (2, 1))] = 1
Updated Q[0x3874, ((1, 1), (2, 1))] = 21700, N[0x3874, ((1, 1), (2, 1))] = 1

--- Simulation 269 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.310337517807, 16803.310337517807, 22190.355252341873, 16803.310337517807, 19603.310337517807]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47cd, Score: 8400
Depth 2: State = 0x47cd, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47cd: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x479e, Score: 11200
Depth 3: State = 0x479e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x479e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x300f, Score: 19600
Depth 4: State = 0x300f, Legal Moves = [((0, 1), (1, 1))]
UCB1 values for moves at state 0x300f: [inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x22b1, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5883400, N[0x3c25, ((2, 3), (2, 4))] = 265
Updated Q[0x3c24, ((0, 0), (0, 1))] = 25200, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47cd, ((1, 3), (2, 3))] = 25200, N[0x47cd, ((1, 3), (2, 3))] = 1
Updated Q[0x479e, ((2, 0), (2, 1))] = 25200, N[0x479e, ((2, 0), (2, 1))] = 1
Updated Q[0x300f, ((0, 1), (1, 1))] = 25200, N[0x300f, ((0, 1), (1, 1))] = 1

--- Simulation 270 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.311439914, 16803.311439914, 22201.712854099147, 16803.311439914, 19603.311439914]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [18901.467405903557, 22401.467405903557, 24501.467405903557, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d78, Score: 8400
Depth 2: State = 0x3d78, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 1), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d78: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x10c0, Score: 16800
Depth 3: State = 0x10c0, Legal Moves = [((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x10c0: [inf, inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x109a, Score: 30500
Depth 4: State = 0x109a, Legal Moves = [((1, 0), (2, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x109a: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x11cb, Score: 41400
End of simulation with depth 5. Reward (Score): 41400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5924800, N[0x3c25, ((2, 3), (2, 4))] = 266
Updated Q[0x3c25, ((2, 0), (2, 1))] = 41400, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3d78, ((0, 0), (0, 1))] = 41400, N[0x3d78, ((0, 0), (0, 1))] = 1
Updated Q[0x10c0, ((1, 4), (2, 4))] = 41400, N[0x10c0, ((1, 4), (2, 4))] = 1
Updated Q[0x109a, ((1, 0), (2, 0))] = 41400, N[0x109a, ((1, 0), (2, 0))] = 1

--- Simulation 271 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.312537854825, 16803.312537854825, 22273.88731525355, 16803.312537854825, 19603.312537854825]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 25201.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d29, Score: 11200
Depth 2: State = 0x3d29, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d29: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3930, Score: 14000
Depth 3: State = 0x3930, Legal Moves = [((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3930: [inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x3974, Score: 16800
Depth 4: State = 0x3974, Legal Moves = [((1, 1), (1, 2)), ((1, 4), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3974: [inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x39a8, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5944400, N[0x3c25, ((2, 3), (2, 4))] = 267
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3d29, ((2, 0), (2, 1))] = 19600, N[0x3d29, ((2, 0), (2, 1))] = 1
Updated Q[0x3930, ((2, 2), (3, 2))] = 19600, N[0x3930, ((2, 2), (3, 2))] = 1
Updated Q[0x3974, ((1, 1), (1, 2))] = 19600, N[0x3974, ((1, 1), (1, 2))] = 1

--- Simulation 272 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.31363137493, 16803.31363137493, 22263.873202931867, 16803.31363137493, 19603.31363137493]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3980, Score: 8400
Depth 2: State = 0x3980, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3980: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2932, Score: 11200
Depth 3: State = 0x2932, Legal Moves = [((2, 2), (2, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2932: [inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x29db, Score: 14000
Depth 4: State = 0x29db, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x29db: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x29c3, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5961200, N[0x3c25, ((2, 3), (2, 4))] = 268
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3980, ((0, 0), (0, 1))] = 16800, N[0x3980, ((0, 0), (0, 1))] = 1
Updated Q[0x2932, ((2, 2), (2, 3))] = 16800, N[0x2932, ((2, 2), (2, 3))] = 1
Updated Q[0x29db, ((2, 0), (2, 1))] = 16800, N[0x29db, ((2, 0), (2, 1))] = 1

--- Simulation 273 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.31472050857, 16803.31472050857, 22243.486060870917, 16803.31472050857, 19603.31472050857]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47c4, Score: 8400
Depth 2: State = 0x47c4, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c4: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4943, Score: 11200
Depth 3: State = 0x4943, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4943: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4859, Score: 16800
Depth 4: State = 0x4859, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4859: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x47ac, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 5986400, N[0x3c25, ((2, 3), (2, 4))] = 269
Updated Q[0x3c25, ((0, 0), (0, 1))] = 25200, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x47c4, ((1, 3), (2, 3))] = 25200, N[0x47c4, ((1, 3), (2, 3))] = 1
Updated Q[0x4943, ((0, 1), (0, 2))] = 25200, N[0x4943, ((0, 1), (0, 2))] = 1
Updated Q[0x4859, ((1, 1), (2, 1))] = 25200, N[0x4859, ((1, 1), (2, 1))] = 1

--- Simulation 274 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.315805289603, 16803.315805289603, 22254.477261153395, 16803.315805289603, 19603.315805289603]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46b2, Score: 8400
Depth 2: State = 0x46b2, Legal Moves = [((0, 3), (0, 4)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x46b2: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x46c2, Score: 14000
Depth 3: State = 0x46c2, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46c2: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x46f8, Score: 16800
Depth 4: State = 0x46f8, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46f8: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x47c3, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6006000, N[0x3c25, ((2, 3), (2, 4))] = 270
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x46b2, ((0, 3), (0, 4))] = 19600, N[0x46b2, ((0, 3), (0, 4))] = 1
Updated Q[0x46c2, ((0, 2), (1, 2))] = 19600, N[0x46c2, ((0, 2), (1, 2))] = 1
Updated Q[0x46f8, ((1, 3), (2, 3))] = 19600, N[0x46f8, ((1, 3), (2, 3))] = 1

--- Simulation 275 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.3168857515, 16803.3168857515, 22244.646303682974, 16803.3168857515, 19603.3168857515]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bc7, Score: 11200
Depth 2: State = 0x3bc7, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc7: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d19, Score: 14000
Depth 3: State = 0x3d19, Legal Moves = [((0, 1), (0, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 1), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d19: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3ab7, Score: 24900
Depth 4: State = 0x3ab7, Legal Moves = [((0, 2), (1, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3ab7: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x454e, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6033700, N[0x3c25, ((2, 3), (2, 4))] = 271
Updated Q[0x3c24, ((1, 2), (2, 2))] = 27700, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3bc7, ((2, 0), (2, 1))] = 27700, N[0x3bc7, ((2, 0), (2, 1))] = 1
Updated Q[0x3d19, ((0, 1), (0, 2))] = 27700, N[0x3d19, ((0, 1), (0, 2))] = 1
Updated Q[0x3ab7, ((0, 2), (1, 2))] = 27700, N[0x3ab7, ((0, 2), (1, 2))] = 1

--- Simulation 276 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.31796192736, 16803.31796192736, 22264.777197589785, 16803.31796192736, 19603.31796192736]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14001.16557645562, 22401.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3964, Score: 13300
Depth 2: State = 0x3964, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3964: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3957, Score: 16100
Depth 3: State = 0x3957, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3957: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3957, Score: 18900
Depth 4: State = 0x3957, Legal Moves = [((2, 1), (3, 1))]
UCB1 values for moves at state 0x3957: [inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x368c, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6055400, N[0x3c25, ((2, 3), (2, 4))] = 272
Updated Q[0x3c24, ((1, 3), (2, 3))] = 21700, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3964, ((1, 3), (2, 3))] = 21700, N[0x3964, ((1, 3), (2, 3))] = 1
Updated Q[0x3957, ((2, 0), (2, 1))] = 21700, N[0x3957, ((2, 0), (2, 1))] = 1
Updated Q[0x3957, ((2, 1), (3, 1))] = 21700, N[0x3957, ((2, 1), (3, 1))] = 1

--- Simulation 277 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.319033849904, 16803.319033849904, 22262.701245987326, 16803.319033849904, 19603.319033849904]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c44, Score: 8400
Depth 1: State = 0x3c44, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c44: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x15e2, Score: 11200
Depth 2: State = 0x15e2, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x15e2: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x1f48, Score: 16800
Depth 3: State = 0x1f48, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1f48: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1df5, Score: 19600
Depth 4: State = 0x1df5, Legal Moves = [((4, 0), (4, 1))]
UCB1 values for moves at state 0x1df5: [inf]
Selected move: ((4, 0), (4, 1))
New board state after move: 0x209a, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6077800, N[0x3c25, ((2, 3), (2, 4))] = 273
Updated Q[0x3c44, ((0, 0), (1, 0))] = 22400, N[0x3c44, ((0, 0), (1, 0))] = 1
Updated Q[0x15e2, ((0, 0), (1, 0))] = 22400, N[0x15e2, ((0, 0), (1, 0))] = 1
Updated Q[0x1f48, ((2, 0), (2, 1))] = 22400, N[0x1f48, ((2, 0), (2, 1))] = 1
Updated Q[0x1df5, ((4, 0), (4, 1))] = 22400, N[0x1df5, ((4, 0), (4, 1))] = 1

--- Simulation 278 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.32010155148, 16803.32010155148, 22263.204604690683, 16803.32010155148, 19603.32010155148]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 19601.467405903557, 27701.467405903557, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c21, Score: 10500
Depth 2: State = 0x3c21, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c21: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36d6, Score: 13300
Depth 3: State = 0x36d6, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x36d6: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x3721, Score: 16100
Depth 4: State = 0x3721, Legal Moves = [((2, 1), (2, 2))]
UCB1 values for moves at state 0x3721: [inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x3873, Score: 18900
End of simulation with depth 5. Reward (Score): 18900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6096700, N[0x3c25, ((2, 3), (2, 4))] = 274
Updated Q[0x3c24, ((2, 3), (2, 4))] = 18900, N[0x3c24, ((2, 3), (2, 4))] = 1
Updated Q[0x3c21, ((2, 0), (2, 1))] = 18900, N[0x3c21, ((2, 0), (2, 1))] = 1
Updated Q[0x36d6, ((4, 1), (4, 2))] = 18900, N[0x36d6, ((4, 1), (4, 2))] = 1
Updated Q[0x3721, ((2, 1), (2, 2))] = 18900, N[0x3721, ((2, 1), (2, 2))] = 1

--- Simulation 279 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.321165064077, 16803.321165064077, 22250.930565926377, 16803.321165064077, 19603.321165064077]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c43, Score: 8400
Depth 2: State = 0x3c43, Legal Moves = [((0, 0), (1, 0)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c43: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3806, Score: 11200
Depth 3: State = 0x3806, Legal Moves = [((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3806: [inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x37bc, Score: 14000
Depth 4: State = 0x37bc, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37bc: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3673, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6113500, N[0x3c25, ((2, 3), (2, 4))] = 275
Updated Q[0x3c24, ((0, 2), (1, 2))] = 16800, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c43, ((0, 0), (1, 0))] = 16800, N[0x3c43, ((0, 0), (1, 0))] = 1
Updated Q[0x3806, ((0, 4), (1, 4))] = 16800, N[0x3806, ((0, 4), (1, 4))] = 1
Updated Q[0x37bc, ((0, 1), (1, 1))] = 16800, N[0x37bc, ((0, 1), (1, 1))] = 1

--- Simulation 280 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.322224419328, 16803.322224419328, 22231.109428579424, 16803.322224419328, 19603.322224419328]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 19601.16557645562, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3812, Score: 21400
Depth 2: State = 0x3812, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3812: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3852, Score: 24200
Depth 3: State = 0x3852, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3852: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3826, Score: 29800
Depth 4: State = 0x3826, Legal Moves = [((1, 3), (1, 4))]
UCB1 values for moves at state 0x3826: [inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3bde, Score: 32600
End of simulation with depth 5. Reward (Score): 32600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6146100, N[0x3c25, ((2, 3), (2, 4))] = 276
Updated Q[0x3c24, ((1, 3), (2, 3))] = 32600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3812, ((1, 3), (2, 3))] = 32600, N[0x3812, ((1, 3), (2, 3))] = 1
Updated Q[0x3852, ((2, 0), (2, 1))] = 32600, N[0x3852, ((2, 0), (2, 1))] = 1
Updated Q[0x3826, ((1, 3), (1, 4))] = 32600, N[0x3826, ((1, 3), (1, 4))] = 1

--- Simulation 281 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.32327964851, 16803.32327964851, 22268.678298797327, 16803.32327964851, 19603.32327964851]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bff, Score: 8400
Depth 1: State = 0x3bff, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bff: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3870, Score: 11200
Depth 2: State = 0x3870, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3870: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3c62, Score: 16800
Depth 3: State = 0x3c62, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c62: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x3c62, Score: 19600
Depth 4: State = 0x3c62, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c62: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x3c4c, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6168500, N[0x3c25, ((2, 3), (2, 4))] = 277
Updated Q[0x3bff, ((1, 3), (2, 3))] = 22400, N[0x3bff, ((1, 3), (2, 3))] = 1
Updated Q[0x3870, ((0, 3), (1, 3))] = 22400, N[0x3870, ((0, 3), (1, 3))] = 1
Updated Q[0x3c62, ((1, 0), (1, 1))] = 22400, N[0x3c62, ((1, 0), (1, 1))] = 1
Updated Q[0x3c62, ((1, 1), (1, 2))] = 22400, N[0x3c62, ((1, 1), (1, 2))] = 1

--- Simulation 282 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.32433078256, 16803.32433078256, 22269.15280827058, 16803.32433078256, 19603.32433078256]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 27701.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d77, Score: 8400
Depth 2: State = 0x3d77, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d77: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x529d, Score: 11200
Depth 3: State = 0x529d, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x529d: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x5543, Score: 14000
Depth 4: State = 0x5543, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (2, 3)), ((2, 1), (3, 1)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x5543: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x5286, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6185300, N[0x3c25, ((2, 3), (2, 4))] = 278
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3d77, ((0, 0), (0, 1))] = 16800, N[0x3d77, ((0, 0), (0, 1))] = 1
Updated Q[0x529d, ((1, 0), (1, 1))] = 16800, N[0x529d, ((1, 0), (1, 1))] = 1
Updated Q[0x5543, ((0, 3), (1, 3))] = 16800, N[0x5543, ((0, 3), (1, 3))] = 1

--- Simulation 283 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.32537785207, 16803.32537785207, 22249.480018449478, 16803.32537785207, 19603.32537785207]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 22401.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d0e, Score: 11200
Depth 2: State = 0x3d0e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d0e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3996, Score: 16800
Depth 3: State = 0x3996, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2))]
UCB1 values for moves at state 0x3996: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x453c, Score: 19600
Depth 4: State = 0x453c, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2))]
UCB1 values for moves at state 0x453c: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x43c7, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6207700, N[0x3c25, ((2, 3), (2, 4))] = 279
Updated Q[0x3c24, ((1, 3), (2, 3))] = 22400, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3d0e, ((2, 0), (2, 1))] = 22400, N[0x3d0e, ((2, 0), (2, 1))] = 1
Updated Q[0x3996, ((0, 2), (1, 2))] = 22400, N[0x3996, ((0, 2), (1, 2))] = 1
Updated Q[0x453c, ((0, 1), (0, 2))] = 22400, N[0x453c, ((0, 1), (0, 2))] = 1

--- Simulation 284 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.326420887286, 16803.326420887286, 22250.01993613984, 16803.326420887286, 19603.326420887286]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 30001.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397f, Score: 8400
Depth 2: State = 0x397f, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397f: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2aaf, Score: 11200
Depth 3: State = 0x2aaf, Legal Moves = [((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2aaf: [inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x2aa2, Score: 14000
Depth 4: State = 0x2aa2, Legal Moves = [((1, 2), (1, 3)), ((1, 2), (2, 2)), ((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2aa2: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2aac, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6224500, N[0x3c25, ((2, 3), (2, 4))] = 280
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x397f, ((0, 0), (0, 1))] = 16800, N[0x397f, ((0, 0), (0, 1))] = 1
Updated Q[0x2aaf, ((2, 3), (2, 4))] = 16800, N[0x2aaf, ((2, 3), (2, 4))] = 1
Updated Q[0x2aa2, ((1, 2), (1, 3))] = 16800, N[0x2aa2, ((1, 2), (1, 3))] = 1

--- Simulation 285 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.327459918135, 16803.327459918135, 22230.55599662167, 16803.327459918135, 19603.327459918135]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 30501.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bc3, Score: 11200
Depth 2: State = 0x3bc3, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc3: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x1d96, Score: 14000
Depth 3: State = 0x1d96, Legal Moves = [((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1d96: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x14b0, Score: 19600
Depth 4: State = 0x14b0, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x14b0: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1477, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6246900, N[0x3c25, ((2, 3), (2, 4))] = 281
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3bc3, ((1, 2), (1, 3))] = 22400, N[0x3bc3, ((1, 2), (1, 3))] = 1
Updated Q[0x1d96, ((1, 2), (2, 2))] = 22400, N[0x1d96, ((1, 2), (2, 2))] = 1
Updated Q[0x14b0, ((0, 2), (1, 2))] = 22400, N[0x14b0, ((0, 2), (1, 2))] = 1

--- Simulation 286 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.32849497421, 16803.32849497421, 22231.159415455644, 16803.32849497421, 19603.32849497421]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14001.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37c0, Score: 16100
Depth 2: State = 0x37c0, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x37c0: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2293, Score: 21700
Depth 3: State = 0x2293, Legal Moves = [((1, 0), (2, 0)), ((1, 2), (2, 2)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x2293: [inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x484b, Score: 24500
Depth 4: State = 0x484b, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x484b: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x47ca, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6274200, N[0x3c25, ((2, 3), (2, 4))] = 282
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27300, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x37c0, ((2, 0), (2, 1))] = 27300, N[0x37c0, ((2, 0), (2, 1))] = 1
Updated Q[0x2293, ((1, 0), (2, 0))] = 27300, N[0x2293, ((1, 0), (2, 0))] = 1
Updated Q[0x484b, ((0, 2), (0, 3))] = 27300, N[0x484b, ((0, 2), (0, 3))] = 1

--- Simulation 287 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.329526084777, 16803.329526084777, 22249.134440605805, 16803.329526084777, 19603.329526084777]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3c69, Score: 11200
Depth 2: State = 0x3c69, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c69: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c06, Score: 14000
Depth 3: State = 0x3c06, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c06: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3961, Score: 16800
Depth 4: State = 0x3961, Legal Moves = [((1, 1), (2, 1))]
UCB1 values for moves at state 0x3961: [inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x5111, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6293800, N[0x3c25, ((2, 3), (2, 4))] = 283
Updated Q[0x3c24, ((1, 3), (1, 4))] = 19600, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x3c69, ((1, 3), (2, 3))] = 19600, N[0x3c69, ((1, 3), (2, 3))] = 1
Updated Q[0x3c06, ((2, 0), (2, 1))] = 19600, N[0x3c06, ((2, 0), (2, 1))] = 1
Updated Q[0x3961, ((1, 1), (2, 1))] = 19600, N[0x3961, ((1, 1), (2, 1))] = 1

--- Simulation 288 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.330553278796, 16803.330553278796, 22239.77395257379, 16803.330553278796, 19603.330553278796]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c3c, Score: 11200
Depth 2: State = 0x3c3c, Legal Moves = [((0, 0), (1, 0)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c3c: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x15da, Score: 14000
Depth 3: State = 0x15da, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x15da: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x15e1, Score: 16800
Depth 4: State = 0x15e1, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x15e1: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x12bb, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6324300, N[0x3c25, ((2, 3), (2, 4))] = 284
Updated Q[0x3c24, ((1, 3), (2, 3))] = 30500, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3c3c, ((0, 0), (1, 0))] = 30500, N[0x3c3c, ((0, 0), (1, 0))] = 1
Updated Q[0x15da, ((0, 2), (1, 2))] = 30500, N[0x15da, ((0, 2), (1, 2))] = 1
Updated Q[0x15e1, ((2, 0), (2, 1))] = 30500, N[0x15e1, ((2, 0), (2, 1))] = 1

--- Simulation 289 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.3315765849, 16803.3315765849, 22268.859664530177, 16803.3315765849, 19603.3315765849]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c6b, Score: 8400
Depth 2: State = 0x3c6b, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6b: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3db4, Score: 11200
Depth 3: State = 0x3db4, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3db4: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x564e, Score: 16800
Depth 4: State = 0x564e, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x564e: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x56da, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6346700, N[0x3c25, ((2, 3), (2, 4))] = 285
Updated Q[0x3c24, ((0, 2), (1, 2))] = 22400, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c6b, ((1, 3), (1, 4))] = 22400, N[0x3c6b, ((1, 3), (1, 4))] = 1
Updated Q[0x3db4, ((1, 2), (1, 3))] = 22400, N[0x3db4, ((1, 2), (1, 3))] = 1
Updated Q[0x564e, ((0, 3), (1, 3))] = 22400, N[0x564e, ((0, 3), (1, 3))] = 1

--- Simulation 290 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.33259603143, 16803.33259603143, 22269.320212969466, 16803.33259603143, 19603.33259603143]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x491f, Score: 8400
Depth 2: State = 0x491f, Legal Moves = [((0, 2), (0, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x491f: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x1447, Score: 11200
Depth 3: State = 0x1447, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1447: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x4a68, Score: 14000
Depth 4: State = 0x4a68, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a68: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4a68, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6363500, N[0x3c25, ((2, 3), (2, 4))] = 286
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x491f, ((0, 2), (0, 3))] = 16800, N[0x491f, ((0, 2), (0, 3))] = 1
Updated Q[0x1447, ((0, 0), (1, 0))] = 16800, N[0x1447, ((0, 0), (1, 0))] = 1
Updated Q[0x4a68, ((2, 0), (2, 1))] = 16800, N[0x4a68, ((2, 0), (2, 1))] = 1

--- Simulation 291 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.333611646405, 16803.333611646405, 22250.197120588993, 16803.333611646405, 19603.333611646405]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.467405903557, 19601.467405903557, 32601.467405903557, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x47cd, Score: 13300
Depth 2: State = 0x47cd, Legal Moves = [((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x47cd: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x4811, Score: 16100
Depth 3: State = 0x4811, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (2, 1)), ((1, 4), (2, 4)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4811: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x43d5, Score: 18900
Depth 4: State = 0x43d5, Legal Moves = [((1, 1), (2, 1)), ((1, 4), (2, 4)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x43d5: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x43cb, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6385200, N[0x3c25, ((2, 3), (2, 4))] = 287
Updated Q[0x3c24, ((2, 0), (2, 1))] = 21700, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x47cd, ((1, 1), (1, 2))] = 21700, N[0x47cd, ((1, 1), (1, 2))] = 1
Updated Q[0x4811, ((0, 3), (1, 3))] = 21700, N[0x4811, ((0, 3), (1, 3))] = 1
Updated Q[0x43d5, ((1, 1), (2, 1))] = 21700, N[0x43d5, ((1, 1), (2, 1))] = 1

--- Simulation 292 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.33462345755, 16803.33462345755, 22248.28046029237, 16803.33462345755, 19603.33462345755]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 19601.467405903557, 16801.467405903557, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c1d, Score: 13300
Depth 2: State = 0x3c1d, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1d: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3977, Score: 16100
Depth 3: State = 0x3977, Legal Moves = [((1, 1), (2, 1)), ((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3977: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x15bb, Score: 18900
Depth 4: State = 0x15bb, Legal Moves = [((1, 1), (2, 1)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x15bb: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x499d, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6409700, N[0x3c25, ((2, 3), (2, 4))] = 288
Updated Q[0x3c24, ((2, 3), (2, 4))] = 24500, N[0x3c24, ((2, 3), (2, 4))] = 1
Updated Q[0x3c1d, ((2, 0), (2, 1))] = 24500, N[0x3c1d, ((2, 0), (2, 1))] = 1
Updated Q[0x3977, ((1, 1), (2, 1))] = 24500, N[0x3977, ((1, 1), (2, 1))] = 1
Updated Q[0x15bb, ((1, 1), (2, 1))] = 24500, N[0x15bb, ((1, 1), (2, 1))] = 1

--- Simulation 293 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.335631492304, 16803.335631492304, 22256.099331748424, 16803.335631492304, 19603.335631492304]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.77609073765, 21701.77609073765, 16801.77609073765, 22401.77609073765, 24501.77609073765]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x1471, Score: 8400
Depth 2: State = 0x1471, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x1471: [inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3dbc, Score: 11200
Depth 3: State = 0x3dbc, Legal Moves = [((0, 3), (0, 4)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x3dbc: [inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3d59, Score: 14000
Depth 4: State = 0x3d59, Legal Moves = [((0, 4), (1, 4))]
UCB1 values for moves at state 0x3d59: [inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3db5, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6426500, N[0x3c25, ((2, 3), (2, 4))] = 289
Updated Q[0x3c25, ((3, 0), (3, 1))] = 41300, N[0x3c25, ((3, 0), (3, 1))] = 2
Updated Q[0x1471, ((0, 0), (1, 0))] = 16800, N[0x1471, ((0, 0), (1, 0))] = 1
Updated Q[0x3dbc, ((0, 3), (0, 4))] = 16800, N[0x3dbc, ((0, 3), (0, 4))] = 1
Updated Q[0x3d59, ((0, 4), (1, 4))] = 16800, N[0x3d59, ((0, 4), (1, 4))] = 1

--- Simulation 294 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.336635777796, 16803.336635777796, 22237.2204941461, 16803.336635777796, 19603.336635777796]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c27, Score: 8400
Depth 1: State = 0x3c27, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c27: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x393e, Score: 11200
Depth 2: State = 0x393e, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x393e: [inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x397e, Score: 14000
Depth 3: State = 0x397e, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x397e: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2981, Score: 16800
Depth 4: State = 0x2981, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2981: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x47ae, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6451700, N[0x3c25, ((2, 3), (2, 4))] = 290
Updated Q[0x3c27, ((1, 3), (2, 3))] = 25200, N[0x3c27, ((1, 3), (2, 3))] = 1
Updated Q[0x393e, ((1, 1), (1, 2))] = 25200, N[0x393e, ((1, 1), (1, 2))] = 1
Updated Q[0x397e, ((0, 0), (0, 1))] = 25200, N[0x397e, ((0, 0), (0, 1))] = 1
Updated Q[0x2981, ((2, 0), (2, 1))] = 25200, N[0x2981, ((2, 0), (2, 1))] = 1

--- Simulation 295 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.337636340882, 16803.337636340882, 22247.43737206482, 16803.337636340882, 19603.337636340882]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.77609073765, 27301.77609073765, 27701.77609073765, 36101.77609073765, 25201.77609073765]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x393f, Score: 22100
Depth 2: State = 0x393f, Legal Moves = [((0, 3), (0, 4)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x393f: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x393c, Score: 24900
Depth 3: State = 0x393c, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x393c: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x36d3, Score: 27700
Depth 4: State = 0x36d3, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d3: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3826, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6482200, N[0x3c25, ((2, 3), (2, 4))] = 291
Updated Q[0x3c24, ((2, 3), (3, 3))] = 66600, N[0x3c24, ((2, 3), (3, 3))] = 2
Updated Q[0x393f, ((0, 3), (0, 4))] = 30500, N[0x393f, ((0, 3), (0, 4))] = 1
Updated Q[0x393c, ((0, 2), (1, 2))] = 30500, N[0x393c, ((0, 2), (1, 2))] = 1
Updated Q[0x36d3, ((1, 1), (2, 1))] = 30500, N[0x36d3, ((1, 1), (2, 1))] = 1

--- Simulation 296 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.338633208128, 16803.338633208128, 22275.797088715197, 16803.338633208128, 19603.338633208128]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3975, Score: 14000
Depth 2: State = 0x3975, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3975: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4a44, Score: 16800
Depth 3: State = 0x4a44, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a44: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x479f, Score: 19600
Depth 4: State = 0x479f, Legal Moves = [((0, 1), (0, 2)), ((0, 1), (1, 1)), ((1, 3), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x479f: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x440c, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6504600, N[0x3c25, ((2, 3), (2, 4))] = 292
Updated Q[0x3c24, ((1, 2), (2, 2))] = 22400, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3975, ((1, 2), (1, 3))] = 22400, N[0x3975, ((1, 2), (1, 3))] = 1
Updated Q[0x4a44, ((1, 1), (2, 1))] = 22400, N[0x4a44, ((1, 1), (2, 1))] = 1
Updated Q[0x479f, ((0, 1), (0, 2))] = 22400, N[0x479f, ((0, 1), (0, 2))] = 1

--- Simulation 297 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.339626405825, 16803.339626405825, 22276.222834113145, 16803.339626405825, 19603.339626405825]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc5, Score: 8400
Depth 1: State = 0x3bc5, Legal Moves = [((0, 3), (0, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc5: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3bbc, Score: 11200
Depth 2: State = 0x3bbc, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbc: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c6b, Score: 14000
Depth 3: State = 0x3c6b, Legal Moves = [((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6b: [inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c6c, Score: 16800
Depth 4: State = 0x3c6c, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6c: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d74, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6524200, N[0x3c25, ((2, 3), (2, 4))] = 293
Updated Q[0x3bc5, ((0, 3), (0, 4))] = 19600, N[0x3bc5, ((0, 3), (0, 4))] = 1
Updated Q[0x3bbc, ((1, 2), (2, 2))] = 19600, N[0x3bbc, ((1, 2), (2, 2))] = 1
Updated Q[0x3c6b, ((0, 4), (1, 4))] = 19600, N[0x3c6b, ((0, 4), (1, 4))] = 1
Updated Q[0x3c6c, ((1, 3), (1, 4))] = 19600, N[0x3c6c, ((1, 3), (1, 4))] = 1

--- Simulation 298 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.340615959976, 16803.340615959976, 22267.08935882042, 16803.340615959976, 19603.340615959976]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 22401.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2a8b, Score: 16800
Depth 2: State = 0x2a8b, Legal Moves = [((0, 4), (1, 4)), ((3, 1), (3, 2)), ((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2a8b: [inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x2a84, Score: 22400
Depth 3: State = 0x2a84, Legal Moves = [((3, 1), (3, 2)), ((3, 2), (4, 2)), ((3, 3), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2a84: [inf, inf, inf, inf]
Selected move: ((3, 1), (3, 2))
New board state after move: 0x2d2a, Score: 25200
Depth 4: State = 0x2d2a, Legal Moves = [((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((2, 4), (3, 4)), ((3, 3), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2d2a: [inf, inf, inf, inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x5263, Score: 35700
End of simulation with depth 5. Reward (Score): 35700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6559900, N[0x3c25, ((2, 3), (2, 4))] = 294
Updated Q[0x3c25, ((2, 0), (2, 1))] = 35700, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x2a8b, ((0, 4), (1, 4))] = 35700, N[0x2a8b, ((0, 4), (1, 4))] = 1
Updated Q[0x2a84, ((3, 1), (3, 2))] = 35700, N[0x2a84, ((3, 1), (3, 2))] = 1
Updated Q[0x2d2a, ((2, 1), (2, 2))] = 35700, N[0x2d2a, ((2, 1), (2, 2))] = 1

--- Simulation 299 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.34160189633, 16803.34160189633, 22312.779920193832, 16803.34160189633, 19603.34160189633]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14001.467405903555, 19601.467405903557, 27301.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c24, Score: 8400
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x484e, Score: 11200
Depth 3: State = 0x484e, Legal Moves = [((1, 0), (1, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x484e: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x1c19, Score: 16800
Depth 4: State = 0x1c19, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x1c19: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x1c65, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6579500, N[0x3c25, ((2, 3), (2, 4))] = 295
Updated Q[0x3c24, ((2, 0), (2, 1))] = 19600, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x484e, ((1, 0), (1, 1))] = 19600, N[0x484e, ((1, 0), (1, 1))] = 1
Updated Q[0x1c19, ((4, 1), (4, 2))] = 19600, N[0x1c19, ((4, 1), (4, 2))] = 1

--- Simulation 300 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.342584240352, 16803.342584240352, 22303.584443287018, 16803.342584240352, 19603.342584240352]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [24901.16557645562, 25201.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d90, Score: 11200
Depth 2: State = 0x3d90, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d90: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x466e, Score: 14000
Depth 3: State = 0x466e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x466e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1554, Score: 19600
Depth 4: State = 0x1554, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1))]
UCB1 values for moves at state 0x1554: [inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1ca9, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6604700, N[0x3c25, ((2, 3), (2, 4))] = 296
Updated Q[0x3c25, ((1, 3), (2, 3))] = 25200, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3d90, ((0, 2), (1, 2))] = 25200, N[0x3d90, ((0, 2), (1, 2))] = 1
Updated Q[0x466e, ((2, 0), (2, 1))] = 25200, N[0x466e, ((2, 0), (2, 1))] = 1
Updated Q[0x1554, ((0, 0), (0, 1))] = 25200, N[0x1554, ((0, 0), (0, 1))] = 1

--- Simulation 301 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.34356301725, 16803.34356301725, 22313.37001632855, 16803.34356301725, 19603.34356301725]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43af, Score: 8400
Depth 2: State = 0x43af, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43af: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x43b0, Score: 11200
Depth 3: State = 0x43b0, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43b0: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x4434, Score: 16800
Depth 4: State = 0x4434, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4434: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4587, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6632400, N[0x3c25, ((2, 3), (2, 4))] = 297
Updated Q[0x3c24, ((0, 0), (0, 1))] = 27700, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43af, ((0, 4), (1, 4))] = 27700, N[0x43af, ((0, 4), (1, 4))] = 1
Updated Q[0x43b0, ((1, 2), (2, 2))] = 27700, N[0x43b0, ((1, 2), (2, 2))] = 1
Updated Q[0x4434, ((1, 3), (2, 3))] = 27700, N[0x4434, ((1, 3), (2, 3))] = 1

--- Simulation 302 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.34453825197, 16803.34453825197, 22331.507201106182, 16803.34453825197, 19603.34453825197]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c25, Score: 8400
Depth 2: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (0, 2)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4416, Score: 16000
Depth 3: State = 0x4416, Legal Moves = [((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4416: [inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x441a, Score: 18800
Depth 4: State = 0x441a, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x441a: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4418, Score: 21600
End of simulation with depth 5. Reward (Score): 21600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6654000, N[0x3c25, ((2, 3), (2, 4))] = 298
Updated Q[0x3c25, ((2, 0), (2, 1))] = 21600, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3c25, ((0, 0), (0, 1))] = 21600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4416, ((2, 3), (3, 3))] = 21600, N[0x4416, ((2, 3), (3, 3))] = 1
Updated Q[0x441a, ((1, 3), (1, 4))] = 21600, N[0x441a, ((1, 3), (1, 4))] = 1

--- Simulation 303 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.345509969207, 16803.345509969207, 22329.052860591713, 16803.345509969207, 19603.345509969207]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 10500
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x48f2, Score: 13300
Depth 2: State = 0x48f2, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f2: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x45a6, Score: 16100
Depth 3: State = 0x45a6, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a6: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4565, Score: 18900
Depth 4: State = 0x4565, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4565: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4565, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6675700, N[0x3c25, ((2, 3), (2, 4))] = 299
Updated Q[0x3c25, ((0, 0), (0, 1))] = 21700, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x48f2, ((0, 1), (1, 1))] = 21700, N[0x48f2, ((0, 1), (1, 1))] = 1
Updated Q[0x45a6, ((1, 3), (2, 3))] = 21700, N[0x45a6, ((1, 3), (2, 3))] = 1
Updated Q[0x4565, ((1, 3), (1, 4))] = 21700, N[0x4565, ((1, 3), (1, 4))] = 1

--- Simulation 304 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.346478193384, 16803.346478193384, 22326.949384673684, 16803.346478193384, 19603.346478193384]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 19601.16557645562, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3bff, Score: 8400
Depth 2: State = 0x3bff, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bff: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c28, Score: 11200
Depth 3: State = 0x3c28, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c28: [inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3be4, Score: 14000
Depth 4: State = 0x3be4, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be4: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3be4, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6692500, N[0x3c25, ((2, 3), (2, 4))] = 300
Updated Q[0x3c24, ((0, 4), (1, 4))] = 16800, N[0x3c24, ((0, 4), (1, 4))] = 1
Updated Q[0x3bff, ((1, 2), (2, 2))] = 16800, N[0x3bff, ((1, 2), (2, 2))] = 1
Updated Q[0x3c28, ((0, 4), (1, 4))] = 16800, N[0x3c28, ((0, 4), (1, 4))] = 1
Updated Q[0x3be4, ((1, 2), (1, 3))] = 16800, N[0x3be4, ((1, 2), (1, 3))] = 1

--- Simulation 305 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.347442948692, 16803.347442948692, 22308.526598042085, 16803.347442948692, 19603.347442948692]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x36e1, Score: 14000
Depth 2: State = 0x36e1, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36e1: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x36da, Score: 16800
Depth 3: State = 0x36da, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36da: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1321, Score: 19600
Depth 4: State = 0x1321, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1321: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x1314, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6714900, N[0x3c25, ((2, 3), (2, 4))] = 301
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x36e1, ((1, 2), (1, 3))] = 22400, N[0x36e1, ((1, 2), (1, 3))] = 1
Updated Q[0x36da, ((0, 0), (0, 1))] = 22400, N[0x36da, ((0, 0), (0, 1))] = 1
Updated Q[0x1321, ((1, 3), (1, 4))] = 22400, N[0x1321, ((1, 3), (1, 4))] = 1

--- Simulation 306 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.348404259068, 16803.348404259068, 22308.830872567105, 16803.348404259068, 19603.348404259068]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 27301.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c25, Score: 8400
Depth 2: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 1), (2, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x5573, Score: 14000
Depth 3: State = 0x5573, Legal Moves = [((1, 1), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x5573: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x57d5, Score: 16800
Depth 4: State = 0x57d5, Legal Moves = [((0, 2), (0, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x57d5: [inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x495e, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6734500, N[0x3c25, ((2, 3), (2, 4))] = 302
Updated Q[0x3c25, ((2, 0), (2, 1))] = 19600, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x5573, ((1, 1), (2, 1))] = 19600, N[0x5573, ((1, 1), (2, 1))] = 1
Updated Q[0x57d5, ((0, 2), (0, 3))] = 19600, N[0x57d5, ((0, 2), (0, 3))] = 1

--- Simulation 307 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.349362148205, 16803.349362148205, 22299.86160830605, 16803.349362148205, 19603.349362148205]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [27300.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c4d, Score: 11200
Depth 2: State = 0x3c4d, Legal Moves = [((0, 0), (1, 0)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4d: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x5572, Score: 14000
Depth 3: State = 0x5572, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5572: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x36fb, Score: 18900
Depth 4: State = 0x36fb, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36fb: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3920, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6761800, N[0x3c25, ((2, 3), (2, 4))] = 303
Updated Q[0x3c25, ((1, 2), (2, 2))] = 27300, N[0x3c25, ((1, 2), (2, 2))] = 1
Updated Q[0x3c4d, ((0, 0), (1, 0))] = 27300, N[0x3c4d, ((0, 0), (1, 0))] = 1
Updated Q[0x5572, ((0, 1), (1, 1))] = 27300, N[0x5572, ((0, 1), (1, 1))] = 1
Updated Q[0x36fb, ((2, 0), (2, 1))] = 27300, N[0x36fb, ((2, 0), (2, 1))] = 1

--- Simulation 308 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.350316639553, 16803.350316639553, 22316.364087823706, 16803.350316639553, 19603.350316639553]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [21700.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3832, Score: 11200
Depth 2: State = 0x3832, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3832: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3985, Score: 14000
Depth 3: State = 0x3985, Legal Moves = [((2, 1), (3, 1))]
UCB1 values for moves at state 0x3985: [inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x519c, Score: 35800
Depth 4: State = 0x519c, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (2, 3))]
UCB1 values for moves at state 0x519c: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x11e2, Score: 38600
End of simulation with depth 5. Reward (Score): 38600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6800400, N[0x3c25, ((2, 3), (2, 4))] = 304
Updated Q[0x3c24, ((1, 3), (2, 3))] = 38600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3832, ((2, 0), (2, 1))] = 38600, N[0x3832, ((2, 0), (2, 1))] = 1
Updated Q[0x3985, ((2, 1), (3, 1))] = 38600, N[0x3985, ((2, 1), (3, 1))] = 1
Updated Q[0x519c, ((0, 0), (0, 1))] = 38600, N[0x519c, ((0, 0), (0, 1))] = 1

--- Simulation 309 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.35126775633, 16803.35126775633, 22369.929050493192, 16803.35126775633, 19603.35126775633]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c5d, Score: 11200
Depth 2: State = 0x3c5d, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5d: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3865, Score: 14000
Depth 3: State = 0x3865, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x3865: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x37c3, Score: 24400
Depth 4: State = 0x37c3, Legal Moves = [((0, 2), (1, 2)), ((1, 1), (2, 1)), ((2, 3), (2, 4))]
UCB1 values for moves at state 0x37c3: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x37cb, Score: 27200
End of simulation with depth 5. Reward (Score): 27200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6827600, N[0x3c25, ((2, 3), (2, 4))] = 305
Updated Q[0x3c24, ((1, 2), (2, 2))] = 27200, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3c5d, ((2, 0), (2, 1))] = 27200, N[0x3c5d, ((2, 0), (2, 1))] = 1
Updated Q[0x3865, ((4, 1), (4, 2))] = 27200, N[0x3865, ((4, 1), (4, 2))] = 1
Updated Q[0x37c3, ((0, 2), (1, 2))] = 27200, N[0x37c3, ((0, 2), (1, 2))] = 1

--- Simulation 310 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.35221552152, 16803.35221552152, 22385.76571779419, 16803.35221552152, 19603.35221552152]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22400.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x386c, Score: 11200
Depth 2: State = 0x386c, Legal Moves = [((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x386c: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3af0, Score: 14000
Depth 3: State = 0x3af0, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3af0: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x399d, Score: 16800
Depth 4: State = 0x399d, Legal Moves = [((1, 1), (2, 1))]
UCB1 values for moves at state 0x399d: [inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4836, Score: 33300
End of simulation with depth 5. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6860900, N[0x3c25, ((2, 3), (2, 4))] = 306
Updated Q[0x3c24, ((1, 3), (2, 3))] = 33300, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x386c, ((1, 2), (1, 3))] = 33300, N[0x386c, ((1, 2), (1, 3))] = 1
Updated Q[0x3af0, ((2, 0), (2, 1))] = 33300, N[0x3af0, ((2, 0), (2, 1))] = 1
Updated Q[0x399d, ((1, 1), (2, 1))] = 33300, N[0x399d, ((1, 1), (2, 1))] = 1

--- Simulation 311 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.35315995787, 16803.35315995787, 22421.433517461537, 16803.35315995787, 19603.35315995787]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [21701.467405903557, 22401.467405903557, 25201.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c22, Score: 8400
Depth 2: State = 0x3c22, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c22: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3be0, Score: 11200
Depth 3: State = 0x3be0, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be0: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3bdd, Score: 14000
Depth 4: State = 0x3bdd, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bdd: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x37e4, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6877700, N[0x3c25, ((2, 3), (2, 4))] = 307
Updated Q[0x3c25, ((2, 3), (3, 3))] = 16800, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3c22, ((1, 2), (2, 2))] = 16800, N[0x3c22, ((1, 2), (2, 2))] = 1
Updated Q[0x3be0, ((1, 2), (1, 3))] = 16800, N[0x3be0, ((1, 2), (1, 3))] = 1
Updated Q[0x3bdd, ((2, 0), (2, 1))] = 16800, N[0x3bdd, ((2, 0), (2, 1))] = 1

--- Simulation 312 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.3541010879, 16803.3541010879, 22403.12302475141, 16803.3541010879, 19603.3541010879]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x382c, Score: 13300
Depth 2: State = 0x382c, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x382c: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2180, Score: 16100
Depth 3: State = 0x2180, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x2180: [inf, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x22d3, Score: 18900
Depth 4: State = 0x22d3, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 1), (3, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x22d3: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x300f, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6899400, N[0x3c25, ((2, 3), (2, 4))] = 308
Updated Q[0x3c24, ((1, 3), (2, 3))] = 21700, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x382c, ((0, 0), (0, 1))] = 21700, N[0x382c, ((0, 0), (0, 1))] = 1
Updated Q[0x2180, ((2, 0), (2, 1))] = 21700, N[0x2180, ((2, 0), (2, 1))] = 1
Updated Q[0x22d3, ((1, 0), (1, 1))] = 21700, N[0x22d3, ((1, 0), (1, 1))] = 1

--- Simulation 313 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.355038933918, 16803.355038933918, 22400.840521734826, 16803.355038933918, 19603.355038933918]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x453c, Score: 8400
Depth 2: State = 0x453c, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x453c: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x43ce, Score: 11200
Depth 3: State = 0x43ce, Legal Moves = [((0, 1), (0, 2)), ((0, 3), (1, 3)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43ce: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x48f7, Score: 14000
Depth 4: State = 0x48f7, Legal Moves = [((0, 3), (1, 3)), ((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f7: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4a8f, Score: 18900
End of simulation with depth 5. Reward (Score): 18900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6918300, N[0x3c25, ((2, 3), (2, 4))] = 309
Updated Q[0x3c24, ((0, 0), (0, 1))] = 18900, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x453c, ((0, 3), (1, 3))] = 18900, N[0x453c, ((0, 3), (1, 3))] = 1
Updated Q[0x43ce, ((0, 1), (0, 2))] = 18900, N[0x43ce, ((0, 1), (0, 2))] = 1
Updated Q[0x48f7, ((0, 3), (1, 3))] = 18900, N[0x48f7, ((0, 3), (1, 3))] = 1

--- Simulation 314 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.35597351799, 16803.35597351799, 22389.511303012616, 16803.35597351799, 19603.35597351799]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.873992678666, 27301.873992678666, 27701.873992678666, 33301.32511293098, 25201.873992678666]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3833, Score: 11200
Depth 2: State = 0x3833, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3833: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x519c, Score: 14000
Depth 3: State = 0x519c, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x519c: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x14ad, Score: 16800
Depth 4: State = 0x14ad, Legal Moves = [((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x14ad: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x115e, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6937900, N[0x3c25, ((2, 3), (2, 4))] = 310
Updated Q[0x3c24, ((2, 3), (3, 3))] = 86200, N[0x3c24, ((2, 3), (3, 3))] = 3
Updated Q[0x3833, ((1, 2), (1, 3))] = 19600, N[0x3833, ((1, 2), (1, 3))] = 1
Updated Q[0x519c, ((0, 0), (0, 1))] = 19600, N[0x519c, ((0, 0), (0, 1))] = 1
Updated Q[0x14ad, ((1, 0), (1, 1))] = 19600, N[0x14ad, ((1, 0), (1, 1))] = 1

--- Simulation 315 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.35690486198, 16803.35690486198, 22380.513240029442, 16803.35690486198, 19603.35690486198]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c5f, Score: 8400
Depth 2: State = 0x3c5f, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5f: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3953, Score: 11200
Depth 3: State = 0x3953, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3953: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3bf9, Score: 14000
Depth 4: State = 0x3bf9, Legal Moves = [((4, 0), (4, 1))]
UCB1 values for moves at state 0x3bf9: [inf]
Selected move: ((4, 0), (4, 1))
New board state after move: 0x200c, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6957500, N[0x3c25, ((2, 3), (2, 4))] = 311
Updated Q[0x3c25, ((0, 2), (1, 2))] = 19600, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3c5f, ((0, 3), (1, 3))] = 19600, N[0x3c5f, ((0, 3), (1, 3))] = 1
Updated Q[0x3953, ((2, 0), (2, 1))] = 19600, N[0x3953, ((2, 0), (2, 1))] = 1
Updated Q[0x3bf9, ((4, 0), (4, 1))] = 19600, N[0x3bf9, ((4, 0), (4, 1))] = 1

--- Simulation 316 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.357832987524, 16803.357832987524, 22371.573041896256, 16803.357832987524, 19603.357832987524]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x444e, Score: 8400
Depth 2: State = 0x444e, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x444e: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x45b2, Score: 11200
Depth 3: State = 0x45b2, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45b2: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4705, Score: 14000
Depth 4: State = 0x4705, Legal Moves = [((0, 1), (0, 2)), ((0, 1), (1, 1)), ((0, 3), (1, 3)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4705: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x43fa, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6974300, N[0x3c25, ((2, 3), (2, 4))] = 312
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x444e, ((0, 2), (1, 2))] = 16800, N[0x444e, ((0, 2), (1, 2))] = 1
Updated Q[0x45b2, ((2, 0), (2, 1))] = 16800, N[0x45b2, ((2, 0), (2, 1))] = 1
Updated Q[0x4705, ((0, 1), (0, 2))] = 16800, N[0x4705, ((0, 1), (0, 2))] = 1

--- Simulation 317 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.35875791605, 16803.35875791605, 22353.71579324822, 16803.35875791605, 19603.35875791605]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bd6, Score: 11200
Depth 2: State = 0x3bd6, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bd6: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5277, Score: 14000
Depth 3: State = 0x5277, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5277: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x540e, Score: 16800
Depth 4: State = 0x540e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x540e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x52bb, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 6993900, N[0x3c25, ((2, 3), (2, 4))] = 313
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3bd6, ((1, 2), (1, 3))] = 19600, N[0x3bd6, ((1, 2), (1, 3))] = 1
Updated Q[0x5277, ((0, 1), (0, 2))] = 19600, N[0x5277, ((0, 1), (0, 2))] = 1
Updated Q[0x540e, ((2, 0), (2, 1))] = 19600, N[0x540e, ((2, 0), (2, 1))] = 1

--- Simulation 318 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.359679668778, 16803.359679668778, 22344.918334827365, 16803.359679668778, 19603.359679668778]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc2, Score: 8400
Depth 1: State = 0x3bc2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc2: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3964, Score: 11200
Depth 2: State = 0x3964, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3964: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x1dff, Score: 14000
Depth 3: State = 0x1dff, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1dff: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x201d, Score: 16800
Depth 4: State = 0x201d, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (0, 2)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((1, 0), (2, 0)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4))]
UCB1 values for moves at state 0x201d: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x3a95, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7013500, N[0x3c25, ((2, 3), (2, 4))] = 314
Updated Q[0x3bc2, ((1, 3), (2, 3))] = 19600, N[0x3bc2, ((1, 3), (2, 3))] = 1
Updated Q[0x3964, ((1, 2), (1, 3))] = 19600, N[0x3964, ((1, 2), (1, 3))] = 1
Updated Q[0x1dff, ((1, 0), (2, 0))] = 19600, N[0x1dff, ((1, 0), (2, 0))] = 1
Updated Q[0x201d, ((0, 0), (0, 1))] = 19600, N[0x201d, ((0, 0), (0, 1))] = 1

--- Simulation 319 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.360598266714, 16803.360598266714, 22336.17691067836, 16803.360598266714, 19603.360598266714]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4957, Score: 8400
Depth 2: State = 0x4957, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4957: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x2b09, Score: 16800
Depth 3: State = 0x2b09, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2b09: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0xf3de, Score: 19600
Depth 4: State = 0xf3de, Legal Moves = [((0, 2), (0, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 0), (4, 0))]
UCB1 values for moves at state 0xf3de: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x2347, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7038700, N[0x3c25, ((2, 3), (2, 4))] = 315
Updated Q[0x3c25, ((0, 0), (0, 1))] = 25200, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4957, ((0, 2), (1, 2))] = 25200, N[0x4957, ((0, 2), (1, 2))] = 1
Updated Q[0x2b09, ((0, 2), (1, 2))] = 25200, N[0x2b09, ((0, 2), (1, 2))] = 1
Updated Q[0xf3de, ((0, 2), (0, 3))] = 25200, N[0xf3de, ((0, 2), (0, 3))] = 1

--- Simulation 320 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.361513730666, 16803.361513730666, 22345.268764921482, 16803.361513730666, 19603.361513730666]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c40, Score: 8400
Depth 1: State = 0x3c40, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c40: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3c61, Score: 11200
Depth 2: State = 0x3c61, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c61: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bb8, Score: 16800
Depth 3: State = 0x3bb8, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb8: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c29, Score: 19600
Depth 4: State = 0x3c29, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c29: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3c22, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7061100, N[0x3c25, ((2, 3), (2, 4))] = 316
Updated Q[0x3c40, ((0, 3), (0, 4))] = 22400, N[0x3c40, ((0, 3), (0, 4))] = 1
Updated Q[0x3c61, ((1, 2), (2, 2))] = 22400, N[0x3c61, ((1, 2), (2, 2))] = 1
Updated Q[0x3bb8, ((1, 2), (2, 2))] = 22400, N[0x3bb8, ((1, 2), (2, 2))] = 1
Updated Q[0x3c29, ((1, 3), (1, 4))] = 22400, N[0x3c29, ((1, 3), (1, 4))] = 1

--- Simulation 321 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.362426081232, 16803.362426081232, 22345.44231580205, 16803.362426081232, 19603.362426081232]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bd6, Score: 14000
Depth 2: State = 0x3bd6, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bd6: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d29, Score: 16800
Depth 3: State = 0x3d29, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d29: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x3d3a, Score: 19600
Depth 4: State = 0x3d3a, Legal Moves = [((2, 2), (3, 2))]
UCB1 values for moves at state 0x3d3a: [inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x3d5c, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7083500, N[0x3c25, ((2, 3), (2, 4))] = 317
Updated Q[0x3c24, ((1, 2), (2, 2))] = 22400, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3bd6, ((2, 0), (2, 1))] = 22400, N[0x3bd6, ((2, 0), (2, 1))] = 1
Updated Q[0x3d29, ((4, 1), (4, 2))] = 22400, N[0x3d29, ((4, 1), (4, 2))] = 1
Updated Q[0x3d3a, ((2, 2), (3, 2))] = 22400, N[0x3d3a, ((2, 2), (3, 2))] = 1

--- Simulation 322 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.363335338818, 16803.363335338818, 22345.614771240493, 16803.363335338818, 19603.363335338818]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3910, Score: 11200
Depth 2: State = 0x3910, Legal Moves = [((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3910: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3979, Score: 14000
Depth 3: State = 0x3979, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3979: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3979, Score: 16800
Depth 4: State = 0x3979, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3979: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x3997, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7103100, N[0x3c25, ((2, 3), (2, 4))] = 318
Updated Q[0x3c25, ((1, 3), (2, 3))] = 19600, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3910, ((1, 2), (2, 2))] = 19600, N[0x3910, ((1, 2), (2, 2))] = 1
Updated Q[0x3979, ((1, 3), (2, 3))] = 19600, N[0x3979, ((1, 3), (2, 3))] = 1
Updated Q[0x3979, ((1, 1), (1, 2))] = 19600, N[0x3979, ((1, 1), (1, 2))] = 1

--- Simulation 323 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.36424152362, 16803.36424152362, 22336.9811101268, 16803.36424152362, 19603.36424152362]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c22, Score: 8400
Depth 1: State = 0x3c22, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c22: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c20, Score: 11200
Depth 2: State = 0x3c20, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c20: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37ee, Score: 14000
Depth 3: State = 0x37ee, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37ee: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3be7, Score: 16800
Depth 4: State = 0x3be7, Legal Moves = [((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1))]
UCB1 values for moves at state 0x3be7: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x3be7, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7127600, N[0x3c25, ((2, 3), (2, 4))] = 319
Updated Q[0x3c22, ((0, 2), (1, 2))] = 24500, N[0x3c22, ((0, 2), (1, 2))] = 1
Updated Q[0x3c20, ((1, 3), (2, 3))] = 24500, N[0x3c20, ((1, 3), (2, 3))] = 1
Updated Q[0x37ee, ((2, 0), (2, 1))] = 24500, N[0x37ee, ((2, 0), (2, 1))] = 1
Updated Q[0x3be7, ((1, 1), (1, 2))] = 24500, N[0x3be7, ((1, 1), (1, 2))] = 1

--- Simulation 324 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.36514465566, 16803.36514465566, 22343.7620796407, 16803.36514465566, 19603.36514465566]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 25201.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3854, Score: 16100
Depth 2: State = 0x3854, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3854: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x43d8, Score: 18900
Depth 3: State = 0x43d8, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((1, 1), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43d8: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x47ae, Score: 24500
Depth 4: State = 0x47ae, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47ae: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3d18, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7154900, N[0x3c25, ((2, 3), (2, 4))] = 320
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27300, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3854, ((0, 2), (1, 2))] = 27300, N[0x3854, ((0, 2), (1, 2))] = 1
Updated Q[0x43d8, ((0, 1), (0, 2))] = 27300, N[0x43d8, ((0, 1), (0, 2))] = 1
Updated Q[0x47ae, ((0, 1), (1, 1))] = 27300, N[0x47ae, ((0, 1), (1, 1))] = 1

--- Simulation 325 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.366044754745, 16803.366044754745, 22359.250667622175, 16803.366044754745, 19603.366044754745]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c65, Score: 8400
Depth 1: State = 0x3c65, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c65: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c24, Score: 11200
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 3), (0, 4)), ((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x48fb, Score: 14000
Depth 3: State = 0x48fb, Legal Moves = [((0, 3), (0, 4)), ((0, 3), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x48fb: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x48f4, Score: 16800
Depth 4: State = 0x48f4, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f4: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x464f, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7174500, N[0x3c25, ((2, 3), (2, 4))] = 321
Updated Q[0x3c65, ((1, 2), (2, 2))] = 19600, N[0x3c65, ((1, 2), (2, 2))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x48fb, ((0, 3), (0, 4))] = 19600, N[0x48fb, ((0, 3), (0, 4))] = 1
Updated Q[0x48f4, ((2, 0), (2, 1))] = 19600, N[0x48f4, ((2, 0), (2, 1))] = 1

--- Simulation 326 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.366941840508, 16803.366941840508, 22350.655214087634, 16803.366941840508, 19603.366941840508]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a46, Score: 8400
Depth 2: State = 0x4a46, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a46: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x48f7, Score: 14000
Depth 3: State = 0x48f7, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f7: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x48f7, Score: 16800
Depth 4: State = 0x48f7, Legal Moves = [((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f7: [inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x48f7, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7194100, N[0x3c25, ((2, 3), (2, 4))] = 322
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a46, ((1, 3), (2, 3))] = 19600, N[0x4a46, ((1, 3), (2, 3))] = 1
Updated Q[0x48f7, ((1, 3), (1, 4))] = 19600, N[0x48f7, ((1, 3), (1, 4))] = 1
Updated Q[0x48f7, ((1, 4), (2, 4))] = 19600, N[0x48f7, ((1, 4), (2, 4))] = 1

--- Simulation 327 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.367835932386, 16803.367835932386, 22342.113147997374, 16803.367835932386, 19603.367835932386]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3be0, Score: 8400
Depth 1: State = 0x3be0, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be0: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3a72, Score: 14000
Depth 2: State = 0x3a72, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3a72: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x37bf, Score: 19600
Depth 3: State = 0x37bf, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37bf: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3677, Score: 22400
Depth 4: State = 0x3677, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3677: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3719, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7219300, N[0x3c25, ((2, 3), (2, 4))] = 323
Updated Q[0x3be0, ((1, 3), (2, 3))] = 25200, N[0x3be0, ((1, 3), (2, 3))] = 1
Updated Q[0x3a72, ((0, 2), (0, 3))] = 25200, N[0x3a72, ((0, 2), (0, 3))] = 1
Updated Q[0x37bf, ((0, 1), (0, 2))] = 25200, N[0x37bf, ((0, 1), (0, 2))] = 1
Updated Q[0x3677, ((1, 2), (2, 2))] = 25200, N[0x3677, ((1, 2), (2, 2))] = 1

--- Simulation 328 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.368727049638, 16803.368727049638, 22350.96143479513, 16803.368727049638, 19603.368727049638]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14000.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x37ca, Score: 11200
Depth 2: State = 0x37ca, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x37ca: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x36dd, Score: 14000
Depth 3: State = 0x36dd, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x36dd: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x523c, Score: 24400
Depth 4: State = 0x523c, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x523c: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3c65, Score: 30000
End of simulation with depth 5. Reward (Score): 30000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7249300, N[0x3c25, ((2, 3), (2, 4))] = 324
Updated Q[0x3c24, ((1, 3), (1, 4))] = 30000, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x37ca, ((0, 1), (0, 2))] = 30000, N[0x37ca, ((0, 1), (0, 2))] = 1
Updated Q[0x36dd, ((0, 1), (1, 1))] = 30000, N[0x36dd, ((0, 1), (1, 1))] = 1
Updated Q[0x523c, ((1, 2), (1, 3))] = 30000, N[0x523c, ((1, 2), (1, 3))] = 1

--- Simulation 329 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.36961521133, 16803.36961521133, 22374.569916894456, 16803.36961521133, 19603.36961521133]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22401.16557645562, 42801.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d77, Score: 8400
Depth 2: State = 0x3d77, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (0, 2)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d77: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x3c1a, Score: 18800
Depth 3: State = 0x3c1a, Legal Moves = [((1, 0), (2, 0)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c1a: [inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x1c9a, Score: 21600
Depth 4: State = 0x1c9a, Legal Moves = [((1, 0), (1, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1c9a: [inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x1c8a, Score: 24400
End of simulation with depth 5. Reward (Score): 24400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7273700, N[0x3c25, ((2, 3), (2, 4))] = 325
Updated Q[0x3c24, ((2, 0), (2, 1))] = 24400, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3d77, ((0, 0), (0, 1))] = 24400, N[0x3d77, ((0, 0), (0, 1))] = 1
Updated Q[0x3c1a, ((1, 0), (2, 0))] = 24400, N[0x3c1a, ((1, 0), (2, 0))] = 1
Updated Q[0x1c9a, ((1, 0), (1, 1))] = 24400, N[0x1c9a, ((1, 0), (1, 1))] = 1

--- Simulation 330 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.37050043636, 16803.37050043636, 22380.802346340726, 16803.37050043636, 19603.37050043636]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x45a2, Score: 8400
Depth 2: State = 0x45a2, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a2: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x45a9, Score: 14000
Depth 3: State = 0x45a9, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a9: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x49a2, Score: 16800
Depth 4: State = 0x49a2, Legal Moves = [((1, 2), (2, 2)), ((2, 1), (2, 2)), ((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x49a2: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x12f9, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7293300, N[0x3c25, ((2, 3), (2, 4))] = 326
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x45a2, ((0, 3), (1, 3))] = 19600, N[0x45a2, ((0, 3), (1, 3))] = 1
Updated Q[0x45a9, ((2, 0), (2, 1))] = 19600, N[0x45a9, ((2, 0), (2, 1))] = 1
Updated Q[0x49a2, ((1, 2), (2, 2))] = 19600, N[0x49a2, ((1, 2), (2, 2))] = 1

--- Simulation 331 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.371382743437, 16803.371382743437, 22372.272613191013, 16803.371382743437, 19603.371382743437]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47a5, Score: 8400
Depth 2: State = 0x47a5, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47a5: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x443b, Score: 11200
Depth 3: State = 0x443b, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443b: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0xf43b, Score: 14000
Depth 4: State = 0xf43b, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0xf43b: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x29e5, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7312900, N[0x3c25, ((2, 3), (2, 4))] = 327
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47a5, ((1, 3), (2, 3))] = 19600, N[0x47a5, ((1, 3), (2, 3))] = 1
Updated Q[0x443b, ((0, 0), (0, 1))] = 19600, N[0x443b, ((0, 0), (0, 1))] = 1
Updated Q[0xf43b, ((0, 2), (1, 2))] = 19600, N[0xf43b, ((0, 2), (1, 2))] = 1

--- Simulation 332 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.3722621511, 16803.3722621511, 22363.795049214208, 16803.3722621511, 19603.3722621511]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x48f4, Score: 8400
Depth 2: State = 0x48f4, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48f4: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x2f00, Score: 14000
Depth 3: State = 0x2f00, Legal Moves = [((0, 0), (1, 0)), ((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2f00: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x4aa9, Score: 19600
Depth 4: State = 0x4aa9, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4aa9: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x48f7, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7335300, N[0x3c25, ((2, 3), (2, 4))] = 328
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x48f4, ((1, 3), (2, 3))] = 22400, N[0x48f4, ((1, 3), (2, 3))] = 1
Updated Q[0x2f00, ((0, 0), (1, 0))] = 22400, N[0x2f00, ((0, 0), (1, 0))] = 1
Updated Q[0x4aa9, ((1, 3), (2, 3))] = 22400, N[0x4aa9, ((1, 3), (2, 3))] = 1

--- Simulation 333 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.37313867771, 16803.37313867771, 22363.905762621045, 16803.37313867771, 19603.37313867771]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [25200.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bbc, Score: 8400
Depth 2: State = 0x3bbc, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbc: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3845, Score: 11200
Depth 3: State = 0x3845, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3845: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x2950, Score: 14000
Depth 4: State = 0x2950, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2950: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x293f, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7354900, N[0x3c25, ((2, 3), (2, 4))] = 329
Updated Q[0x3c25, ((0, 2), (1, 2))] = 19600, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3bbc, ((1, 3), (2, 3))] = 19600, N[0x3bbc, ((1, 3), (2, 3))] = 1
Updated Q[0x3845, ((0, 2), (1, 2))] = 19600, N[0x3845, ((0, 2), (1, 2))] = 1
Updated Q[0x2950, ((0, 1), (0, 2))] = 19600, N[0x2950, ((0, 1), (0, 2))] = 1

--- Simulation 334 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.374012341465, 16803.374012341465, 22355.50516425796, 16803.374012341465, 19603.374012341465]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 19601.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d77, Score: 11200
Depth 2: State = 0x3d77, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d77: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x567d, Score: 14000
Depth 3: State = 0x567d, Legal Moves = [((1, 2), (2, 2)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x567d: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x5103, Score: 16800
Depth 4: State = 0x5103, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x5103: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x52ec, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7374500, N[0x3c25, ((2, 3), (2, 4))] = 330
Updated Q[0x3c24, ((2, 0), (2, 1))] = 19600, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3d77, ((0, 0), (0, 1))] = 19600, N[0x3d77, ((0, 0), (0, 1))] = 1
Updated Q[0x567d, ((1, 2), (2, 2))] = 19600, N[0x567d, ((1, 2), (2, 2))] = 1
Updated Q[0x5103, ((0, 1), (0, 2))] = 19600, N[0x5103, ((0, 1), (0, 2))] = 1

--- Simulation 335 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.374883160384, 16803.374883160384, 22347.155478173252, 16803.374883160384, 19603.374883160384]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c3c, Score: 8400
Depth 1: State = 0x3c3c, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c3c: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x2180, Score: 11200
Depth 2: State = 0x2180, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2180: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x1ec9, Score: 16100
Depth 3: State = 0x1ec9, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1ec9: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x216f, Score: 18900
Depth 4: State = 0x216f, Legal Moves = [((3, 0), (3, 1))]
UCB1 values for moves at state 0x216f: [inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x22c2, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7396200, N[0x3c25, ((2, 3), (2, 4))] = 331
Updated Q[0x3c3c, ((0, 0), (1, 0))] = 21700, N[0x3c3c, ((0, 0), (1, 0))] = 1
Updated Q[0x2180, ((0, 3), (1, 3))] = 21700, N[0x2180, ((0, 3), (1, 3))] = 1
Updated Q[0x1ec9, ((2, 0), (2, 1))] = 21700, N[0x1ec9, ((2, 0), (2, 1))] = 1
Updated Q[0x216f, ((3, 0), (3, 1))] = 21700, N[0x216f, ((3, 0), (3, 1))] = 1

--- Simulation 336 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.375751152318, 16803.375751152318, 22345.20065380435, 16803.375751152318, 19603.375751152318]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c0a, Score: 8400
Depth 1: State = 0x3c0a, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c0a: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37e9, Score: 11200
Depth 2: State = 0x37e9, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37e9: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x37df, Score: 14000
Depth 3: State = 0x37df, Legal Moves = [((1, 4), (2, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37df: [inf, inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x37dd, Score: 27700
Depth 4: State = 0x37dd, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37dd: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x369b, Score: 33300
End of simulation with depth 5. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7429500, N[0x3c25, ((2, 3), (2, 4))] = 332
Updated Q[0x3c0a, ((1, 3), (2, 3))] = 33300, N[0x3c0a, ((1, 3), (2, 3))] = 1
Updated Q[0x37e9, ((0, 3), (1, 3))] = 33300, N[0x37e9, ((0, 3), (1, 3))] = 1
Updated Q[0x37df, ((1, 4), (2, 4))] = 33300, N[0x37df, ((1, 4), (2, 4))] = 1
Updated Q[0x37dd, ((1, 1), (2, 1))] = 33300, N[0x37dd, ((1, 1), (2, 1))] = 1

--- Simulation 337 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.37661633496, 16803.37661633496, 22378.197364089407, 16803.37661633496, 19603.37661633496]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [18900.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x36f4, Score: 11200
Depth 2: State = 0x36f4, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x36f4: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0xefc2, Score: 16800
Depth 3: State = 0xefc2, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0xefc2: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0xefc3, Score: 19600
Depth 4: State = 0xefc3, Legal Moves = [((3, 2), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0xefc3: [inf, inf]
Selected move: ((3, 2), (3, 3))
New board state after move: 0xef8c, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7451900, N[0x3c25, ((2, 3), (2, 4))] = 333
Updated Q[0x3c24, ((1, 3), (2, 3))] = 22400, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x36f4, ((0, 2), (1, 2))] = 22400, N[0x36f4, ((0, 2), (1, 2))] = 1
Updated Q[0xefc2, ((2, 0), (2, 1))] = 22400, N[0xefc2, ((2, 0), (2, 1))] = 1
Updated Q[0xefc3, ((3, 2), (3, 3))] = 22400, N[0xefc3, ((3, 2), (3, 3))] = 1

--- Simulation 338 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.377478725837, 16803.377478725837, 22378.263162772135, 16803.377478725837, 19603.377478725837]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c2b, Score: 11200
Depth 2: State = 0x3c2b, Legal Moves = [((0, 3), (1, 3)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c2b: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3bd6, Score: 14000
Depth 3: State = 0x3bd6, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bd6: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x37de, Score: 16800
Depth 4: State = 0x37de, Legal Moves = [((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x37de: [inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x3870, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7471500, N[0x3c25, ((2, 3), (2, 4))] = 334
Updated Q[0x3c25, ((1, 2), (2, 2))] = 19600, N[0x3c25, ((1, 2), (2, 2))] = 1
Updated Q[0x3c2b, ((0, 3), (1, 3))] = 19600, N[0x3c2b, ((0, 3), (1, 3))] = 1
Updated Q[0x3bd6, ((2, 0), (2, 1))] = 19600, N[0x3bd6, ((2, 0), (2, 1))] = 1
Updated Q[0x37de, ((2, 1), (2, 2))] = 19600, N[0x37de, ((2, 1), (2, 2))] = 1

--- Simulation 339 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.378338342314, 16803.378338342314, 22369.945333491498, 16803.378338342314, 19603.378338342314]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 19601.16557645562, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3c27, Score: 8400
Depth 2: State = 0x3c27, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c27: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x390f, Score: 11200
Depth 3: State = 0x390f, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x390f: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5430, Score: 24900
Depth 4: State = 0x5430, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5430: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x468e, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7502000, N[0x3c25, ((2, 3), (2, 4))] = 335
Updated Q[0x3c25, ((0, 3), (0, 4))] = 30500, N[0x3c25, ((0, 3), (0, 4))] = 1
Updated Q[0x3c27, ((1, 3), (2, 3))] = 30500, N[0x3c27, ((1, 3), (2, 3))] = 1
Updated Q[0x390f, ((1, 2), (1, 3))] = 30500, N[0x390f, ((1, 2), (1, 3))] = 1
Updated Q[0x5430, ((1, 1), (2, 1))] = 30500, N[0x5430, ((1, 1), (2, 1))] = 1

--- Simulation 340 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.379195201593, 16803.379195201593, 22394.214475902707, 16803.379195201593, 19603.379195201593]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [25200.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bbc, Score: 11200
Depth 2: State = 0x3bbc, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbc: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3671, Score: 14000
Depth 3: State = 0x3671, Legal Moves = [((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3671: [inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3c66, Score: 16800
Depth 4: State = 0x3c66, Legal Moves = [((2, 0), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c66: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2f2a, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7521600, N[0x3c25, ((2, 3), (2, 4))] = 336
Updated Q[0x3c24, ((1, 2), (2, 2))] = 19600, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3bbc, ((2, 0), (2, 1))] = 19600, N[0x3bbc, ((2, 0), (2, 1))] = 1
Updated Q[0x3671, ((1, 2), (1, 3))] = 19600, N[0x3671, ((1, 2), (1, 3))] = 1
Updated Q[0x3c66, ((2, 0), (2, 1))] = 19600, N[0x3c66, ((2, 0), (2, 1))] = 1

--- Simulation 341 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.380049320724, 16803.380049320724, 22385.898682522202, 16803.380049320724, 19603.380049320724]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x397e, Score: 11200
Depth 2: State = 0x397e, Legal Moves = [((0, 0), (0, 1)), ((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x397e: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x301f, Score: 14000
Depth 3: State = 0x301f, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x301f: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3017, Score: 16800
Depth 4: State = 0x3017, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3017: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x53dd, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7541200, N[0x3c25, ((2, 3), (2, 4))] = 337
Updated Q[0x3c24, ((1, 3), (1, 4))] = 19600, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x397e, ((0, 0), (0, 1))] = 19600, N[0x397e, ((0, 0), (0, 1))] = 1
Updated Q[0x301f, ((0, 3), (0, 4))] = 19600, N[0x301f, ((0, 3), (0, 4))] = 1
Updated Q[0x3017, ((0, 0), (0, 1))] = 19600, N[0x3017, ((0, 0), (0, 1))] = 1

--- Simulation 342 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.380900716595, 16803.380900716595, 22377.632240613995, 16803.380900716595, 19603.380900716595]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.77609073765, 19601.77609073765, 24501.77609073765, 22401.77609073765, 19601.77609073765]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d77, Score: 8400
Depth 2: State = 0x3d77, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d77: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x567a, Score: 11200
Depth 3: State = 0x567a, Legal Moves = [((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x567a: [inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x567a, Score: 14000
Depth 4: State = 0x567a, Legal Moves = [((0, 2), (0, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x567a: [inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x5692, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7560800, N[0x3c25, ((2, 3), (2, 4))] = 338
Updated Q[0x3c24, ((2, 0), (2, 1))] = 44100, N[0x3c24, ((2, 0), (2, 1))] = 2
Updated Q[0x3d77, ((0, 0), (0, 1))] = 19600, N[0x3d77, ((0, 0), (0, 1))] = 1
Updated Q[0x567a, ((2, 3), (3, 3))] = 19600, N[0x567a, ((2, 3), (3, 3))] = 1
Updated Q[0x567a, ((0, 2), (0, 3))] = 19600, N[0x567a, ((0, 2), (0, 3))] = 1

--- Simulation 343 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.38174940595, 16803.38174940595, 22369.414712149017, 16803.38174940595, 19603.38174940595]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [25201.16557645562, 19601.16557645562, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c40, Score: 8400
Depth 2: State = 0x3c40, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c40: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x12d3, Score: 11200
Depth 3: State = 0x12d3, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x12d3: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x484b, Score: 14000
Depth 4: State = 0x484b, Legal Moves = [((0, 2), (0, 3)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x484b: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x47af, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7577600, N[0x3c25, ((2, 3), (2, 4))] = 339
Updated Q[0x3c25, ((0, 4), (1, 4))] = 16800, N[0x3c25, ((0, 4), (1, 4))] = 1
Updated Q[0x3c40, ((0, 0), (1, 0))] = 16800, N[0x3c40, ((0, 0), (1, 0))] = 1
Updated Q[0x12d3, ((0, 0), (1, 0))] = 16800, N[0x12d3, ((0, 0), (1, 0))] = 1
Updated Q[0x484b, ((0, 2), (0, 3))] = 16800, N[0x484b, ((0, 2), (0, 3))] = 1

--- Simulation 344 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.382595405372, 16803.382595405372, 22352.986077246027, 16803.382595405372, 19603.382595405372]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3be0, Score: 11200
Depth 2: State = 0x3be0, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be0: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3a8d, Score: 14000
Depth 3: State = 0x3a8d, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((1, 1), (1, 2)), ((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3a8d: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x3aec, Score: 16800
Depth 4: State = 0x3aec, Legal Moves = [((0, 2), (1, 2)), ((1, 1), (1, 2)), ((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3aec: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x46d5, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7597200, N[0x3c25, ((2, 3), (2, 4))] = 340
Updated Q[0x3c25, ((1, 2), (2, 2))] = 19600, N[0x3c25, ((1, 2), (2, 2))] = 1
Updated Q[0x3be0, ((2, 0), (2, 1))] = 19600, N[0x3be0, ((2, 0), (2, 1))] = 1
Updated Q[0x3a8d, ((0, 2), (0, 3))] = 19600, N[0x3a8d, ((0, 2), (0, 3))] = 1
Updated Q[0x3aec, ((0, 2), (1, 2))] = 19600, N[0x3aec, ((0, 2), (1, 2))] = 1

--- Simulation 345 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.3834387313, 16803.3834387313, 22344.889375081188, 16803.3834387313, 19603.3834387313]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [25200.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c69, Score: 8400
Depth 2: State = 0x3c69, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c69: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3702, Score: 14000
Depth 3: State = 0x3702, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3702: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3064, Score: 16800
Depth 4: State = 0x3064, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3064: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1426, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7619600, N[0x3c25, ((2, 3), (2, 4))] = 341
Updated Q[0x3c25, ((0, 2), (1, 2))] = 22400, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3c69, ((1, 3), (2, 3))] = 22400, N[0x3c69, ((1, 3), (2, 3))] = 1
Updated Q[0x3702, ((0, 2), (1, 2))] = 22400, N[0x3702, ((0, 2), (1, 2))] = 1
Updated Q[0x3064, ((0, 2), (1, 2))] = 22400, N[0x3064, ((0, 2), (1, 2))] = 1

--- Simulation 346 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.384279400016, 16803.384279400016, 22345.05130419516, 16803.384279400016, 19603.384279400016]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.648374031523, 19601.648374031523, 16801.648374031523, 24501.648374031523, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c1a, Score: 8400
Depth 2: State = 0x3c1a, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1a: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c5e, Score: 11200
Depth 3: State = 0x3c5e, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5e: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3c64, Score: 16800
Depth 4: State = 0x3c64, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3c64: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3dbf, Score: 32100
End of simulation with depth 5. Reward (Score): 32100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7651700, N[0x3c25, ((2, 3), (2, 4))] = 342
Updated Q[0x3c24, ((2, 3), (3, 3))] = 32100, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x3c1a, ((0, 2), (1, 2))] = 32100, N[0x3c1a, ((0, 2), (1, 2))] = 1
Updated Q[0x3c5e, ((0, 3), (0, 4))] = 32100, N[0x3c5e, ((0, 3), (0, 4))] = 1
Updated Q[0x3c64, ((1, 2), (2, 2))] = 32100, N[0x3c64, ((1, 2), (2, 2))] = 1

--- Simulation 347 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.38511742767, 16803.38511742767, 22373.574859052103, 16803.38511742767, 19603.38511742767]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3977, Score: 11200
Depth 2: State = 0x3977, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3977: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3999, Score: 16800
Depth 3: State = 0x3999, Legal Moves = [((1, 0), (1, 1)), ((2, 1), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3999: [inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x3d0a, Score: 19600
Depth 4: State = 0x3d0a, Legal Moves = [((1, 3), (1, 4)), ((2, 3), (2, 4)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3d0a: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d0c, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7674100, N[0x3c25, ((2, 3), (2, 4))] = 343
Updated Q[0x3c24, ((1, 3), (2, 3))] = 22400, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3977, ((2, 0), (2, 1))] = 22400, N[0x3977, ((2, 0), (2, 1))] = 1
Updated Q[0x3999, ((1, 0), (1, 1))] = 22400, N[0x3999, ((1, 0), (1, 1))] = 1
Updated Q[0x3d0a, ((1, 3), (1, 4))] = 22400, N[0x3d0a, ((1, 3), (1, 4))] = 1

--- Simulation 348 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.385952830253, 16803.385952830253, 22373.652212023262, 16803.385952830253, 19603.385952830253]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c06, Score: 8400
Depth 1: State = 0x3c06, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c06: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37c7, Score: 11200
Depth 2: State = 0x37c7, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37c7: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x37c7, Score: 14000
Depth 3: State = 0x37c7, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37c7: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3674, Score: 16800
Depth 4: State = 0x3674, Legal Moves = [((0, 3), (1, 3)), ((2, 1), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3674: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3873, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7693700, N[0x3c25, ((2, 3), (2, 4))] = 344
Updated Q[0x3c06, ((1, 3), (2, 3))] = 19600, N[0x3c06, ((1, 3), (2, 3))] = 1
Updated Q[0x37c7, ((0, 3), (1, 3))] = 19600, N[0x37c7, ((0, 3), (1, 3))] = 1
Updated Q[0x37c7, ((2, 0), (2, 1))] = 19600, N[0x37c7, ((2, 0), (2, 1))] = 1
Updated Q[0x3674, ((0, 3), (1, 3))] = 19600, N[0x3674, ((0, 3), (1, 3))] = 1

--- Simulation 349 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.38678562362, 16803.38678562362, 22365.58957998721, 16803.38678562362, 19603.38678562362]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47c6, Score: 8400
Depth 2: State = 0x47c6, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c6: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x47c6, Score: 14000
Depth 3: State = 0x47c6, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c6: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x49a4, Score: 16800
Depth 4: State = 0x49a4, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x49a4: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4960, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7716100, N[0x3c25, ((2, 3), (2, 4))] = 345
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x47c6, ((0, 4), (1, 4))] = 22400, N[0x47c6, ((0, 4), (1, 4))] = 1
Updated Q[0x47c6, ((1, 3), (2, 3))] = 22400, N[0x47c6, ((1, 3), (2, 3))] = 1
Updated Q[0x49a4, ((0, 3), (1, 3))] = 22400, N[0x49a4, ((0, 3), (1, 3))] = 1

--- Simulation 350 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.387615823485, 16803.387615823485, 22365.68962948186, 16803.387615823485, 19603.387615823485]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c28, Score: 8400
Depth 2: State = 0x3c28, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c28: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3c4c, Score: 11200
Depth 3: State = 0x3c4c, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4c: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x57b2, Score: 14000
Depth 4: State = 0x57b2, Legal Moves = [((0, 2), (0, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x57b2: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x2b2c, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7732900, N[0x3c25, ((2, 3), (2, 4))] = 346
Updated Q[0x3c24, ((0, 2), (1, 2))] = 16800, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c28, ((0, 3), (1, 3))] = 16800, N[0x3c28, ((0, 3), (1, 3))] = 1
Updated Q[0x3c4c, ((0, 0), (1, 0))] = 16800, N[0x3c4c, ((0, 0), (1, 0))] = 1
Updated Q[0x57b2, ((0, 2), (0, 3))] = 16800, N[0x57b2, ((0, 2), (0, 3))] = 1

--- Simulation 351 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.388443445416, 16803.388443445416, 22349.60412916609, 16803.388443445416, 19603.388443445416]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c07, Score: 8400
Depth 1: State = 0x3c07, Legal Moves = [((0, 1), (0, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c07: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x391c, Score: 11200
Depth 2: State = 0x391c, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x391c: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x36d9, Score: 14000
Depth 3: State = 0x36d9, Legal Moves = [((0, 0), (0, 1)), ((0, 3), (1, 3)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d9: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x11a1, Score: 16800
Depth 4: State = 0x11a1, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x11a1: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0xefc3, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7752500, N[0x3c25, ((2, 3), (2, 4))] = 347
Updated Q[0x3c07, ((0, 1), (0, 2))] = 19600, N[0x3c07, ((0, 1), (0, 2))] = 1
Updated Q[0x391c, ((1, 3), (2, 3))] = 19600, N[0x391c, ((1, 3), (2, 3))] = 1
Updated Q[0x36d9, ((0, 0), (0, 1))] = 19600, N[0x36d9, ((0, 0), (0, 1))] = 1
Updated Q[0x11a1, ((1, 1), (2, 1))] = 19600, N[0x11a1, ((1, 1), (2, 1))] = 1

--- Simulation 352 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.389268504852, 16803.389268504852, 22341.680504544176, 16803.389268504852, 19603.389268504852]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [24901.467405903557, 25201.467405903557, 25201.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d78, Score: 8400
Depth 2: State = 0x3d78, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d78: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x563f, Score: 11200
Depth 3: State = 0x563f, Legal Moves = [((1, 2), (2, 2)), ((2, 2), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x563f: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x56a4, Score: 14000
Depth 4: State = 0x56a4, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x56a4: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x56d7, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7769300, N[0x3c25, ((2, 3), (2, 4))] = 348
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3d78, ((0, 0), (0, 1))] = 16800, N[0x3d78, ((0, 0), (0, 1))] = 1
Updated Q[0x563f, ((1, 2), (2, 2))] = 16800, N[0x563f, ((1, 2), (2, 2))] = 1
Updated Q[0x56a4, ((4, 1), (4, 2))] = 16800, N[0x56a4, ((4, 1), (4, 2))] = 1

--- Simulation 353 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.390091017092, 16803.390091017092, 22325.756440597364, 16803.390091017092, 19603.390091017092]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 16801.16557645562, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c47, Score: 8400
Depth 2: State = 0x3c47, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c47: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x48fb, Score: 14000
Depth 3: State = 0x48fb, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48fb: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x493e, Score: 19600
Depth 4: State = 0x493e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x493e: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x46c1, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7791700, N[0x3c25, ((2, 3), (2, 4))] = 349
Updated Q[0x3c24, ((0, 4), (1, 4))] = 22400, N[0x3c24, ((0, 4), (1, 4))] = 1
Updated Q[0x3c47, ((0, 0), (1, 0))] = 22400, N[0x3c47, ((0, 0), (1, 0))] = 1
Updated Q[0x48fb, ((1, 2), (2, 2))] = 22400, N[0x48fb, ((1, 2), (2, 2))] = 1
Updated Q[0x493e, ((1, 3), (2, 3))] = 22400, N[0x493e, ((1, 3), (2, 3))] = 1

--- Simulation 354 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.390910997296, 16803.390910997296, 22325.96947692026, 16803.390910997296, 19603.390910997296]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.467405903557, 44201.46740590355, 19601.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x12df, Score: 24900
Depth 2: State = 0x12df, Legal Moves = [((0, 3), (1, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x12df: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x1343, Score: 30500
Depth 3: State = 0x1343, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1343: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x133f, Score: 33300
Depth 4: State = 0x133f, Legal Moves = [((0, 2), (0, 3)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x133f: [inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x1316, Score: 38900
End of simulation with depth 5. Reward (Score): 38900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7830600, N[0x3c25, ((2, 3), (2, 4))] = 350
Updated Q[0x3c25, ((2, 0), (2, 1))] = 38900, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x12df, ((0, 3), (1, 3))] = 38900, N[0x12df, ((0, 3), (1, 3))] = 1
Updated Q[0x1343, ((1, 2), (2, 2))] = 38900, N[0x1343, ((1, 2), (2, 2))] = 1
Updated Q[0x133f, ((0, 2), (0, 3))] = 38900, N[0x133f, ((0, 2), (0, 3))] = 1

--- Simulation 355 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.391728460498, 16803.391728460498, 22373.324152654975, 16803.391728460498, 19603.391728460498]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [33301.16557645562, 29401.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4547, Score: 11200
Depth 2: State = 0x4547, Legal Moves = [((1, 0), (1, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4547: [inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x213d, Score: 25200
Depth 3: State = 0x213d, Legal Moves = [((3, 2), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x213d: [inf, inf]
Selected move: ((3, 2), (3, 3))
New board state after move: 0x2181, Score: 28000
Depth 4: State = 0x2181, Legal Moves = [((3, 1), (4, 1)), ((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2181: [inf, inf, inf]
Selected move: ((3, 1), (4, 1))
New board state after move: 0x36f2, Score: 30800
End of simulation with depth 5. Reward (Score): 30800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7861400, N[0x3c25, ((2, 3), (2, 4))] = 351
Updated Q[0x3c25, ((2, 0), (2, 1))] = 30800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x4547, ((1, 0), (1, 1))] = 30800, N[0x4547, ((1, 0), (1, 1))] = 1
Updated Q[0x213d, ((3, 2), (3, 3))] = 30800, N[0x213d, ((3, 2), (3, 3))] = 1
Updated Q[0x2181, ((3, 1), (4, 1))] = 30800, N[0x2181, ((3, 1), (4, 1))] = 1

--- Simulation 356 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.39254342159, 16803.39254342159, 22397.3320777226, 16803.39254342159, 19603.39254342159]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.95294236785, 27301.95294236785, 27701.95294236785, 28734.460865135123, 25201.95294236785]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c24, Score: 11200
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x452b, Score: 14000
Depth 3: State = 0x452b, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x452b: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x43cb, Score: 19600
Depth 4: State = 0x43cb, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43cb: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a47, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7883800, N[0x3c25, ((2, 3), (2, 4))] = 352
Updated Q[0x3c24, ((2, 3), (3, 3))] = 108600, N[0x3c24, ((2, 3), (3, 3))] = 4
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x452b, ((1, 3), (2, 3))] = 22400, N[0x452b, ((1, 3), (2, 3))] = 1
Updated Q[0x43cb, ((1, 3), (2, 3))] = 22400, N[0x43cb, ((1, 3), (2, 3))] = 1

--- Simulation 357 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.393355895343, 16803.393355895343, 22397.339957386026, 16803.393355895343, 19603.393355895343]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 25201.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0xee48, Score: 13300
Depth 2: State = 0xee48, Legal Moves = [((0, 2), (1, 2)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0xee48: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x43f6, Score: 18900
Depth 3: State = 0x43f6, Legal Moves = [((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x43f6: [inf, inf]
Selected move: ((2, 4), (3, 4))
New board state after move: 0x43f6, Score: 21700
Depth 4: State = 0x43f6, Legal Moves = [((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x43f6: [inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x43f3, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7908300, N[0x3c25, ((2, 3), (2, 4))] = 353
Updated Q[0x3c24, ((2, 0), (2, 1))] = 24500, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0xee48, ((0, 2), (1, 2))] = 24500, N[0xee48, ((0, 2), (1, 2))] = 1
Updated Q[0x43f6, ((2, 4), (3, 4))] = 24500, N[0x43f6, ((2, 4), (3, 4))] = 1
Updated Q[0x43f6, ((2, 3), (2, 4))] = 24500, N[0x43f6, ((2, 3), (2, 4))] = 1

--- Simulation 358 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.3941658964, 16803.3941658964, 22403.296800531218, 16803.3941658964, 19603.3941658964]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4af5, Score: 8400
Depth 2: State = 0x4af5, Legal Moves = [((0, 3), (0, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4af5: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x4412, Score: 11200
Depth 3: State = 0x4412, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4412: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x43b1, Score: 16800
Depth 4: State = 0x43b1, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43b1: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x43b1, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7927900, N[0x3c25, ((2, 3), (2, 4))] = 354
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4af5, ((0, 3), (0, 4))] = 19600, N[0x4af5, ((0, 3), (0, 4))] = 1
Updated Q[0x4412, ((1, 2), (2, 2))] = 19600, N[0x4412, ((1, 2), (2, 2))] = 1
Updated Q[0x43b1, ((0, 3), (1, 3))] = 19600, N[0x43b1, ((0, 3), (1, 3))] = 1

--- Simulation 359 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.39497343927, 16803.39497343927, 22395.37818091548, 16803.39497343927, 19603.39497343927]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [30000.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x1ff4, Score: 19300
Depth 2: State = 0x1ff4, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x1ff4: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x1ff4, Score: 27000
Depth 3: State = 0x1ff4, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1ff4: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1f0a, Score: 29800
Depth 4: State = 0x1f0a, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1f0a: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x21af, Score: 32600
End of simulation with depth 5. Reward (Score): 32600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7960500, N[0x3c25, ((2, 3), (2, 4))] = 355
Updated Q[0x3c25, ((1, 3), (1, 4))] = 32600, N[0x3c25, ((1, 3), (1, 4))] = 1
Updated Q[0x1ff4, ((0, 2), (0, 3))] = 32600, N[0x1ff4, ((0, 2), (0, 3))] = 1
Updated Q[0x1ff4, ((0, 2), (1, 2))] = 32600, N[0x1ff4, ((0, 2), (1, 2))] = 1
Updated Q[0x1f0a, ((2, 0), (2, 1))] = 32600, N[0x1f0a, ((2, 0), (2, 1))] = 1

--- Simulation 360 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.39577853834, 16803.39577853834, 22424.12389118334, 16803.39577853834, 19603.39577853834]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22401.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x231e, Score: 13300
Depth 2: State = 0x231e, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x231e: [inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x231e, Score: 16100
Depth 3: State = 0x231e, Legal Moves = [((2, 0), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x231e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2079, Score: 18900
Depth 4: State = 0x2079, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2079: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2b0f, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 7982200, N[0x3c25, ((2, 3), (2, 4))] = 356
Updated Q[0x3c25, ((2, 0), (2, 1))] = 21700, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x231e, ((1, 0), (1, 1))] = 21700, N[0x231e, ((1, 0), (1, 1))] = 1
Updated Q[0x231e, ((2, 0), (2, 1))] = 21700, N[0x231e, ((2, 0), (2, 1))] = 1
Updated Q[0x2079, ((0, 0), (0, 1))] = 21700, N[0x2079, ((0, 0), (0, 1))] = 1

--- Simulation 361 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.396581207868, 16803.396581207868, 22422.09013080353, 16803.396581207868, 19603.396581207868]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x455e, Score: 8400
Depth 2: State = 0x455e, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x455e: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4901, Score: 14000
Depth 3: State = 0x4901, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4901: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x443e, Score: 16800
Depth 4: State = 0x443e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x443e, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8001800, N[0x3c25, ((2, 3), (2, 4))] = 357
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x455e, ((0, 2), (1, 2))] = 19600, N[0x455e, ((0, 2), (1, 2))] = 1
Updated Q[0x4901, ((0, 1), (1, 1))] = 19600, N[0x4901, ((0, 1), (1, 1))] = 1
Updated Q[0x443e, ((2, 0), (2, 1))] = 19600, N[0x443e, ((2, 0), (2, 1))] = 1

--- Simulation 362 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.397381462, 16803.397381462, 22414.18541073534, 16803.397381462, 19603.397381462]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c21, Score: 14000
Depth 2: State = 0x3c21, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c21: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d8f, Score: 16800
Depth 3: State = 0x3d8f, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d8f: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x551d, Score: 19600
Depth 4: State = 0x551d, Legal Moves = [((0, 1), (1, 1)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x551d: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x1422, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8024200, N[0x3c25, ((2, 3), (2, 4))] = 358
Updated Q[0x3c24, ((0, 2), (1, 2))] = 22400, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c21, ((1, 3), (2, 3))] = 22400, N[0x3c21, ((1, 3), (2, 3))] = 1
Updated Q[0x3d8f, ((0, 2), (1, 2))] = 22400, N[0x3d8f, ((0, 2), (1, 2))] = 1
Updated Q[0x551d, ((0, 1), (1, 1))] = 22400, N[0x551d, ((0, 1), (1, 1))] = 1

--- Simulation 363 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.398179314747, 16803.398179314747, 22414.1460798044, 16803.398179314747, 19603.398179314747]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x36d8, Score: 19300
Depth 2: State = 0x36d8, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d8: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x11cd, Score: 22100
Depth 3: State = 0x11cd, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x11cd: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x2c89, Score: 30500
Depth 4: State = 0x2c89, Legal Moves = [((2, 3), (2, 4)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2c89: [inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x2c7b, Score: 33300
End of simulation with depth 5. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8057500, N[0x3c25, ((2, 3), (2, 4))] = 359
Updated Q[0x3c24, ((1, 2), (2, 2))] = 33300, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x36d8, ((0, 0), (0, 1))] = 33300, N[0x36d8, ((0, 0), (0, 1))] = 1
Updated Q[0x11cd, ((2, 0), (2, 1))] = 33300, N[0x11cd, ((2, 0), (2, 1))] = 1
Updated Q[0x2c89, ((2, 3), (2, 4))] = 33300, N[0x2c89, ((2, 3), (2, 4))] = 1

--- Simulation 364 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.39897478001, 16803.39897478001, 22444.46908462102, 16803.39897478001, 19603.39897478001]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.467405903557, 30501.467405903557, 22401.467405903557, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c2c, Score: 10500
Depth 2: State = 0x3c2c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c2c: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c5e, Score: 24200
Depth 3: State = 0x3c5e, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5e: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3c5f, Score: 27000
Depth 4: State = 0x3c5f, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3c5f: [inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x3bb5, Score: 29800
End of simulation with depth 5. Reward (Score): 29800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8087300, N[0x3c25, ((2, 3), (2, 4))] = 360
Updated Q[0x3c25, ((2, 3), (2, 4))] = 29800, N[0x3c25, ((2, 3), (2, 4))] = 1
Updated Q[0x3c2c, ((1, 2), (2, 2))] = 29800, N[0x3c2c, ((1, 2), (2, 2))] = 1
Updated Q[0x3c5e, ((1, 3), (1, 4))] = 29800, N[0x3c5e, ((1, 3), (1, 4))] = 1
Updated Q[0x3c5f, ((0, 2), (0, 3))] = 29800, N[0x3c5f, ((0, 2), (0, 3))] = 1

--- Simulation 365 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.39976787157, 16803.39976787157, 22464.901405722056, 16803.39976787157, 19603.39976787157]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4836, Score: 8400
Depth 2: State = 0x4836, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4836: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x493e, Score: 14000
Depth 3: State = 0x493e, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x493e: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x4a91, Score: 19600
Depth 4: State = 0x4a91, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a91: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4a8a, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8109700, N[0x3c25, ((2, 3), (2, 4))] = 361
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4836, ((1, 3), (2, 3))] = 22400, N[0x4836, ((1, 3), (2, 3))] = 1
Updated Q[0x493e, ((0, 1), (1, 1))] = 22400, N[0x493e, ((0, 1), (1, 1))] = 1
Updated Q[0x4a91, ((0, 3), (1, 3))] = 22400, N[0x4a91, ((0, 3), (1, 3))] = 1

--- Simulation 366 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.400558603087, 16803.400558603087, 22464.721913056674, 16803.400558603087, 19603.400558603087]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x455e, Score: 8400
Depth 2: State = 0x455e, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x455e: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x47f3, Score: 11200
Depth 3: State = 0x47f3, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47f3: [inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x4a73, Score: 14000
Depth 4: State = 0x4a73, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a73: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4855, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8126500, N[0x3c25, ((2, 3), (2, 4))] = 362
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x455e, ((0, 3), (1, 3))] = 16800, N[0x455e, ((0, 3), (1, 3))] = 1
Updated Q[0x47f3, ((0, 1), (1, 1))] = 16800, N[0x47f3, ((0, 1), (1, 1))] = 1
Updated Q[0x4a73, ((0, 1), (0, 2))] = 16800, N[0x4a73, ((0, 1), (0, 2))] = 1

--- Simulation 367 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.401346988103, 16803.401346988103, 22449.07379845305, 16803.401346988103, 19603.401346988103]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4673, Score: 19300
Depth 2: State = 0x4673, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4673: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3db7, Score: 24900
Depth 3: State = 0x3db7, Legal Moves = [((0, 2), (1, 2))]
UCB1 values for moves at state 0x3db7: [inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x56ba, Score: 30500
Depth 4: State = 0x56ba, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8157000, N[0x3c25, ((2, 3), (2, 4))] = 363
Updated Q[0x3c25, ((1, 3), (1, 4))] = 30500, N[0x3c25, ((1, 3), (1, 4))] = 1
Updated Q[0x4673, ((2, 0), (2, 1))] = 30500, N[0x4673, ((2, 0), (2, 1))] = 1
Updated Q[0x3db7, ((0, 2), (1, 2))] = 30500, N[0x3db7, ((0, 2), (1, 2))] = 1

--- Simulation 368 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.402133040046, 16803.402133040046, 22471.252945840424, 16803.402133040046, 19603.402133040046]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c1f, Score: 8400
Depth 1: State = 0x3c1f, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1f: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37f0, Score: 11200
Depth 2: State = 0x37f0, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37f0: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3a92, Score: 14000
Depth 3: State = 0x3a92, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3a92: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x2dde, Score: 16800
Depth 4: State = 0x2dde, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2dde: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x2dad, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8179400, N[0x3c25, ((2, 3), (2, 4))] = 364
Updated Q[0x3c1f, ((1, 3), (2, 3))] = 22400, N[0x3c1f, ((1, 3), (2, 3))] = 1
Updated Q[0x37f0, ((0, 3), (1, 3))] = 22400, N[0x37f0, ((0, 3), (1, 3))] = 1
Updated Q[0x3a92, ((0, 2), (1, 2))] = 22400, N[0x3a92, ((0, 2), (1, 2))] = 1
Updated Q[0x2dde, ((0, 3), (1, 3))] = 22400, N[0x2dde, ((0, 3), (1, 3))] = 1

--- Simulation 369 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.402916772244, 16803.402916772244, 22471.05748218177, 16803.402916772244, 19603.402916772244]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x47b0, Score: 8400
Depth 2: State = 0x47b0, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47b0: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x491d, Score: 14000
Depth 3: State = 0x491d, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x491d: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4920, Score: 16800
Depth 4: State = 0x4920, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4920: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x5129, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8199000, N[0x3c25, ((2, 3), (2, 4))] = 365
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x47b0, ((1, 2), (2, 2))] = 19600, N[0x47b0, ((1, 2), (2, 2))] = 1
Updated Q[0x491d, ((0, 3), (1, 3))] = 19600, N[0x491d, ((0, 3), (1, 3))] = 1
Updated Q[0x4920, ((0, 2), (0, 3))] = 19600, N[0x4920, ((0, 2), (0, 3))] = 1

--- Simulation 370 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.40369819789, 16803.40369819789, 22463.191856336343, 16803.40369819789, 19603.40369819789]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [30500.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3956, Score: 11200
Depth 2: State = 0x3956, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3956: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x1335, Score: 21700
Depth 3: State = 0x1335, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1335: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x564e, Score: 24500
Depth 4: State = 0x564e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x564e: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x5658, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8226300, N[0x3c25, ((2, 3), (2, 4))] = 366
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27300, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3956, ((0, 3), (0, 4))] = 27300, N[0x3956, ((0, 3), (0, 4))] = 1
Updated Q[0x1335, ((0, 2), (1, 2))] = 27300, N[0x1335, ((0, 2), (1, 2))] = 1
Updated Q[0x564e, ((1, 3), (2, 3))] = 27300, N[0x564e, ((1, 3), (2, 3))] = 1

--- Simulation 371 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.404477330085, 16803.404477330085, 22476.4074630775, 16803.404477330085, 19603.404477330085]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc2, Score: 8400
Depth 1: State = 0x3bc2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc2: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3869, Score: 11200
Depth 2: State = 0x3869, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3869: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x1317, Score: 14000
Depth 3: State = 0x1317, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1317: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x43ed, Score: 16800
Depth 4: State = 0x43ed, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43ed: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x43f4, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8245900, N[0x3c25, ((2, 3), (2, 4))] = 367
Updated Q[0x3bc2, ((1, 3), (2, 3))] = 19600, N[0x3bc2, ((1, 3), (2, 3))] = 1
Updated Q[0x3869, ((1, 2), (1, 3))] = 19600, N[0x3869, ((1, 2), (1, 3))] = 1
Updated Q[0x1317, ((0, 0), (1, 0))] = 19600, N[0x1317, ((0, 0), (1, 0))] = 1
Updated Q[0x43ed, ((1, 3), (1, 4))] = 19600, N[0x43ed, ((1, 3), (1, 4))] = 1

--- Simulation 372 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.405254181806, 16803.405254181806, 22468.570123393598, 16803.405254181806, 19603.405254181806]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 19601.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3ae9, Score: 11200
Depth 2: State = 0x3ae9, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3ae9: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x12cf, Score: 21700
Depth 3: State = 0x12cf, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x12cf: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x12d0, Score: 24500
Depth 4: State = 0x12d0, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x12d0: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x102b, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8273200, N[0x3c25, ((2, 3), (2, 4))] = 368
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27300, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3ae9, ((0, 1), (1, 1))] = 27300, N[0x3ae9, ((0, 1), (1, 1))] = 1
Updated Q[0x12cf, ((1, 3), (1, 4))] = 27300, N[0x12cf, ((1, 3), (1, 4))] = 1
Updated Q[0x12d0, ((2, 0), (2, 1))] = 27300, N[0x12d0, ((2, 0), (2, 1))] = 1

--- Simulation 373 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.406028765934, 16803.406028765934, 22481.699290653534, 16803.406028765934, 19603.406028765934]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.467405903557, 27301.467405903557, 19601.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c1e, Score: 8400
Depth 2: State = 0x3c1e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1e: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3979, Score: 11200
Depth 3: State = 0x3979, Legal Moves = [((0, 1), (1, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3979: [inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x100c, Score: 14000
Depth 4: State = 0x100c, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x100c: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x1099, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8290000, N[0x3c25, ((2, 3), (2, 4))] = 369
Updated Q[0x3c25, ((2, 3), (3, 3))] = 16800, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3c1e, ((2, 0), (2, 1))] = 16800, N[0x3c1e, ((2, 0), (2, 1))] = 1
Updated Q[0x3979, ((0, 1), (1, 1))] = 16800, N[0x3979, ((0, 1), (1, 1))] = 1
Updated Q[0x100c, ((4, 1), (4, 2))] = 16800, N[0x100c, ((4, 1), (4, 2))] = 1

--- Simulation 374 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.406801095236, 16803.406801095236, 22466.30201222763, 16803.406801095236, 19603.406801095236]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4ab4, Score: 8400
Depth 2: State = 0x4ab4, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab4: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4925, Score: 14000
Depth 3: State = 0x4925, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4925: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4a77, Score: 16800
Depth 4: State = 0x4a77, Legal Moves = [((0, 1), (0, 2)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((3, 1), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4a77: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4592, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8309600, N[0x3c25, ((2, 3), (2, 4))] = 370
Updated Q[0x3c25, ((0, 0), (0, 1))] = 19600, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4ab4, ((1, 3), (2, 3))] = 19600, N[0x4ab4, ((1, 3), (2, 3))] = 1
Updated Q[0x4925, ((2, 0), (2, 1))] = 19600, N[0x4925, ((2, 0), (2, 1))] = 1
Updated Q[0x4a77, ((0, 1), (0, 2))] = 19600, N[0x4a77, ((0, 1), (0, 2))] = 1

--- Simulation 375 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.40757118237, 16803.40757118237, 22458.55552956868, 16803.40757118237, 19603.40757118237]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x46c2, Score: 8400
Depth 2: State = 0x46c2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46c2: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4815, Score: 11200
Depth 3: State = 0x4815, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4815: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4968, Score: 14000
Depth 4: State = 0x4968, Legal Moves = [((1, 2), (1, 3)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4968: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4965, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8326400, N[0x3c25, ((2, 3), (2, 4))] = 371
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x46c2, ((1, 3), (2, 3))] = 16800, N[0x46c2, ((1, 3), (2, 3))] = 1
Updated Q[0x4815, ((1, 1), (2, 1))] = 16800, N[0x4815, ((1, 1), (2, 1))] = 1
Updated Q[0x4968, ((1, 2), (1, 3))] = 16800, N[0x4968, ((1, 2), (1, 3))] = 1

--- Simulation 376 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.4083390399, 16803.4083390399, 22443.30363678226, 16803.4083390399, 19603.4083390399]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 8400
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x493c, Score: 14000
Depth 2: State = 0x493c, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x493c: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x43ea, Score: 16800
Depth 3: State = 0x43ea, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x43ea: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x453d, Score: 19600
Depth 4: State = 0x453d, Legal Moves = [((3, 3), (3, 4))]
UCB1 values for moves at state 0x453d: [inf]
Selected move: ((3, 3), (3, 4))
New board state after move: 0x453d, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8348800, N[0x3c25, ((2, 3), (2, 4))] = 372
Updated Q[0x3c25, ((0, 0), (0, 1))] = 22400, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x493c, ((1, 3), (1, 4))] = 22400, N[0x493c, ((1, 3), (1, 4))] = 1
Updated Q[0x43ea, ((2, 0), (2, 1))] = 22400, N[0x43ea, ((2, 0), (2, 1))] = 1
Updated Q[0x453d, ((3, 3), (3, 4))] = 22400, N[0x453d, ((3, 3), (3, 4))] = 1

--- Simulation 377 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.40910468027, 16803.40910468027, 22443.18750653196, 16803.40910468027, 19603.40910468027]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [25201.467405903557, 19601.467405903557, 16801.467405903557, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x386f, Score: 27700
Depth 2: State = 0x386f, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x386f: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x386f, Score: 30500
Depth 3: State = 0x386f, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x386f: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x36bd, Score: 38200
Depth 4: State = 0x36bd, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36bd: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d11, Score: 43800
End of simulation with depth 5. Reward (Score): 43800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8392600, N[0x3c25, ((2, 3), (2, 4))] = 373
Updated Q[0x3c25, ((1, 3), (2, 3))] = 43800, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x386f, ((0, 4), (1, 4))] = 43800, N[0x386f, ((0, 4), (1, 4))] = 1
Updated Q[0x386f, ((1, 3), (2, 3))] = 43800, N[0x386f, ((1, 3), (2, 3))] = 1
Updated Q[0x36bd, ((2, 0), (2, 1))] = 43800, N[0x36bd, ((2, 0), (2, 1))] = 1

--- Simulation 378 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.409868115836, 16803.409868115836, 22500.44465279326, 16803.409868115836, 19603.409868115836]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x493e, Score: 8400
Depth 2: State = 0x493e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x493e: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x49aa, Score: 14000
Depth 3: State = 0x49aa, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x49aa: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x48f7, Score: 19600
Depth 4: State = 0x48f7, Legal Moves = [((0, 3), (0, 4)), ((0, 3), (1, 3)), ((3, 2), (4, 2)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x48f7: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x48f1, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8415000, N[0x3c25, ((2, 3), (2, 4))] = 374
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x493e, ((1, 3), (2, 3))] = 22400, N[0x493e, ((1, 3), (2, 3))] = 1
Updated Q[0x49aa, ((2, 0), (2, 1))] = 22400, N[0x49aa, ((2, 0), (2, 1))] = 1
Updated Q[0x48f7, ((0, 3), (0, 4))] = 22400, N[0x48f7, ((0, 3), (0, 4))] = 1

--- Simulation 379 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.410629358845, 16803.410629358845, 22500.17635944566, 16803.410629358845, 19603.410629358845]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bbc, Score: 8400
Depth 1: State = 0x3bbc, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbc: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3d74, Score: 11200
Depth 2: State = 0x3d74, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d74: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397c, Score: 14000
Depth 3: State = 0x397c, Legal Moves = [((1, 3), (2, 3))]
UCB1 values for moves at state 0x397c: [inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3953, Score: 16800
Depth 4: State = 0x3953, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((0, 3), (1, 3))]
UCB1 values for moves at state 0x3953: [inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x390f, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8434600, N[0x3c25, ((2, 3), (2, 4))] = 375
Updated Q[0x3bbc, ((1, 3), (1, 4))] = 19600, N[0x3bbc, ((1, 3), (1, 4))] = 1
Updated Q[0x3d74, ((2, 0), (2, 1))] = 19600, N[0x3d74, ((2, 0), (2, 1))] = 1
Updated Q[0x397c, ((1, 3), (2, 3))] = 19600, N[0x397c, ((1, 3), (2, 3))] = 1
Updated Q[0x3953, ((0, 2), (0, 3))] = 19600, N[0x3953, ((0, 2), (0, 3))] = 1

--- Simulation 380 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.411388421442, 16803.411388421442, 22492.44283000725, 16803.411388421442, 19603.411388421442]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22401.467405903557, 19601.467405903557, 16801.467405903557, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3ab7, Score: 13300
Depth 2: State = 0x3ab7, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3ab7: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1216, Score: 16100
Depth 3: State = 0x1216, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1216: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x1074, Score: 21000
Depth 4: State = 0x1074, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x1074: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x2ef0, Score: 39500
End of simulation with depth 5. Reward (Score): 39500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8474100, N[0x3c25, ((2, 3), (2, 4))] = 376
Updated Q[0x3c25, ((2, 3), (2, 4))] = 39500, N[0x3c25, ((2, 3), (2, 4))] = 1
Updated Q[0x3ab7, ((0, 2), (1, 2))] = 39500, N[0x3ab7, ((0, 2), (1, 2))] = 1
Updated Q[0x1216, ((1, 3), (2, 3))] = 39500, N[0x1216, ((1, 3), (2, 3))] = 1
Updated Q[0x1074, ((1, 1), (2, 1))] = 39500, N[0x1074, ((1, 1), (2, 1))] = 1

--- Simulation 381 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.41214531568, 16803.41214531568, 22537.675967958698, 16803.41214531568, 19603.41214531568]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [21700.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37bc, Score: 11200
Depth 2: State = 0x37bc, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37bc: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3a65, Score: 14000
Depth 3: State = 0x3a65, Legal Moves = [((0, 2), (0, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x3a65: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x3a83, Score: 16800
Depth 4: State = 0x3a83, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3a83: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x37de, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8493700, N[0x3c25, ((2, 3), (2, 4))] = 377
Updated Q[0x3c24, ((1, 3), (2, 3))] = 19600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x37bc, ((1, 3), (2, 3))] = 19600, N[0x37bc, ((1, 3), (2, 3))] = 1
Updated Q[0x3a65, ((0, 2), (0, 3))] = 19600, N[0x3a65, ((0, 2), (0, 3))] = 1
Updated Q[0x3a83, ((2, 0), (2, 1))] = 19600, N[0x3a83, ((2, 0), (2, 1))] = 1

--- Simulation 382 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.41290005351, 16803.41290005351, 22529.88399610712, 16803.41290005351, 19603.41290005351]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 30501.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x367a, Score: 13300
Depth 2: State = 0x367a, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x367a: [inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x366d, Score: 16100
Depth 3: State = 0x366d, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x366d: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3692, Score: 18900
Depth 4: State = 0x3692, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3692: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x523b, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8518200, N[0x3c25, ((2, 3), (2, 4))] = 378
Updated Q[0x3c25, ((1, 3), (2, 3))] = 24500, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x367a, ((0, 3), (0, 4))] = 24500, N[0x367a, ((0, 3), (0, 4))] = 1
Updated Q[0x366d, ((1, 3), (2, 3))] = 24500, N[0x366d, ((1, 3), (2, 3))] = 1
Updated Q[0x3692, ((1, 2), (1, 3))] = 24500, N[0x3692, ((1, 2), (1, 3))] = 1

--- Simulation 383 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.41365264678, 16803.41365264678, 22535.09621426697, 16803.41365264678, 19603.41365264678]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [27201.467405903557, 16801.467405903557, 16801.467405903557, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c29, Score: 13300
Depth 2: State = 0x3c29, Legal Moves = [((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c29: [inf, inf, inf]
Selected move: ((1, 4), (2, 4))
New board state after move: 0x3c62, Score: 16100
Depth 3: State = 0x3c62, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c62: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x386a, Score: 18900
Depth 4: State = 0x386a, Legal Moves = [((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x386a: [inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2162, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8545500, N[0x3c25, ((2, 3), (2, 4))] = 379
Updated Q[0x3c24, ((1, 2), (2, 2))] = 27300, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3c29, ((1, 4), (2, 4))] = 27300, N[0x3c29, ((1, 4), (2, 4))] = 1
Updated Q[0x3c62, ((2, 0), (2, 1))] = 27300, N[0x3c62, ((2, 0), (2, 1))] = 1
Updated Q[0x386a, ((1, 2), (1, 3))] = 27300, N[0x386a, ((1, 2), (1, 3))] = 1

--- Simulation 384 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.41440310725, 16803.41440310725, 22547.668789800813, 16803.41440310725, 19603.41440310725]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 35001.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d4c, Score: 16100
Depth 2: State = 0x3d4c, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d4c: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x48f2, Score: 21700
Depth 3: State = 0x48f2, Legal Moves = [((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x48f2: [inf, inf]
Selected move: ((3, 1), (3, 2))
New board state after move: 0x4a44, Score: 27300
Depth 4: State = 0x4a44, Legal Moves = [((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4a44: [inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2d27, Score: 35700
End of simulation with depth 5. Reward (Score): 35700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8581200, N[0x3c25, ((2, 3), (2, 4))] = 380
Updated Q[0x3c25, ((2, 0), (2, 1))] = 35700, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3d4c, ((1, 1), (2, 1))] = 35700, N[0x3d4c, ((1, 1), (2, 1))] = 1
Updated Q[0x48f2, ((3, 1), (3, 2))] = 35700, N[0x48f2, ((3, 1), (3, 2))] = 1
Updated Q[0x4a44, ((1, 2), (1, 3))] = 35700, N[0x4a44, ((1, 2), (1, 3))] = 1

--- Simulation 385 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.415151446578, 16803.415151446578, 22582.280456730557, 16803.415151446578, 19603.415151446578]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22400.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c24, Score: 8400
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4ad8, Score: 11200
Depth 3: State = 0x4ad8, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x4ad8: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x5267, Score: 14000
Depth 4: State = 0x5267, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x5267: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x516f, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8598000, N[0x3c25, ((2, 3), (2, 4))] = 381
Updated Q[0x3c24, ((0, 4), (1, 4))] = 16800, N[0x3c24, ((0, 4), (1, 4))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4ad8, ((0, 0), (0, 1))] = 16800, N[0x4ad8, ((0, 0), (0, 1))] = 1
Updated Q[0x5267, ((1, 3), (2, 3))] = 16800, N[0x5267, ((1, 3), (2, 3))] = 1

--- Simulation 386 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.415897676336, 16803.415897676336, 22567.104135597554, 16803.415897676336, 19603.415897676336]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c64, Score: 14000
Depth 2: State = 0x3c64, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c64: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x39bf, Score: 16800
Depth 3: State = 0x39bf, Legal Moves = [((0, 1), (0, 2)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x39bf: [inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3d33, Score: 30500
Depth 4: State = 0x3d33, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8628500, N[0x3c25, ((2, 3), (2, 4))] = 382
Updated Q[0x3c24, ((1, 3), (2, 3))] = 30500, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3c64, ((2, 0), (2, 1))] = 30500, N[0x3c64, ((2, 0), (2, 1))] = 1
Updated Q[0x39bf, ((0, 1), (0, 2))] = 30500, N[0x39bf, ((0, 1), (0, 2))] = 1

--- Simulation 387 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.416641808, 16803.416641808, 22587.871145680936, 16803.416641808, 19603.416641808]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [27201.648374031523, 16801.648374031523, 16801.648374031523, 27301.648374031523, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3aa7, Score: 16000
Depth 2: State = 0x3aa7, Legal Moves = [((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3aa7: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x3ab6, Score: 18800
Depth 3: State = 0x3ab6, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3ab6: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d5c, Score: 21600
Depth 4: State = 0x3d5c, Legal Moves = [((0, 2), (1, 2))]
UCB1 values for moves at state 0x3d5c: [inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x57ec, Score: 27200
End of simulation with depth 5. Reward (Score): 27200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8655700, N[0x3c25, ((2, 3), (2, 4))] = 383
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27200, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3aa7, ((0, 3), (0, 4))] = 27200, N[0x3aa7, ((0, 3), (0, 4))] = 1
Updated Q[0x3ab6, ((2, 0), (2, 1))] = 27200, N[0x3ab6, ((2, 0), (2, 1))] = 1
Updated Q[0x3d5c, ((0, 2), (1, 2))] = 27200, N[0x3d5c, ((0, 2), (1, 2))] = 1

--- Simulation 388 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.417383852942, 16803.417383852942, 22599.91352355195, 16803.417383852942, 19603.417383852942]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.648374031523, 30501.648374031523, 22401.648374031523, 29801.648374031523, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c1e, Score: 8400
Depth 2: State = 0x3c1e, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3c1e: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d71, Score: 11200
Depth 3: State = 0x3d71, Legal Moves = [((1, 1), (2, 1)), ((3, 0), (3, 1)), ((3, 2), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d71: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x4808, Score: 14000
Depth 4: State = 0x4808, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (1, 1)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4808: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x1c5b, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8672500, N[0x3c25, ((2, 3), (2, 4))] = 384
Updated Q[0x3c25, ((2, 3), (3, 3))] = 16800, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3c1e, ((2, 0), (2, 1))] = 16800, N[0x3c1e, ((2, 0), (2, 1))] = 1
Updated Q[0x3d71, ((1, 1), (2, 1))] = 16800, N[0x3d71, ((1, 1), (2, 1))] = 1
Updated Q[0x4808, ((0, 0), (1, 0))] = 16800, N[0x4808, ((0, 0), (1, 0))] = 1

--- Simulation 389 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.41812382246, 16803.41812382246, 22584.809847067558, 16803.41812382246, 19603.41812382246]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c02, Score: 8400
Depth 1: State = 0x3c02, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c02: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3c46, Score: 11200
Depth 2: State = 0x3c46, Legal Moves = [((0, 0), (1, 0)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c46: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x1dd5, Score: 14000
Depth 3: State = 0x1dd5, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1dd5: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1c82, Score: 16800
Depth 4: State = 0x1c82, Legal Moves = [((0, 1), (0, 2)), ((2, 1), (3, 1)), ((2, 3), (3, 3)), ((3, 1), (4, 1))]
UCB1 values for moves at state 0x1c82: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x1ea0, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8692100, N[0x3c25, ((2, 3), (2, 4))] = 385
Updated Q[0x3c02, ((1, 3), (1, 4))] = 19600, N[0x3c02, ((1, 3), (1, 4))] = 1
Updated Q[0x3c46, ((0, 0), (1, 0))] = 19600, N[0x3c46, ((0, 0), (1, 0))] = 1
Updated Q[0x1dd5, ((2, 0), (2, 1))] = 19600, N[0x1dd5, ((2, 0), (2, 1))] = 1
Updated Q[0x1c82, ((0, 1), (0, 2))] = 19600, N[0x1c82, ((0, 1), (0, 2))] = 1

--- Simulation 390 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.418861727754, 16803.418861727754, 22577.057358210863, 16803.418861727754, 19603.418861727754]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [21700.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x368f, Score: 11200
Depth 2: State = 0x368f, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x368f: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d2d, Score: 14000
Depth 3: State = 0x3d2d, Legal Moves = [((1, 1), (2, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3d2d: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x39bf, Score: 16800
Depth 4: State = 0x39bf, Legal Moves = [((0, 1), (0, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((1, 4), (2, 4)), ((3, 1), (3, 2)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x39bf: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3d50, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8719800, N[0x3c25, ((2, 3), (2, 4))] = 386
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27700, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x368f, ((2, 0), (2, 1))] = 27700, N[0x368f, ((2, 0), (2, 1))] = 1
Updated Q[0x3d2d, ((1, 1), (2, 1))] = 27700, N[0x3d2d, ((1, 1), (2, 1))] = 1
Updated Q[0x39bf, ((0, 1), (0, 2))] = 27700, N[0x39bf, ((0, 1), (0, 2))] = 1

--- Simulation 391 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.419597579934, 16803.419597579934, 22590.32949334857, 16803.419597579934, 19603.419597579934]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bfc, Score: 11200
Depth 1: State = 0x3bfc, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bfc: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3919, Score: 14000
Depth 2: State = 0x3919, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3919: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3919, Score: 16800
Depth 3: State = 0x3919, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3919: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3919, Score: 19600
Depth 4: State = 0x3919, Legal Moves = [((1, 1), (2, 1)), ((2, 2), (3, 2))]
UCB1 values for moves at state 0x3919: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x53f7, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8742200, N[0x3c25, ((2, 3), (2, 4))] = 387
Updated Q[0x3bfc, ((1, 3), (2, 3))] = 22400, N[0x3bfc, ((1, 3), (2, 3))] = 1
Updated Q[0x3919, ((0, 3), (1, 3))] = 22400, N[0x3919, ((0, 3), (1, 3))] = 1
Updated Q[0x3919, ((2, 0), (2, 1))] = 22400, N[0x3919, ((2, 0), (2, 1))] = 1
Updated Q[0x3919, ((1, 1), (2, 1))] = 22400, N[0x3919, ((1, 1), (2, 1))] = 1

--- Simulation 392 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.42033139002, 16803.42033139002, 22589.83794790302, 16803.42033139002, 19603.42033139002]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 19601.467405903557, 27301.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3670, Score: 16800
Depth 2: State = 0x3670, Legal Moves = [((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3670: [inf, inf]
Selected move: ((3, 2), (4, 2))
New board state after move: 0x390f, Score: 19600
Depth 3: State = 0x390f, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x390f: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x39a8, Score: 22400
Depth 4: State = 0x39a8, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x39a8: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d30, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8767400, N[0x3c25, ((2, 3), (2, 4))] = 388
Updated Q[0x3c24, ((2, 0), (2, 1))] = 25200, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3670, ((3, 2), (4, 2))] = 25200, N[0x3670, ((3, 2), (4, 2))] = 1
Updated Q[0x390f, ((0, 1), (1, 1))] = 25200, N[0x390f, ((0, 1), (1, 1))] = 1
Updated Q[0x39a8, ((2, 0), (2, 1))] = 25200, N[0x39a8, ((2, 0), (2, 1))] = 1

--- Simulation 393 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.421063168957, 16803.421063168957, 22596.565430745784, 16803.421063168957, 19603.421063168957]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 22401.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36da, Score: 8400
Depth 2: State = 0x36da, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (1, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x36da: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x14ab, Score: 11200
Depth 3: State = 0x14ab, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 2), (1, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x14ab: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x4aaa, Score: 16800
Depth 4: State = 0x4aaa, Legal Moves = [((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4aaa: [inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x4ab8, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8787000, N[0x3c25, ((2, 3), (2, 4))] = 389
Updated Q[0x3c25, ((2, 0), (2, 1))] = 19600, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x36da, ((0, 0), (0, 1))] = 19600, N[0x36da, ((0, 0), (0, 1))] = 1
Updated Q[0x14ab, ((0, 1), (1, 1))] = 19600, N[0x14ab, ((0, 1), (1, 1))] = 1
Updated Q[0x4aaa, ((2, 3), (2, 4))] = 19600, N[0x4aaa, ((2, 3), (2, 4))] = 1

--- Simulation 394 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.421792927584, 16803.421792927584, 22588.862437803746, 16803.421792927584, 19603.421792927584]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [27301.16557645562, 27301.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bde, Score: 11200
Depth 2: State = 0x3bde, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bde: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c5f, Score: 14000
Depth 3: State = 0x3c5f, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5f: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3b0c, Score: 16800
Depth 4: State = 0x3b0c, Legal Moves = [((0, 2), (1, 2)), ((1, 1), (2, 1))]
UCB1 values for moves at state 0x3b0c: [inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x21e7, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8806600, N[0x3c25, ((2, 3), (2, 4))] = 390
Updated Q[0x3c25, ((1, 3), (2, 3))] = 19600, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3bde, ((0, 2), (1, 2))] = 19600, N[0x3bde, ((0, 2), (1, 2))] = 1
Updated Q[0x3c5f, ((2, 0), (2, 1))] = 19600, N[0x3c5f, ((2, 0), (2, 1))] = 1
Updated Q[0x3b0c, ((0, 2), (1, 2))] = 19600, N[0x3b0c, ((0, 2), (1, 2))] = 1

--- Simulation 395 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.422520676668, 16803.422520676668, 22581.198947096836, 16803.422520676668, 19603.422520676668]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c68, Score: 16500
Depth 1: State = 0x3c68, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c68: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3847, Score: 22100
Depth 2: State = 0x3847, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3847: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3c09, Score: 24900
Depth 3: State = 0x3c09, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c09: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x50f2, Score: 27700
Depth 4: State = 0x50f2, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x50f2: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4542, Score: 47000
End of simulation with depth 5. Reward (Score): 47000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8853600, N[0x3c25, ((2, 3), (2, 4))] = 391
Updated Q[0x3c68, ((1, 3), (2, 3))] = 47000, N[0x3c68, ((1, 3), (2, 3))] = 1
Updated Q[0x3847, ((0, 1), (0, 2))] = 47000, N[0x3847, ((0, 1), (0, 2))] = 1
Updated Q[0x3c09, ((1, 2), (1, 3))] = 47000, N[0x3c09, ((1, 2), (1, 3))] = 1
Updated Q[0x50f2, ((2, 0), (2, 1))] = 47000, N[0x50f2, ((2, 0), (2, 1))] = 1

--- Simulation 396 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.42324642689, 16803.42324642689, 22643.651381882628, 16803.42324642689, 19603.42324642689]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 30501.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x458d, Score: 13300
Depth 2: State = 0x458d, Legal Moves = [((0, 0), (0, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x458d: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1dbb, Score: 18900
Depth 3: State = 0x1dbb, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1dbb: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x107f, Score: 21700
Depth 4: State = 0x107f, Legal Moves = [((2, 0), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x107f: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1325, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8878100, N[0x3c25, ((2, 3), (2, 4))] = 392
Updated Q[0x3c24, ((2, 0), (2, 1))] = 24500, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x458d, ((0, 0), (0, 1))] = 24500, N[0x458d, ((0, 0), (0, 1))] = 1
Updated Q[0x1dbb, ((1, 0), (1, 1))] = 24500, N[0x1dbb, ((1, 0), (1, 1))] = 1
Updated Q[0x107f, ((2, 0), (2, 1))] = 24500, N[0x107f, ((2, 0), (2, 1))] = 1

--- Simulation 397 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.42397018884, 16803.42397018884, 22648.38722232422, 16803.42397018884, 19603.42397018884]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bff, Score: 11200
Depth 1: State = 0x3bff, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bff: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c64, Score: 14000
Depth 2: State = 0x3c64, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c64: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x386c, Score: 16800
Depth 3: State = 0x386c, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x386c: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x1bfb, Score: 33300
Depth 4: State = 0x1bfb, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1))]
UCB1 values for moves at state 0x1bfb: [inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x2168, Score: 38900
End of simulation with depth 5. Reward (Score): 38900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8917000, N[0x3c25, ((2, 3), (2, 4))] = 393
Updated Q[0x3bff, ((1, 3), (2, 3))] = 38900, N[0x3bff, ((1, 3), (2, 3))] = 1
Updated Q[0x3c64, ((2, 0), (2, 1))] = 38900, N[0x3c64, ((2, 0), (2, 1))] = 1
Updated Q[0x386c, ((1, 1), (2, 1))] = 38900, N[0x386c, ((1, 1), (2, 1))] = 1
Updated Q[0x1bfb, ((0, 3), (1, 3))] = 38900, N[0x1bfb, ((0, 3), (1, 3))] = 1

--- Simulation 398 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.424691973032, 16803.424691973032, 22689.740182883306, 16803.424691973032, 19603.424691973032]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.873992678666, 19601.873992678666, 22051.325112930976, 22401.873992678666, 19601.873992678666]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3af6, Score: 11200
Depth 2: State = 0x3af6, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3af6: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x390f, Score: 14000
Depth 3: State = 0x390f, Legal Moves = [((0, 0), (1, 0)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x390f: [inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x1007, Score: 16800
Depth 4: State = 0x1007, Legal Moves = [((0, 0), (0, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1007: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1d87, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8936600, N[0x3c25, ((2, 3), (2, 4))] = 394
Updated Q[0x3c24, ((2, 3), (3, 3))] = 42000, N[0x3c24, ((2, 3), (3, 3))] = 2
Updated Q[0x3af6, ((0, 1), (1, 1))] = 19600, N[0x3af6, ((0, 1), (1, 1))] = 1
Updated Q[0x390f, ((0, 0), (1, 0))] = 19600, N[0x390f, ((0, 0), (1, 0))] = 1
Updated Q[0x1007, ((0, 0), (0, 1))] = 19600, N[0x1007, ((0, 0), (0, 1))] = 1

--- Simulation 399 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.425411789896, 16803.425411789896, 22681.898458077783, 16803.425411789896, 19603.425411789896]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 25201.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d76, Score: 8400
Depth 2: State = 0x3d76, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d76: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x567a, Score: 11200
Depth 3: State = 0x567a, Legal Moves = [((1, 3), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x567a: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x5176, Score: 18900
Depth 4: State = 0x5176, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x5176: [inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x514d, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8958300, N[0x3c25, ((2, 3), (2, 4))] = 395
Updated Q[0x3c24, ((2, 0), (2, 1))] = 21700, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3d76, ((0, 0), (0, 1))] = 21700, N[0x3d76, ((0, 0), (0, 1))] = 1
Updated Q[0x567a, ((1, 3), (2, 3))] = 21700, N[0x567a, ((1, 3), (2, 3))] = 1
Updated Q[0x5176, ((0, 1), (1, 1))] = 21700, N[0x5176, ((0, 1), (1, 1))] = 1

--- Simulation 400 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.42612964978, 16803.42612964978, 22679.412893620323, 16803.42612964978, 19603.42612964978]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 30501.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x10b1, Score: 13300
Depth 2: State = 0x10b1, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x10b1: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x1203, Score: 16100
Depth 3: State = 0x1203, Legal Moves = [((2, 0), (3, 0)), ((2, 2), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1203: [inf, inf, inf]
Selected move: ((2, 0), (3, 0))
New board state after move: 0x1204, Score: 18900
Depth 4: State = 0x1204, Legal Moves = [((2, 2), (3, 2)), ((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1204: [inf, inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x1204, Score: 21700
End of simulation with depth 5. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 8980000, N[0x3c25, ((2, 3), (2, 4))] = 396
Updated Q[0x3c24, ((2, 0), (2, 1))] = 21700, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x10b1, ((1, 1), (2, 1))] = 21700, N[0x10b1, ((1, 1), (2, 1))] = 1
Updated Q[0x1203, ((2, 0), (3, 0))] = 21700, N[0x1203, ((2, 0), (3, 0))] = 1
Updated Q[0x1204, ((2, 2), (3, 2))] = 21700, N[0x1204, ((2, 2), (3, 2))] = 1

--- Simulation 401 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.426845562954, 16803.426845562954, 22676.93988223657, 16803.426845562954, 19603.426845562954]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 22401.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3afa, Score: 11200
Depth 2: State = 0x3afa, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3afa: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x2ffe, Score: 22100
Depth 3: State = 0x2ffe, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x2ffe: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x2fee, Score: 24900
Depth 4: State = 0x2fee, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 2), (3, 3)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x2fee: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x5388, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9007700, N[0x3c25, ((2, 3), (2, 4))] = 397
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27700, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3afa, ((0, 2), (1, 2))] = 27700, N[0x3afa, ((0, 2), (1, 2))] = 1
Updated Q[0x2ffe, ((0, 3), (1, 3))] = 27700, N[0x2ffe, ((0, 3), (1, 3))] = 1
Updated Q[0x2fee, ((1, 2), (1, 3))] = 27700, N[0x2fee, ((1, 2), (1, 3))] = 1

--- Simulation 402 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.427559539603, 16803.427559539603, 22689.59267919398, 16803.427559539603, 19603.427559539603]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c5e, Score: 8400
Depth 1: State = 0x3c5e, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5e: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3c2b, Score: 11200
Depth 2: State = 0x3c2b, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c2b: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3986, Score: 14000
Depth 3: State = 0x3986, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9021700, N[0x3c25, ((2, 3), (2, 4))] = 398
Updated Q[0x3c5e, ((0, 3), (1, 3))] = 14000, N[0x3c5e, ((0, 3), (1, 3))] = 1
Updated Q[0x3c2b, ((2, 0), (2, 1))] = 14000, N[0x3c2b, ((2, 0), (2, 1))] = 1

--- Simulation 403 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.428271589837, 16803.428271589837, 22667.75978342566, 16803.428271589837, 19603.428271589837]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [30501.16557645562, 19601.16557645562, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3aa6, Score: 15400
Depth 2: State = 0x3aa6, Legal Moves = [((0, 2), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3aa6: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c5e, Score: 18200
Depth 3: State = 0x3c5e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5e: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x36d6, Score: 21000
Depth 4: State = 0x36d6, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d6: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c6c, Score: 28600
End of simulation with depth 5. Reward (Score): 28600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9050300, N[0x3c25, ((2, 3), (2, 4))] = 399
Updated Q[0x3c24, ((1, 3), (2, 3))] = 28600, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3aa6, ((0, 2), (1, 2))] = 28600, N[0x3aa6, ((0, 2), (1, 2))] = 1
Updated Q[0x3c5e, ((1, 3), (2, 3))] = 28600, N[0x3c5e, ((1, 3), (2, 3))] = 1
Updated Q[0x36d6, ((2, 0), (2, 1))] = 28600, N[0x36d6, ((2, 0), (2, 1))] = 1

--- Simulation 404 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.428981723693, 16803.428981723693, 22682.627804151092, 16803.428981723693, 19603.428981723693]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bff, Score: 8400
Depth 2: State = 0x3bff, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bff: [inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3bde, Score: 11200
Depth 3: State = 0x3bde, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bde: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3dbb, Score: 14000
Depth 4: State = 0x3dbb, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3dbb: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3db1, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9067100, N[0x3c25, ((2, 3), (2, 4))] = 400
Updated Q[0x3c24, ((0, 2), (1, 2))] = 16800, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3bff, ((0, 4), (1, 4))] = 16800, N[0x3bff, ((0, 4), (1, 4))] = 1
Updated Q[0x3bde, ((1, 3), (2, 3))] = 16800, N[0x3bde, ((1, 3), (2, 3))] = 1
Updated Q[0x3dbb, ((0, 3), (1, 3))] = 16800, N[0x3dbb, ((0, 3), (1, 3))] = 1

--- Simulation 405 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.429689951117, 16803.429689951117, 22667.921484497558, 16803.429689951117, 19603.429689951117]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 30501.467405903557, 24501.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x380d, Score: 24400
Depth 2: State = 0x380d, Legal Moves = [((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x380d: [inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x37c7, Score: 27200
Depth 3: State = 0x37c7, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37c7: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x37cd, Score: 30000
Depth 4: State = 0x37cd, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x37cd: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3ab3, Score: 35600
End of simulation with depth 5. Reward (Score): 35600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9102700, N[0x3c25, ((2, 3), (2, 4))] = 401
Updated Q[0x3c24, ((2, 3), (3, 3))] = 35600, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x380d, ((1, 1), (1, 2))] = 35600, N[0x380d, ((1, 1), (1, 2))] = 1
Updated Q[0x37c7, ((0, 3), (1, 3))] = 35600, N[0x37c7, ((0, 3), (1, 3))] = 1
Updated Q[0x37cd, ((2, 0), (2, 1))] = 35600, N[0x37cd, ((2, 0), (2, 1))] = 1

--- Simulation 406 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.430396281994, 16803.430396281994, 22700.171305815496, 16803.430396281994, 19603.430396281994]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 33301.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bfb, Score: 16100
Depth 2: State = 0x3bfb, Legal Moves = [((1, 0), (1, 1)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bfb: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x3956, Score: 18900
Depth 3: State = 0x3956, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3956: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3bbb, Score: 21700
Depth 4: State = 0x3bbb, Legal Moves = [((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbb: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c47, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9127200, N[0x3c25, ((2, 3), (2, 4))] = 402
Updated Q[0x3c24, ((1, 3), (2, 3))] = 24500, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3bfb, ((1, 0), (1, 1))] = 24500, N[0x3bfb, ((1, 0), (1, 1))] = 1
Updated Q[0x3956, ((0, 3), (1, 3))] = 24500, N[0x3956, ((0, 3), (1, 3))] = 1
Updated Q[0x3bbb, ((1, 2), (2, 2))] = 24500, N[0x3bbb, ((1, 2), (2, 2))] = 1

--- Simulation 407 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.431100726124, 16803.431100726124, 22704.64873969067, 16803.431100726124, 19603.431100726124]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.467405903557, 30501.467405903557, 24501.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c25, Score: 8400
Depth 2: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x465a, Score: 11200
Depth 3: State = 0x465a, Legal Moves = [((1, 3), (2, 3)), ((2, 2), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x465a: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x46a0, Score: 14000
Depth 4: State = 0x46a0, Legal Moves = [((0, 3), (0, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x46a0: [inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x469a, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9144000, N[0x3c25, ((2, 3), (2, 4))] = 403
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x465a, ((1, 3), (2, 3))] = 16800, N[0x465a, ((1, 3), (2, 3))] = 1
Updated Q[0x46a0, ((0, 3), (0, 4))] = 16800, N[0x46a0, ((0, 3), (0, 4))] = 1

--- Simulation 408 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.431803293235, 16803.431803293235, 22689.99725302808, 16803.431803293235, 19603.431803293235]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [33301.46740590355, 29401.467405903557, 30801.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3a63, Score: 22100
Depth 2: State = 0x3a63, Legal Moves = [((0, 0), (1, 0)), ((0, 1), (0, 2)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 2), (3, 3)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3a63: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x2e9b, Score: 24900
Depth 3: State = 0x2e9b, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x2e9b: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x2e80, Score: 27700
Depth 4: State = 0x2e80, Legal Moves = [((1, 0), (1, 1)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x2e80: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x2fd3, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9174500, N[0x3c25, ((2, 3), (2, 4))] = 404
Updated Q[0x3c25, ((2, 3), (3, 3))] = 30500, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3a63, ((0, 0), (1, 0))] = 30500, N[0x3a63, ((0, 0), (1, 0))] = 1
Updated Q[0x2e9b, ((0, 2), (0, 3))] = 30500, N[0x2e9b, ((0, 2), (0, 3))] = 1
Updated Q[0x2e80, ((1, 0), (1, 1))] = 30500, N[0x2e80, ((1, 0), (1, 1))] = 1

--- Simulation 409 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.432503992983, 16803.432503992983, 22709.329189298012, 16803.432503992983, 19603.432503992983]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c1d, Score: 8400
Depth 1: State = 0x3c1d, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1d: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3876, Score: 11200
Depth 2: State = 0x3876, Legal Moves = [((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3876: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3872, Score: 14000
Depth 3: State = 0x3872, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3872: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3d2d, Score: 19600
Depth 4: State = 0x3d2d, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d2d: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x54ff, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9196900, N[0x3c25, ((2, 3), (2, 4))] = 405
Updated Q[0x3c1d, ((1, 3), (2, 3))] = 22400, N[0x3c1d, ((1, 3), (2, 3))] = 1
Updated Q[0x3876, ((1, 2), (1, 3))] = 22400, N[0x3876, ((1, 2), (1, 3))] = 1
Updated Q[0x3872, ((0, 1), (0, 2))] = 22400, N[0x3872, ((0, 1), (0, 2))] = 1
Updated Q[0x3d2d, ((1, 2), (1, 3))] = 22400, N[0x3d2d, ((1, 2), (1, 3))] = 1

--- Simulation 410 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.43320283494, 16803.43320283494, 22708.565658948828, 16803.43320283494, 19603.43320283494]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [21701.16557645562, 27701.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397f, Score: 8400
Depth 2: State = 0x397f, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397f: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2bff, Score: 14000
Depth 3: State = 0x2bff, Legal Moves = [((1, 3), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2bff: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x2fd9, Score: 22400
Depth 4: State = 0x2fd9, Legal Moves = [((1, 3), (2, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2fd9: [inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x2fd5, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9222100, N[0x3c25, ((2, 3), (2, 4))] = 406
Updated Q[0x3c24, ((2, 0), (2, 1))] = 25200, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x397f, ((0, 0), (0, 1))] = 25200, N[0x397f, ((0, 0), (0, 1))] = 1
Updated Q[0x2bff, ((1, 3), (2, 3))] = 25200, N[0x2bff, ((1, 3), (2, 3))] = 1
Updated Q[0x2fd9, ((1, 3), (2, 3))] = 25200, N[0x2fd9, ((1, 3), (2, 3))] = 1

--- Simulation 411 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.433899828622, 16803.433899828622, 22714.702441291454, 16803.433899828622, 19603.433899828622]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bde, Score: 8400
Depth 1: State = 0x3bde, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bde: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c06, Score: 11200
Depth 2: State = 0x3c06, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c06: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bc2, Score: 14000
Depth 3: State = 0x3bc2, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc2: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x160a, Score: 16800
Depth 4: State = 0x160a, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x160a: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x160a, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9241700, N[0x3c25, ((2, 3), (2, 4))] = 407
Updated Q[0x3bde, ((1, 3), (2, 3))] = 19600, N[0x3bde, ((1, 3), (2, 3))] = 1
Updated Q[0x3c06, ((0, 2), (1, 2))] = 19600, N[0x3c06, ((0, 2), (1, 2))] = 1
Updated Q[0x3bc2, ((1, 2), (1, 3))] = 19600, N[0x3bc2, ((1, 2), (1, 3))] = 1
Updated Q[0x160a, ((1, 3), (1, 4))] = 19600, N[0x160a, ((1, 3), (1, 4))] = 1

--- Simulation 412 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.43459498346, 16803.43459498346, 22707.049853432287, 16803.43459498346, 19603.43459498346]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19602.01883764124, 27302.01883764124, 27702.01883764124, 27151.00941882062, 25202.01883764124]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36d9, Score: 8400
Depth 2: State = 0x36d9, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x36d9: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x12fb, Score: 11200
Depth 3: State = 0x12fb, Legal Moves = [((0, 1), (0, 2)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x12fb: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x1ee9, Score: 49700
Depth 4: State = 0x1ee9, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x1ee9: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x1f0b, Score: 55300
End of simulation with depth 5. Reward (Score): 55300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9297000, N[0x3c25, ((2, 3), (2, 4))] = 408
Updated Q[0x3c24, ((2, 0), (2, 1))] = 83000, N[0x3c24, ((2, 0), (2, 1))] = 2
Updated Q[0x36d9, ((0, 0), (0, 1))] = 55300, N[0x36d9, ((0, 0), (0, 1))] = 1
Updated Q[0x12fb, ((0, 1), (0, 2))] = 55300, N[0x12fb, ((0, 1), (0, 2))] = 1
Updated Q[0x1ee9, ((4, 1), (4, 2))] = 55300, N[0x1ee9, ((4, 1), (4, 2))] = 1

--- Simulation 413 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.43528830882, 16803.43528830882, 22786.934777996274, 16803.43528830882, 19603.43528830882]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x36d3, Score: 21600
Depth 2: State = 0x36d3, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d3: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x36d3, Score: 24400
Depth 3: State = 0x36d3, Legal Moves = [((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36d3: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c1e, Score: 27200
Depth 4: State = 0x3c1e, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (1, 1))]
UCB1 values for moves at state 0x3c1e: [inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x5544, Score: 32800
End of simulation with depth 5. Reward (Score): 32800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9329800, N[0x3c25, ((2, 3), (2, 4))] = 409
Updated Q[0x3c25, ((1, 3), (2, 3))] = 32800, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x36d3, ((1, 2), (1, 3))] = 32800, N[0x36d3, ((1, 2), (1, 3))] = 1
Updated Q[0x36d3, ((2, 0), (2, 1))] = 32800, N[0x36d3, ((2, 0), (2, 1))] = 1
Updated Q[0x3c1e, ((0, 0), (0, 1))] = 32800, N[0x3c1e, ((0, 0), (0, 1))] = 1

--- Simulation 414 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.435979814, 16803.435979814, 22811.41684203257, 16803.435979814, 19603.435979814]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c0a, Score: 8400
Depth 1: State = 0x3c0a, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c0a: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x366e, Score: 11200
Depth 2: State = 0x366e, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x366e: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3be1, Score: 24900
Depth 3: State = 0x3be1, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be1: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4830, Score: 27700
Depth 4: State = 0x4830, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x4830: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0xf009, Score: 33300
End of simulation with depth 5. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9363100, N[0x3c25, ((2, 3), (2, 4))] = 410
Updated Q[0x3c0a, ((1, 3), (2, 3))] = 33300, N[0x3c0a, ((1, 3), (2, 3))] = 1
Updated Q[0x366e, ((1, 3), (1, 4))] = 33300, N[0x366e, ((1, 3), (1, 4))] = 1
Updated Q[0x3be1, ((1, 2), (1, 3))] = 33300, N[0x3be1, ((1, 2), (1, 3))] = 1
Updated Q[0x4830, ((0, 1), (1, 1))] = 33300, N[0x4830, ((0, 1), (1, 1))] = 1

--- Simulation 415 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.436669508217, 16803.436669508217, 22836.99899330204, 16803.436669508217, 19603.436669508217]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.16557645562, 25201.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397e, Score: 8400
Depth 2: State = 0x397e, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (1, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397e: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2c3c, Score: 11200
Depth 3: State = 0x2c3c, Legal Moves = [((1, 0), (1, 1)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2c3c: [inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x2996, Score: 14000
Depth 4: State = 0x2996, Legal Moves = [((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2996: [inf, inf]
Selected move: ((2, 4), (3, 4))
New board state after move: 0x2997, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9379900, N[0x3c25, ((2, 3), (2, 4))] = 411
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x397e, ((0, 0), (0, 1))] = 16800, N[0x397e, ((0, 0), (0, 1))] = 1
Updated Q[0x2c3c, ((1, 0), (1, 1))] = 16800, N[0x2c3c, ((1, 0), (1, 1))] = 1
Updated Q[0x2996, ((2, 4), (3, 4))] = 16800, N[0x2996, ((2, 4), (3, 4))] = 1

--- Simulation 416 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.437357400628, 16803.437357400628, 22822.310671558138, 16803.437357400628, 19603.437357400628]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.648374031523, 30501.648374031523, 24501.648374031523, 35601.64837403152, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x569d, Score: 8400
Depth 2: State = 0x569d, Legal Moves = [((1, 3), (2, 3)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x569d: [inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x5634, Score: 14000
Depth 3: State = 0x5634, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3))]
UCB1 values for moves at state 0x5634: [inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x56e1, Score: 16800
Depth 4: State = 0x56e1, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9396700, N[0x3c25, ((2, 3), (2, 4))] = 412
Updated Q[0x3c24, ((3, 0), (3, 1))] = 16800, N[0x3c24, ((3, 0), (3, 1))] = 1
Updated Q[0x569d, ((1, 3), (2, 3))] = 16800, N[0x569d, ((1, 3), (2, 3))] = 1
Updated Q[0x5634, ((1, 2), (2, 2))] = 16800, N[0x5634, ((1, 2), (2, 2))] = 1

--- Simulation 417 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.438043500322, 16803.438043500322, 22807.693652090686, 16803.438043500322, 19603.438043500322]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3be7, Score: 8400
Depth 1: State = 0x3be7, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be7: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c28, Score: 11200
Depth 2: State = 0x3c28, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c28: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3982, Score: 14000
Depth 3: State = 0x3982, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x3982: [inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x20a0, Score: 16800
Depth 4: State = 0x20a0, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x20a0: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x2af3, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9416300, N[0x3c25, ((2, 3), (2, 4))] = 413
Updated Q[0x3be7, ((1, 3), (2, 3))] = 19600, N[0x3be7, ((1, 3), (2, 3))] = 1
Updated Q[0x3c28, ((2, 0), (2, 1))] = 19600, N[0x3c28, ((2, 0), (2, 1))] = 1
Updated Q[0x3982, ((1, 0), (2, 0))] = 19600, N[0x3982, ((1, 0), (2, 0))] = 1
Updated Q[0x20a0, ((0, 1), (1, 1))] = 19600, N[0x20a0, ((0, 1), (1, 1))] = 1

--- Simulation 418 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.43872781632, 16803.43872781632, 22799.9270779833, 16803.43872781632, 19603.43872781632]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bbf, Score: 8400
Depth 1: State = 0x3bbf, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbf: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c43, Score: 14000
Depth 2: State = 0x3c43, Legal Moves = [((0, 0), (1, 0)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c43: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x45a8, Score: 16800
Depth 3: State = 0x45a8, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a8: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x45a8, Score: 19600
Depth 4: State = 0x45a8, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1))]
UCB1 values for moves at state 0x45a8: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x1f25, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9438700, N[0x3c25, ((2, 3), (2, 4))] = 414
Updated Q[0x3bbf, ((1, 3), (2, 3))] = 22400, N[0x3bbf, ((1, 3), (2, 3))] = 1
Updated Q[0x3c43, ((0, 0), (1, 0))] = 22400, N[0x3c43, ((0, 0), (1, 0))] = 1
Updated Q[0x45a8, ((2, 0), (2, 1))] = 22400, N[0x45a8, ((2, 0), (2, 1))] = 1
Updated Q[0x45a8, ((1, 1), (2, 1))] = 22400, N[0x45a8, ((1, 1), (2, 1))] = 1

--- Simulation 419 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.43941035757, 16803.43941035757, 22798.96130832845, 16803.43941035757, 19603.43941035757]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c64, Score: 13200
Depth 1: State = 0x3c64, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c64: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bdd, Score: 16000
Depth 2: State = 0x3bdd, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bdd: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d2f, Score: 18800
Depth 3: State = 0x3d2f, Legal Moves = [((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d2f: [inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3d29, Score: 21600
Depth 4: State = 0x3d29, Legal Moves = [((2, 2), (2, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d29: [inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x3d6c, Score: 24400
End of simulation with depth 5. Reward (Score): 24400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9463100, N[0x3c25, ((2, 3), (2, 4))] = 415
Updated Q[0x3c64, ((1, 2), (2, 2))] = 24400, N[0x3c64, ((1, 2), (2, 2))] = 1
Updated Q[0x3bdd, ((2, 0), (2, 1))] = 24400, N[0x3bdd, ((2, 0), (2, 1))] = 1
Updated Q[0x3d2f, ((2, 3), (2, 4))] = 24400, N[0x3d2f, ((2, 3), (2, 4))] = 1
Updated Q[0x3d29, ((2, 2), (2, 3))] = 24400, N[0x3d29, ((2, 2), (2, 3))] = 1

--- Simulation 420 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.440091132958, 16803.440091132958, 22802.8194698418, 16803.440091132958, 19603.440091132958]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 22401.467405903557, 27701.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36d9, Score: 8400
Depth 2: State = 0x36d9, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x36d9: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1319, Score: 11200
Depth 3: State = 0x1319, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1319: [inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x10be, Score: 14000
Depth 4: State = 0x10be, Legal Moves = [((1, 2), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x10be: [inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x107e, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9479900, N[0x3c25, ((2, 3), (2, 4))] = 416
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x36d9, ((0, 0), (0, 1))] = 16800, N[0x36d9, ((0, 0), (0, 1))] = 1
Updated Q[0x1319, ((0, 3), (1, 3))] = 16800, N[0x1319, ((0, 3), (1, 3))] = 1
Updated Q[0x10be, ((1, 2), (2, 2))] = 16800, N[0x10be, ((1, 2), (2, 2))] = 1

--- Simulation 421 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.440770151305, 16803.440770151305, 22788.389851482145, 16803.440770151305, 19603.440770151305]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bff, Score: 8400
Depth 2: State = 0x3bff, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bff: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c00, Score: 11200
Depth 3: State = 0x3c00, Legal Moves = [((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c00: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c03, Score: 14000
Depth 4: State = 0x3c03, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c03: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3b19, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9499500, N[0x3c25, ((2, 3), (2, 4))] = 417
Updated Q[0x3c24, ((0, 2), (1, 2))] = 19600, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3bff, ((0, 4), (1, 4))] = 19600, N[0x3bff, ((0, 4), (1, 4))] = 1
Updated Q[0x3c00, ((0, 4), (1, 4))] = 19600, N[0x3c00, ((0, 4), (1, 4))] = 1
Updated Q[0x3c03, ((1, 3), (2, 3))] = 19600, N[0x3c03, ((1, 3), (2, 3))] = 1

--- Simulation 422 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.441447421366, 16803.441447421366, 22780.74406797364, 16803.441447421366, 19603.441447421366]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22401.16557645562, 22401.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x36d8, Score: 8400
Depth 2: State = 0x36d8, Legal Moves = [((0, 0), (0, 1)), ((1, 1), (1, 2)), ((1, 2), (2, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x36d8: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x15b8, Score: 11200
Depth 3: State = 0x15b8, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x15b8: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x159a, Score: 14000
Depth 4: State = 0x159a, Legal Moves = [((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x159a: [inf, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0xefc3, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9516300, N[0x3c25, ((2, 3), (2, 4))] = 418
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x36d8, ((0, 0), (0, 1))] = 16800, N[0x36d8, ((0, 0), (0, 1))] = 1
Updated Q[0x15b8, ((0, 2), (1, 2))] = 16800, N[0x15b8, ((0, 2), (1, 2))] = 1
Updated Q[0x159a, ((3, 0), (3, 1))] = 16800, N[0x159a, ((3, 0), (3, 1))] = 1

--- Simulation 423 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.44212295183, 16803.44212295183, 22766.436302320584, 16803.44212295183, 19603.44212295183]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x48fb, Score: 8400
Depth 2: State = 0x48fb, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x48fb: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x45a8, Score: 14000
Depth 3: State = 0x45a8, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45a8: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1319, Score: 22400
Depth 4: State = 0x1319, Legal Moves = [((2, 0), (3, 0)), ((2, 1), (2, 2)), ((3, 3), (4, 3))]
UCB1 values for moves at state 0x1319: [inf, inf, inf]
Selected move: ((2, 0), (3, 0))
New board state after move: 0x1319, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9541500, N[0x3c25, ((2, 3), (2, 4))] = 419
Updated Q[0x3c24, ((0, 0), (0, 1))] = 25200, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x48fb, ((1, 3), (2, 3))] = 25200, N[0x48fb, ((1, 3), (2, 3))] = 1
Updated Q[0x45a8, ((2, 0), (2, 1))] = 25200, N[0x45a8, ((2, 0), (2, 1))] = 1
Updated Q[0x1319, ((2, 0), (3, 0))] = 25200, N[0x1319, ((2, 0), (3, 0))] = 1

--- Simulation 424 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.442796751326, 16803.442796751326, 22772.244563942528, 16803.442796751326, 19603.442796751326]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.467405903557, 19601.467405903557, 21601.467405903557, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x36ff, Score: 14000
Depth 2: State = 0x36ff, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36ff: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x37ed, Score: 16800
Depth 3: State = 0x37ed, Legal Moves = [((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37ed: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d38, Score: 19600
Depth 4: State = 0x3d38, Legal Moves = [((4, 0), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d38: [inf, inf]
Selected move: ((4, 0), (4, 1))
New board state after move: 0x22c0, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9563900, N[0x3c25, ((2, 3), (2, 4))] = 420
Updated Q[0x3c25, ((2, 3), (2, 4))] = 22400, N[0x3c25, ((2, 3), (2, 4))] = 1
Updated Q[0x36ff, ((0, 1), (1, 1))] = 22400, N[0x36ff, ((0, 1), (1, 1))] = 1
Updated Q[0x37ed, ((2, 0), (2, 1))] = 22400, N[0x37ed, ((2, 0), (2, 1))] = 1
Updated Q[0x3d38, ((4, 0), (4, 1))] = 22400, N[0x3d38, ((4, 0), (4, 1))] = 1

--- Simulation 425 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.443468828413, 16803.443468828413, 22771.35850026452, 16803.443468828413, 19603.443468828413]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.467405903557, 25201.467405903557, 24501.467405903557, inf, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c27, Score: 8400
Depth 2: State = 0x3c27, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c27: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x301c, Score: 16800
Depth 3: State = 0x301c, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (0, 2)), ((0, 1), (1, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x301c: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1c20, Score: 22400
Depth 4: State = 0x1c20, Legal Moves = [((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1c20: [inf, inf, inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x1c20, Score: 25200
End of simulation with depth 5. Reward (Score): 25200
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9589100, N[0x3c25, ((2, 3), (2, 4))] = 421
Updated Q[0x3c24, ((2, 3), (3, 3))] = 25200, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x3c27, ((2, 0), (2, 1))] = 25200, N[0x3c27, ((2, 0), (2, 1))] = 1
Updated Q[0x301c, ((0, 0), (0, 1))] = 25200, N[0x301c, ((0, 0), (0, 1))] = 1
Updated Q[0x1c20, ((2, 2), (2, 3))] = 25200, N[0x1c20, ((2, 2), (2, 3))] = 1

--- Simulation 426 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.444139191597, 16803.444139191597, 22777.127477025864, 16803.444139191597, 19603.444139191597]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [21701.16557645562, 34401.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3952, Score: 21700
Depth 2: State = 0x3952, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3952: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3d4a, Score: 24500
Depth 3: State = 0x3d4a, Legal Moves = [((1, 1), (1, 2)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d4a: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x36ac, Score: 27300
Depth 4: State = 0x36ac, Legal Moves = [((0, 1), (0, 2)), ((1, 0), (2, 0)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36ac: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x39a0, Score: 30100
End of simulation with depth 5. Reward (Score): 30100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9619200, N[0x3c25, ((2, 3), (2, 4))] = 422
Updated Q[0x3c25, ((1, 3), (2, 3))] = 30100, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3952, ((1, 1), (2, 1))] = 30100, N[0x3952, ((1, 1), (2, 1))] = 1
Updated Q[0x3d4a, ((1, 1), (1, 2))] = 30100, N[0x3d4a, ((1, 1), (1, 2))] = 1
Updated Q[0x36ac, ((0, 1), (0, 2))] = 30100, N[0x36ac, ((0, 1), (0, 2))] = 1

--- Simulation 427 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.44480784931, 16803.44480784931, 22794.4804868309, 16803.44480784931, 19603.44480784931]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c24: [27700.0, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c64, Score: 8400
Depth 2: State = 0x3c64, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c64: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3dbb, Score: 11200
Depth 3: State = 0x3dbb, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3dbb: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3db7, Score: 14000
Depth 4: State = 0x3db7, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3db7: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bbf, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9641600, N[0x3c25, ((2, 3), (2, 4))] = 423
Updated Q[0x3c24, ((0, 2), (1, 2))] = 22400, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c64, ((1, 3), (2, 3))] = 22400, N[0x3c64, ((1, 3), (2, 3))] = 1
Updated Q[0x3dbb, ((0, 3), (1, 3))] = 22400, N[0x3dbb, ((0, 3), (1, 3))] = 1
Updated Q[0x3db7, ((1, 2), (2, 2))] = 22400, N[0x3db7, ((1, 2), (2, 2))] = 1

--- Simulation 428 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.445474809938, 16803.445474809938, 22793.54813937516, 16803.445474809938, 19603.445474809938]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bb6, Score: 8400
Depth 1: State = 0x3bb6, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (0, 4)), ((0, 3), (1, 3)), ((0, 4), (1, 4)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3bb6: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3d34, Score: 11200
Depth 2: State = 0x3d34, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3d34: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bff, Score: 29800
Depth 3: State = 0x3bff, Legal Moves = [((0, 1), (1, 1)), ((1, 0), (1, 1)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bff: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x1074, Score: 32600
Depth 4: State = 0x1074, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1074: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x1011, Score: 35400
End of simulation with depth 5. Reward (Score): 35400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9677000, N[0x3c25, ((2, 3), (2, 4))] = 424
Updated Q[0x3bb6, ((0, 1), (1, 1))] = 35400, N[0x3bb6, ((0, 1), (1, 1))] = 1
Updated Q[0x3d34, ((1, 2), (2, 2))] = 35400, N[0x3d34, ((1, 2), (2, 2))] = 1
Updated Q[0x3bff, ((0, 1), (1, 1))] = 35400, N[0x3bff, ((0, 1), (1, 1))] = 1
Updated Q[0x1074, ((0, 3), (1, 3))] = 35400, N[0x1074, ((0, 3), (1, 3))] = 1

--- Simulation 429 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.446140081793, 16803.446140081793, 22823.280566904225, 16803.446140081793, 19603.446140081793]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19600.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x456b, Score: 14000
Depth 2: State = 0x456b, Legal Moves = [((0, 3), (0, 4)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x456b: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x455f, Score: 16800
Depth 3: State = 0x455f, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x455f: [inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x455f, Score: 19600
Depth 4: State = 0x455f, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((1, 2), (1, 3)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x455f: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x47c1, Score: 30000
End of simulation with depth 5. Reward (Score): 30000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9707000, N[0x3c25, ((2, 3), (2, 4))] = 425
Updated Q[0x3c25, ((1, 3), (1, 4))] = 30000, N[0x3c25, ((1, 3), (1, 4))] = 1
Updated Q[0x456b, ((0, 3), (0, 4))] = 30000, N[0x456b, ((0, 3), (0, 4))] = 1
Updated Q[0x455f, ((1, 1), (2, 1))] = 30000, N[0x455f, ((1, 1), (2, 1))] = 1
Updated Q[0x455f, ((0, 1), (0, 2))] = 30000, N[0x455f, ((0, 1), (0, 2))] = 1

--- Simulation 430 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.44680367313, 16803.44680367313, 22840.167194536647, 16803.44680367313, 19603.44680367313]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14001.467405903555, 22401.467405903557, 21701.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x382c, Score: 8400
Depth 2: State = 0x382c, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x382c: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x21e9, Score: 11200
Depth 3: State = 0x21e9, Legal Moves = [((1, 3), (2, 3)), ((2, 1), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x21e9: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x21a9, Score: 14000
Depth 4: State = 0x21a9, Legal Moves = [((1, 2), (2, 2)), ((2, 1), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x21a9: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x218d, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9723800, N[0x3c25, ((2, 3), (2, 4))] = 426
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x382c, ((0, 0), (0, 1))] = 16800, N[0x382c, ((0, 0), (0, 1))] = 1
Updated Q[0x21e9, ((1, 3), (2, 3))] = 16800, N[0x21e9, ((1, 3), (2, 3))] = 1
Updated Q[0x21a9, ((1, 2), (2, 2))] = 16800, N[0x21a9, ((1, 2), (2, 2))] = 1

--- Simulation 431 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.447465592144, 16803.447465592144, 22825.988626497845, 16803.447465592144, 19603.447465592144]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43cb, Score: 8400
Depth 2: State = 0x43cb, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43cb: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4ab3, Score: 14000
Depth 3: State = 0x4ab3, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab3: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x4ab7, Score: 16800
Depth 4: State = 0x4ab7, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ab7: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4811, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9743400, N[0x3c25, ((2, 3), (2, 4))] = 427
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x43cb, ((1, 3), (2, 3))] = 19600, N[0x43cb, ((1, 3), (2, 3))] = 1
Updated Q[0x4ab3, ((0, 3), (1, 3))] = 19600, N[0x4ab3, ((0, 3), (1, 3))] = 1
Updated Q[0x4ab7, ((2, 0), (2, 1))] = 19600, N[0x4ab7, ((2, 0), (2, 1))] = 1

--- Simulation 432 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.44812584698, 16803.44812584698, 22818.43384542798, 16803.44812584698, 19603.44812584698]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4ad8, Score: 8400
Depth 2: State = 0x4ad8, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4ad8: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x52ee, Score: 11200
Depth 3: State = 0x52ee, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x52ee: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x22f8, Score: 14000
Depth 4: State = 0x22f8, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x22f8: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x1d4e, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9760200, N[0x3c25, ((2, 3), (2, 4))] = 428
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4ad8, ((0, 0), (0, 1))] = 16800, N[0x4ad8, ((0, 0), (0, 1))] = 1
Updated Q[0x52ee, ((0, 0), (0, 1))] = 16800, N[0x52ee, ((0, 0), (0, 1))] = 1
Updated Q[0x22f8, ((1, 3), (1, 4))] = 16800, N[0x22f8, ((1, 3), (1, 4))] = 1

--- Simulation 433 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.448784445707, 16803.448784445707, 22804.372310764964, 16803.448784445707, 19603.448784445707]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c42, Score: 8400
Depth 1: State = 0x3c42, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c42: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x2186, Score: 11200
Depth 2: State = 0x2186, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2186: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x22f4, Score: 14000
Depth 3: State = 0x22f4, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x22f4: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1da9, Score: 16800
Depth 4: State = 0x1da9, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x1da9: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x455d, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9779800, N[0x3c25, ((2, 3), (2, 4))] = 429
Updated Q[0x3c42, ((0, 0), (1, 0))] = 19600, N[0x3c42, ((0, 0), (1, 0))] = 1
Updated Q[0x2186, ((1, 3), (2, 3))] = 19600, N[0x2186, ((1, 3), (2, 3))] = 1
Updated Q[0x22f4, ((2, 0), (2, 1))] = 19600, N[0x22f4, ((2, 0), (2, 1))] = 1
Updated Q[0x1da9, ((1, 0), (1, 1))] = 19600, N[0x1da9, ((1, 0), (1, 1))] = 1

--- Simulation 434 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.449441396355, 16803.449441396355, 22796.903137336565, 16803.449441396355, 19603.449441396355]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c4c, Score: 8400
Depth 1: State = 0x3c4c, Legal Moves = [((0, 0), (1, 0)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c4c: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x5441, Score: 11200
Depth 2: State = 0x5441, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5441: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2d9b, Score: 14000
Depth 3: State = 0x2d9b, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2d9b: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3c4c, Score: 25200
Depth 4: State = 0x3c4c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 0), (4, 0))]
UCB1 values for moves at state 0x3c4c: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bbe, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9807800, N[0x3c25, ((2, 3), (2, 4))] = 430
Updated Q[0x3c4c, ((0, 0), (1, 0))] = 28000, N[0x3c4c, ((0, 0), (1, 0))] = 1
Updated Q[0x5441, ((0, 0), (0, 1))] = 28000, N[0x5441, ((0, 0), (0, 1))] = 1
Updated Q[0x2d9b, ((0, 0), (1, 0))] = 28000, N[0x2d9b, ((0, 0), (1, 0))] = 1
Updated Q[0x3c4c, ((1, 2), (2, 2))] = 28000, N[0x3c4c, ((1, 2), (2, 2))] = 1

--- Simulation 435 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.45009670688, 16803.45009670688, 22809.003587739593, 16803.45009670688, 19603.45009670688]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x443d, Score: 8400
Depth 2: State = 0x443d, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x443d: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x1c59, Score: 14000
Depth 3: State = 0x1c59, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1c59: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1eff, Score: 16800
Depth 4: State = 0x1eff, Legal Moves = [((1, 0), (1, 1)), ((1, 1), (2, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1eff: [inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x1eff, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9827400, N[0x3c25, ((2, 3), (2, 4))] = 431
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x443d, ((1, 3), (2, 3))] = 19600, N[0x443d, ((1, 3), (2, 3))] = 1
Updated Q[0x1c59, ((2, 0), (2, 1))] = 19600, N[0x1c59, ((2, 0), (2, 1))] = 1
Updated Q[0x1eff, ((1, 0), (1, 1))] = 19600, N[0x1eff, ((1, 0), (1, 1))] = 1

--- Simulation 436 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.450750385196, 16803.450750385196, 22801.55832816624, 16803.450750385196, 19603.450750385196]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.16557645562, 21701.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x382c, Score: 8400
Depth 2: State = 0x382c, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x382c: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2071, Score: 11200
Depth 3: State = 0x2071, Legal Moves = [((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2071: [inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2078, Score: 14000
Depth 4: State = 0x2078, Legal Moves = [((2, 1), (2, 2)), ((2, 2), (3, 2)), ((3, 2), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2078: [inf, inf, inf, inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x1fe9, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9844200, N[0x3c25, ((2, 3), (2, 4))] = 432
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x382c, ((0, 0), (0, 1))] = 16800, N[0x382c, ((0, 0), (0, 1))] = 1
Updated Q[0x2071, ((1, 2), (1, 3))] = 16800, N[0x2071, ((1, 2), (1, 3))] = 1
Updated Q[0x2078, ((2, 1), (2, 2))] = 16800, N[0x2078, ((2, 1), (2, 2))] = 1

--- Simulation 437 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.45140243915, 16803.45140243915, 22787.666055677277, 16803.45140243915, 19603.45140243915]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22401.16557645562, 16801.16557645562, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x29b9, Score: 22100
Depth 2: State = 0x29b9, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x29b9: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1c5b, Score: 30500
Depth 3: State = 0x1c5b, Legal Moves = [((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 1), (2, 2))]
UCB1 values for moves at state 0x1c5b: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4562, Score: 33300
Depth 4: State = 0x4562, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9877500, N[0x3c25, ((2, 3), (2, 4))] = 433
Updated Q[0x3c24, ((1, 3), (1, 4))] = 33300, N[0x3c24, ((1, 3), (1, 4))] = 1
Updated Q[0x29b9, ((2, 0), (2, 1))] = 33300, N[0x29b9, ((2, 0), (2, 1))] = 1
Updated Q[0x1c5b, ((1, 2), (1, 3))] = 33300, N[0x1c5b, ((1, 2), (1, 3))] = 1

--- Simulation 438 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.452052876535, 16803.452052876535, 22811.944186067332, 16803.452052876535, 19603.452052876535]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 8400
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c09, Score: 11200
Depth 2: State = 0x3c09, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c09: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c6b, Score: 14000
Depth 3: State = 0x3c6b, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6b: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c1a, Score: 16800
Depth 4: State = 0x3c1a, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1a: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3952, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9897100, N[0x3c25, ((2, 3), (2, 4))] = 434
Updated Q[0x3c25, ((0, 2), (1, 2))] = 19600, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3c09, ((1, 3), (2, 3))] = 19600, N[0x3c09, ((1, 3), (2, 3))] = 1
Updated Q[0x3c6b, ((0, 2), (1, 2))] = 19600, N[0x3c6b, ((0, 2), (1, 2))] = 1
Updated Q[0x3c1a, ((1, 2), (1, 3))] = 19600, N[0x3c1a, ((1, 2), (1, 3))] = 1

--- Simulation 439 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.45270170509, 16803.45270170509, 22804.543615169783, 16803.45270170509, 19603.45270170509]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [30501.467405903557, 19601.467405903557, 28601.467405903557, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397e, Score: 8400
Depth 2: State = 0x397e, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397e: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2d4f, Score: 14000
Depth 3: State = 0x2d4f, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 3), (2, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2d4f: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x2af4, Score: 16800
Depth 4: State = 0x2af4, Legal Moves = [((0, 1), (0, 2)), ((3, 3), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2af4: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x2dbc, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9916700, N[0x3c25, ((2, 3), (2, 4))] = 435
Updated Q[0x3c24, ((2, 0), (2, 1))] = 19600, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x397e, ((0, 0), (0, 1))] = 19600, N[0x397e, ((0, 0), (0, 1))] = 1
Updated Q[0x2d4f, ((1, 3), (1, 4))] = 19600, N[0x2d4f, ((1, 3), (1, 4))] = 1
Updated Q[0x2af4, ((0, 1), (0, 2))] = 19600, N[0x2af4, ((0, 1), (0, 2))] = 1

--- Simulation 440 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.453348932504, 16803.453348932504, 22797.17706966091, 16803.453348932504, 19603.453348932504]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.77609073765, 30501.77609073765, 24501.77609073765, 35601.77609073765, 16801.77609073765]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c21, Score: 8400
Depth 2: State = 0x3c21, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c21: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397b, Score: 11200
Depth 3: State = 0x397b, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397b: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3a8a, Score: 14000
Depth 4: State = 0x3a8a, Legal Moves = [((1, 2), (1, 3)), ((2, 4), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3a8a: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4ad1, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9933500, N[0x3c25, ((2, 3), (2, 4))] = 436
Updated Q[0x3c24, ((2, 3), (3, 3))] = 52400, N[0x3c24, ((2, 3), (3, 3))] = 2
Updated Q[0x3c21, ((2, 0), (2, 1))] = 16800, N[0x3c21, ((2, 0), (2, 1))] = 1
Updated Q[0x397b, ((0, 1), (0, 2))] = 16800, N[0x397b, ((0, 1), (0, 2))] = 1
Updated Q[0x3a8a, ((1, 2), (1, 3))] = 16800, N[0x3a8a, ((1, 2), (1, 3))] = 1

--- Simulation 441 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.453994566404, 16803.453994566404, 22783.42229707318, 16803.453994566404, 19603.453994566404]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [25200.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3bfe, Score: 8400
Depth 2: State = 0x3bfe, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bfe: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c5d, Score: 11200
Depth 3: State = 0x3c5d, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5d: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c5d, Score: 14000
Depth 4: State = 0x3c5d, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9947500, N[0x3c25, ((2, 3), (2, 4))] = 437
Updated Q[0x3c24, ((0, 2), (1, 2))] = 14000, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3bfe, ((1, 3), (2, 3))] = 14000, N[0x3bfe, ((1, 3), (2, 3))] = 1
Updated Q[0x3c5d, ((2, 0), (2, 1))] = 14000, N[0x3c5d, ((2, 0), (2, 1))] = 1

--- Simulation 442 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.454638614367, 16803.454638614367, 22763.323152513127, 16803.454638614367, 19603.454638614367]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [24901.648374031523, 25201.648374031523, 25201.648374031523, 16801.648374031523, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x495b, Score: 16100
Depth 2: State = 0x495b, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x495b: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x43ee, Score: 27000
Depth 3: State = 0x43ee, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43ee: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1050, Score: 29800
Depth 4: State = 0x1050, Legal Moves = [((1, 1), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1050: [inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x1029, Score: 32600
End of simulation with depth 5. Reward (Score): 32600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 9980100, N[0x3c25, ((2, 3), (2, 4))] = 438
Updated Q[0x3c25, ((2, 3), (3, 3))] = 32600, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x495b, ((1, 3), (2, 3))] = 32600, N[0x495b, ((1, 3), (2, 3))] = 1
Updated Q[0x43ee, ((0, 0), (0, 1))] = 32600, N[0x43ee, ((0, 0), (0, 1))] = 1
Updated Q[0x1050, ((1, 1), (1, 2))] = 32600, N[0x1050, ((1, 1), (1, 2))] = 1

--- Simulation 443 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.455281083916, 16803.455281083916, 22785.7815380726, 16803.455281083916, 19603.455281083916]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c46, Score: 8400
Depth 1: State = 0x3c46, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c46: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x569c, Score: 11200
Depth 2: State = 0x569c, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x569c: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x5170, Score: 16800
Depth 3: State = 0x5170, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5170: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397c, Score: 25200
Depth 4: State = 0x397c, Legal Moves = [((1, 3), (2, 3))]
UCB1 values for moves at state 0x397c: [inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c6f, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10008100, N[0x3c25, ((2, 3), (2, 4))] = 439
Updated Q[0x3c46, ((0, 0), (1, 0))] = 28000, N[0x3c46, ((0, 0), (1, 0))] = 1
Updated Q[0x569c, ((1, 3), (1, 4))] = 28000, N[0x569c, ((1, 3), (1, 4))] = 1
Updated Q[0x5170, ((2, 0), (2, 1))] = 28000, N[0x5170, ((2, 0), (2, 1))] = 1
Updated Q[0x397c, ((1, 3), (2, 3))] = 28000, N[0x397c, ((1, 3), (2, 3))] = 1

--- Simulation 444 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.455921982524, 16803.455921982524, 22797.65924739615, 16803.455921982524, 19603.455921982524]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.467405903557, 25201.467405903557, 19601.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1f4b, Score: 24400
Depth 2: State = 0x1f4b, Legal Moves = [((1, 3), (1, 4)), ((2, 3), (2, 4)), ((3, 2), (4, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1f4b: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x1bf5, Score: 27200
Depth 3: State = 0x1bf5, Legal Moves = [((0, 3), (0, 4)), ((3, 2), (4, 2)), ((3, 3), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1bf5: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x1bf7, Score: 30000
Depth 4: State = 0x1bf7, Legal Moves = [((0, 3), (1, 3)), ((2, 2), (2, 3)), ((3, 2), (4, 2)), ((3, 3), (3, 4)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1bf7: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x1ca1, Score: 32800
End of simulation with depth 5. Reward (Score): 32800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10040900, N[0x3c25, ((2, 3), (2, 4))] = 440
Updated Q[0x3c24, ((2, 0), (2, 1))] = 32800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x1f4b, ((1, 3), (1, 4))] = 32800, N[0x1f4b, ((1, 3), (1, 4))] = 1
Updated Q[0x1bf5, ((0, 3), (0, 4))] = 32800, N[0x1bf5, ((0, 3), (0, 4))] = 1
Updated Q[0x1bf7, ((0, 3), (1, 3))] = 32800, N[0x1bf7, ((0, 3), (1, 3))] = 1

--- Simulation 445 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.456561317606, 16803.456561317606, 22820.39205782246, 16803.456561317606, 19603.456561317606]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 21701.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4852, Score: 11200
Depth 2: State = 0x4852, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((1, 0), (1, 1)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 4), (2, 4)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x4852: [inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x21c8, Score: 16100
Depth 3: State = 0x21c8, Legal Moves = [((0, 0), (0, 1)), ((0, 0), (1, 0)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x21c8: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x15bd, Score: 21700
Depth 4: State = 0x15bd, Legal Moves = [((0, 0), (1, 0)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((4, 0), (4, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x15bd: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3d71, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10065400, N[0x3c25, ((2, 3), (2, 4))] = 441
Updated Q[0x3c25, ((2, 0), (2, 1))] = 24500, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x4852, ((0, 1), (1, 1))] = 24500, N[0x4852, ((0, 1), (1, 1))] = 1
Updated Q[0x21c8, ((0, 0), (0, 1))] = 24500, N[0x21c8, ((0, 0), (0, 1))] = 1
Updated Q[0x15bd, ((0, 0), (1, 0))] = 24500, N[0x15bd, ((0, 0), (1, 0))] = 1

--- Simulation 446 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.45719909653, 16803.45719909653, 22824.200909707546, 16803.45719909653, 19603.45719909653]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x495e, Score: 8400
Depth 2: State = 0x495e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x495e: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4671, Score: 11200
Depth 3: State = 0x4671, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4671: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x4a43, Score: 18900
Depth 4: State = 0x4a43, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a43: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3712, Score: 26500
End of simulation with depth 5. Reward (Score): 26500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10091900, N[0x3c25, ((2, 3), (2, 4))] = 442
Updated Q[0x3c25, ((0, 0), (0, 1))] = 26500, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x495e, ((1, 3), (2, 3))] = 26500, N[0x495e, ((1, 3), (2, 3))] = 1
Updated Q[0x4671, ((1, 2), (1, 3))] = 26500, N[0x4671, ((1, 2), (1, 3))] = 1
Updated Q[0x4a43, ((1, 1), (2, 1))] = 26500, N[0x4a43, ((1, 1), (2, 1))] = 1

--- Simulation 447 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.45783532661, 16803.45783532661, 22832.517413630438, 16803.45783532661, 19603.45783532661]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bfc, Score: 8400
Depth 1: State = 0x3bfc, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3bfc: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3bbc, Score: 11200
Depth 2: State = 0x3bbc, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbc: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3bff, Score: 14000
Depth 3: State = 0x3bff, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bff: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x371d, Score: 16800
Depth 4: State = 0x371d, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 0), (3, 0)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x371d: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3719, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10111500, N[0x3c25, ((2, 3), (2, 4))] = 443
Updated Q[0x3bfc, ((1, 2), (2, 2))] = 19600, N[0x3bfc, ((1, 2), (2, 2))] = 1
Updated Q[0x3bbc, ((0, 3), (1, 3))] = 19600, N[0x3bbc, ((0, 3), (1, 3))] = 1
Updated Q[0x3bff, ((1, 3), (2, 3))] = 19600, N[0x3bff, ((1, 3), (2, 3))] = 1
Updated Q[0x371d, ((0, 3), (1, 3))] = 19600, N[0x371d, ((0, 3), (1, 3))] = 1

--- Simulation 448 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.458470015114, 16803.458470015114, 22825.220750277804, 16803.458470015114, 19603.458470015114]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bbf, Score: 8400
Depth 1: State = 0x3bbf, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbf: [19600.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3ab7, Score: 16100
Depth 2: State = 0x3ab7, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3ab7: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3ab7, Score: 18900
Depth 3: State = 0x3ab7, Legal Moves = [((3, 1), (4, 1))]
UCB1 values for moves at state 0x3ab7: [inf]
Selected move: ((3, 1), (4, 1))
New board state after move: 0x37e9, Score: 27300
Depth 4: State = 0x37e9, Legal Moves = [((2, 2), (3, 2)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x37e9: [inf, inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x307e, Score: 32900
End of simulation with depth 5. Reward (Score): 32900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10144400, N[0x3c25, ((2, 3), (2, 4))] = 444
Updated Q[0x3bbf, ((1, 3), (2, 3))] = 32900, N[0x3bbf, ((1, 3), (2, 3))] = 1
Updated Q[0x3ab7, ((2, 0), (2, 1))] = 32900, N[0x3ab7, ((2, 0), (2, 1))] = 1
Updated Q[0x3ab7, ((3, 1), (4, 1))] = 32900, N[0x3ab7, ((3, 1), (4, 1))] = 1
Updated Q[0x37e9, ((2, 2), (3, 2))] = 32900, N[0x37e9, ((2, 2), (3, 2))] = 1

--- Simulation 449 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.459103169254, 16803.459103169254, 22847.91190951931, 16803.459103169254, 19603.459103169254]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x45b3, Score: 8400
Depth 2: State = 0x45b3, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x45b3: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4afa, Score: 11200
Depth 3: State = 0x4afa, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4afa: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x47af, Score: 14000
Depth 4: State = 0x47af, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47af: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4a54, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10161200, N[0x3c25, ((2, 3), (2, 4))] = 445
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x45b3, ((1, 3), (1, 4))] = 16800, N[0x45b3, ((1, 3), (1, 4))] = 1
Updated Q[0x4afa, ((0, 1), (1, 1))] = 16800, N[0x4afa, ((0, 1), (1, 1))] = 1
Updated Q[0x47af, ((2, 0), (2, 1))] = 16800, N[0x47af, ((2, 0), (2, 1))] = 1

--- Simulation 450 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.45973479619, 16803.45973479619, 22834.321310529165, 16803.45973479619, 19603.45973479619]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19600.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3724, Score: 16100
Depth 2: State = 0x3724, Legal Moves = [((0, 4), (1, 4)), ((1, 1), (2, 1)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3724: [inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x36e0, Score: 21700
Depth 3: State = 0x36e0, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x36e0: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x53fe, Score: 24500
Depth 4: State = 0x53fe, Legal Moves = [((0, 3), (1, 3)), ((1, 1), (2, 1)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x53fe: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x5437, Score: 27300
End of simulation with depth 5. Reward (Score): 27300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10188500, N[0x3c25, ((2, 3), (2, 4))] = 446
Updated Q[0x3c24, ((1, 3), (2, 3))] = 27300, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3724, ((0, 4), (1, 4))] = 27300, N[0x3724, ((0, 4), (1, 4))] = 1
Updated Q[0x36e0, ((0, 1), (1, 1))] = 27300, N[0x36e0, ((0, 1), (1, 1))] = 1
Updated Q[0x53fe, ((0, 3), (1, 3))] = 27300, N[0x53fe, ((0, 3), (1, 3))] = 1

--- Simulation 451 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.460364903043, 16803.460364903043, 22844.33425661454, 16803.460364903043, 19603.460364903043]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22400.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d52, Score: 19600
Depth 2: State = 0x3d52, Legal Moves = [((0, 2), (1, 2)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3d52: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3d4e, Score: 22400
Depth 3: State = 0x3d4e, Legal Moves = [((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3d4e: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3d52, Score: 25200
Depth 4: State = 0x3d52, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((4, 2), (4, 3))]
UCB1 values for moves at state 0x3d52: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c6f, Score: 30800
End of simulation with depth 5. Reward (Score): 30800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10219300, N[0x3c25, ((2, 3), (2, 4))] = 447
Updated Q[0x3c24, ((1, 3), (2, 3))] = 30800, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3d52, ((0, 2), (1, 2))] = 30800, N[0x3d52, ((0, 2), (1, 2))] = 1
Updated Q[0x3d4e, ((0, 3), (1, 3))] = 30800, N[0x3d4e, ((0, 3), (1, 3))] = 1
Updated Q[0x3d52, ((2, 0), (2, 1))] = 30800, N[0x3d52, ((2, 0), (2, 1))] = 1

--- Simulation 452 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.460993496876, 16803.460993496876, 22862.13237946464, 16803.460993496876, 19603.460993496876]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c6f, Score: 11200
Depth 1: State = 0x3c6f, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6f: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3be7, Score: 14000
Depth 2: State = 0x3be7, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be7: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3866, Score: 21700
Depth 3: State = 0x3866, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3866: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x1597, Score: 27300
Depth 4: State = 0x1597, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1597: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1444, Score: 30100
End of simulation with depth 5. Reward (Score): 30100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10249400, N[0x3c25, ((2, 3), (2, 4))] = 448
Updated Q[0x3c6f, ((1, 2), (2, 2))] = 30100, N[0x3c6f, ((1, 2), (2, 2))] = 1
Updated Q[0x3be7, ((1, 3), (1, 4))] = 30100, N[0x3be7, ((1, 3), (1, 4))] = 1
Updated Q[0x3866, ((0, 2), (1, 2))] = 30100, N[0x3866, ((0, 2), (1, 2))] = 1
Updated Q[0x1597, ((2, 0), (2, 1))] = 30100, N[0x1597, ((2, 0), (2, 1))] = 1

--- Simulation 453 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.46162058471, 16803.46162058471, 22878.28854620001, 16803.46162058471, 19603.46162058471]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c6c, Score: 11200
Depth 2: State = 0x3c6c, Legal Moves = [((0, 1), (0, 2)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6c: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3d51, Score: 14000
Depth 3: State = 0x3d51, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d51: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3d3a, Score: 16800
Depth 4: State = 0x3d3a, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3d3a: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c2b, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10271800, N[0x3c25, ((2, 3), (2, 4))] = 449
Updated Q[0x3c24, ((1, 2), (2, 2))] = 22400, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3c6c, ((0, 1), (0, 2))] = 22400, N[0x3c6c, ((0, 1), (0, 2))] = 1
Updated Q[0x3d51, ((1, 2), (2, 2))] = 22400, N[0x3d51, ((1, 2), (2, 2))] = 1
Updated Q[0x3d3a, ((2, 0), (2, 1))] = 22400, N[0x3d3a, ((2, 0), (2, 1))] = 1

--- Simulation 454 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.462246173505, 16803.462246173505, 22877.223527129423, 16803.462246173505, 19603.462246173505]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [24401.16557645562, 22401.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3d14, Score: 16100
Depth 2: State = 0x3d14, Legal Moves = [((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d14: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3ab2, Score: 21700
Depth 3: State = 0x3ab2, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 21700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10293500, N[0x3c25, ((2, 3), (2, 4))] = 450
Updated Q[0x3c25, ((1, 3), (2, 3))] = 21700, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3d14, ((2, 0), (2, 1))] = 21700, N[0x3d14, ((2, 0), (2, 1))] = 1

--- Simulation 455 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.46287027019, 16803.46287027019, 22874.607685714473, 16803.46287027019, 19603.46287027019]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3be0, Score: 8400
Depth 1: State = 0x3be0, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be0: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3800, Score: 14000
Depth 2: State = 0x3800, Legal Moves = [((0, 1), (0, 2)), ((1, 1), (1, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3800: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x390f, Score: 16800
Depth 3: State = 0x390f, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x390f: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x391c, Score: 19600
Depth 4: State = 0x391c, Legal Moves = [((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x391c: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d15, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10315900, N[0x3c25, ((2, 3), (2, 4))] = 451
Updated Q[0x3be0, ((1, 3), (2, 3))] = 22400, N[0x3be0, ((1, 3), (2, 3))] = 1
Updated Q[0x3800, ((0, 1), (0, 2))] = 22400, N[0x3800, ((0, 1), (0, 2))] = 1
Updated Q[0x390f, ((1, 3), (2, 3))] = 22400, N[0x390f, ((1, 3), (2, 3))] = 1
Updated Q[0x391c, ((2, 0), (2, 1))] = 22400, N[0x391c, ((2, 0), (2, 1))] = 1

--- Simulation 456 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.463492881638, 16803.463492881638, 22873.555550707544, 16803.463492881638, 19603.463492881638]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a6c, Score: 8400
Depth 2: State = 0x4a6c, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a6c: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x46d9, Score: 11200
Depth 3: State = 0x46d9, Legal Moves = [((0, 1), (0, 2)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46d9: [inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x49ab, Score: 16800
Depth 4: State = 0x49ab, Legal Moves = [((0, 1), (1, 1)), ((1, 2), (1, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x49ab: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x43b0, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10335500, N[0x3c25, ((2, 3), (2, 4))] = 452
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a6c, ((1, 3), (2, 3))] = 19600, N[0x4a6c, ((1, 3), (2, 3))] = 1
Updated Q[0x46d9, ((0, 1), (0, 2))] = 19600, N[0x46d9, ((0, 1), (0, 2))] = 1
Updated Q[0x49ab, ((0, 1), (1, 1))] = 19600, N[0x49ab, ((0, 1), (1, 1))] = 1

--- Simulation 457 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.46411401467, 16803.46411401467, 22866.31338069508, 16803.46411401467, 19603.46411401467]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 8400
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22401.16557645562, 19601.16557645562, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c61, Score: 11200
Depth 2: State = 0x3c61, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c61: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3829, Score: 14000
Depth 3: State = 0x3829, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3829: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3855, Score: 16800
Depth 4: State = 0x3855, Legal Moves = [((1, 2), (1, 3)), ((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3855: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x3855, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10355100, N[0x3c25, ((2, 3), (2, 4))] = 453
Updated Q[0x3c25, ((0, 4), (1, 4))] = 19600, N[0x3c25, ((0, 4), (1, 4))] = 1
Updated Q[0x3c61, ((1, 3), (2, 3))] = 19600, N[0x3c61, ((1, 3), (2, 3))] = 1
Updated Q[0x3829, ((1, 3), (2, 3))] = 19600, N[0x3829, ((1, 3), (2, 3))] = 1
Updated Q[0x3855, ((1, 2), (1, 3))] = 19600, N[0x3855, ((1, 2), (1, 3))] = 1

--- Simulation 458 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.46473367608, 16803.46473367608, 22859.10318473956, 16803.46473367608, 19603.46473367608]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4829, Score: 8400
Depth 2: State = 0x4829, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4829: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x52a5, Score: 14000
Depth 3: State = 0x52a5, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x52a5: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x53cc, Score: 29300
Depth 4: State = 0x53cc, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1))]
UCB1 values for moves at state 0x53cc: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x47e2, Score: 32100
End of simulation with depth 5. Reward (Score): 32100
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10387200, N[0x3c25, ((2, 3), (2, 4))] = 454
Updated Q[0x3c25, ((0, 0), (0, 1))] = 32100, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4829, ((1, 3), (2, 3))] = 32100, N[0x4829, ((1, 3), (2, 3))] = 1
Updated Q[0x52a5, ((0, 1), (1, 1))] = 32100, N[0x52a5, ((0, 1), (1, 1))] = 1
Updated Q[0x53cc, ((1, 1), (2, 1))] = 32100, N[0x53cc, ((1, 1), (2, 1))] = 1

--- Simulation 459 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.46535187259, 16803.46535187259, 22879.457791206893, 16803.46535187259, 19603.46535187259]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c25, Score: 8400
Depth 2: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43d2, Score: 11200
Depth 3: State = 0x43d2, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43d2: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x442d, Score: 27700
Depth 4: State = 0x442d, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x442d: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x442d, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10417700, N[0x3c25, ((2, 3), (2, 4))] = 455
Updated Q[0x3c24, ((0, 4), (1, 4))] = 30500, N[0x3c24, ((0, 4), (1, 4))] = 1
Updated Q[0x3c25, ((0, 0), (0, 1))] = 30500, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x43d2, ((1, 2), (2, 2))] = 30500, N[0x43d2, ((1, 2), (2, 2))] = 1
Updated Q[0x442d, ((2, 0), (2, 1))] = 30500, N[0x442d, ((2, 0), (2, 1))] = 1

--- Simulation 460 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.465968610897, 16803.465968610897, 22896.206443158655, 16803.465968610897, 19603.465968610897]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [22401.16557645562, 30801.16557645562, inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397e, Score: 8400
Depth 2: State = 0x397e, Legal Moves = [((0, 0), (0, 1)), ((0, 1), (1, 1)), ((0, 2), (1, 2)), ((1, 2), (2, 2)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397e: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2bd6, Score: 11200
Depth 3: State = 0x2bd6, Legal Moves = [((1, 2), (2, 2)), ((2, 1), (2, 2)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2bd6: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x294f, Score: 14000
Depth 4: State = 0x294f, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((2, 1), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x294f: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x2aef, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10434500, N[0x3c25, ((2, 3), (2, 4))] = 456
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x397e, ((0, 0), (0, 1))] = 16800, N[0x397e, ((0, 0), (0, 1))] = 1
Updated Q[0x2bd6, ((1, 2), (2, 2))] = 16800, N[0x2bd6, ((1, 2), (2, 2))] = 1
Updated Q[0x294f, ((0, 2), (1, 2))] = 16800, N[0x294f, ((0, 2), (1, 2))] = 1

--- Simulation 461 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.46658389764, 16803.46658389764, 22882.837776261153, 16803.46658389764, 19603.46658389764]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16800.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3674, Score: 11200
Depth 2: State = 0x3674, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3674: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3a85, Score: 18900
Depth 3: State = 0x3a85, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3a85: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3d9a, Score: 21700
Depth 4: State = 0x3d9a, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3d9a: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3a8f, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10459000, N[0x3c25, ((2, 3), (2, 4))] = 457
Updated Q[0x3c25, ((0, 2), (1, 2))] = 24500, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3674, ((1, 3), (2, 3))] = 24500, N[0x3674, ((1, 3), (2, 3))] = 1
Updated Q[0x3a85, ((0, 3), (1, 3))] = 24500, N[0x3a85, ((0, 3), (1, 3))] = 1
Updated Q[0x3d9a, ((1, 1), (2, 1))] = 24500, N[0x3d9a, ((1, 1), (2, 1))] = 1

--- Simulation 462 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.467197739425, 16803.467197739425, 22886.376630682505, 16803.467197739425, 19603.467197739425]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x456e, Score: 8400
Depth 2: State = 0x456e, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x456e: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x479e, Score: 11200
Depth 3: State = 0x479e, Legal Moves = [((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x479e: [inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x47ab, Score: 16800
Depth 4: State = 0x47ab, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47ab: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x47ab, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10481400, N[0x3c25, ((2, 3), (2, 4))] = 458
Updated Q[0x3c24, ((0, 0), (0, 1))] = 22400, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x456e, ((1, 3), (2, 3))] = 22400, N[0x456e, ((1, 3), (2, 3))] = 1
Updated Q[0x479e, ((1, 2), (1, 3))] = 22400, N[0x479e, ((1, 2), (1, 3))] = 1
Updated Q[0x47ab, ((2, 0), (2, 1))] = 22400, N[0x47ab, ((2, 0), (2, 1))] = 1

--- Simulation 463 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.467810142804, 16803.467810142804, 22885.314878554433, 16803.467810142804, 19603.467810142804]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3bbb, Score: 11200
Depth 2: State = 0x3bbb, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bbb: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d0d, Score: 14000
Depth 3: State = 0x3d0d, Legal Moves = [((1, 1), (2, 1)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x3d0d: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x399d, Score: 16800
Depth 4: State = 0x399d, Legal Moves = [((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x399d: [inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3d76, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10505900, N[0x3c25, ((2, 3), (2, 4))] = 459
Updated Q[0x3c24, ((1, 3), (2, 3))] = 24500, N[0x3c24, ((1, 3), (2, 3))] = 1
Updated Q[0x3bbb, ((2, 0), (2, 1))] = 24500, N[0x3bbb, ((2, 0), (2, 1))] = 1
Updated Q[0x3d0d, ((1, 1), (2, 1))] = 24500, N[0x3d0d, ((1, 1), (2, 1))] = 1
Updated Q[0x399d, ((1, 2), (2, 2))] = 24500, N[0x399d, ((1, 2), (2, 2))] = 1

--- Simulation 464 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.468421114285, 16803.468421114285, 22888.832915998784, 16803.468421114285, 19603.468421114285]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bc2, Score: 11200
Depth 1: State = 0x3bc2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bc2: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x37e5, Score: 14000
Depth 2: State = 0x37e5, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37e5: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x371a, Score: 19600
Depth 3: State = 0x371a, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x371a: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x386d, Score: 22400
Depth 4: State = 0x386d, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10528300, N[0x3c25, ((2, 3), (2, 4))] = 460
Updated Q[0x3bc2, ((1, 3), (2, 3))] = 22400, N[0x3bc2, ((1, 3), (2, 3))] = 1
Updated Q[0x37e5, ((1, 2), (1, 3))] = 22400, N[0x37e5, ((1, 2), (1, 3))] = 1
Updated Q[0x371a, ((2, 0), (2, 1))] = 22400, N[0x371a, ((2, 0), (2, 1))] = 1

--- Simulation 465 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.469030660337, 16803.469030660337, 22887.770440040706, 16803.469030660337, 19603.469030660337]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.467405903557, 22401.467405903557, 35701.46740590355, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x39c7, Score: 11200
Depth 2: State = 0x39c7, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x39c7: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3dbf, Score: 14000
Depth 3: State = 0x3dbf, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10542300, N[0x3c25, ((2, 3), (2, 4))] = 461
Updated Q[0x3c25, ((2, 3), (3, 3))] = 14000, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x39c7, ((2, 0), (2, 1))] = 14000, N[0x39c7, ((2, 0), (2, 1))] = 1

--- Simulation 466 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.46963878739, 16803.46963878739, 22868.491315193183, 16803.46963878739, 19603.46963878739]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4678, Score: 8400
Depth 2: State = 0x4678, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4678: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4a8f, Score: 11200
Depth 3: State = 0x4a8f, Legal Moves = [((0, 1), (1, 1)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a8f: [inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x469a, Score: 14000
Depth 4: State = 0x469a, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x469a: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x4940, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10559100, N[0x3c25, ((2, 3), (2, 4))] = 462
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4678, ((1, 3), (1, 4))] = 16800, N[0x4678, ((1, 3), (1, 4))] = 1
Updated Q[0x4a8f, ((0, 1), (1, 1))] = 16800, N[0x4a8f, ((0, 1), (1, 1))] = 1
Updated Q[0x469a, ((2, 0), (2, 1))] = 16800, N[0x469a, ((2, 0), (2, 1))] = 1

--- Simulation 467 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.470245501816, 16803.470245501816, 22855.356255627088, 16803.470245501816, 19603.470245501816]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3c25: [16801.467405903557, 19601.467405903557, 30501.467405903557, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3bda, Score: 8400
Depth 2: State = 0x3bda, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bda: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3677, Score: 11200
Depth 3: State = 0x3677, Legal Moves = [((1, 1), (2, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3677: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x3699, Score: 14000
Depth 4: State = 0x3699, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3699: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3a91, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10575900, N[0x3c25, ((2, 3), (2, 4))] = 463
Updated Q[0x3c25, ((0, 4), (1, 4))] = 16800, N[0x3c25, ((0, 4), (1, 4))] = 1
Updated Q[0x3bda, ((1, 3), (2, 3))] = 16800, N[0x3bda, ((1, 3), (2, 3))] = 1
Updated Q[0x3677, ((1, 1), (2, 1))] = 16800, N[0x3677, ((1, 1), (2, 1))] = 1
Updated Q[0x3699, ((2, 0), (2, 1))] = 16800, N[0x3699, ((2, 0), (2, 1))] = 1

--- Simulation 468 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.470850809965, 16803.470850809965, 22842.277934786118, 16803.470850809965, 19603.470850809965]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.467405903557, 21701.467405903557, 25201.467405903557, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x397f, Score: 8400
Depth 2: State = 0x397f, Legal Moves = [((0, 0), (0, 1)), ((1, 0), (1, 1)), ((1, 2), (2, 2)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x397f: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2fed, Score: 11200
Depth 3: State = 0x2fed, Legal Moves = [((1, 0), (1, 1)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2fed: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x2aa2, Score: 14000
Depth 4: State = 0x2aa2, Legal Moves = [((1, 2), (1, 3)), ((1, 2), (2, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x2aa2: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x2aa9, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10592700, N[0x3c25, ((2, 3), (2, 4))] = 464
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x397f, ((0, 0), (0, 1))] = 16800, N[0x397f, ((0, 0), (0, 1))] = 1
Updated Q[0x2fed, ((1, 0), (1, 1))] = 16800, N[0x2fed, ((1, 0), (1, 1))] = 1
Updated Q[0x2aa2, ((1, 2), (1, 3))] = 16800, N[0x2aa2, ((1, 2), (1, 3))] = 1

--- Simulation 469 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.471454718125, 16803.471454718125, 22829.255985825668, 16803.471454718125, 19603.471454718125]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [30501.648374031523, 19601.648374031523, 28601.648374031523, 19601.648374031523, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x384b, Score: 23200
Depth 2: State = 0x384b, Legal Moves = [((0, 2), (1, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x384b: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x5787, Score: 26000
Depth 3: State = 0x5787, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x5787: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x5634, Score: 28800
Depth 4: State = 0x5634, Legal Moves = [((0, 2), (1, 2)), ((1, 1), (2, 1)), ((1, 2), (2, 2))]
UCB1 values for moves at state 0x5634: [inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x528a, Score: 31600
End of simulation with depth 5. Reward (Score): 31600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10624300, N[0x3c25, ((2, 3), (2, 4))] = 465
Updated Q[0x3c24, ((2, 3), (2, 4))] = 31600, N[0x3c24, ((2, 3), (2, 4))] = 1
Updated Q[0x384b, ((0, 2), (1, 2))] = 31600, N[0x384b, ((0, 2), (1, 2))] = 1
Updated Q[0x5787, ((2, 0), (2, 1))] = 31600, N[0x5787, ((2, 0), (2, 1))] = 1
Updated Q[0x5634, ((0, 2), (1, 2))] = 31600, N[0x5634, ((0, 2), (1, 2))] = 1

--- Simulation 470 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.472057232557, 16803.472057232557, 22848.118002046016, 16803.472057232557, 19603.472057232557]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [27700.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3c24, Score: 8400
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a69, Score: 11200
Depth 3: State = 0x4a69, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a69: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4591, Score: 14000
Depth 4: State = 0x4591, Legal Moves = [((0, 1), (0, 2)), ((0, 1), (1, 1)), ((1, 1), (1, 2)), ((1, 1), (2, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4591: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4aba, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10643900, N[0x3c25, ((2, 3), (2, 4))] = 466
Updated Q[0x3c24, ((0, 4), (1, 4))] = 19600, N[0x3c24, ((0, 4), (1, 4))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a69, ((1, 3), (2, 3))] = 19600, N[0x4a69, ((1, 3), (2, 3))] = 1
Updated Q[0x4591, ((0, 1), (0, 2))] = 19600, N[0x4591, ((0, 1), (0, 2))] = 1

--- Simulation 471 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.472658359475, 16803.472658359475, 22841.14799225559, 16803.472658359475, 19603.472658359475]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.648374031523, 27301.648374031523, 19601.648374031523, 16801.648374031523, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x3c65, Score: 16800
Depth 2: State = 0x3c65, Legal Moves = [((2, 2), (3, 2))]
UCB1 values for moves at state 0x3c65: [inf]
Selected move: ((2, 2), (3, 2))
New board state after move: 0x3c24, Score: 22400
Depth 3: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 4), (1, 4)), ((1, 2), (2, 2))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4af0, Score: 25200
Depth 4: State = 0x4af0, Legal Moves = [((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 2), (1, 3)), ((1, 2), (2, 2))]
UCB1 values for moves at state 0x4af0: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x4ab3, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10671900, N[0x3c25, ((2, 3), (2, 4))] = 467
Updated Q[0x3c25, ((3, 0), (3, 1))] = 28000, N[0x3c25, ((3, 0), (3, 1))] = 1
Updated Q[0x3c65, ((2, 2), (3, 2))] = 28000, N[0x3c65, ((2, 2), (3, 2))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 28000, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4af0, ((0, 2), (1, 2))] = 28000, N[0x4af0, ((0, 2), (1, 2))] = 1

--- Simulation 472 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.47325810505, 16803.47325810505, 22852.194984459336, 16803.47325810505, 19603.47325810505]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [21700.0, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3867, Score: 19300
Depth 2: State = 0x3867, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3867: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3867, Score: 24900
Depth 3: State = 0x3867, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3867: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3b0c, Score: 27700
Depth 4: State = 0x3b0c, Legal Moves = [((2, 1), (3, 1)), ((2, 3), (2, 4)), ((3, 1), (4, 1))]
UCB1 values for moves at state 0x3b0c: [inf, inf, inf]
Selected move: ((2, 1), (3, 1))
New board state after move: 0x45a3, Score: 33300
End of simulation with depth 5. Reward (Score): 33300
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10705200, N[0x3c25, ((2, 3), (2, 4))] = 468
Updated Q[0x3c25, ((1, 3), (1, 4))] = 33300, N[0x3c25, ((1, 3), (1, 4))] = 1
Updated Q[0x3867, ((0, 2), (1, 2))] = 33300, N[0x3867, ((0, 2), (1, 2))] = 1
Updated Q[0x3867, ((2, 0), (2, 1))] = 33300, N[0x3867, ((2, 0), (2, 1))] = 1
Updated Q[0x3b0c, ((2, 1), (3, 1))] = 33300, N[0x3b0c, ((2, 1), (3, 1))] = 1

--- Simulation 473 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.47385647541, 16803.47385647541, 22874.519553431353, 16803.47385647541, 19603.47385647541]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 8400
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x451a, Score: 11200
Depth 2: State = 0x451a, Legal Moves = [((0, 3), (0, 4)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x451a: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x47f2, Score: 14000
Depth 3: State = 0x47f2, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47f2: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4411, Score: 16800
Depth 4: State = 0x4411, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4411: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x4411, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10724800, N[0x3c25, ((2, 3), (2, 4))] = 469
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x451a, ((0, 3), (0, 4))] = 19600, N[0x451a, ((0, 3), (0, 4))] = 1
Updated Q[0x47f2, ((1, 3), (2, 3))] = 19600, N[0x47f2, ((1, 3), (2, 3))] = 1
Updated Q[0x4411, ((1, 3), (1, 4))] = 19600, N[0x4411, ((1, 3), (1, 4))] = 1

--- Simulation 474 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.474453476654, 16803.474453476654, 22867.537834075625, 16803.474453476654, 19603.474453476654]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 32801.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x382d, Score: 8400
Depth 2: State = 0x382d, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x382d: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x200f, Score: 11200
Depth 3: State = 0x200f, Legal Moves = [((0, 0), (0, 1)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x200f: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x3844, Score: 14000
Depth 4: State = 0x3844, Legal Moves = [((1, 2), (1, 3)), ((3, 1), (3, 2)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3844: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x386d, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10744400, N[0x3c25, ((2, 3), (2, 4))] = 470
Updated Q[0x3c25, ((2, 0), (2, 1))] = 19600, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x382d, ((0, 0), (0, 1))] = 19600, N[0x382d, ((0, 0), (0, 1))] = 1
Updated Q[0x200f, ((0, 0), (0, 1))] = 19600, N[0x200f, ((0, 0), (0, 1))] = 1
Updated Q[0x3844, ((1, 2), (1, 3))] = 19600, N[0x3844, ((1, 2), (1, 3))] = 1

--- Simulation 475 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.475049114837, 16803.475049114837, 22860.585823977788, 16803.475049114837, 19603.475049114837]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22401.648374031523, 19601.648374031523, 16801.648374031523, 39501.64837403152, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3ab0, Score: 11200
Depth 2: State = 0x3ab0, Legal Moves = [((0, 2), (0, 3)), ((0, 2), (1, 2)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3ab0: [inf, inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x47c7, Score: 14000
Depth 3: State = 0x47c7, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c7: [inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x47c0, Score: 16800
Depth 4: State = 0x47c0, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x47c0: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x451b, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10764000, N[0x3c25, ((2, 3), (2, 4))] = 471
Updated Q[0x3c25, ((2, 3), (3, 3))] = 19600, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3ab0, ((0, 2), (0, 3))] = 19600, N[0x3ab0, ((0, 2), (0, 3))] = 1
Updated Q[0x47c7, ((1, 3), (1, 4))] = 19600, N[0x47c7, ((1, 3), (1, 4))] = 1
Updated Q[0x47c0, ((2, 0), (2, 1))] = 19600, N[0x47c0, ((2, 0), (2, 1))] = 1

--- Simulation 476 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.475643395963, 16803.475643395963, 22853.663333907458, 16803.475643395963, 19603.475643395963]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x452b, Score: 8400
Depth 2: State = 0x452b, Legal Moves = [((0, 3), (0, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x452b: [inf, inf, inf, inf]
Selected move: ((0, 3), (0, 4))
New board state after move: 0x43f1, Score: 11200
Depth 3: State = 0x43f1, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43f1: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x43aa, Score: 14000
Depth 4: State = 0x43aa, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43aa: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x43b1, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10780800, N[0x3c25, ((2, 3), (2, 4))] = 472
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x452b, ((0, 3), (0, 4))] = 16800, N[0x452b, ((0, 3), (0, 4))] = 1
Updated Q[0x43f1, ((1, 3), (2, 3))] = 16800, N[0x43f1, ((1, 3), (2, 3))] = 1
Updated Q[0x43aa, ((1, 3), (1, 4))] = 16800, N[0x43aa, ((1, 3), (1, 4))] = 1

--- Simulation 477 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.476236326012, 16803.476236326012, 22840.837972848072, 16803.476236326012, 19603.476236326012]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.648374031523, 19601.648374031523, 21601.648374031523, 22401.648374031523, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c2c, Score: 8400
Depth 2: State = 0x3c2c, Legal Moves = [((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c2c: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x3c2c, Score: 11200
Depth 3: State = 0x3c2c, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c2c: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1478, Score: 19600
Depth 4: State = 0x1478, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1478: [inf, inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x47f3, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10803200, N[0x3c25, ((2, 3), (2, 4))] = 473
Updated Q[0x3c25, ((2, 3), (3, 3))] = 22400, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3c2c, ((1, 3), (1, 4))] = 22400, N[0x3c2c, ((1, 3), (1, 4))] = 1
Updated Q[0x3c2c, ((2, 0), (2, 1))] = 22400, N[0x3c2c, ((2, 0), (2, 1))] = 1
Updated Q[0x1478, ((1, 1), (2, 1))] = 22400, N[0x1478, ((1, 1), (2, 1))] = 1

--- Simulation 478 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.47682791092, 16803.47682791092, 22839.90616492908, 16803.47682791092, 19603.47682791092]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [14001.648374031522, 19601.648374031523, 27301.648374031523, 19601.648374031523, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c27, Score: 8400
Depth 2: State = 0x3c27, Legal Moves = [((1, 3), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c27: [inf, inf, inf]
Selected move: ((1, 3), (1, 4))
New board state after move: 0x380d, Score: 11200
Depth 3: State = 0x380d, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x380d: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x11cd, Score: 14000
Depth 4: State = 0x11cd, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x11cd: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x1212, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10820000, N[0x3c25, ((2, 3), (2, 4))] = 474
Updated Q[0x3c24, ((2, 3), (3, 3))] = 16800, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x3c27, ((1, 3), (1, 4))] = 16800, N[0x3c27, ((1, 3), (1, 4))] = 1
Updated Q[0x380d, ((1, 2), (1, 3))] = 16800, N[0x380d, ((1, 2), (1, 3))] = 1
Updated Q[0x11cd, ((1, 2), (2, 2))] = 16800, N[0x11cd, ((1, 2), (2, 2))] = 1

--- Simulation 479 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.477418156577, 16803.477418156577, 22827.163942515122, 16803.477418156577, 19603.477418156577]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3bb8, Score: 8400
Depth 1: State = 0x3bb8, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb8: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3673, Score: 11200
Depth 2: State = 0x3673, Legal Moves = [((0, 3), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3673: [inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x3677, Score: 14000
Depth 3: State = 0x3677, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (0, 4)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3677: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3bf8, Score: 16800
Depth 4: State = 0x3bf8, Legal Moves = [((1, 1), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bf8: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 1), (1, 2))
New board state after move: 0x3be8, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10842400, N[0x3c25, ((2, 3), (2, 4))] = 475
Updated Q[0x3bb8, ((1, 3), (2, 3))] = 22400, N[0x3bb8, ((1, 3), (2, 3))] = 1
Updated Q[0x3673, ((0, 3), (1, 3))] = 22400, N[0x3673, ((0, 3), (1, 3))] = 1
Updated Q[0x3677, ((0, 1), (1, 1))] = 22400, N[0x3677, ((0, 1), (1, 1))] = 1
Updated Q[0x3bf8, ((1, 1), (1, 2))] = 22400, N[0x3bf8, ((1, 1), (1, 2))] = 1

--- Simulation 480 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.478007068843, 16803.478007068843, 22826.264845066715, 16803.478007068843, 19603.478007068843]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.467405903557, 32801.46740590355, 19601.467405903557, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c28, Score: 8400
Depth 2: State = 0x3c28, Legal Moves = [((0, 1), (0, 2)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c28: [inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x3a70, Score: 11200
Depth 3: State = 0x3a70, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3a70: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x37ca, Score: 14000
Depth 4: State = 0x37ca, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x37ca: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x3833, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10859200, N[0x3c25, ((2, 3), (2, 4))] = 476
Updated Q[0x3c25, ((2, 3), (3, 3))] = 16800, N[0x3c25, ((2, 3), (3, 3))] = 1
Updated Q[0x3c28, ((0, 1), (0, 2))] = 16800, N[0x3c28, ((0, 1), (0, 2))] = 1
Updated Q[0x3a70, ((2, 0), (2, 1))] = 16800, N[0x3a70, ((2, 0), (2, 1))] = 1
Updated Q[0x37ca, ((4, 1), (4, 2))] = 16800, N[0x37ca, ((4, 1), (4, 2))] = 1

--- Simulation 481 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.47859465354, 16803.47859465354, 22813.604819275795, 16803.47859465354, 19603.47859465354]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [30500.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c3d, Score: 19300
Depth 2: State = 0x3c3d, Legal Moves = [((0, 0), (1, 0)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c3d: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3bb5, Score: 22100
Depth 3: State = 0x3bb5, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3bb5: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x37bd, Score: 24900
Depth 4: State = 0x37bd, Legal Moves = [((1, 1), (2, 1))]
UCB1 values for moves at state 0x37bd: [inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x1205, Score: 30500
End of simulation with depth 5. Reward (Score): 30500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10889700, N[0x3c25, ((2, 3), (2, 4))] = 477
Updated Q[0x3c25, ((1, 3), (2, 3))] = 30500, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3c3d, ((0, 0), (1, 0))] = 30500, N[0x3c3d, ((0, 0), (1, 0))] = 1
Updated Q[0x3bb5, ((2, 0), (2, 1))] = 30500, N[0x3bb5, ((2, 0), (2, 1))] = 1
Updated Q[0x37bd, ((1, 1), (2, 1))] = 30500, N[0x37bd, ((1, 1), (2, 1))] = 1

--- Simulation 482 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.479180916453, 16803.479180916453, 22829.719049178595, 16803.479180916453, 19603.479180916453]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.16557645562, 30001.16557645562, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3852, Score: 13300
Depth 2: State = 0x3852, Legal Moves = [((0, 1), (1, 1)), ((0, 2), (1, 2)), ((0, 3), (0, 4)), ((0, 4), (1, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3852: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3713, Score: 16100
Depth 3: State = 0x3713, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x3713: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x5540, Score: 21700
Depth 4: State = 0x5540, Legal Moves = [((0, 0), (1, 0)), ((0, 3), (0, 4)), ((2, 2), (2, 3)), ((3, 3), (3, 4))]
UCB1 values for moves at state 0x5540: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3844, Score: 24500
End of simulation with depth 5. Reward (Score): 24500
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10914200, N[0x3c25, ((2, 3), (2, 4))] = 478
Updated Q[0x3c25, ((1, 3), (2, 3))] = 24500, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x3852, ((0, 1), (1, 1))] = 24500, N[0x3852, ((0, 1), (1, 1))] = 1
Updated Q[0x3713, ((2, 0), (2, 1))] = 24500, N[0x3713, ((2, 0), (2, 1))] = 1
Updated Q[0x5540, ((0, 0), (1, 0))] = 24500, N[0x5540, ((0, 0), (1, 0))] = 1

--- Simulation 483 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.47976586332, 16803.47976586332, 22833.21355409138, 16803.47976586332, 19603.47976586332]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4a43, Score: 8400
Depth 2: State = 0x4a43, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a43: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x43ac, Score: 11200
Depth 3: State = 0x43ac, Legal Moves = [((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43ac: [inf, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x48f7, Score: 14000
Depth 4: State = 0x48f7, Legal Moves = [((2, 2), (2, 3)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x48f7: [inf, inf]
Selected move: ((2, 2), (2, 3))
New board state after move: 0x4946, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10933800, N[0x3c25, ((2, 3), (2, 4))] = 479
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4a43, ((0, 1), (1, 1))] = 19600, N[0x4a43, ((0, 1), (1, 1))] = 1
Updated Q[0x43ac, ((2, 0), (2, 1))] = 19600, N[0x43ac, ((2, 0), (2, 1))] = 1
Updated Q[0x48f7, ((2, 2), (2, 3))] = 19600, N[0x48f7, ((2, 2), (2, 3))] = 1

--- Simulation 484 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.480349499856, 16803.480349499856, 22826.463822897713, 16803.480349499856, 19603.480349499856]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.467405903557, 22401.467405903557, 19601.467405903557, inf, inf, inf]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c2c, Score: 10500
Depth 2: State = 0x3c2c, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c2c: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c42, Score: 13300
Depth 3: State = 0x3c42, Legal Moves = [((0, 0), (1, 0)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x3c42: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x100e, Score: 16100
Depth 4: State = 0x100e, Legal Moves = [((0, 1), (1, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1)), ((3, 2), (3, 3))]
UCB1 values for moves at state 0x100e: [inf, inf, inf, inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x49a0, Score: 18900
End of simulation with depth 5. Reward (Score): 18900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10952700, N[0x3c25, ((2, 3), (2, 4))] = 480
Updated Q[0x3c25, ((2, 3), (2, 4))] = 18900, N[0x3c25, ((2, 3), (2, 4))] = 1
Updated Q[0x3c2c, ((1, 2), (2, 2))] = 18900, N[0x3c2c, ((1, 2), (2, 2))] = 1
Updated Q[0x3c42, ((0, 0), (1, 0))] = 18900, N[0x3c42, ((0, 0), (1, 0))] = 1
Updated Q[0x100e, ((0, 1), (1, 1))] = 18900, N[0x100e, ((0, 1), (1, 1))] = 1

--- Simulation 485 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48093183173, 16803.48093183173, 22818.28388207378, 16803.48093183173, 19603.48093183173]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [32100.0, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x382d, Score: 14000
Depth 2: State = 0x382d, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x382d: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x1dd6, Score: 16800
Depth 3: State = 0x1dd6, Legal Moves = [((0, 2), (1, 2)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1dd6: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x510e, Score: 19600
Depth 4: State = 0x510e, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((1, 0), (2, 0)), ((1, 1), (1, 2)), ((1, 2), (1, 3)), ((1, 2), (2, 2)), ((2, 0), (2, 1)), ((2, 2), (3, 2)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x510e: [inf, inf, inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x578a, Score: 22400
End of simulation with depth 5. Reward (Score): 22400
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10975100, N[0x3c25, ((2, 3), (2, 4))] = 481
Updated Q[0x3c25, ((1, 3), (2, 3))] = 22400, N[0x3c25, ((1, 3), (2, 3))] = 1
Updated Q[0x382d, ((0, 0), (0, 1))] = 22400, N[0x382d, ((0, 0), (0, 1))] = 1
Updated Q[0x1dd6, ((0, 2), (1, 2))] = 22400, N[0x1dd6, ((0, 2), (1, 2))] = 1
Updated Q[0x510e, ((0, 1), (0, 2))] = 22400, N[0x510e, ((0, 1), (0, 2))] = 1

--- Simulation 486 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48151286458, 16803.48151286458, 22817.414460578304, 16803.48151286458, 19603.48151286458]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [16801.648374031523, 25201.648374031523, 19601.648374031523, 18901.648374031523, inf, inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x3c1a, Score: 8400
Depth 2: State = 0x3c1a, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1a: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c3c, Score: 11200
Depth 3: State = 0x3c3c, Legal Moves = [((0, 0), (1, 0)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c3c: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x1c35, Score: 14000
Depth 4: State = 0x1c35, Legal Moves = [((1, 0), (1, 1)), ((1, 4), (2, 4)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x1c35: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x21c7, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 10991900, N[0x3c25, ((2, 3), (2, 4))] = 482
Updated Q[0x3c24, ((2, 3), (3, 3))] = 16800, N[0x3c24, ((2, 3), (3, 3))] = 1
Updated Q[0x3c1a, ((0, 2), (1, 2))] = 16800, N[0x3c1a, ((0, 2), (1, 2))] = 1
Updated Q[0x3c3c, ((0, 0), (1, 0))] = 16800, N[0x3c3c, ((0, 0), (1, 0))] = 1
Updated Q[0x1c35, ((1, 0), (1, 1))] = 16800, N[0x1c35, ((1, 0), (1, 1))] = 1

--- Simulation 487 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.482092604, 16803.482092604, 22804.930389204364, 16803.482092604, 19603.482092604]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1)), ((3, 4), (4, 4))]
UCB1 values for moves at state 0x3c24: [16800.0, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x3c61, Score: 14000
Depth 2: State = 0x3c61, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c61: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x39bc, Score: 16800
Depth 3: State = 0x39bc, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 3. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11008700, N[0x3c25, ((2, 3), (2, 4))] = 483
Updated Q[0x3c24, ((1, 2), (2, 2))] = 16800, N[0x3c24, ((1, 2), (2, 2))] = 1
Updated Q[0x3c61, ((2, 0), (2, 1))] = 16800, N[0x3c61, ((2, 0), (2, 1))] = 1

--- Simulation 488 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48267105556, 16803.48267105556, 22792.498011533502, 16803.48267105556, 19603.48267105556]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [32101.16557645562, 22401.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x1dee, Score: 13300
Depth 2: State = 0x1dee, Legal Moves = [((1, 2), (1, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x1dee: [inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x1dee, Score: 16100
Depth 3: State = 0x1dee, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x1dee: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x1db1, Score: 18900
Depth 4: State = 0x1db1, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 18900
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11027600, N[0x3c25, ((2, 3), (2, 4))] = 484
Updated Q[0x3c25, ((2, 0), (2, 1))] = 18900, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x1dee, ((1, 2), (1, 3))] = 18900, N[0x1dee, ((1, 2), (1, 3))] = 1
Updated Q[0x1dee, ((4, 1), (4, 2))] = 18900, N[0x1dee, ((4, 1), (4, 2))] = 1

--- Simulation 489 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.483248224784, 16803.483248224784, 22784.45585012592, 16803.483248224784, 19603.483248224784]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [16801.16557645562, 24501.16557645562, inf, inf, inf, inf, inf]
Selected move: ((0, 4), (1, 4))
New board state after move: 0x3be8, Score: 8400
Depth 2: State = 0x3be8, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3be8: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x3c6d, Score: 11200
Depth 3: State = 0x3c6d, Legal Moves = [((0, 2), (1, 2)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c6d: [inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c1b, Score: 14000
Depth 4: State = 0x3c1b, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c1b: [inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x11e3, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11044400, N[0x3c25, ((2, 3), (2, 4))] = 485
Updated Q[0x3c25, ((0, 4), (1, 4))] = 16800, N[0x3c25, ((0, 4), (1, 4))] = 1
Updated Q[0x3be8, ((1, 3), (2, 3))] = 16800, N[0x3be8, ((1, 3), (2, 3))] = 1
Updated Q[0x3c6d, ((0, 2), (1, 2))] = 16800, N[0x3c6d, ((0, 2), (1, 2))] = 1
Updated Q[0x3c1b, ((1, 2), (1, 3))] = 16800, N[0x3c1b, ((1, 2), (1, 3))] = 1

--- Simulation 490 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48382411717, 16803.48382411717, 22772.116955190813, 16803.48382411717, 19603.48382411717]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [18901.16557645562, 22401.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3c24, Score: 8400
Depth 2: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((2, 1), (3, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4412, Score: 11200
Depth 3: State = 0x4412, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x4412: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x43d4, Score: 14000
Depth 4: State = 0x43d4, Legal Moves = [((1, 1), (2, 1)), ((1, 2), (2, 2))]
UCB1 values for moves at state 0x43d4: [inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x43d4, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11061200, N[0x3c25, ((2, 3), (2, 4))] = 486
Updated Q[0x3c24, ((2, 0), (2, 1))] = 16800, N[0x3c24, ((2, 0), (2, 1))] = 1
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x4412, ((4, 1), (4, 2))] = 16800, N[0x4412, ((4, 1), (4, 2))] = 1
Updated Q[0x43d4, ((1, 1), (2, 1))] = 16800, N[0x43d4, ((1, 1), (2, 1))] = 1

--- Simulation 491 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.484398738172, 16803.484398738172, 22759.828837429464, 16803.484398738172, 19603.484398738172]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.77609073765, 19601.77609073765, 16801.77609073765, 24501.77609073765, 32101.77609073765, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x2ee8, Score: 8400
Depth 2: State = 0x2ee8, Legal Moves = [((1, 0), (2, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x2ee8: [inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x37e7, Score: 11200
Depth 3: State = 0x37e7, Legal Moves = [((0, 0), (1, 0)), ((1, 4), (2, 4)), ((2, 3), (2, 4)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x37e7: [inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x4524, Score: 14000
Depth 4: State = 0x4524, Legal Moves = [((1, 0), (1, 1)), ((1, 4), (2, 4)), ((2, 3), (2, 4)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x4524: [inf, inf, inf, inf]
Selected move: ((1, 0), (1, 1))
New board state after move: 0x440e, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11078000, N[0x3c25, ((2, 3), (2, 4))] = 487
Updated Q[0x3c24, ((3, 0), (3, 1))] = 16800, N[0x3c24, ((3, 0), (3, 1))] = 1
Updated Q[0x2ee8, ((1, 0), (2, 0))] = 16800, N[0x2ee8, ((1, 0), (2, 0))] = 1
Updated Q[0x37e7, ((0, 0), (1, 0))] = 16800, N[0x37e7, ((0, 0), (1, 0))] = 1
Updated Q[0x4524, ((1, 0), (1, 1))] = 16800, N[0x4524, ((1, 0), (1, 1))] = 1

--- Simulation 492 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.484972093214, 16803.484972093214, 22747.591184046654, 16803.484972093214, 19603.484972093214]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [25200.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c27, Score: 8400
Depth 2: State = 0x3c27, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c27: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x397e, Score: 11200
Depth 3: State = 0x397e, Legal Moves = [((0, 0), (0, 1)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x397e: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x2ae5, Score: 14000
Depth 4: State = 0x2ae5, Legal Moves = [((1, 2), (1, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x2ae5: [inf, inf, inf, inf, inf]
Selected move: ((1, 2), (1, 3))
New board state after move: 0x1313, Score: 27700
End of simulation with depth 5. Reward (Score): 27700
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11105700, N[0x3c25, ((2, 3), (2, 4))] = 488
Updated Q[0x3c24, ((0, 2), (1, 2))] = 27700, N[0x3c24, ((0, 2), (1, 2))] = 1
Updated Q[0x3c27, ((1, 3), (2, 3))] = 27700, N[0x3c27, ((1, 3), (2, 3))] = 1
Updated Q[0x397e, ((0, 0), (0, 1))] = 27700, N[0x397e, ((0, 0), (0, 1))] = 1
Updated Q[0x2ae5, ((1, 2), (1, 3))] = 27700, N[0x2ae5, ((1, 2), (1, 3))] = 1

--- Simulation 493 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.485544187686, 16803.485544187686, 22757.73975038481, 16803.485544187686, 19603.485544187686]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((0, 2), (1, 2)), ((0, 4), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [14000.0, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 2), (1, 2))
New board state after move: 0x3c5e, Score: 8400
Depth 2: State = 0x3c5e, Legal Moves = [((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c5e: [inf, inf, inf, inf, inf]
Selected move: ((0, 3), (1, 3))
New board state after move: 0x369c, Score: 11200
Depth 3: State = 0x369c, Legal Moves = [((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x369c: [inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3a95, Score: 14000
Depth 4: State = 0x3a95, Legal Moves = [((2, 1), (2, 2))]
UCB1 values for moves at state 0x3a95: [inf]
Selected move: ((2, 1), (2, 2))
New board state after move: 0x3b1c, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11122500, N[0x3c25, ((2, 3), (2, 4))] = 489
Updated Q[0x3c25, ((0, 2), (1, 2))] = 16800, N[0x3c25, ((0, 2), (1, 2))] = 1
Updated Q[0x3c5e, ((0, 3), (1, 3))] = 16800, N[0x3c5e, ((0, 3), (1, 3))] = 1
Updated Q[0x369c, ((2, 0), (2, 1))] = 16800, N[0x369c, ((2, 0), (2, 1))] = 1
Updated Q[0x3a95, ((2, 1), (2, 2))] = 16800, N[0x3a95, ((2, 1), (2, 2))] = 1

--- Simulation 494 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48611502695, 16803.48611502695, 22745.556420577024, 16803.48611502695, 19603.48611502695]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x444e, Score: 8400
Depth 2: State = 0x444e, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (1, 2)), ((0, 3), (1, 3)), ((1, 2), (1, 3)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x444e: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4a73, Score: 11200
Depth 3: State = 0x4a73, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a73: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x46f8, Score: 14000
Depth 4: State = 0x46f8, Legal Moves = [((0, 2), (0, 3)), ((0, 3), (1, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x46f8: [inf, inf, inf, inf]
Selected move: ((0, 2), (0, 3))
New board state after move: 0x4705, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11139300, N[0x3c25, ((2, 3), (2, 4))] = 490
Updated Q[0x3c24, ((0, 0), (0, 1))] = 16800, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x444e, ((0, 1), (0, 2))] = 16800, N[0x444e, ((0, 1), (0, 2))] = 1
Updated Q[0x4a73, ((1, 3), (2, 3))] = 16800, N[0x4a73, ((1, 3), (2, 3))] = 1
Updated Q[0x46f8, ((0, 2), (0, 3))] = 16800, N[0x46f8, ((0, 2), (0, 3))] = 1

--- Simulation 495 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48668461632, 16803.48668461632, 22733.42281847774, 16803.48668461632, 19603.48668461632]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19601.648374031523, 22401.648374031523, 35701.64837403152, 14001.648374031522, inf]
Selected move: ((3, 0), (3, 1))
New board state after move: 0x569d, Score: 8400
Depth 2: State = 0x569d, Legal Moves = [((1, 0), (2, 0)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3))]
UCB1 values for moves at state 0x569d: [inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x2ea5, Score: 11200
Depth 3: State = 0x2ea5, Legal Moves = [((2, 3), (3, 3))]
UCB1 values for moves at state 0x2ea5: [inf]
Selected move: ((2, 3), (3, 3))
New board state after move: 0x2e9b, Score: 14000
Depth 4: State = 0x2e9b, Legal Moves = []
No more legal moves. Ending simulation.
End of simulation with depth 4. Reward (Score): 14000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11153300, N[0x3c25, ((2, 3), (2, 4))] = 491
Updated Q[0x3c25, ((3, 0), (3, 1))] = 14000, N[0x3c25, ((3, 0), (3, 1))] = 1
Updated Q[0x569d, ((1, 0), (2, 0))] = 14000, N[0x569d, ((1, 0), (2, 0))] = 1
Updated Q[0x2ea5, ((2, 3), (3, 3))] = 14000, N[0x2ea5, ((2, 3), (3, 3))] = 1

--- Simulation 496 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48725296109, 16803.48725296109, 22715.63599259431, 16803.48725296109, 19603.48725296109]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [22401.16557645562, 21701.16557645562, inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3d78, Score: 8400
Depth 2: State = 0x3d78, Legal Moves = [((0, 0), (0, 1)), ((2, 3), (3, 3)), ((4, 1), (4, 2))]
UCB1 values for moves at state 0x3d78: [inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x5413, Score: 11200
Depth 3: State = 0x5413, Legal Moves = [((4, 1), (4, 2))]
UCB1 values for moves at state 0x5413: [inf]
Selected move: ((4, 1), (4, 2))
New board state after move: 0x5438, Score: 14000
Depth 4: State = 0x5438, Legal Moves = [((0, 1), (1, 1))]
UCB1 values for moves at state 0x5438: [inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x5504, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11170100, N[0x3c25, ((2, 3), (2, 4))] = 492
Updated Q[0x3c25, ((2, 0), (2, 1))] = 16800, N[0x3c25, ((2, 0), (2, 1))] = 1
Updated Q[0x3d78, ((0, 0), (0, 1))] = 16800, N[0x3d78, ((0, 0), (0, 1))] = 1
Updated Q[0x5413, ((4, 1), (4, 2))] = 16800, N[0x5413, ((4, 1), (4, 2))] = 1
Updated Q[0x5438, ((0, 1), (1, 1))] = 16800, N[0x5438, ((0, 1), (1, 1))] = 1

--- Simulation 497 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.487820066515, 16803.487820066515, 22703.612527625104, 16803.487820066515, 19603.487820066515]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c25, Score: 5600
Depth 1: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x43ed, Score: 8400
Depth 2: State = 0x43ed, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x43ed: [inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4693, Score: 11200
Depth 3: State = 0x4693, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4693: [inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4829, Score: 14000
Depth 4: State = 0x4829, Legal Moves = [((1, 0), (2, 0)), ((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (2, 2)), ((2, 1), (3, 1)), ((3, 0), (3, 1)), ((3, 1), (3, 2))]
UCB1 values for moves at state 0x4829: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((1, 0), (2, 0))
New board state after move: 0x516d, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11186900, N[0x3c25, ((2, 3), (2, 4))] = 493
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x43ed, ((1, 3), (2, 3))] = 16800, N[0x43ed, ((1, 3), (2, 3))] = 1
Updated Q[0x4693, ((1, 3), (2, 3))] = 16800, N[0x4693, ((1, 3), (2, 3))] = 1
Updated Q[0x4829, ((1, 0), (2, 0))] = 16800, N[0x4829, ((1, 0), (2, 0))] = 1

--- Simulation 498 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.488385937817, 16803.488385937817, 22691.63783922426, 16803.488385937817, 19603.488385937817]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((2, 4), (3, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [19601.648374031523, 25201.648374031523, 24501.648374031523, 25201.648374031523, inf, inf]
Selected move: ((2, 4), (3, 4))
New board state after move: 0x3c25, Score: 8400
Depth 2: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x4921, Score: 11200
Depth 3: State = 0x4921, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4921: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x4544, Score: 14000
Depth 4: State = 0x4544, Legal Moves = [((1, 2), (2, 2)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4544: [inf, inf, inf, inf]
Selected move: ((1, 2), (2, 2))
New board state after move: 0x454d, Score: 16800
End of simulation with depth 5. Reward (Score): 16800
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11203700, N[0x3c25, ((2, 3), (2, 4))] = 494
Updated Q[0x3c24, ((2, 4), (3, 4))] = 16800, N[0x3c24, ((2, 4), (3, 4))] = 1
Updated Q[0x3c25, ((0, 0), (0, 1))] = 16800, N[0x3c25, ((0, 0), (0, 1))] = 1
Updated Q[0x4921, ((0, 1), (0, 2))] = 16800, N[0x4921, ((0, 1), (0, 2))] = 1
Updated Q[0x4544, ((1, 2), (2, 2))] = 16800, N[0x4544, ((1, 2), (2, 2))] = 1

--- Simulation 499 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.488950580184, 16803.488950580184, 22679.711631178277, 16803.488950580184, 19603.488950580184]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c24, Score: 5600
Depth 1: State = 0x3c24, Legal Moves = [((0, 0), (0, 1)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c24: [inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (0, 1))
New board state after move: 0x44fe, Score: 8400
Depth 2: State = 0x44fe, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x44fe: [inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x4a8a, Score: 11200
Depth 3: State = 0x4a8a, Legal Moves = [((2, 0), (2, 1)), ((2, 3), (2, 4)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x4a8a: [inf, inf, inf]
Selected move: ((2, 0), (2, 1))
New board state after move: 0x3955, Score: 16800
Depth 4: State = 0x3955, Legal Moves = [((0, 1), (1, 1)), ((0, 3), (1, 3))]
UCB1 values for moves at state 0x3955: [inf, inf]
Selected move: ((0, 1), (1, 1))
New board state after move: 0x3c64, Score: 19600
End of simulation with depth 5. Reward (Score): 19600
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11223300, N[0x3c25, ((2, 3), (2, 4))] = 495
Updated Q[0x3c24, ((0, 0), (0, 1))] = 19600, N[0x3c24, ((0, 0), (0, 1))] = 1
Updated Q[0x44fe, ((1, 3), (2, 3))] = 19600, N[0x44fe, ((1, 3), (2, 3))] = 1
Updated Q[0x4a8a, ((2, 0), (2, 1))] = 19600, N[0x4a8a, ((2, 0), (2, 1))] = 1
Updated Q[0x3955, ((0, 1), (1, 1))] = 19600, N[0x3955, ((0, 1), (1, 1))] = 1

--- Simulation 500 ---
Depth 0: State = 0x3c25, Legal Moves = [((0, 0), (0, 1)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c25: [19603.48951399878, 16803.48951399878, 22673.490175323866, 16803.48951399878, 19603.48951399878]
Selected move: ((2, 3), (2, 4))
New board state after move: 0x3c47, Score: 8400
Depth 1: State = 0x3c47, Legal Moves = [((0, 0), (1, 0)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3c47: [inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 0), (1, 0))
New board state after move: 0x3a8e, Score: 14000
Depth 2: State = 0x3a8e, Legal Moves = [((0, 1), (0, 2)), ((0, 2), (0, 3)), ((1, 3), (1, 4)), ((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x3a8e: [inf, inf, inf, inf, inf, inf, inf, inf]
Selected move: ((0, 1), (0, 2))
New board state after move: 0x37c6, Score: 16800
Depth 3: State = 0x37c6, Legal Moves = [((1, 3), (2, 3)), ((2, 0), (2, 1)), ((2, 2), (2, 3)), ((2, 3), (2, 4)), ((2, 3), (3, 3)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x37c6: [inf, inf, inf, inf, inf, inf]
Selected move: ((1, 3), (2, 3))
New board state after move: 0x395c, Score: 25200
Depth 4: State = 0x395c, Legal Moves = [((1, 1), (2, 1)), ((2, 0), (2, 1)), ((2, 1), (3, 1)), ((3, 0), (3, 1))]
UCB1 values for moves at state 0x395c: [inf, inf, inf, inf]
Selected move: ((1, 1), (2, 1))
New board state after move: 0x36b7, Score: 28000
End of simulation with depth 5. Reward (Score): 28000
Updated Q[0x3c25, ((2, 3), (2, 4))] = 11251300, N[0x3c25, ((2, 3), (2, 4))] = 496
Updated Q[0x3c47, ((0, 0), (1, 0))] = 28000, N[0x3c47, ((0, 0), (1, 0))] = 1
Updated Q[0x3a8e, ((0, 1), (0, 2))] = 28000, N[0x3a8e, ((0, 1), (0, 2))] = 1
Updated Q[0x37c6, ((1, 3), (2, 3))] = 28000, N[0x37c6, ((1, 3), (2, 3))] = 1
Updated Q[0x395c, ((1, 1), (2, 1))] = 28000, N[0x395c, ((1, 1), (2, 1))] = 1

Best move selected: ((2, 3), (2, 4))

--- Summary of States Visited ---
State 0x3c25 visited 500 times
State 0x43d2 visited 1 times
State 0x11a9 visited 1 times
State 0x144f visited 1 times
State 0x36b8 visited 1 times
State 0x3d78 visited 1 times
State 0x510b visited 1 times
State 0x50e9 visited 1 times
State 0x5171 visited 1 times
State 0x3c25 visited 4 times
State 0x45ad visited 1 times
State 0x4917 visited 1 times
State 0x4acf visited 1 times
State 0x3c29 visited 1 times
State 0x3c22 visited 1 times
State 0x382a visited 1 times
State 0x57cb visited 1 times
State 0x2ee9 visited 1 times
State 0x2ee8 visited 1 times
State 0x2a8d visited 1 times
State 0x2b11 visited 1 times
State 0x3c24 visited 7 times
State 0x4a6c visited 1 times
State 0x4934 visited 1 times
State 0x43e9 visited 1 times
State 0x3c25 visited 1 times
State 0x3bb9 visited 1 times
State 0x3983 visited 1 times
State 0x3983 visited 1 times
State 0x3c25 visited 2 times
State 0x47ed visited 1 times
State 0x4525 visited 1 times
State 0x4522 visited 1 times
State 0x3c24 visited 1 times
State 0x46dc visited 1 times
State 0x453b visited 1 times
State 0x455d visited 1 times
State 0x3c24 visited 1 times
State 0x4a47 visited 1 times
State 0x46ff visited 1 times
State 0x46ff visited 1 times
State 0x3c25 visited 5 times
State 0x43d6 visited 1 times
State 0x47a9 visited 1 times
State 0x47a2 visited 1 times
State 0x3c5e visited 1 times
State 0x397b visited 1 times
State 0x3b0a visited 1 times
State 0x3b0a visited 1 times
State 0x3c25 visited 5 times
State 0x464c visited 1 times
State 0x469a visited 1 times
State 0x47ec visited 1 times
State 0x3c25 visited 6 times
State 0x482a visited 1 times
State 0x46b9 visited 1 times
State 0x441d visited 1 times
State 0x3c24 visited 2 times
State 0x4a51 visited 1 times
State 0x4a65 visited 1 times
State 0x4a70 visited 1 times
State 0x3bbf visited 1 times
State 0x3b19 visited 1 times
State 0x53b7 visited 1 times
State 0x3c24 visited 5 times
State 0x4590 visited 1 times
State 0x4836 visited 1 times
State 0x3c24 visited 2 times
State 0x4833 visited 1 times
State 0x3695 visited 1 times
State 0x3c43 visited 1 times
State 0x3c25 visited 2 times
State 0x4a55 visited 1 times
State 0x4547 visited 1 times
State 0x1d52 visited 1 times
State 0x3c25 visited 3 times
State 0x493c visited 1 times
State 0x4aaa visited 1 times
State 0x46b2 visited 1 times
State 0x3c24 visited 1 times
State 0x45ac visited 1 times
State 0x45a9 visited 1 times
State 0x4503 visited 1 times
State 0x3c5d visited 1 times
State 0x3c28 visited 1 times
State 0x3b11 visited 1 times
State 0x3d95 visited 1 times
State 0x3c25 visited 3 times
State 0x4565 visited 1 times
State 0x4a8f visited 1 times
State 0x4a88 visited 1 times
State 0x3c25 visited 5 times
State 0x480b visited 1 times
State 0x11ea visited 1 times
State 0x5547 visited 1 times
State 0x3c24 visited 3 times
State 0x4437 visited 1 times
State 0x43ce visited 1 times
State 0x43ce visited 1 times
State 0x3c24 visited 4 times
State 0x4702 visited 1 times
State 0x4934 visited 1 times
State 0x3bbf visited 1 times
State 0x3866 visited 1 times
State 0x3b0b visited 1 times
State 0x5671 visited 1 times
State 0x3c24 visited 4 times
State 0x46c2 visited 1 times
State 0x454a visited 1 times
State 0x4942 visited 1 times
State 0x3c24 visited 4 times
State 0x456b visited 1 times
State 0x45a5 visited 1 times
State 0x45a8 visited 1 times
State 0x3c47 visited 1 times
State 0x3a8e visited 1 times
State 0x384e visited 1 times
State 0x3d71 visited 1 times
State 0x3c25 visited 4 times
State 0x43f1 visited 1 times
State 0x43cb visited 1 times
State 0x441c visited 1 times
State 0x3c24 visited 5 times
State 0x47c2 visited 1 times
State 0x442c visited 1 times
State 0x48f5 visited 1 times
State 0x3d0a visited 1 times
State 0x3d08 visited 1 times
State 0x3d3a visited 1 times
State 0x3c24 visited 3 times
State 0x458d visited 1 times
State 0x1dd9 visited 1 times
State 0x21f7 visited 1 times
State 0x3bb8 visited 1 times
State 0x3bb8 visited 1 times
State 0x3b0f visited 1 times
State 0x36d3 visited 1 times
State 0x3c62 visited 1 times
State 0x380b visited 1 times
State 0x36bb visited 1 times
State 0x3bb5 visited 1 times
State 0x3bd7 visited 1 times
State 0x3bda visited 1 times
State 0x3c43 visited 1 times
State 0x3c06 visited 1 times
State 0x3c06 visited 1 times
State 0x214a visited 1 times
State 0x218d visited 1 times
State 0x3c25 visited 4 times
State 0x43c8 visited 1 times
State 0x4aae visited 1 times
State 0x4a71 visited 1 times
State 0x43d5 visited 1 times
State 0x4419 visited 1 times
State 0x3d9d visited 1 times
State 0x3c25 visited 3 times
State 0x46dd visited 1 times
State 0x4af4 visited 1 times
State 0x484f visited 1 times
State 0x3b16 visited 1 times
State 0x29e8 visited 1 times
State 0x214e visited 1 times
State 0x3c5e visited 1 times
State 0x36d3 visited 1 times
State 0x3674 visited 1 times
State 0x3997 visited 1 times
State 0x3c25 visited 1 times
State 0x49a2 visited 1 times
State 0x4a4f visited 1 times
State 0x4a52 visited 1 times
State 0x3c40 visited 1 times
State 0x4acf visited 1 times
State 0x443b visited 1 times
State 0xf65e visited 1 times
State 0x3c24 visited 9 times
State 0x491d visited 1 times
State 0x443b visited 1 times
State 0x104b visited 1 times
State 0x3c25 visited 2 times
State 0x4a99 visited 1 times
State 0x4913 visited 1 times
State 0x1d88 visited 1 times
State 0x3c24 visited 3 times
State 0x4913 visited 1 times
State 0x44f8 visited 1 times
State 0x43c7 visited 1 times
State 0x3c6c visited 1 times
State 0x3919 visited 1 times
State 0x3916 visited 1 times
State 0x36be visited 1 times
State 0x3c24 visited 5 times
State 0x43f3 visited 1 times
State 0x4a87 visited 1 times
State 0x45ab visited 1 times
State 0x3c24 visited 3 times
State 0x47c2 visited 1 times
State 0x4858 visited 1 times
State 0x493b visited 1 times
State 0x3c25 visited 2 times
State 0x4570 visited 1 times
State 0x4582 visited 1 times
State 0x44f8 visited 1 times
State 0x3c24 visited 1 times
State 0x46b7 visited 1 times
State 0x45a5 visited 1 times
State 0x4a76 visited 1 times
State 0x3c24 visited 3 times
State 0x443a visited 1 times
State 0x1161 visited 1 times
State 0x29dd visited 1 times
State 0x3c24 visited 5 times
State 0x4aac visited 1 times
State 0x455e visited 1 times
State 0x47f2 visited 1 times
State 0x3c24 visited 3 times
State 0x452b visited 1 times
State 0x48f5 visited 1 times
State 0x49a1 visited 1 times
State 0x368c visited 1 times
State 0x4450 visited 1 times
State 0x4848 visited 1 times
State 0x3c24 visited 6 times
State 0x43f9 visited 1 times
State 0x4705 visited 1 times
State 0x4705 visited 1 times
State 0x3d2e visited 1 times
State 0x3d50 visited 1 times
State 0x3957 visited 1 times
State 0x3c24 visited 3 times
State 0x46d5 visited 1 times
State 0x4825 visited 1 times
State 0x3c24 visited 1 times
State 0x46c1 visited 1 times
State 0x455d visited 1 times
State 0x440a visited 1 times
State 0x3be4 visited 1 times
State 0x3c06 visited 1 times
State 0x3c02 visited 1 times
State 0x3c06 visited 1 times
State 0x3c5e visited 1 times
State 0x3865 visited 1 times
State 0x382d visited 1 times
State 0x21ee visited 1 times
State 0x1f48 visited 1 times
State 0x3c25 visited 1 times
State 0x4852 visited 1 times
State 0x4a6a visited 1 times
State 0x47e3 visited 1 times
State 0x3c24 visited 2 times
State 0x4aed visited 1 times
State 0x4aba visited 1 times
State 0x36d9 visited 1 times
State 0x3c25 visited 2 times
State 0x4965 visited 1 times
State 0x480b visited 1 times
State 0x482c visited 1 times
State 0x3c24 visited 1 times
State 0x47a4 visited 1 times
State 0x47c0 visited 1 times
State 0x46b8 visited 1 times
State 0x3c24 visited 2 times
State 0x46e3 visited 1 times
State 0x4ad5 visited 1 times
State 0x4aca visited 1 times
State 0x3c25 visited 3 times
State 0x4957 visited 1 times
State 0x4a66 visited 1 times
State 0x3c24 visited 4 times
State 0x43d4 visited 1 times
State 0x43fb visited 1 times
State 0x1412 visited 1 times
State 0x3c24 visited 2 times
State 0x48f7 visited 1 times
State 0x4a91 visited 1 times
State 0x4a6c visited 1 times
State 0x3c24 visited 4 times
State 0x47ec visited 1 times
State 0x47f3 visited 1 times
State 0x4834 visited 1 times
State 0x3c25 visited 2 times
State 0x465a visited 1 times
State 0x4a92 visited 1 times
State 0x4a8c visited 1 times
State 0x395d visited 1 times
State 0x39bc visited 1 times
State 0x3b0f visited 1 times
State 0x3c24 visited 1 times
State 0x46e3 visited 1 times
State 0x4705 visited 1 times
State 0x3c25 visited 3 times
State 0x452c visited 1 times
State 0x4580 visited 1 times
State 0x4935 visited 1 times
State 0x3c24 visited 2 times
State 0x43f3 visited 1 times
State 0x4456 visited 1 times
State 0x43a8 visited 1 times
State 0x3c24 visited 3 times
State 0x4832 visited 1 times
State 0x3d51 visited 1 times
State 0x3d5d visited 1 times
State 0x3c24 visited 2 times
State 0x464e visited 1 times
State 0x4ad5 visited 1 times
State 0x482f visited 1 times
State 0x3c25 visited 4 times
State 0x4419 visited 1 times
State 0x43b3 visited 1 times
State 0x499a visited 1 times
State 0x3bbc visited 1 times
State 0x3917 visited 1 times
State 0x2bdb visited 1 times
State 0x3a69 visited 1 times
State 0x371e visited 1 times
State 0x2017 visited 1 times
State 0x3c25 visited 3 times
State 0x46b1 visited 1 times
State 0x4413 visited 1 times
State 0x4ab1 visited 1 times
State 0x3c24 visited 4 times
State 0x4520 visited 1 times
State 0x4ab3 visited 1 times
State 0x4ab3 visited 1 times
State 0x3c2c visited 1 times
State 0x46c3 visited 1 times
State 0x46d9 visited 1 times
State 0x3c25 visited 4 times
State 0x47af visited 1 times
State 0x47ac visited 1 times
State 0x4412 visited 1 times
State 0x3c24 visited 3 times
State 0x43d4 visited 1 times
State 0x46d2 visited 1 times
State 0x1443 visited 1 times
State 0x3c4d visited 1 times
State 0x5289 visited 1 times
State 0x53d5 visited 1 times
State 0x5573 visited 1 times
State 0x3c25 visited 3 times
State 0x4a4b visited 1 times
State 0x4837 visited 1 times
State 0x4592 visited 1 times
State 0x3c25 visited 2 times
State 0x4438 visited 1 times
State 0x4677 visited 1 times
State 0x479e visited 1 times
State 0x3c6d visited 1 times
State 0x399e visited 1 times
State 0x3845 visited 1 times
State 0x3845 visited 1 times
State 0x3c24 visited 2 times
State 0x456b visited 1 times
State 0x43d5 visited 1 times
State 0x3c24 visited 1 times
State 0x469f visited 1 times
State 0x4a52 visited 1 times
State 0x1f0b visited 1 times
State 0x37c9 visited 1 times
State 0x3bc2 visited 1 times
State 0x11cd visited 1 times
State 0x3c24 visited 1 times
State 0x4459 visited 1 times
State 0x4677 visited 1 times
State 0x4524 visited 1 times
State 0x3c24 visited 3 times
State 0x4561 visited 1 times
State 0x482c visited 1 times
State 0x4858 visited 1 times
State 0x3c61 visited 1 times
State 0x1d51 visited 1 times
State 0x231d visited 1 times
State 0x21ca visited 1 times
State 0x3c24 visited 3 times
State 0x4956 visited 1 times
State 0x4412 visited 1 times
State 0x480a visited 1 times
State 0x3c25 visited 2 times
State 0x44f9 visited 1 times
State 0x4678 visited 1 times
State 0x469a visited 1 times
State 0x3c24 visited 1 times
State 0x4aed visited 1 times
State 0x466d visited 1 times
State 0x43c7 visited 1 times
State 0x3c25 visited 3 times
State 0x43b4 visited 1 times
State 0x443d visited 1 times
State 0x442e visited 1 times
State 0x3d36 visited 1 times
State 0x3c07 visited 1 times
State 0x391c visited 1 times
State 0x3975 visited 1 times
State 0x3670 visited 1 times
State 0x3c24 visited 3 times
State 0x482b visited 1 times
State 0x47eb visited 1 times
State 0x47e4 visited 1 times
State 0x3c25 visited 1 times
State 0x4ad6 visited 1 times
State 0x47cb visited 1 times
State 0x4671 visited 1 times
State 0x3c25 visited 4 times
State 0x466e visited 1 times
State 0x4546 visited 1 times
State 0x4698 visited 1 times
State 0x3c24 visited 2 times
State 0x4923 visited 1 times
State 0x4935 visited 1 times
State 0x453d visited 1 times
State 0x3c4c visited 1 times
State 0x3ab6 visited 1 times
State 0x3974 visited 1 times
State 0x46d2 visited 1 times
State 0x3c24 visited 2 times
State 0x4ab3 visited 1 times
State 0x43f6 visited 1 times
State 0x4942 visited 1 times
State 0x4903 visited 1 times
State 0x57f7 visited 1 times
State 0x550e visited 1 times
State 0x3c5f visited 1 times
State 0x4580 visited 1 times
State 0x39b9 visited 1 times
State 0x3c25 visited 3 times
State 0x4584 visited 1 times
State 0x482a visited 1 times
State 0x4570 visited 1 times
State 0x3c25 visited 1 times
State 0x4afb visited 1 times
State 0x495a visited 1 times
State 0x2184 visited 1 times
State 0x3d99 visited 1 times
State 0x3c24 visited 2 times
State 0x43f3 visited 1 times
State 0x45a1 visited 1 times
State 0x4847 visited 1 times
State 0x3c25 visited 3 times
State 0x4aee visited 1 times
State 0x45a9 visited 1 times
State 0x484f visited 1 times
State 0x3c6b visited 1 times
State 0x20a0 visited 1 times
State 0x2096 visited 1 times
State 0x3c4d visited 1 times
State 0x541f visited 1 times
State 0x5136 visited 1 times
State 0x5136 visited 1 times
State 0x3c40 visited 2 times
State 0x29b9 visited 1 times
State 0x2977 visited 1 times
State 0x10b1 visited 1 times
State 0x3c24 visited 3 times
State 0x4430 visited 1 times
State 0x46be visited 1 times
State 0x46b7 visited 1 times
State 0x3c25 visited 2 times
State 0x4815 visited 1 times
State 0x4add visited 1 times
State 0x4ab1 visited 1 times
State 0x4524 visited 1 times
State 0x47c0 visited 1 times
State 0x39a1 visited 1 times
State 0x3c1a visited 1 times
State 0x397b visited 1 times
State 0x39bf visited 1 times
State 0x3da1 visited 1 times
State 0x118e visited 1 times
State 0x3c24 visited 2 times
State 0x453c visited 1 times
State 0x454a visited 1 times
State 0x454b visited 1 times
State 0x3c25 visited 2 times
State 0x4540 visited 1 times
State 0x47a1 visited 1 times
State 0x467e visited 1 times
State 0x1c1d visited 1 times
State 0x1c61 visited 1 times
State 0x1fe9 visited 1 times
State 0x3c6c visited 1 times
State 0x3975 visited 1 times
State 0x4957 visited 1 times
State 0x4804 visited 1 times
State 0x3c24 visited 3 times
State 0x47ca visited 1 times
State 0x482f visited 1 times
State 0x4830 visited 1 times
State 0x3c0a visited 1 times
State 0x3be0 visited 1 times
State 0x3bdd visited 1 times
State 0x3bde visited 1 times
State 0x3af6 visited 1 times
State 0x3d4b visited 1 times
State 0x36cf visited 1 times
State 0x3c24 visited 1 times
State 0x53ce visited 1 times
State 0x5524 visited 1 times
State 0x5103 visited 1 times
State 0x3c24 visited 4 times
State 0x46f4 visited 1 times
State 0x464e visited 1 times
State 0x464e visited 1 times
State 0x3c65 visited 1 times
State 0x3917 visited 1 times
State 0x3917 visited 1 times
State 0x3c25 visited 5 times
State 0x43d9 visited 1 times
State 0x45a2 visited 1 times
State 0x4aaa visited 1 times
State 0x3bdb visited 1 times
State 0x3871 visited 1 times
State 0x3d78 visited 1 times
State 0x5812 visited 1 times
State 0x3c24 visited 2 times
State 0x47a1 visited 1 times
State 0x4811 visited 1 times
State 0x47a1 visited 1 times
State 0x3c25 visited 3 times
State 0x4653 visited 1 times
State 0x4588 visited 1 times
State 0x4588 visited 1 times
State 0x3c25 visited 2 times
State 0x4935 visited 1 times
State 0x4939 visited 1 times
State 0x3c25 visited 3 times
State 0x4693 visited 1 times
State 0x4656 visited 1 times
State 0x4656 visited 1 times
State 0x3bfe visited 1 times
State 0x3701 visited 1 times
State 0x54ea visited 1 times
State 0x563d visited 1 times
State 0x3c24 visited 2 times
State 0x469c visited 1 times
State 0x1c34 visited 1 times
State 0x1d43 visited 1 times
State 0x3c1e visited 1 times
State 0x3c40 visited 1 times
State 0x53ad visited 1 times
State 0x5413 visited 1 times
State 0x3c27 visited 1 times
State 0x3c27 visited 1 times
State 0x3d7a visited 1 times
State 0x3c25 visited 5 times
State 0x484c visited 1 times
State 0x47a9 visited 1 times
State 0x47ac visited 1 times
State 0x3c1a visited 1 times
State 0x3d8f visited 1 times
State 0x368b visited 1 times
State 0x366c visited 1 times
State 0x368e visited 1 times
State 0x371a visited 1 times
State 0x3bc1 visited 1 times
State 0x3d7a visited 1 times
State 0x2c67 visited 1 times
State 0x2c5e visited 1 times
State 0x39bd visited 1 times
State 0x4584 visited 1 times
State 0x46d7 visited 1 times
State 0x3c25 visited 1 times
State 0x47c4 visited 1 times
State 0x4852 visited 1 times
State 0x4852 visited 1 times
State 0x3c25 visited 4 times
State 0x47cb visited 1 times
State 0x4658 visited 1 times
State 0x3720 visited 1 times
State 0x3d55 visited 1 times
State 0x3af4 visited 1 times
State 0x5287 visited 1 times
State 0x567f visited 1 times
State 0x3c24 visited 2 times
State 0x442d visited 1 times
State 0x4509 visited 1 times
State 0x47af visited 1 times
State 0x3c25 visited 4 times
State 0x4837 visited 1 times
State 0x45a9 visited 1 times
State 0x456b visited 1 times
State 0x3c24 visited 1 times
State 0x47f2 visited 1 times
State 0x45a5 visited 1 times
State 0x4ad6 visited 1 times
State 0x57ce visited 1 times
State 0x5245 visited 1 times
State 0x56d6 visited 1 times
State 0x3c25 visited 1 times
State 0x47c4 visited 1 times
State 0x3c24 visited 2 times
State 0x4a91 visited 1 times
State 0x4589 visited 1 times
State 0x457f visited 1 times
State 0x3c02 visited 1 times
State 0x3b18 visited 1 times
State 0x3c6b visited 1 times
State 0x563a visited 1 times
State 0x3915 visited 1 times
State 0x3a68 visited 1 times
State 0x36f7 visited 1 times
State 0x3bb6 visited 1 times
State 0x371b visited 1 times
State 0x1f48 visited 1 times
State 0x1c40 visited 1 times
State 0x3bbf visited 2 times
State 0x3bbf visited 1 times
State 0x3bbf visited 1 times
State 0x3c4e visited 1 times
State 0x29a5 visited 1 times
State 0x29a4 visited 1 times
State 0x3c24 visited 1 times
State 0x469f visited 1 times
State 0x4aed visited 1 times
State 0x4ab9 visited 1 times
State 0x3c25 visited 1 times
State 0x46da visited 1 times
State 0x4808 visited 1 times
State 0x495b visited 1 times
State 0x3c25 visited 3 times
State 0x454e visited 1 times
State 0x2d69 visited 1 times
State 0x300f visited 1 times
State 0x3c02 visited 1 times
State 0x36fb visited 1 times
State 0x4568 visited 1 times
State 0x4567 visited 1 times
State 0x3d70 visited 1 times
State 0x22b4 visited 1 times
State 0x5260 visited 1 times
State 0x3aa7 visited 1 times
State 0x15fd visited 1 times
State 0x11ab visited 1 times
State 0x3c24 visited 3 times
State 0x45a5 visited 1 times
State 0x4702 visited 1 times
State 0x4a98 visited 1 times
State 0x36ac visited 1 times
State 0x3986 visited 1 times
State 0x393a visited 1 times
State 0x3c47 visited 1 times
State 0x56d7 visited 1 times
State 0x5242 visited 1 times
State 0x107b visited 1 times
State 0x3c24 visited 1 times
State 0x4854 visited 1 times
State 0x46e3 visited 1 times
State 0x46e3 visited 1 times
State 0x3bb6 visited 1 times
State 0x3d08 visited 1 times
State 0x3d56 visited 1 times
State 0x3982 visited 1 times
State 0x3978 visited 1 times
State 0x3982 visited 1 times
State 0x3c25 visited 3 times
State 0x46d3 visited 1 times
State 0x44f9 visited 1 times
State 0x4a44 visited 1 times
State 0x3bf9 visited 1 times
State 0x3aed visited 1 times
State 0xedaf visited 1 times
State 0x3bb8 visited 1 times
State 0x1470 visited 1 times
State 0x22bb visited 1 times
State 0x2346 visited 1 times
State 0x3bbe visited 1 times
State 0x5789 visited 1 times
State 0x5637 visited 1 times
State 0x391d visited 1 times
State 0x1f2c visited 1 times
State 0x2d99 visited 1 times
State 0x3c25 visited 1 times
State 0x47a2 visited 1 times
State 0x4a88 visited 1 times
State 0x4a8c visited 1 times
State 0x3c3f visited 1 times
State 0x440e visited 1 times
State 0x4415 visited 1 times
State 0x4a88 visited 1 times
State 0x3d96 visited 1 times
State 0x3db8 visited 1 times
State 0x3dbf visited 1 times
State 0xee0b visited 1 times
State 0xedaf visited 1 times
State 0xf1eb visited 1 times
State 0x3c24 visited 2 times
State 0x440b visited 1 times
State 0x4a8b visited 1 times
State 0x4ab7 visited 1 times
State 0x39bc visited 1 times
State 0x39a1 visited 1 times
State 0x391d visited 1 times
State 0x3be2 visited 1 times
State 0x3bb9 visited 1 times
State 0x3c1b visited 1 times
State 0x1c62 visited 1 times
State 0x3bb8 visited 1 times
State 0x3bbb visited 1 times
State 0x393b visited 1 times
State 0x3673 visited 1 times
State 0xf227 visited 1 times
State 0x131a visited 1 times
State 0x3c24 visited 4 times
State 0x467c visited 1 times
State 0x4655 visited 1 times
State 0x4655 visited 1 times
State 0x3975 visited 1 times
State 0x391d visited 1 times
State 0x3a70 visited 1 times
State 0x3c24 visited 2 times
State 0x4a91 visited 1 times
State 0x21c4 visited 1 times
State 0x47c0 visited 1 times
State 0x3bd9 visited 1 times
State 0x3d0d visited 1 times
State 0x3806 visited 1 times
State 0x3806 visited 1 times
State 0x3bfc visited 1 times
State 0x3807 visited 1 times
State 0x3aad visited 1 times
State 0x3c24 visited 2 times
State 0x4549 visited 1 times
State 0x454a visited 1 times
State 0x49a8 visited 1 times
State 0x3c24 visited 5 times
State 0x148e visited 1 times
State 0x57c9 visited 1 times
State 0x22fb visited 1 times
State 0x3da1 visited 1 times
State 0x3be7 visited 1 times
State 0x3be7 visited 1 times
State 0x3af6 visited 1 times
State 0x3d6d visited 1 times
State 0x213c visited 1 times
State 0x3c69 visited 1 times
State 0x3bb9 visited 1 times
State 0x11cb visited 1 times
State 0x4678 visited 1 times
State 0x3c24 visited 2 times
State 0x4afa visited 1 times
State 0x4ad9 visited 1 times
State 0x53dc visited 1 times
State 0x3c25 visited 5 times
State 0x48fc visited 1 times
State 0x4566 visited 1 times
State 0x4ab1 visited 1 times
State 0x3c24 visited 1 times
State 0x46fe visited 1 times
State 0x47f2 visited 1 times
State 0x454c visited 1 times
State 0x3bd7 visited 1 times
State 0x36f4 visited 1 times
State 0x3677 visited 1 times
State 0x37eb visited 1 times
State 0x3c24 visited 2 times
State 0x45ab visited 1 times
State 0x4ad1 visited 1 times
State 0x1df4 visited 1 times
State 0x3be8 visited 1 times
State 0x3bd7 visited 1 times
State 0x3d2a visited 1 times
State 0x3c25 visited 1 times
State 0x49a2 visited 1 times
State 0x443c visited 1 times
State 0x1300 visited 1 times
State 0x3b16 visited 1 times
State 0x1d56 visited 1 times
State 0x1d55 visited 1 times
State 0x3c24 visited 6 times
State 0x4960 visited 1 times
State 0x465c visited 1 times
State 0x465c visited 1 times
State 0x3d37 visited 1 times
State 0x29c3 visited 1 times
State 0x2c68 visited 1 times
State 0x1f4b visited 1 times
State 0x458b visited 1 times
State 0x4581 visited 1 times
State 0x3d90 visited 1 times
State 0x1dee visited 1 times
State 0x2094 visited 1 times
State 0x3c24 visited 2 times
State 0x46e0 visited 1 times
State 0x2ee1 visited 1 times
State 0x2ee1 visited 1 times
State 0x3d4b visited 1 times
State 0x2b29 visited 1 times
State 0x2b34 visited 1 times
State 0x3c24 visited 2 times
State 0x47ab visited 1 times
State 0x47af visited 1 times
State 0x4902 visited 1 times
State 0x3c46 visited 1 times
State 0x3be0 visited 1 times
State 0x3825 visited 1 times
State 0x3c68 visited 1 times
State 0x3bda visited 1 times
State 0x386d visited 1 times
State 0x2c62 visited 1 times
State 0x1212 visited 1 times
State 0x3719 visited 1 times
State 0x3db8 visited 1 times
State 0x3ab0 visited 1 times
State 0x3d7f visited 1 times
State 0x3913 visited 1 times
State 0x5129 visited 1 times
State 0x3c0a visited 1 times
State 0x3c27 visited 1 times
State 0x382f visited 1 times
State 0x3874 visited 1 times
State 0x3c21 visited 1 times
State 0x397b visited 1 times
State 0x120a visited 1 times
State 0x3c6f visited 1 times
State 0x3c67 visited 1 times
State 0x3be0 visited 1 times
State 0x3c25 visited 1 times
State 0x3c24 visited 1 times
State 0x4506 visited 1 times
State 0x4a76 visited 1 times
State 0x47d1 visited 1 times
State 0x3c25 visited 2 times
State 0x48f8 visited 1 times
State 0x499a visited 1 times
State 0x46bb visited 1 times
State 0x3c24 visited 2 times
State 0x4705 visited 1 times
State 0x4527 visited 1 times
State 0x4527 visited 1 times
State 0x3c3b visited 1 times
State 0x46d2 visited 1 times
State 0x46d2 visited 1 times
State 0x3c1b visited 1 times
State 0x1d45 visited 1 times
State 0x2038 visited 1 times
State 0x3c24 visited 1 times
State 0x4a72 visited 1 times
State 0x4a94 visited 1 times
State 0x37ca visited 1 times
State 0x3a70 visited 1 times
State 0x2c8a visited 1 times
State 0x3c4d visited 1 times
State 0x1f51 visited 1 times
State 0x1f07 visited 1 times
State 0x1efd visited 1 times
State 0x3d78 visited 1 times
State 0x578a visited 1 times
State 0x57ce visited 1 times
State 0x3c25 visited 1 times
State 0x464f visited 1 times
State 0x48f5 visited 1 times
State 0x44fd visited 1 times
State 0x36d8 visited 1 times
State 0x15eb visited 1 times
State 0x56c4 visited 1 times
State 0x3bc6 visited 1 times
State 0x3bc6 visited 1 times
State 0x3c06 visited 1 times
State 0x3673 visited 1 times
State 0x3d4f visited 1 times
State 0x3d15 visited 1 times
State 0x3821 visited 1 times
State 0x4912 visited 1 times
State 0x4915 visited 1 times
State 0x3c24 visited 3 times
State 0x4506 visited 1 times
State 0x45af visited 1 times
State 0x4afa visited 1 times
State 0x3c25 visited 2 times
State 0x4431 visited 1 times
State 0x4a4b visited 1 times
State 0x4a4f visited 1 times
State 0x36da visited 1 times
State 0x11c1 visited 1 times
State 0x2dae visited 1 times
State 0x3829 visited 1 times
State 0x3d74 visited 1 times
State 0x2d2c visited 1 times
State 0x3bc0 visited 1 times
State 0x39a5 visited 1 times
State 0x37bd visited 1 times
State 0x3910 visited 1 times
State 0x3c24 visited 2 times
State 0x46f4 visited 1 times
State 0x4ab3 visited 1 times
State 0x4ab4 visited 1 times
State 0x3c24 visited 3 times
State 0x4967 visited 1 times
State 0x469f visited 1 times
State 0x469f visited 1 times
State 0x382d visited 1 times
State 0x2293 visited 1 times
State 0x2bf9 visited 1 times
State 0x3c1a visited 1 times
State 0x3bb9 visited 1 times
State 0x2d6e visited 1 times
State 0x3bb8 visited 1 times
State 0x37de visited 1 times
State 0x3bbf visited 1 times
State 0x3c1e visited 1 times
State 0x3825 visited 1 times
State 0x440f visited 1 times
State 0x43c7 visited 1 times
State 0x3bbc visited 1 times
State 0x3c61 visited 1 times
State 0x39bc visited 1 times
State 0x3c25 visited 1 times
State 0x495e visited 1 times
State 0x4852 visited 1 times
State 0x57a6 visited 1 times
State 0x3c4d visited 1 times
State 0x1f51 visited 1 times
State 0x22d3 visited 1 times
State 0x2346 visited 1 times
State 0x5434 visited 1 times
State 0x5431 visited 1 times
State 0x3c5d visited 1 times
State 0x3865 visited 1 times
State 0x380e visited 1 times
State 0x37ed visited 1 times
State 0x5570 visited 1 times
State 0x52df visited 1 times
State 0x5675 visited 1 times
State 0x567c visited 1 times
State 0x56de visited 1 times
State 0x36d8 visited 1 times
State 0x15eb visited 1 times
State 0x1587 visited 1 times
State 0x3d5d visited 1 times
State 0x39a5 visited 1 times
State 0x3932 visited 1 times
State 0x36b8 visited 1 times
State 0x3c24 visited 2 times
State 0x49ab visited 1 times
State 0x43d5 visited 1 times
State 0x39b9 visited 1 times
State 0x3b0c visited 1 times
State 0x3823 visited 1 times
State 0x399a visited 1 times
State 0x1d47 visited 1 times
State 0x1c57 visited 1 times
State 0x3c03 visited 1 times
State 0x3c40 visited 1 times
State 0x484c visited 1 times
State 0x4aae visited 1 times
State 0x3bc7 visited 1 times
State 0x3871 visited 1 times
State 0x3844 visited 1 times
State 0x3942 visited 1 times
State 0x3c1b visited 1 times
State 0x3873 visited 1 times
State 0x39c6 visited 1 times
State 0x37c7 visited 1 times
State 0x3c24 visited 1 times
State 0x4afa visited 1 times
State 0x43c7 visited 1 times
State 0x4565 visited 1 times
State 0x3d4f visited 1 times
State 0x3d59 visited 1 times
State 0x36bb visited 1 times
State 0x3bc3 visited 1 times
State 0x3d7c visited 1 times
State 0x565d visited 1 times
State 0x5661 visited 1 times
State 0x3c24 visited 1 times
State 0x4804 visited 1 times
State 0x5693 visited 1 times
State 0x3871 visited 1 times
State 0x3874 visited 1 times
State 0x3874 visited 1 times
State 0x3c24 visited 1 times
State 0x47cd visited 1 times
State 0x479e visited 1 times
State 0x300f visited 1 times
State 0x3d78 visited 1 times
State 0x10c0 visited 1 times
State 0x109a visited 1 times
State 0x3d29 visited 1 times
State 0x3930 visited 1 times
State 0x3974 visited 1 times
State 0x3980 visited 1 times
State 0x2932 visited 1 times
State 0x29db visited 1 times
State 0x3c25 visited 4 times
State 0x47c4 visited 1 times
State 0x4943 visited 1 times
State 0x4859 visited 1 times
State 0x3c25 visited 1 times
State 0x46b2 visited 1 times
State 0x46c2 visited 1 times
State 0x46f8 visited 1 times
State 0x3bc7 visited 1 times
State 0x3d19 visited 1 times
State 0x3ab7 visited 1 times
State 0x3964 visited 1 times
State 0x3957 visited 1 times
State 0x3957 visited 1 times
State 0x3c44 visited 1 times
State 0x15e2 visited 1 times
State 0x1f48 visited 1 times
State 0x1df5 visited 1 times
State 0x3c21 visited 1 times
State 0x36d6 visited 1 times
State 0x3721 visited 1 times
State 0x3c43 visited 1 times
State 0x3806 visited 1 times
State 0x37bc visited 1 times
State 0x3812 visited 1 times
State 0x3852 visited 1 times
State 0x3826 visited 1 times
State 0x3bff visited 1 times
State 0x3870 visited 1 times
State 0x3c62 visited 1 times
State 0x3c62 visited 1 times
State 0x3d77 visited 1 times
State 0x529d visited 1 times
State 0x5543 visited 1 times
State 0x3d0e visited 1 times
State 0x3996 visited 1 times
State 0x453c visited 1 times
State 0x397f visited 1 times
State 0x2aaf visited 1 times
State 0x2aa2 visited 1 times
State 0x3bc3 visited 1 times
State 0x1d96 visited 1 times
State 0x14b0 visited 1 times
State 0x37c0 visited 1 times
State 0x2293 visited 1 times
State 0x484b visited 1 times
State 0x3c69 visited 1 times
State 0x3c06 visited 1 times
State 0x3961 visited 1 times
State 0x3c3c visited 1 times
State 0x15da visited 1 times
State 0x15e1 visited 1 times
State 0x3c6b visited 1 times
State 0x3db4 visited 1 times
State 0x564e visited 1 times
State 0x3c24 visited 2 times
State 0x491f visited 1 times
State 0x1447 visited 1 times
State 0x4a68 visited 1 times
State 0x47cd visited 1 times
State 0x4811 visited 1 times
State 0x43d5 visited 1 times
State 0x3c1d visited 1 times
State 0x3977 visited 1 times
State 0x15bb visited 1 times
State 0x1471 visited 1 times
State 0x3dbc visited 1 times
State 0x3d59 visited 1 times
State 0x3c27 visited 1 times
State 0x393e visited 1 times
State 0x397e visited 1 times
State 0x2981 visited 1 times
State 0x393f visited 1 times
State 0x393c visited 1 times
State 0x36d3 visited 1 times
State 0x3975 visited 1 times
State 0x4a44 visited 1 times
State 0x479f visited 1 times
State 0x3bc5 visited 1 times
State 0x3bbc visited 1 times
State 0x3c6b visited 1 times
State 0x3c6c visited 1 times
State 0x2a8b visited 1 times
State 0x2a84 visited 1 times
State 0x2d2a visited 1 times
State 0x3c24 visited 1 times
State 0x484e visited 1 times
State 0x1c19 visited 1 times
State 0x3d90 visited 1 times
State 0x466e visited 1 times
State 0x1554 visited 1 times
State 0x3c24 visited 2 times
State 0x43af visited 1 times
State 0x43b0 visited 1 times
State 0x4434 visited 1 times
State 0x3c25 visited 1 times
State 0x4416 visited 1 times
State 0x441a visited 1 times
State 0x3c25 visited 2 times
State 0x48f2 visited 1 times
State 0x45a6 visited 1 times
State 0x4565 visited 1 times
State 0x3bff visited 1 times
State 0x3c28 visited 1 times
State 0x3be4 visited 1 times
State 0x36e1 visited 1 times
State 0x36da visited 1 times
State 0x1321 visited 1 times
State 0x3c25 visited 1 times
State 0x5573 visited 1 times
State 0x57d5 visited 1 times
State 0x3c4d visited 1 times
State 0x5572 visited 1 times
State 0x36fb visited 1 times
State 0x3832 visited 1 times
State 0x3985 visited 1 times
State 0x519c visited 1 times
State 0x3c5d visited 1 times
State 0x3865 visited 1 times
State 0x37c3 visited 1 times
State 0x386c visited 1 times
State 0x3af0 visited 1 times
State 0x399d visited 1 times
State 0x3c22 visited 1 times
State 0x3be0 visited 1 times
State 0x3bdd visited 1 times
State 0x382c visited 1 times
State 0x2180 visited 1 times
State 0x22d3 visited 1 times
State 0x3c24 visited 3 times
State 0x453c visited 1 times
State 0x43ce visited 1 times
State 0x48f7 visited 1 times
State 0x3833 visited 1 times
State 0x519c visited 1 times
State 0x14ad visited 1 times
State 0x3c5f visited 1 times
State 0x3953 visited 1 times
State 0x3bf9 visited 1 times
State 0x3c24 visited 2 times
State 0x444e visited 1 times
State 0x45b2 visited 1 times
State 0x4705 visited 1 times
State 0x3bd6 visited 1 times
State 0x5277 visited 1 times
State 0x540e visited 1 times
State 0x3bc2 visited 1 times
State 0x3964 visited 1 times
State 0x1dff visited 1 times
State 0x201d visited 1 times
State 0x3c25 visited 2 times
State 0x4957 visited 1 times
State 0x2b09 visited 1 times
State 0xf3de visited 1 times
State 0x3c61 visited 1 times
State 0x3bb8 visited 1 times
State 0x3c29 visited 1 times
State 0x3bd6 visited 1 times
State 0x3d29 visited 1 times
State 0x3d3a visited 1 times
State 0x3910 visited 1 times
State 0x3979 visited 1 times
State 0x3979 visited 1 times
State 0x3c22 visited 1 times
State 0x3c20 visited 1 times
State 0x37ee visited 1 times
State 0x3be7 visited 1 times
State 0x3854 visited 1 times
State 0x43d8 visited 1 times
State 0x47ae visited 1 times
State 0x3c65 visited 1 times
State 0x3c24 visited 1 times
State 0x48fb visited 1 times
State 0x48f4 visited 1 times
State 0x3c24 visited 2 times
State 0x4a46 visited 1 times
State 0x48f7 visited 1 times
State 0x48f7 visited 1 times
State 0x3be0 visited 1 times
State 0x3a72 visited 1 times
State 0x37bf visited 1 times
State 0x3677 visited 1 times
State 0x37ca visited 1 times
State 0x36dd visited 1 times
State 0x523c visited 1 times
State 0x3d77 visited 1 times
State 0x3c1a visited 1 times
State 0x1c9a visited 1 times
State 0x3c25 visited 1 times
State 0x45a2 visited 1 times
State 0x45a9 visited 1 times
State 0x49a2 visited 1 times
State 0x3c24 visited 2 times
State 0x47a5 visited 1 times
State 0x443b visited 1 times
State 0xf43b visited 1 times
State 0x3c24 visited 3 times
State 0x48f4 visited 1 times
State 0x2f00 visited 1 times
State 0x4aa9 visited 1 times
State 0x3bbc visited 1 times
State 0x3845 visited 1 times
State 0x2950 visited 1 times
State 0x3d77 visited 1 times
State 0x567d visited 1 times
State 0x5103 visited 1 times
State 0x3c3c visited 1 times
State 0x2180 visited 1 times
State 0x1ec9 visited 1 times
State 0x216f visited 1 times
State 0x3c0a visited 1 times
State 0x37e9 visited 1 times
State 0x37df visited 1 times
State 0x37dd visited 1 times
State 0x36f4 visited 1 times
State 0xefc2 visited 1 times
State 0xefc3 visited 1 times
State 0x3c2b visited 1 times
State 0x3bd6 visited 1 times
State 0x37de visited 1 times
State 0x3c27 visited 1 times
State 0x390f visited 1 times
State 0x5430 visited 1 times
State 0x3bbc visited 1 times
State 0x3671 visited 1 times
State 0x3c66 visited 1 times
State 0x397e visited 1 times
State 0x301f visited 1 times
State 0x3017 visited 1 times
State 0x3d77 visited 1 times
State 0x567a visited 1 times
State 0x567a visited 1 times
State 0x3c40 visited 1 times
State 0x12d3 visited 1 times
State 0x484b visited 1 times
State 0x3be0 visited 1 times
State 0x3a8d visited 1 times
State 0x3aec visited 1 times
State 0x3c69 visited 1 times
State 0x3702 visited 1 times
State 0x3064 visited 1 times
State 0x3c1a visited 1 times
State 0x3c5e visited 1 times
State 0x3c64 visited 1 times
State 0x3977 visited 1 times
State 0x3999 visited 1 times
State 0x3d0a visited 1 times
State 0x3c06 visited 1 times
State 0x37c7 visited 1 times
State 0x37c7 visited 1 times
State 0x3674 visited 1 times
State 0x3c24 visited 3 times
State 0x47c6 visited 1 times
State 0x47c6 visited 1 times
State 0x49a4 visited 1 times
State 0x3c28 visited 1 times
State 0x3c4c visited 1 times
State 0x57b2 visited 1 times
State 0x3c07 visited 1 times
State 0x391c visited 1 times
State 0x36d9 visited 1 times
State 0x11a1 visited 1 times
State 0x3d78 visited 1 times
State 0x563f visited 1 times
State 0x56a4 visited 1 times
State 0x3c47 visited 1 times
State 0x48fb visited 1 times
State 0x493e visited 1 times
State 0x12df visited 1 times
State 0x1343 visited 1 times
State 0x133f visited 1 times
State 0x4547 visited 1 times
State 0x213d visited 1 times
State 0x2181 visited 1 times
State 0x3c24 visited 1 times
State 0x452b visited 1 times
State 0x43cb visited 1 times
State 0xee48 visited 1 times
State 0x43f6 visited 1 times
State 0x43f6 visited 1 times
State 0x3c25 visited 1 times
State 0x4af5 visited 1 times
State 0x4412 visited 1 times
State 0x43b1 visited 1 times
State 0x1ff4 visited 1 times
State 0x1ff4 visited 1 times
State 0x1f0a visited 1 times
State 0x231e visited 1 times
State 0x231e visited 1 times
State 0x2079 visited 1 times
State 0x3c24 visited 2 times
State 0x455e visited 1 times
State 0x4901 visited 1 times
State 0x443e visited 1 times
State 0x3c21 visited 1 times
State 0x3d8f visited 1 times
State 0x551d visited 1 times
State 0x36d8 visited 1 times
State 0x11cd visited 1 times
State 0x2c89 visited 1 times
State 0x3c2c visited 1 times
State 0x3c5e visited 1 times
State 0x3c5f visited 1 times
State 0x3c24 visited 1 times
State 0x4836 visited 1 times
State 0x493e visited 1 times
State 0x4a91 visited 1 times
State 0x3c24 visited 1 times
State 0x455e visited 1 times
State 0x47f3 visited 1 times
State 0x4a73 visited 1 times
State 0x4673 visited 1 times
State 0x3db7 visited 1 times
State 0x3c1f visited 1 times
State 0x37f0 visited 1 times
State 0x3a92 visited 1 times
State 0x2dde visited 1 times
State 0x3c25 visited 1 times
State 0x47b0 visited 1 times
State 0x491d visited 1 times
State 0x4920 visited 1 times
State 0x3956 visited 1 times
State 0x1335 visited 1 times
State 0x564e visited 1 times
State 0x3bc2 visited 1 times
State 0x3869 visited 1 times
State 0x1317 visited 1 times
State 0x43ed visited 1 times
State 0x3ae9 visited 1 times
State 0x12cf visited 1 times
State 0x12d0 visited 1 times
State 0x3c1e visited 1 times
State 0x3979 visited 1 times
State 0x100c visited 1 times
State 0x3c25 visited 1 times
State 0x4ab4 visited 1 times
State 0x4925 visited 1 times
State 0x4a77 visited 1 times
State 0x3c25 visited 1 times
State 0x46c2 visited 1 times
State 0x4815 visited 1 times
State 0x4968 visited 1 times
State 0x3c25 visited 1 times
State 0x493c visited 1 times
State 0x43ea visited 1 times
State 0x453d visited 1 times
State 0x386f visited 1 times
State 0x386f visited 1 times
State 0x36bd visited 1 times
State 0x3c24 visited 1 times
State 0x493e visited 1 times
State 0x49aa visited 1 times
State 0x48f7 visited 1 times
State 0x3bbc visited 1 times
State 0x3d74 visited 1 times
State 0x397c visited 1 times
State 0x3953 visited 1 times
State 0x3ab7 visited 1 times
State 0x1216 visited 1 times
State 0x1074 visited 1 times
State 0x37bc visited 1 times
State 0x3a65 visited 1 times
State 0x3a83 visited 1 times
State 0x367a visited 1 times
State 0x366d visited 1 times
State 0x3692 visited 1 times
State 0x3c29 visited 1 times
State 0x3c62 visited 1 times
State 0x386a visited 1 times
State 0x3d4c visited 1 times
State 0x48f2 visited 1 times
State 0x4a44 visited 1 times
State 0x3c24 visited 1 times
State 0x4ad8 visited 1 times
State 0x5267 visited 1 times
State 0x3c64 visited 1 times
State 0x39bf visited 1 times
State 0x3aa7 visited 1 times
State 0x3ab6 visited 1 times
State 0x3d5c visited 1 times
State 0x3c1e visited 1 times
State 0x3d71 visited 1 times
State 0x4808 visited 1 times
State 0x3c02 visited 1 times
State 0x3c46 visited 1 times
State 0x1dd5 visited 1 times
State 0x1c82 visited 1 times
State 0x368f visited 1 times
State 0x3d2d visited 1 times
State 0x39bf visited 1 times
State 0x3bfc visited 1 times
State 0x3919 visited 1 times
State 0x3919 visited 1 times
State 0x3919 visited 1 times
State 0x3670 visited 1 times
State 0x390f visited 1 times
State 0x39a8 visited 1 times
State 0x36da visited 1 times
State 0x14ab visited 1 times
State 0x4aaa visited 1 times
State 0x3bde visited 1 times
State 0x3c5f visited 1 times
State 0x3b0c visited 1 times
State 0x3c68 visited 1 times
State 0x3847 visited 1 times
State 0x3c09 visited 1 times
State 0x50f2 visited 1 times
State 0x458d visited 1 times
State 0x1dbb visited 1 times
State 0x107f visited 1 times
State 0x3bff visited 1 times
State 0x3c64 visited 1 times
State 0x386c visited 1 times
State 0x1bfb visited 1 times
State 0x3af6 visited 1 times
State 0x390f visited 1 times
State 0x1007 visited 1 times
State 0x3d76 visited 1 times
State 0x567a visited 1 times
State 0x5176 visited 1 times
State 0x10b1 visited 1 times
State 0x1203 visited 1 times
State 0x1204 visited 1 times
State 0x3afa visited 1 times
State 0x2ffe visited 1 times
State 0x2fee visited 1 times
State 0x3c5e visited 1 times
State 0x3c2b visited 1 times
State 0x3aa6 visited 1 times
State 0x3c5e visited 1 times
State 0x36d6 visited 1 times
State 0x3bff visited 1 times
State 0x3bde visited 1 times
State 0x3dbb visited 1 times
State 0x380d visited 1 times
State 0x37c7 visited 1 times
State 0x37cd visited 1 times
State 0x3bfb visited 1 times
State 0x3956 visited 1 times
State 0x3bbb visited 1 times
State 0x3c25 visited 1 times
State 0x465a visited 1 times
State 0x46a0 visited 1 times
State 0x3a63 visited 1 times
State 0x2e9b visited 1 times
State 0x2e80 visited 1 times
State 0x3c1d visited 1 times
State 0x3876 visited 1 times
State 0x3872 visited 1 times
State 0x3d2d visited 1 times
State 0x397f visited 1 times
State 0x2bff visited 1 times
State 0x2fd9 visited 1 times
State 0x3bde visited 1 times
State 0x3c06 visited 1 times
State 0x3bc2 visited 1 times
State 0x160a visited 1 times
State 0x36d9 visited 1 times
State 0x12fb visited 1 times
State 0x1ee9 visited 1 times
State 0x36d3 visited 1 times
State 0x36d3 visited 1 times
State 0x3c1e visited 1 times
State 0x3c0a visited 1 times
State 0x366e visited 1 times
State 0x3be1 visited 1 times
State 0x4830 visited 1 times
State 0x397e visited 1 times
State 0x2c3c visited 1 times
State 0x2996 visited 1 times
State 0x569d visited 1 times
State 0x5634 visited 1 times
State 0x3be7 visited 1 times
State 0x3c28 visited 1 times
State 0x3982 visited 1 times
State 0x20a0 visited 1 times
State 0x3bbf visited 1 times
State 0x3c43 visited 1 times
State 0x45a8 visited 1 times
State 0x45a8 visited 1 times
State 0x3c64 visited 1 times
State 0x3bdd visited 1 times
State 0x3d2f visited 1 times
State 0x3d29 visited 1 times
State 0x36d9 visited 1 times
State 0x1319 visited 1 times
State 0x10be visited 1 times
State 0x3bff visited 1 times
State 0x3c00 visited 1 times
State 0x3c03 visited 1 times
State 0x36d8 visited 1 times
State 0x15b8 visited 1 times
State 0x159a visited 1 times
State 0x3c24 visited 2 times
State 0x48fb visited 1 times
State 0x45a8 visited 1 times
State 0x1319 visited 1 times
State 0x36ff visited 1 times
State 0x37ed visited 1 times
State 0x3d38 visited 1 times
State 0x3c27 visited 1 times
State 0x301c visited 1 times
State 0x1c20 visited 1 times
State 0x3952 visited 1 times
State 0x3d4a visited 1 times
State 0x36ac visited 1 times
State 0x3c64 visited 1 times
State 0x3dbb visited 1 times
State 0x3db7 visited 1 times
State 0x3bb6 visited 1 times
State 0x3d34 visited 1 times
State 0x3bff visited 1 times
State 0x1074 visited 1 times
State 0x456b visited 1 times
State 0x455f visited 1 times
State 0x455f visited 1 times
State 0x382c visited 1 times
State 0x21e9 visited 1 times
State 0x21a9 visited 1 times
State 0x3c24 visited 1 times
State 0x43cb visited 1 times
State 0x4ab3 visited 1 times
State 0x4ab7 visited 1 times
State 0x3c24 visited 1 times
State 0x4ad8 visited 1 times
State 0x52ee visited 1 times
State 0x22f8 visited 1 times
State 0x3c42 visited 1 times
State 0x2186 visited 1 times
State 0x22f4 visited 1 times
State 0x1da9 visited 1 times
State 0x3c4c visited 1 times
State 0x5441 visited 1 times
State 0x2d9b visited 1 times
State 0x3c4c visited 1 times
State 0x3c24 visited 1 times
State 0x443d visited 1 times
State 0x1c59 visited 1 times
State 0x1eff visited 1 times
State 0x382c visited 1 times
State 0x2071 visited 1 times
State 0x2078 visited 1 times
State 0x29b9 visited 1 times
State 0x1c5b visited 1 times
State 0x3c09 visited 1 times
State 0x3c6b visited 1 times
State 0x3c1a visited 1 times
State 0x397e visited 1 times
State 0x2d4f visited 1 times
State 0x2af4 visited 1 times
State 0x3c21 visited 1 times
State 0x397b visited 1 times
State 0x3a8a visited 1 times
State 0x3bfe visited 1 times
State 0x3c5d visited 1 times
State 0x495b visited 1 times
State 0x43ee visited 1 times
State 0x1050 visited 1 times
State 0x3c46 visited 1 times
State 0x569c visited 1 times
State 0x5170 visited 1 times
State 0x397c visited 1 times
State 0x1f4b visited 1 times
State 0x1bf5 visited 1 times
State 0x1bf7 visited 1 times
State 0x4852 visited 1 times
State 0x21c8 visited 1 times
State 0x15bd visited 1 times
State 0x3c25 visited 1 times
State 0x495e visited 1 times
State 0x4671 visited 1 times
State 0x4a43 visited 1 times
State 0x3bfc visited 1 times
State 0x3bbc visited 1 times
State 0x3bff visited 1 times
State 0x371d visited 1 times
State 0x3ab7 visited 1 times
State 0x3ab7 visited 1 times
State 0x37e9 visited 1 times
State 0x3c24 visited 1 times
State 0x45b3 visited 1 times
State 0x4afa visited 1 times
State 0x47af visited 1 times
State 0x3724 visited 1 times
State 0x36e0 visited 1 times
State 0x53fe visited 1 times
State 0x3d52 visited 1 times
State 0x3d4e visited 1 times
State 0x3d52 visited 1 times
State 0x3c6f visited 1 times
State 0x3be7 visited 1 times
State 0x3866 visited 1 times
State 0x1597 visited 1 times
State 0x3c6c visited 1 times
State 0x3d51 visited 1 times
State 0x3d3a visited 1 times
State 0x3d14 visited 1 times
State 0x3be0 visited 1 times
State 0x3800 visited 1 times
State 0x390f visited 1 times
State 0x391c visited 1 times
State 0x3c24 visited 1 times
State 0x4a6c visited 1 times
State 0x46d9 visited 1 times
State 0x49ab visited 1 times
State 0x3c61 visited 1 times
State 0x3829 visited 1 times
State 0x3855 visited 1 times
State 0x3c25 visited 3 times
State 0x4829 visited 1 times
State 0x52a5 visited 1 times
State 0x53cc visited 1 times
State 0x3c25 visited 1 times
State 0x43d2 visited 1 times
State 0x442d visited 1 times
State 0x397e visited 1 times
State 0x2bd6 visited 1 times
State 0x294f visited 1 times
State 0x3674 visited 1 times
State 0x3a85 visited 1 times
State 0x3d9a visited 1 times
State 0x3c24 visited 1 times
State 0x456e visited 1 times
State 0x479e visited 1 times
State 0x47ab visited 1 times
State 0x3bbb visited 1 times
State 0x3d0d visited 1 times
State 0x399d visited 1 times
State 0x3bc2 visited 1 times
State 0x37e5 visited 1 times
State 0x371a visited 1 times
State 0x39c7 visited 1 times
State 0x3c25 visited 1 times
State 0x4678 visited 1 times
State 0x4a8f visited 1 times
State 0x469a visited 1 times
State 0x3bda visited 1 times
State 0x3677 visited 1 times
State 0x3699 visited 1 times
State 0x397f visited 1 times
State 0x2fed visited 1 times
State 0x2aa2 visited 1 times
State 0x384b visited 1 times
State 0x5787 visited 1 times
State 0x5634 visited 1 times
State 0x3c24 visited 1 times
State 0x4a69 visited 1 times
State 0x4591 visited 1 times
State 0x3c65 visited 1 times
State 0x3c24 visited 1 times
State 0x4af0 visited 1 times
State 0x3867 visited 1 times
State 0x3867 visited 1 times
State 0x3b0c visited 1 times
State 0x3c24 visited 1 times
State 0x451a visited 1 times
State 0x47f2 visited 1 times
State 0x4411 visited 1 times
State 0x382d visited 1 times
State 0x200f visited 1 times
State 0x3844 visited 1 times
State 0x3ab0 visited 1 times
State 0x47c7 visited 1 times
State 0x47c0 visited 1 times
State 0x3c24 visited 1 times
State 0x452b visited 1 times
State 0x43f1 visited 1 times
State 0x43aa visited 1 times
State 0x3c2c visited 1 times
State 0x3c2c visited 1 times
State 0x1478 visited 1 times
State 0x3c27 visited 1 times
State 0x380d visited 1 times
State 0x11cd visited 1 times
State 0x3bb8 visited 1 times
State 0x3673 visited 1 times
State 0x3677 visited 1 times
State 0x3bf8 visited 1 times
State 0x3c28 visited 1 times
State 0x3a70 visited 1 times
State 0x37ca visited 1 times
State 0x3c3d visited 1 times
State 0x3bb5 visited 1 times
State 0x37bd visited 1 times
State 0x3852 visited 1 times
State 0x3713 visited 1 times
State 0x5540 visited 1 times
State 0x3c24 visited 1 times
State 0x4a43 visited 1 times
State 0x43ac visited 1 times
State 0x48f7 visited 1 times
State 0x3c2c visited 1 times
State 0x3c42 visited 1 times
State 0x100e visited 1 times
State 0x382d visited 1 times
State 0x1dd6 visited 1 times
State 0x510e visited 1 times
State 0x3c1a visited 1 times
State 0x3c3c visited 1 times
State 0x1c35 visited 1 times
State 0x3c61 visited 1 times
State 0x1dee visited 1 times
State 0x1dee visited 1 times
State 0x3be8 visited 1 times
State 0x3c6d visited 1 times
State 0x3c1b visited 1 times
State 0x3c24 visited 1 times
State 0x4412 visited 1 times
State 0x43d4 visited 1 times
State 0x2ee8 visited 1 times
State 0x37e7 visited 1 times
State 0x4524 visited 1 times
State 0x3c27 visited 1 times
State 0x397e visited 1 times
State 0x2ae5 visited 1 times
State 0x3c5e visited 1 times
State 0x369c visited 1 times
State 0x3a95 visited 1 times
State 0x3c24 visited 1 times
State 0x444e visited 1 times
State 0x4a73 visited 1 times
State 0x46f8 visited 1 times
State 0x569d visited 1 times
State 0x2ea5 visited 1 times
State 0x3d78 visited 1 times
State 0x5413 visited 1 times
State 0x5438 visited 1 times
State 0x3c25 visited 1 times
State 0x43ed visited 1 times
State 0x4693 visited 1 times
State 0x4829 visited 1 times
State 0x3c25 visited 1 times
State 0x4921 visited 1 times
State 0x4544 visited 1 times
State 0x3c24 visited 1 times
State 0x44fe visited 1 times
State 0x4a8a visited 1 times
State 0x3955 visited 1 times
State 0x3c47 visited 1 times
State 0x3a8e visited 1 times
State 0x37c6 visited 1 times
State 0x395c visited 1 times
